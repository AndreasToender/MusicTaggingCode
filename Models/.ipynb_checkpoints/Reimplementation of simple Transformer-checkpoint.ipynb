{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/text/transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import argparse\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = \"C:\\\\Users\\\\toend\\\\Documents\\\\ITU\\\\Thesis\"\n",
    "pathToSave = os.path.join(workdir, \"MIDIdata\\\\RESULTS\")\n",
    "frequency = 10\n",
    "DATASET_SIZE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(workdir + '\\\\Code\\\\Utils')\n",
    "from Utils import getAllData\n",
    "from Utils import getDataSets\n",
    "from Utils import reshape\n",
    "from Utils import matchOneToAnyNumberOfMatches\n",
    "from Utils import piano_roll_to_pretty_midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING DATA TO PREPARE A PRE-TRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cuts02, Cuts04, Cuts06, Cuts08, Cuts09, Cuts11, Cuts13, Cuts14, Cuts15, Cuts17, Cuts18 = getAllData(frequency) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3380, 300, 128)\n",
      "(5700, 300, 128)\n",
      "(6496, 300, 128)\n",
      "(3738, 300, 128)\n",
      "(5885, 300, 128)\n",
      "(2333, 300, 128)\n",
      "(2079, 300, 128)\n",
      "(6324, 300, 128)\n",
      "(2183, 300, 128)\n",
      "(2351, 300, 128)\n",
      "(5976, 300, 128)\n"
     ]
    }
   ],
   "source": [
    "print(Cuts02.shape)\n",
    "print(Cuts04.shape)\n",
    "print(Cuts06.shape)\n",
    "print(Cuts08.shape)\n",
    "print(Cuts09.shape)\n",
    "print(Cuts11.shape)\n",
    "print(Cuts13.shape)\n",
    "print(Cuts14.shape)\n",
    "print(Cuts15.shape)\n",
    "print(Cuts17.shape)\n",
    "print(Cuts18.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = np.concatenate([Cuts02, Cuts04, Cuts06, Cuts08, Cuts09, Cuts11, Cuts13, Cuts14, Cuts15, Cuts17, Cuts18], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46445, 300, 128)\n"
     ]
    }
   ],
   "source": [
    "print(allData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR ALL DATA\n",
    "encoderRolls = allData\n",
    "decoderRolls = allData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING DATA TO TRAIN MODEL ON THE MOOD CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "AN, AP, CN, CP = getDataSets(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 300, 128)\n",
      "(280, 300, 128)\n",
      "(147, 300, 128)\n",
      "(103, 300, 128)\n"
     ]
    }
   ],
   "source": [
    "#AN\n",
    "print(AN.shape)\n",
    "#AP\n",
    "print(AP.shape)\n",
    "#CN\n",
    "print(CN.shape)\n",
    "#CP\n",
    "print(CP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVES TEN LAST ELEMENTS FOR VALIDATION\n",
    "VALIDATION = AP[-10:,:,:]\n",
    "AP = AP[:-10,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = matchOneToAnyNumberOfMatches(AP, CP, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 300, 128)\n",
      "(2700, 300, 128)\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(Z)\n",
    "\n",
    "X, Y = zip(*Z)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderRolls = X\n",
    "decoderRolls = np.empty((Y.shape[0], Y.shape[1] + 2, Y.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "startToken = np.full((128), 0)\n",
    "endToken = np.full((1, 128), 0)\n",
    "\n",
    "for i in range(len(Y)):\n",
    "    paddedRoll = np.insert(Y[i], 0, startToken, axis = 0)\n",
    "    decoderRolls[i] = np.append(paddedRoll, endToken, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 300, 128)\n",
      "(2700, 302, 128)\n",
      "2700\n",
      "(300, 128)\n",
      "(302, 128)\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE = encoderRolls.shape[0]\n",
    "print(encoderRolls.shape)\n",
    "print(decoderRolls.shape)\n",
    "print(DATASET_SIZE)\n",
    "print(encoderRolls[1].shape)\n",
    "print(decoderRolls[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "d_model = 128 #Dimensionality of the input and output of the model\n",
    "dff = 512 #Dimenstionality of inner-layer in FFN\n",
    "num_heads = 8\n",
    "batch_size = 64 \n",
    "dropout_rate = 0.1\n",
    "EPOCHS = 200\n",
    "seq_length = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USED TO PAD TOKENS THAT ARE NOT PRIOR TO CURRENT ONE\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead) \n",
    "    but it must be broadcastable for addition.\n",
    "  \n",
    "    Args:\n",
    "        q: query shape == (..., seq_len_q, depth)\n",
    "        k: key shape == (..., seq_len_k, depth)\n",
    "        v: value shape == (..., seq_len_v, depth_v)\n",
    "        mask: Float tensor with shape broadcastable \n",
    "            to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        output, attention_weights\n",
    "          \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    #MASK IS NOT NEEDED AND SHOULD BE DISREGARDED\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "    \n",
    "        assert d_model % self.num_heads == 0\n",
    "    \n",
    "        self.depth = d_model // self.num_heads\n",
    "    \n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "    \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "    \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model, activation='sigmoid')  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    #def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "    \n",
    "        #self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model) #EMBED PIANO ROLLS?\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "    \n",
    "    \n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "    \n",
    "        # adding embedding and position encoding.\n",
    "        #x = self.embedding(x)  # (batch_size, input_seq_len, d_model)     \n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    #def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "    \n",
    "        #self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model) #SAME AS ENCODER EMBEDDING\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "    \n",
    "        #x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "      \n",
    "        attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "        attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    #def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, pe_input, pe_target, rate=0.1): \n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, pe_input, rate) #removed vocabsize\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, pe_target, rate) #removed vocabsize\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(d_model, activation='sigmoid') #Replaced vocabsize with d-model and added activation\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=40):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "    \n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(128)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(400, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(\n",
    "    from_logits=False, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    #print(real.shape)\n",
    "    #print(pred.shape)\n",
    "    #mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    #mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    #loss_ *= mask\n",
    "  \n",
    "    return tf.reduce_sum(loss_)#/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "#train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "train_accuracy = tf.keras.metrics.BinaryAccuracy(\n",
    "    name='train_accuracy', dtype=None, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK PE_INPUT AND PE_TARGET\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff, \n",
    "                          pe_input=10000, \n",
    "                          pe_target=10000,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(tar):\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    return look_ahead_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.float64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.float64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:-1, :]\n",
    "    tar_real = tar[1:, :]\n",
    "    \n",
    "    inp = tf.expand_dims(inp, 0)\n",
    "    tar_inp = tf.expand_dims(tar_inp, 0)\n",
    "    tar_real = tf.expand_dims(tar_real, 0)\n",
    "  \n",
    "    #enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "    look_ahead_mask = create_masks(tar_inp)\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                    True, \n",
    "                                    None, \n",
    "                                    look_ahead_mask, \n",
    "                                    None)\n",
    "        \n",
    "        loss = loss_function(tar_real, predictions)\n",
    "        \n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700\n"
     ]
    }
   ],
   "source": [
    "print(DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 300, 128)\n",
      "(2700, 302, 128)\n"
     ]
    }
   ],
   "source": [
    "print(encoderRolls.shape)\n",
    "print(decoderRolls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer transformer is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer decoder is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1 Batch 0 Loss 55.9135 Accuracy 0.9654\n",
      "Epoch 1 Batch 50 Loss 31.0854 Accuracy 0.9710\n",
      "Epoch 1 Batch 100 Loss 23.6750 Accuracy 0.9765\n",
      "Epoch 1 Batch 150 Loss 20.3335 Accuracy 0.9801\n",
      "Epoch 1 Batch 200 Loss 18.3763 Accuracy 0.9823\n",
      "Epoch 1 Batch 250 Loss 16.9789 Accuracy 0.9838\n",
      "Epoch 1 Batch 300 Loss 16.1235 Accuracy 0.9848\n",
      "Epoch 1 Batch 350 Loss 15.4889 Accuracy 0.9854\n",
      "Epoch 1 Batch 400 Loss 14.9280 Accuracy 0.9860\n",
      "Epoch 1 Batch 450 Loss 14.5440 Accuracy 0.9864\n",
      "Epoch 1 Batch 500 Loss 14.1530 Accuracy 0.9868\n",
      "Epoch 1 Batch 550 Loss 13.9191 Accuracy 0.9870\n",
      "Epoch 1 Batch 600 Loss 13.6855 Accuracy 0.9872\n",
      "Epoch 1 Batch 650 Loss 13.4781 Accuracy 0.9874\n",
      "Epoch 1 Batch 700 Loss 13.2703 Accuracy 0.9876\n",
      "Epoch 1 Batch 750 Loss 13.0782 Accuracy 0.9878\n",
      "Epoch 1 Batch 800 Loss 12.8630 Accuracy 0.9880\n",
      "Epoch 1 Batch 850 Loss 12.7283 Accuracy 0.9881\n",
      "Epoch 1 Batch 900 Loss 12.6357 Accuracy 0.9881\n",
      "Epoch 1 Batch 950 Loss 12.5416 Accuracy 0.9882\n",
      "Epoch 1 Batch 1000 Loss 12.4331 Accuracy 0.9883\n",
      "Epoch 1 Batch 1050 Loss 12.3375 Accuracy 0.9884\n",
      "Epoch 1 Batch 1100 Loss 12.2200 Accuracy 0.9885\n",
      "Epoch 1 Batch 1150 Loss 12.1162 Accuracy 0.9886\n",
      "Epoch 1 Batch 1200 Loss 12.0463 Accuracy 0.9886\n",
      "Epoch 1 Batch 1250 Loss 11.9451 Accuracy 0.9887\n",
      "Epoch 1 Batch 1300 Loss 11.8831 Accuracy 0.9888\n",
      "Epoch 1 Batch 1350 Loss 11.8151 Accuracy 0.9888\n",
      "Epoch 1 Batch 1400 Loss 11.7652 Accuracy 0.9889\n",
      "Epoch 1 Batch 1450 Loss 11.7029 Accuracy 0.9889\n",
      "Epoch 1 Batch 1500 Loss 11.6348 Accuracy 0.9890\n",
      "Epoch 1 Batch 1550 Loss 11.6021 Accuracy 0.9890\n",
      "Epoch 1 Batch 1600 Loss 11.5517 Accuracy 0.9890\n",
      "Epoch 1 Batch 1650 Loss 11.5082 Accuracy 0.9890\n",
      "Epoch 1 Batch 1700 Loss 11.4744 Accuracy 0.9891\n",
      "Epoch 1 Batch 1750 Loss 11.4084 Accuracy 0.9891\n",
      "Epoch 1 Batch 1800 Loss 11.3843 Accuracy 0.9891\n",
      "Epoch 1 Batch 1850 Loss 11.3352 Accuracy 0.9892\n",
      "Epoch 1 Batch 1900 Loss 11.2825 Accuracy 0.9892\n",
      "Epoch 1 Batch 1950 Loss 11.2322 Accuracy 0.9893\n",
      "Epoch 1 Batch 2000 Loss 11.2079 Accuracy 0.9893\n",
      "Epoch 1 Batch 2050 Loss 11.1801 Accuracy 0.9893\n",
      "Epoch 1 Batch 2100 Loss 11.1315 Accuracy 0.9893\n",
      "Epoch 1 Batch 2150 Loss 11.0992 Accuracy 0.9893\n",
      "Epoch 1 Batch 2200 Loss 11.0727 Accuracy 0.9894\n",
      "Epoch 1 Batch 2250 Loss 11.0351 Accuracy 0.9894\n",
      "Epoch 1 Batch 2300 Loss 11.0095 Accuracy 0.9894\n",
      "Epoch 1 Batch 2350 Loss 10.9909 Accuracy 0.9894\n",
      "Epoch 1 Batch 2400 Loss 10.9664 Accuracy 0.9894\n",
      "Epoch 1 Batch 2450 Loss 10.9420 Accuracy 0.9894\n",
      "Epoch 1 Batch 2500 Loss 10.9273 Accuracy 0.9894\n",
      "Epoch 1 Batch 2550 Loss 10.9081 Accuracy 0.9894\n",
      "Epoch 1 Batch 2600 Loss 10.8730 Accuracy 0.9895\n",
      "Epoch 1 Batch 2650 Loss 10.8493 Accuracy 0.9895\n",
      "Epoch 1 Loss 10.8202 Accuracy 0.9895\n",
      "Time taken for 1 epoch: 185.44645309448242 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 4.2931 Accuracy 0.9962\n",
      "Epoch 2 Batch 50 Loss 9.2876 Accuracy 0.9905\n",
      "Epoch 2 Batch 100 Loss 9.2058 Accuracy 0.9905\n",
      "Epoch 2 Batch 150 Loss 9.3289 Accuracy 0.9904\n",
      "Epoch 2 Batch 200 Loss 9.3702 Accuracy 0.9904\n",
      "Epoch 2 Batch 250 Loss 9.2498 Accuracy 0.9905\n",
      "Epoch 2 Batch 300 Loss 9.2843 Accuracy 0.9905\n",
      "Epoch 2 Batch 350 Loss 9.3028 Accuracy 0.9905\n",
      "Epoch 2 Batch 400 Loss 9.2574 Accuracy 0.9905\n",
      "Epoch 2 Batch 450 Loss 9.2960 Accuracy 0.9905\n",
      "Epoch 2 Batch 500 Loss 9.2687 Accuracy 0.9905\n",
      "Epoch 2 Batch 550 Loss 9.3193 Accuracy 0.9904\n",
      "Epoch 2 Batch 600 Loss 9.3297 Accuracy 0.9904\n",
      "Epoch 2 Batch 650 Loss 9.3279 Accuracy 0.9904\n",
      "Epoch 2 Batch 700 Loss 9.3099 Accuracy 0.9904\n",
      "Epoch 2 Batch 750 Loss 9.2796 Accuracy 0.9904\n",
      "Epoch 2 Batch 800 Loss 9.2186 Accuracy 0.9905\n",
      "Epoch 2 Batch 850 Loss 9.2129 Accuracy 0.9905\n",
      "Epoch 2 Batch 900 Loss 9.2265 Accuracy 0.9905\n",
      "Epoch 2 Batch 950 Loss 9.2358 Accuracy 0.9904\n",
      "Epoch 2 Batch 1000 Loss 9.2263 Accuracy 0.9904\n",
      "Epoch 2 Batch 1050 Loss 9.2157 Accuracy 0.9905\n",
      "Epoch 2 Batch 1100 Loss 9.1870 Accuracy 0.9905\n",
      "Epoch 2 Batch 1150 Loss 9.1624 Accuracy 0.9905\n",
      "Epoch 2 Batch 1200 Loss 9.1708 Accuracy 0.9905\n",
      "Epoch 2 Batch 1250 Loss 9.1408 Accuracy 0.9905\n",
      "Epoch 2 Batch 1300 Loss 9.1435 Accuracy 0.9905\n",
      "Epoch 2 Batch 1350 Loss 9.1311 Accuracy 0.9905\n",
      "Epoch 2 Batch 1400 Loss 9.1356 Accuracy 0.9905\n",
      "Epoch 2 Batch 1450 Loss 9.1226 Accuracy 0.9905\n",
      "Epoch 2 Batch 1500 Loss 9.1092 Accuracy 0.9905\n",
      "Epoch 2 Batch 1550 Loss 9.1222 Accuracy 0.9905\n",
      "Epoch 2 Batch 1600 Loss 9.1163 Accuracy 0.9905\n",
      "Epoch 2 Batch 1650 Loss 9.1136 Accuracy 0.9905\n",
      "Epoch 2 Batch 1700 Loss 9.1197 Accuracy 0.9905\n",
      "Epoch 2 Batch 1750 Loss 9.0932 Accuracy 0.9905\n",
      "Epoch 2 Batch 1800 Loss 9.1018 Accuracy 0.9905\n",
      "Epoch 2 Batch 1850 Loss 9.0860 Accuracy 0.9905\n",
      "Epoch 2 Batch 1900 Loss 9.0678 Accuracy 0.9905\n",
      "Epoch 2 Batch 1950 Loss 9.0504 Accuracy 0.9906\n",
      "Epoch 2 Batch 2000 Loss 9.0559 Accuracy 0.9905\n",
      "Epoch 2 Batch 2050 Loss 9.0559 Accuracy 0.9905\n",
      "Epoch 2 Batch 2100 Loss 9.0362 Accuracy 0.9905\n",
      "Epoch 2 Batch 2150 Loss 9.0319 Accuracy 0.9906\n",
      "Epoch 2 Batch 2200 Loss 9.0325 Accuracy 0.9905\n",
      "Epoch 2 Batch 2250 Loss 9.0227 Accuracy 0.9906\n",
      "Epoch 2 Batch 2300 Loss 9.0190 Accuracy 0.9906\n",
      "Epoch 2 Batch 2350 Loss 9.0205 Accuracy 0.9905\n",
      "Epoch 2 Batch 2400 Loss 9.0174 Accuracy 0.9905\n",
      "Epoch 2 Batch 2450 Loss 9.0137 Accuracy 0.9905\n",
      "Epoch 2 Batch 2500 Loss 9.0194 Accuracy 0.9905\n",
      "Epoch 2 Batch 2550 Loss 9.0196 Accuracy 0.9905\n",
      "Epoch 2 Batch 2600 Loss 9.0057 Accuracy 0.9905\n",
      "Epoch 2 Batch 2650 Loss 8.9997 Accuracy 0.9905\n",
      "Epoch 2 Loss 8.9905 Accuracy 0.9905\n",
      "Time taken for 1 epoch: 193.113422870636 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 3.6842 Accuracy 0.9967\n",
      "Epoch 3 Batch 50 Loss 8.4937 Accuracy 0.9908\n",
      "Epoch 3 Batch 100 Loss 8.4083 Accuracy 0.9909\n",
      "Epoch 3 Batch 150 Loss 8.5290 Accuracy 0.9907\n",
      "Epoch 3 Batch 200 Loss 8.5417 Accuracy 0.9907\n",
      "Epoch 3 Batch 250 Loss 8.4193 Accuracy 0.9909\n",
      "Epoch 3 Batch 300 Loss 8.4565 Accuracy 0.9909\n",
      "Epoch 3 Batch 350 Loss 8.4679 Accuracy 0.9908\n",
      "Epoch 3 Batch 400 Loss 8.4217 Accuracy 0.9909\n",
      "Epoch 3 Batch 450 Loss 8.4631 Accuracy 0.9908\n",
      "Epoch 3 Batch 500 Loss 8.4361 Accuracy 0.9909\n",
      "Epoch 3 Batch 550 Loss 8.4794 Accuracy 0.9908\n",
      "Epoch 3 Batch 600 Loss 8.4986 Accuracy 0.9908\n",
      "Epoch 3 Batch 650 Loss 8.4989 Accuracy 0.9908\n",
      "Epoch 3 Batch 700 Loss 8.4856 Accuracy 0.9908\n",
      "Epoch 3 Batch 750 Loss 8.4586 Accuracy 0.9908\n",
      "Epoch 3 Batch 800 Loss 8.4086 Accuracy 0.9909\n",
      "Epoch 3 Batch 850 Loss 8.4070 Accuracy 0.9909\n",
      "Epoch 3 Batch 900 Loss 8.4178 Accuracy 0.9908\n",
      "Epoch 3 Batch 950 Loss 8.4283 Accuracy 0.9908\n",
      "Epoch 3 Batch 1000 Loss 8.4185 Accuracy 0.9908\n",
      "Epoch 3 Batch 1050 Loss 8.4078 Accuracy 0.9908\n",
      "Epoch 3 Batch 1100 Loss 8.3862 Accuracy 0.9909\n",
      "Epoch 3 Batch 1150 Loss 8.3650 Accuracy 0.9909\n",
      "Epoch 3 Batch 1200 Loss 8.3766 Accuracy 0.9909\n",
      "Epoch 3 Batch 1250 Loss 8.3528 Accuracy 0.9909\n",
      "Epoch 3 Batch 1300 Loss 8.3595 Accuracy 0.9909\n",
      "Epoch 3 Batch 1350 Loss 8.3465 Accuracy 0.9909\n",
      "Epoch 3 Batch 1400 Loss 8.3509 Accuracy 0.9909\n",
      "Epoch 3 Batch 1450 Loss 8.3406 Accuracy 0.9909\n",
      "Epoch 3 Batch 1500 Loss 8.3275 Accuracy 0.9909\n",
      "Epoch 3 Batch 1550 Loss 8.3408 Accuracy 0.9909\n",
      "Epoch 3 Batch 1600 Loss 8.3343 Accuracy 0.9909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 1650 Loss 8.3308 Accuracy 0.9909\n",
      "Epoch 3 Batch 1700 Loss 8.3370 Accuracy 0.9909\n",
      "Epoch 3 Batch 1750 Loss 8.3128 Accuracy 0.9909\n",
      "Epoch 3 Batch 1800 Loss 8.3201 Accuracy 0.9909\n",
      "Epoch 3 Batch 1850 Loss 8.3037 Accuracy 0.9909\n",
      "Epoch 3 Batch 1900 Loss 8.2882 Accuracy 0.9909\n",
      "Epoch 3 Batch 1950 Loss 8.2710 Accuracy 0.9909\n",
      "Epoch 3 Batch 2000 Loss 8.2768 Accuracy 0.9909\n",
      "Epoch 3 Batch 2050 Loss 8.2798 Accuracy 0.9909\n",
      "Epoch 3 Batch 2100 Loss 8.2649 Accuracy 0.9909\n",
      "Epoch 3 Batch 2150 Loss 8.2622 Accuracy 0.9910\n",
      "Epoch 3 Batch 2200 Loss 8.2645 Accuracy 0.9909\n",
      "Epoch 3 Batch 2250 Loss 8.2568 Accuracy 0.9910\n",
      "Epoch 3 Batch 2300 Loss 8.2535 Accuracy 0.9910\n",
      "Epoch 3 Batch 2350 Loss 8.2550 Accuracy 0.9909\n",
      "Epoch 3 Batch 2400 Loss 8.2527 Accuracy 0.9909\n",
      "Epoch 3 Batch 2450 Loss 8.2503 Accuracy 0.9909\n",
      "Epoch 3 Batch 2500 Loss 8.2571 Accuracy 0.9909\n",
      "Epoch 3 Batch 2550 Loss 8.2573 Accuracy 0.9909\n",
      "Epoch 3 Batch 2600 Loss 8.2458 Accuracy 0.9909\n",
      "Epoch 3 Batch 2650 Loss 8.2410 Accuracy 0.9909\n",
      "Epoch 3 Loss 8.2343 Accuracy 0.9909\n",
      "Time taken for 1 epoch: 196.05343437194824 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 4.0361 Accuracy 0.9964\n",
      "Epoch 4 Batch 50 Loss 7.9427 Accuracy 0.9911\n",
      "Epoch 4 Batch 100 Loss 7.8056 Accuracy 0.9912\n",
      "Epoch 4 Batch 150 Loss 7.9179 Accuracy 0.9911\n",
      "Epoch 4 Batch 200 Loss 7.8898 Accuracy 0.9911\n",
      "Epoch 4 Batch 250 Loss 7.7796 Accuracy 0.9913\n",
      "Epoch 4 Batch 300 Loss 7.8103 Accuracy 0.9912\n",
      "Epoch 4 Batch 350 Loss 7.8176 Accuracy 0.9912\n",
      "Epoch 4 Batch 400 Loss 7.7754 Accuracy 0.9913\n",
      "Epoch 4 Batch 450 Loss 7.8229 Accuracy 0.9912\n",
      "Epoch 4 Batch 500 Loss 7.8025 Accuracy 0.9912\n",
      "Epoch 4 Batch 550 Loss 7.8369 Accuracy 0.9912\n",
      "Epoch 4 Batch 600 Loss 7.8578 Accuracy 0.9912\n",
      "Epoch 4 Batch 650 Loss 7.8565 Accuracy 0.9911\n",
      "Epoch 4 Batch 700 Loss 7.8442 Accuracy 0.9912\n",
      "Epoch 4 Batch 750 Loss 7.8190 Accuracy 0.9912\n",
      "Epoch 4 Batch 800 Loss 7.7747 Accuracy 0.9913\n",
      "Epoch 4 Batch 850 Loss 7.7731 Accuracy 0.9913\n",
      "Epoch 4 Batch 900 Loss 7.7763 Accuracy 0.9912\n",
      "Epoch 4 Batch 950 Loss 7.7872 Accuracy 0.9912\n",
      "Epoch 4 Batch 1000 Loss 7.7800 Accuracy 0.9912\n",
      "Epoch 4 Batch 1050 Loss 7.7688 Accuracy 0.9912\n",
      "Epoch 4 Batch 1100 Loss 7.7536 Accuracy 0.9913\n",
      "Epoch 4 Batch 1150 Loss 7.7312 Accuracy 0.9913\n",
      "Epoch 4 Batch 1200 Loss 7.7459 Accuracy 0.9913\n",
      "Epoch 4 Batch 1250 Loss 7.7248 Accuracy 0.9913\n",
      "Epoch 4 Batch 1300 Loss 7.7331 Accuracy 0.9913\n",
      "Epoch 4 Batch 1350 Loss 7.7204 Accuracy 0.9913\n",
      "Epoch 4 Batch 1400 Loss 7.7272 Accuracy 0.9913\n",
      "Epoch 4 Batch 1450 Loss 7.7127 Accuracy 0.9913\n",
      "Epoch 4 Batch 1500 Loss 7.7033 Accuracy 0.9913\n",
      "Epoch 4 Batch 1550 Loss 7.7157 Accuracy 0.9913\n",
      "Epoch 4 Batch 1600 Loss 7.7099 Accuracy 0.9913\n",
      "Epoch 4 Batch 1650 Loss 7.7070 Accuracy 0.9913\n",
      "Epoch 4 Batch 1700 Loss 7.7149 Accuracy 0.9913\n",
      "Epoch 4 Batch 1750 Loss 7.6919 Accuracy 0.9913\n",
      "Epoch 4 Batch 1800 Loss 7.6980 Accuracy 0.9913\n",
      "Epoch 4 Batch 1850 Loss 7.6823 Accuracy 0.9913\n",
      "Epoch 4 Batch 1900 Loss 7.6683 Accuracy 0.9913\n",
      "Epoch 4 Batch 1950 Loss 7.6514 Accuracy 0.9914\n",
      "Epoch 4 Batch 2000 Loss 7.6591 Accuracy 0.9913\n",
      "Epoch 4 Batch 2050 Loss 7.6621 Accuracy 0.9913\n",
      "Epoch 4 Batch 2100 Loss 7.6498 Accuracy 0.9913\n",
      "Epoch 4 Batch 2150 Loss 7.6488 Accuracy 0.9914\n",
      "Epoch 4 Batch 2200 Loss 7.6520 Accuracy 0.9913\n",
      "Epoch 4 Batch 2250 Loss 7.6454 Accuracy 0.9914\n",
      "Epoch 4 Batch 2300 Loss 7.6434 Accuracy 0.9914\n",
      "Epoch 4 Batch 2350 Loss 7.6443 Accuracy 0.9913\n",
      "Epoch 4 Batch 2400 Loss 7.6429 Accuracy 0.9913\n",
      "Epoch 4 Batch 2450 Loss 7.6421 Accuracy 0.9913\n",
      "Epoch 4 Batch 2500 Loss 7.6493 Accuracy 0.9913\n",
      "Epoch 4 Batch 2550 Loss 7.6486 Accuracy 0.9913\n",
      "Epoch 4 Batch 2600 Loss 7.6391 Accuracy 0.9913\n",
      "Epoch 4 Batch 2650 Loss 7.6346 Accuracy 0.9913\n",
      "Epoch 4 Loss 7.6298 Accuracy 0.9913\n",
      "Time taken for 1 epoch: 195.70977807044983 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 3.5194 Accuracy 0.9965\n",
      "Epoch 5 Batch 50 Loss 7.4347 Accuracy 0.9914\n",
      "Epoch 5 Batch 100 Loss 7.3025 Accuracy 0.9916\n",
      "Epoch 5 Batch 150 Loss 7.3959 Accuracy 0.9915\n",
      "Epoch 5 Batch 200 Loss 7.3602 Accuracy 0.9915\n",
      "Epoch 5 Batch 250 Loss 7.2667 Accuracy 0.9916\n",
      "Epoch 5 Batch 300 Loss 7.3019 Accuracy 0.9916\n",
      "Epoch 5 Batch 350 Loss 7.3071 Accuracy 0.9916\n",
      "Epoch 5 Batch 400 Loss 7.2724 Accuracy 0.9916\n",
      "Epoch 5 Batch 450 Loss 7.3149 Accuracy 0.9916\n",
      "Epoch 5 Batch 500 Loss 7.3014 Accuracy 0.9916\n",
      "Epoch 5 Batch 550 Loss 7.3337 Accuracy 0.9915\n",
      "Epoch 5 Batch 600 Loss 7.3595 Accuracy 0.9915\n",
      "Epoch 5 Batch 650 Loss 7.3575 Accuracy 0.9915\n",
      "Epoch 5 Batch 700 Loss 7.3458 Accuracy 0.9915\n",
      "Epoch 5 Batch 750 Loss 7.3229 Accuracy 0.9916\n",
      "Epoch 5 Batch 800 Loss 7.2834 Accuracy 0.9916\n",
      "Epoch 5 Batch 850 Loss 7.2833 Accuracy 0.9916\n",
      "Epoch 5 Batch 900 Loss 7.2830 Accuracy 0.9916\n",
      "Epoch 5 Batch 950 Loss 7.2932 Accuracy 0.9916\n",
      "Epoch 5 Batch 1000 Loss 7.2852 Accuracy 0.9916\n",
      "Epoch 5 Batch 1050 Loss 7.2696 Accuracy 0.9916\n",
      "Epoch 5 Batch 1100 Loss 7.2555 Accuracy 0.9916\n",
      "Epoch 5 Batch 1150 Loss 7.2363 Accuracy 0.9916\n",
      "Epoch 5 Batch 1200 Loss 7.2519 Accuracy 0.9916\n",
      "Epoch 5 Batch 1250 Loss 7.2344 Accuracy 0.9917\n",
      "Epoch 5 Batch 1300 Loss 7.2413 Accuracy 0.9916\n",
      "Epoch 5 Batch 1350 Loss 7.2289 Accuracy 0.9917\n",
      "Epoch 5 Batch 1400 Loss 7.2362 Accuracy 0.9916\n",
      "Epoch 5 Batch 1450 Loss 7.2246 Accuracy 0.9917\n",
      "Epoch 5 Batch 1500 Loss 7.2168 Accuracy 0.9917\n",
      "Epoch 5 Batch 1550 Loss 7.2291 Accuracy 0.9917\n",
      "Epoch 5 Batch 1600 Loss 7.2248 Accuracy 0.9917\n",
      "Epoch 5 Batch 1650 Loss 7.2214 Accuracy 0.9917\n",
      "Epoch 5 Batch 1700 Loss 7.2267 Accuracy 0.9916\n",
      "Epoch 5 Batch 1750 Loss 7.2066 Accuracy 0.9917\n",
      "Epoch 5 Batch 1800 Loss 7.2126 Accuracy 0.9917\n",
      "Epoch 5 Batch 1850 Loss 7.1965 Accuracy 0.9917\n",
      "Epoch 5 Batch 1900 Loss 7.1830 Accuracy 0.9917\n",
      "Epoch 5 Batch 1950 Loss 7.1661 Accuracy 0.9917\n",
      "Epoch 5 Batch 2000 Loss 7.1746 Accuracy 0.9917\n",
      "Epoch 5 Batch 2050 Loss 7.1783 Accuracy 0.9917\n",
      "Epoch 5 Batch 2100 Loss 7.1680 Accuracy 0.9917\n",
      "Epoch 5 Batch 2150 Loss 7.1675 Accuracy 0.9917\n",
      "Epoch 5 Batch 2200 Loss 7.1734 Accuracy 0.9917\n",
      "Epoch 5 Batch 2250 Loss 7.1702 Accuracy 0.9917\n",
      "Epoch 5 Batch 2300 Loss 7.1669 Accuracy 0.9917\n",
      "Epoch 5 Batch 2350 Loss 7.1669 Accuracy 0.9917\n",
      "Epoch 5 Batch 2400 Loss 7.1643 Accuracy 0.9917\n",
      "Epoch 5 Batch 2450 Loss 7.1630 Accuracy 0.9917\n",
      "Epoch 5 Batch 2500 Loss 7.1702 Accuracy 0.9917\n",
      "Epoch 5 Batch 2550 Loss 7.1696 Accuracy 0.9917\n",
      "Epoch 5 Batch 2600 Loss 7.1614 Accuracy 0.9917\n",
      "Epoch 5 Batch 2650 Loss 7.1576 Accuracy 0.9917\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train\\ckpt-2\n",
      "Epoch 5 Loss 7.1541 Accuracy 0.9917\n",
      "Time taken for 1 epoch: 199.69335985183716 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 3.6460 Accuracy 0.9966\n",
      "Epoch 6 Batch 50 Loss 7.0394 Accuracy 0.9917\n",
      "Epoch 6 Batch 100 Loss 6.9096 Accuracy 0.9919\n",
      "Epoch 6 Batch 150 Loss 6.9900 Accuracy 0.9918\n",
      "Epoch 6 Batch 200 Loss 6.9378 Accuracy 0.9918\n",
      "Epoch 6 Batch 250 Loss 6.8522 Accuracy 0.9920\n",
      "Epoch 6 Batch 300 Loss 6.8778 Accuracy 0.9919\n",
      "Epoch 6 Batch 350 Loss 6.8738 Accuracy 0.9919\n",
      "Epoch 6 Batch 400 Loss 6.8456 Accuracy 0.9920\n",
      "Epoch 6 Batch 450 Loss 6.8878 Accuracy 0.9919\n",
      "Epoch 6 Batch 500 Loss 6.8708 Accuracy 0.9920\n",
      "Epoch 6 Batch 550 Loss 6.9037 Accuracy 0.9919\n",
      "Epoch 6 Batch 600 Loss 6.9303 Accuracy 0.9919\n",
      "Epoch 6 Batch 650 Loss 6.9295 Accuracy 0.9919\n",
      "Epoch 6 Batch 700 Loss 6.9177 Accuracy 0.9919\n",
      "Epoch 6 Batch 750 Loss 6.8957 Accuracy 0.9919\n",
      "Epoch 6 Batch 800 Loss 6.8551 Accuracy 0.9920\n",
      "Epoch 6 Batch 850 Loss 6.8554 Accuracy 0.9920\n",
      "Epoch 6 Batch 900 Loss 6.8551 Accuracy 0.9920\n",
      "Epoch 6 Batch 950 Loss 6.8658 Accuracy 0.9919\n",
      "Epoch 6 Batch 1000 Loss 6.8584 Accuracy 0.9920\n",
      "Epoch 6 Batch 1050 Loss 6.8409 Accuracy 0.9920\n",
      "Epoch 6 Batch 1100 Loss 6.8323 Accuracy 0.9920\n",
      "Epoch 6 Batch 1150 Loss 6.8147 Accuracy 0.9920\n",
      "Epoch 6 Batch 1200 Loss 6.8334 Accuracy 0.9920\n",
      "Epoch 6 Batch 1250 Loss 6.8157 Accuracy 0.9920\n",
      "Epoch 6 Batch 1300 Loss 6.8225 Accuracy 0.9920\n",
      "Epoch 6 Batch 1350 Loss 6.8099 Accuracy 0.9920\n",
      "Epoch 6 Batch 1400 Loss 6.8185 Accuracy 0.9920\n",
      "Epoch 6 Batch 1450 Loss 6.8055 Accuracy 0.9920\n",
      "Epoch 6 Batch 1500 Loss 6.7976 Accuracy 0.9920\n",
      "Epoch 6 Batch 1550 Loss 6.8082 Accuracy 0.9920\n",
      "Epoch 6 Batch 1600 Loss 6.8043 Accuracy 0.9920\n",
      "Epoch 6 Batch 1650 Loss 6.8010 Accuracy 0.9920\n",
      "Epoch 6 Batch 1700 Loss 6.8102 Accuracy 0.9920\n",
      "Epoch 6 Batch 1750 Loss 6.7915 Accuracy 0.9920\n",
      "Epoch 6 Batch 1800 Loss 6.7942 Accuracy 0.9920\n",
      "Epoch 6 Batch 1850 Loss 6.7785 Accuracy 0.9920\n",
      "Epoch 6 Batch 1900 Loss 6.7657 Accuracy 0.9921\n",
      "Epoch 6 Batch 1950 Loss 6.7481 Accuracy 0.9921\n",
      "Epoch 6 Batch 2000 Loss 6.7565 Accuracy 0.9921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 2050 Loss 6.7607 Accuracy 0.9921\n",
      "Epoch 6 Batch 2100 Loss 6.7510 Accuracy 0.9921\n",
      "Epoch 6 Batch 2150 Loss 6.7524 Accuracy 0.9921\n",
      "Epoch 6 Batch 2200 Loss 6.7575 Accuracy 0.9921\n",
      "Epoch 6 Batch 2250 Loss 6.7554 Accuracy 0.9921\n",
      "Epoch 6 Batch 2300 Loss 6.7517 Accuracy 0.9921\n",
      "Epoch 6 Batch 2350 Loss 6.7515 Accuracy 0.9921\n",
      "Epoch 6 Batch 2400 Loss 6.7494 Accuracy 0.9921\n",
      "Epoch 6 Batch 2450 Loss 6.7479 Accuracy 0.9921\n",
      "Epoch 6 Batch 2500 Loss 6.7568 Accuracy 0.9920\n",
      "Epoch 6 Batch 2550 Loss 6.7552 Accuracy 0.9920\n",
      "Epoch 6 Batch 2600 Loss 6.7476 Accuracy 0.9921\n",
      "Epoch 6 Batch 2650 Loss 6.7435 Accuracy 0.9921\n",
      "Epoch 6 Loss 6.7416 Accuracy 0.9921\n",
      "Time taken for 1 epoch: 195.94001245498657 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 3.7571 Accuracy 0.9963\n",
      "Epoch 7 Batch 50 Loss 6.6706 Accuracy 0.9920\n",
      "Epoch 7 Batch 100 Loss 6.5520 Accuracy 0.9922\n",
      "Epoch 7 Batch 150 Loss 6.6320 Accuracy 0.9921\n",
      "Epoch 7 Batch 200 Loss 6.5756 Accuracy 0.9921\n",
      "Epoch 7 Batch 250 Loss 6.4972 Accuracy 0.9922\n",
      "Epoch 7 Batch 300 Loss 6.5156 Accuracy 0.9922\n",
      "Epoch 7 Batch 350 Loss 6.5091 Accuracy 0.9922\n",
      "Epoch 7 Batch 400 Loss 6.4796 Accuracy 0.9923\n",
      "Epoch 7 Batch 450 Loss 6.5213 Accuracy 0.9922\n",
      "Epoch 7 Batch 500 Loss 6.5056 Accuracy 0.9922\n",
      "Epoch 7 Batch 550 Loss 6.5319 Accuracy 0.9922\n",
      "Epoch 7 Batch 600 Loss 6.5594 Accuracy 0.9922\n",
      "Epoch 7 Batch 650 Loss 6.5580 Accuracy 0.9922\n",
      "Epoch 7 Batch 700 Loss 6.5478 Accuracy 0.9922\n",
      "Epoch 7 Batch 750 Loss 6.5302 Accuracy 0.9922\n",
      "Epoch 7 Batch 800 Loss 6.4945 Accuracy 0.9923\n",
      "Epoch 7 Batch 850 Loss 6.4956 Accuracy 0.9923\n",
      "Epoch 7 Batch 900 Loss 6.4905 Accuracy 0.9923\n",
      "Epoch 7 Batch 950 Loss 6.4935 Accuracy 0.9923\n",
      "Epoch 7 Batch 1000 Loss 6.4896 Accuracy 0.9923\n",
      "Epoch 7 Batch 1050 Loss 6.4718 Accuracy 0.9923\n",
      "Epoch 7 Batch 1100 Loss 6.4612 Accuracy 0.9923\n",
      "Epoch 7 Batch 1150 Loss 6.4443 Accuracy 0.9923\n",
      "Epoch 7 Batch 1200 Loss 6.4615 Accuracy 0.9923\n",
      "Epoch 7 Batch 1250 Loss 6.4447 Accuracy 0.9923\n",
      "Epoch 7 Batch 1300 Loss 6.4531 Accuracy 0.9923\n",
      "Epoch 7 Batch 1350 Loss 6.4425 Accuracy 0.9923\n",
      "Epoch 7 Batch 1400 Loss 6.4504 Accuracy 0.9923\n",
      "Epoch 7 Batch 1450 Loss 6.4390 Accuracy 0.9923\n",
      "Epoch 7 Batch 1500 Loss 6.4326 Accuracy 0.9923\n",
      "Epoch 7 Batch 1550 Loss 6.4410 Accuracy 0.9923\n",
      "Epoch 7 Batch 1600 Loss 6.4392 Accuracy 0.9923\n",
      "Epoch 7 Batch 1650 Loss 6.4347 Accuracy 0.9923\n",
      "Epoch 7 Batch 1700 Loss 6.4436 Accuracy 0.9923\n",
      "Epoch 7 Batch 1750 Loss 6.4248 Accuracy 0.9923\n",
      "Epoch 7 Batch 1800 Loss 6.4290 Accuracy 0.9923\n",
      "Epoch 7 Batch 1850 Loss 6.4142 Accuracy 0.9924\n",
      "Epoch 7 Batch 1900 Loss 6.4018 Accuracy 0.9924\n",
      "Epoch 7 Batch 1950 Loss 6.3863 Accuracy 0.9924\n",
      "Epoch 7 Batch 2000 Loss 6.3934 Accuracy 0.9924\n",
      "Epoch 7 Batch 2050 Loss 6.4004 Accuracy 0.9924\n",
      "Epoch 7 Batch 2100 Loss 6.3918 Accuracy 0.9924\n",
      "Epoch 7 Batch 2150 Loss 6.3928 Accuracy 0.9924\n",
      "Epoch 7 Batch 2200 Loss 6.3989 Accuracy 0.9924\n",
      "Epoch 7 Batch 2250 Loss 6.3987 Accuracy 0.9924\n",
      "Epoch 7 Batch 2300 Loss 6.3960 Accuracy 0.9924\n",
      "Epoch 7 Batch 2350 Loss 6.3950 Accuracy 0.9924\n",
      "Epoch 7 Batch 2400 Loss 6.3931 Accuracy 0.9924\n",
      "Epoch 7 Batch 2450 Loss 6.3930 Accuracy 0.9924\n",
      "Epoch 7 Batch 2500 Loss 6.4015 Accuracy 0.9924\n",
      "Epoch 7 Batch 2550 Loss 6.4003 Accuracy 0.9924\n",
      "Epoch 7 Batch 2600 Loss 6.3927 Accuracy 0.9924\n",
      "Epoch 7 Batch 2650 Loss 6.3892 Accuracy 0.9924\n",
      "Epoch 7 Loss 6.3867 Accuracy 0.9924\n",
      "Time taken for 1 epoch: 195.23988127708435 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 3.4989 Accuracy 0.9964\n",
      "Epoch 8 Batch 50 Loss 6.4253 Accuracy 0.9922\n",
      "Epoch 8 Batch 100 Loss 6.2457 Accuracy 0.9924\n",
      "Epoch 8 Batch 150 Loss 6.3222 Accuracy 0.9924\n",
      "Epoch 8 Batch 200 Loss 6.2263 Accuracy 0.9925\n",
      "Epoch 8 Batch 250 Loss 6.1634 Accuracy 0.9926\n",
      "Epoch 8 Batch 300 Loss 6.1942 Accuracy 0.9925\n",
      "Epoch 8 Batch 350 Loss 6.1824 Accuracy 0.9926\n",
      "Epoch 8 Batch 400 Loss 6.1545 Accuracy 0.9926\n",
      "Epoch 8 Batch 450 Loss 6.2016 Accuracy 0.9925\n",
      "Epoch 8 Batch 500 Loss 6.1926 Accuracy 0.9926\n",
      "Epoch 8 Batch 550 Loss 6.2201 Accuracy 0.9925\n",
      "Epoch 8 Batch 600 Loss 6.2484 Accuracy 0.9925\n",
      "Epoch 8 Batch 650 Loss 6.2443 Accuracy 0.9925\n",
      "Epoch 8 Batch 700 Loss 6.2377 Accuracy 0.9925\n",
      "Epoch 8 Batch 750 Loss 6.2222 Accuracy 0.9925\n",
      "Epoch 8 Batch 800 Loss 6.1900 Accuracy 0.9926\n",
      "Epoch 8 Batch 850 Loss 6.1917 Accuracy 0.9926\n",
      "Epoch 8 Batch 900 Loss 6.1883 Accuracy 0.9926\n",
      "Epoch 8 Batch 950 Loss 6.1957 Accuracy 0.9925\n",
      "Epoch 8 Batch 1000 Loss 6.1896 Accuracy 0.9926\n",
      "Epoch 8 Batch 1050 Loss 6.1703 Accuracy 0.9926\n",
      "Epoch 8 Batch 1100 Loss 6.1642 Accuracy 0.9926\n",
      "Epoch 8 Batch 1150 Loss 6.1464 Accuracy 0.9926\n",
      "Epoch 8 Batch 1200 Loss 6.1623 Accuracy 0.9926\n",
      "Epoch 8 Batch 1250 Loss 6.1456 Accuracy 0.9926\n",
      "Epoch 8 Batch 1300 Loss 6.1517 Accuracy 0.9926\n",
      "Epoch 8 Batch 1350 Loss 6.1412 Accuracy 0.9926\n",
      "Epoch 8 Batch 1400 Loss 6.1500 Accuracy 0.9926\n",
      "Epoch 8 Batch 1450 Loss 6.1372 Accuracy 0.9926\n",
      "Epoch 8 Batch 1500 Loss 6.1334 Accuracy 0.9926\n",
      "Epoch 8 Batch 1550 Loss 6.1433 Accuracy 0.9926\n",
      "Epoch 8 Batch 1600 Loss 6.1395 Accuracy 0.9926\n",
      "Epoch 8 Batch 1650 Loss 6.1351 Accuracy 0.9926\n",
      "Epoch 8 Batch 1700 Loss 6.1426 Accuracy 0.9926\n",
      "Epoch 8 Batch 1750 Loss 6.1267 Accuracy 0.9926\n",
      "Epoch 8 Batch 1800 Loss 6.1279 Accuracy 0.9926\n",
      "Epoch 8 Batch 1850 Loss 6.1145 Accuracy 0.9926\n",
      "Epoch 8 Batch 1900 Loss 6.1038 Accuracy 0.9927\n",
      "Epoch 8 Batch 1950 Loss 6.0865 Accuracy 0.9927\n",
      "Epoch 8 Batch 2000 Loss 6.0939 Accuracy 0.9927\n",
      "Epoch 8 Batch 2050 Loss 6.1001 Accuracy 0.9927\n",
      "Epoch 8 Batch 2100 Loss 6.0930 Accuracy 0.9927\n",
      "Epoch 8 Batch 2150 Loss 6.0936 Accuracy 0.9927\n",
      "Epoch 8 Batch 2200 Loss 6.0986 Accuracy 0.9927\n",
      "Epoch 8 Batch 2250 Loss 6.0990 Accuracy 0.9927\n",
      "Epoch 8 Batch 2300 Loss 6.0950 Accuracy 0.9927\n",
      "Epoch 8 Batch 2350 Loss 6.0945 Accuracy 0.9927\n",
      "Epoch 8 Batch 2400 Loss 6.0924 Accuracy 0.9927\n",
      "Epoch 8 Batch 2450 Loss 6.0934 Accuracy 0.9927\n",
      "Epoch 8 Batch 2500 Loss 6.1005 Accuracy 0.9927\n",
      "Epoch 8 Batch 2550 Loss 6.1000 Accuracy 0.9927\n",
      "Epoch 8 Batch 2600 Loss 6.0945 Accuracy 0.9927\n",
      "Epoch 8 Batch 2650 Loss 6.0917 Accuracy 0.9927\n",
      "Epoch 8 Loss 6.0907 Accuracy 0.9927\n",
      "Time taken for 1 epoch: 196.32004594802856 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 3.3651 Accuracy 0.9968\n",
      "Epoch 9 Batch 50 Loss 6.1660 Accuracy 0.9925\n",
      "Epoch 9 Batch 100 Loss 6.0053 Accuracy 0.9927\n",
      "Epoch 9 Batch 150 Loss 6.0661 Accuracy 0.9927\n",
      "Epoch 9 Batch 200 Loss 5.9859 Accuracy 0.9927\n",
      "Epoch 9 Batch 250 Loss 5.9225 Accuracy 0.9928\n",
      "Epoch 9 Batch 300 Loss 5.9407 Accuracy 0.9928\n",
      "Epoch 9 Batch 350 Loss 5.9345 Accuracy 0.9928\n",
      "Epoch 9 Batch 400 Loss 5.9097 Accuracy 0.9928\n",
      "Epoch 9 Batch 450 Loss 5.9474 Accuracy 0.9928\n",
      "Epoch 9 Batch 500 Loss 5.9307 Accuracy 0.9928\n",
      "Epoch 9 Batch 550 Loss 5.9545 Accuracy 0.9928\n",
      "Epoch 9 Batch 600 Loss 5.9846 Accuracy 0.9927\n",
      "Epoch 9 Batch 650 Loss 5.9841 Accuracy 0.9927\n",
      "Epoch 9 Batch 700 Loss 5.9744 Accuracy 0.9928\n",
      "Epoch 9 Batch 750 Loss 5.9571 Accuracy 0.9928\n",
      "Epoch 9 Batch 800 Loss 5.9266 Accuracy 0.9928\n",
      "Epoch 9 Batch 850 Loss 5.9282 Accuracy 0.9928\n",
      "Epoch 9 Batch 900 Loss 5.9232 Accuracy 0.9928\n",
      "Epoch 9 Batch 950 Loss 5.9315 Accuracy 0.9928\n",
      "Epoch 9 Batch 1000 Loss 5.9258 Accuracy 0.9928\n",
      "Epoch 9 Batch 1050 Loss 5.9082 Accuracy 0.9928\n",
      "Epoch 9 Batch 1100 Loss 5.9003 Accuracy 0.9929\n",
      "Epoch 9 Batch 1150 Loss 5.8853 Accuracy 0.9929\n",
      "Epoch 9 Batch 1200 Loss 5.9054 Accuracy 0.9929\n",
      "Epoch 9 Batch 1250 Loss 5.8913 Accuracy 0.9929\n",
      "Epoch 9 Batch 1300 Loss 5.8972 Accuracy 0.9929\n",
      "Epoch 9 Batch 1350 Loss 5.8858 Accuracy 0.9929\n",
      "Epoch 9 Batch 1400 Loss 5.8940 Accuracy 0.9929\n",
      "Epoch 9 Batch 1450 Loss 5.8806 Accuracy 0.9929\n",
      "Epoch 9 Batch 1500 Loss 5.8764 Accuracy 0.9929\n",
      "Epoch 9 Batch 1550 Loss 5.8849 Accuracy 0.9929\n",
      "Epoch 9 Batch 1600 Loss 5.8822 Accuracy 0.9929\n",
      "Epoch 9 Batch 1650 Loss 5.8787 Accuracy 0.9929\n",
      "Epoch 9 Batch 1700 Loss 5.8870 Accuracy 0.9929\n",
      "Epoch 9 Batch 1750 Loss 5.8704 Accuracy 0.9929\n",
      "Epoch 9 Batch 1800 Loss 5.8737 Accuracy 0.9929\n",
      "Epoch 9 Batch 1850 Loss 5.8598 Accuracy 0.9929\n",
      "Epoch 9 Batch 1900 Loss 5.8480 Accuracy 0.9929\n",
      "Epoch 9 Batch 1950 Loss 5.8343 Accuracy 0.9929\n",
      "Epoch 9 Batch 2000 Loss 5.8418 Accuracy 0.9929\n",
      "Epoch 9 Batch 2050 Loss 5.8482 Accuracy 0.9929\n",
      "Epoch 9 Batch 2100 Loss 5.8423 Accuracy 0.9929\n",
      "Epoch 9 Batch 2150 Loss 5.8440 Accuracy 0.9929\n",
      "Epoch 9 Batch 2200 Loss 5.8479 Accuracy 0.9929\n",
      "Epoch 9 Batch 2250 Loss 5.8473 Accuracy 0.9929\n",
      "Epoch 9 Batch 2300 Loss 5.8425 Accuracy 0.9929\n",
      "Epoch 9 Batch 2350 Loss 5.8415 Accuracy 0.9929\n",
      "Epoch 9 Batch 2400 Loss 5.8411 Accuracy 0.9929\n",
      "Epoch 9 Batch 2450 Loss 5.8407 Accuracy 0.9929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 2500 Loss 5.8480 Accuracy 0.9929\n",
      "Epoch 9 Batch 2550 Loss 5.8489 Accuracy 0.9929\n",
      "Epoch 9 Batch 2600 Loss 5.8440 Accuracy 0.9929\n",
      "Epoch 9 Batch 2650 Loss 5.8398 Accuracy 0.9929\n",
      "Epoch 9 Loss 5.8400 Accuracy 0.9929\n",
      "Time taken for 1 epoch: 195.95350527763367 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 2.9254 Accuracy 0.9969\n",
      "Epoch 10 Batch 50 Loss 5.8781 Accuracy 0.9928\n",
      "Epoch 10 Batch 100 Loss 5.7296 Accuracy 0.9930\n",
      "Epoch 10 Batch 150 Loss 5.8144 Accuracy 0.9929\n",
      "Epoch 10 Batch 200 Loss 5.7339 Accuracy 0.9930\n",
      "Epoch 10 Batch 250 Loss 5.6773 Accuracy 0.9931\n",
      "Epoch 10 Batch 300 Loss 5.6892 Accuracy 0.9931\n",
      "Epoch 10 Batch 350 Loss 5.6919 Accuracy 0.9931\n",
      "Epoch 10 Batch 400 Loss 5.6670 Accuracy 0.9931\n",
      "Epoch 10 Batch 450 Loss 5.7138 Accuracy 0.9930\n",
      "Epoch 10 Batch 500 Loss 5.6998 Accuracy 0.9931\n",
      "Epoch 10 Batch 550 Loss 5.7316 Accuracy 0.9930\n",
      "Epoch 10 Batch 600 Loss 5.7599 Accuracy 0.9930\n",
      "Epoch 10 Batch 650 Loss 5.7568 Accuracy 0.9930\n",
      "Epoch 10 Batch 700 Loss 5.7473 Accuracy 0.9930\n",
      "Epoch 10 Batch 750 Loss 5.7260 Accuracy 0.9930\n",
      "Epoch 10 Batch 800 Loss 5.6952 Accuracy 0.9931\n",
      "Epoch 10 Batch 850 Loss 5.7007 Accuracy 0.9931\n",
      "Epoch 10 Batch 900 Loss 5.6966 Accuracy 0.9931\n",
      "Epoch 10 Batch 950 Loss 5.7064 Accuracy 0.9931\n",
      "Epoch 10 Batch 1000 Loss 5.6981 Accuracy 0.9931\n",
      "Epoch 10 Batch 1050 Loss 5.6782 Accuracy 0.9931\n",
      "Epoch 10 Batch 1100 Loss 5.6714 Accuracy 0.9931\n",
      "Epoch 10 Batch 1150 Loss 5.6543 Accuracy 0.9931\n",
      "Epoch 10 Batch 1200 Loss 5.6740 Accuracy 0.9931\n",
      "Epoch 10 Batch 1250 Loss 5.6603 Accuracy 0.9931\n",
      "Epoch 10 Batch 1300 Loss 5.6680 Accuracy 0.9931\n",
      "Epoch 10 Batch 1350 Loss 5.6562 Accuracy 0.9931\n",
      "Epoch 10 Batch 1400 Loss 5.6615 Accuracy 0.9931\n",
      "Epoch 10 Batch 1450 Loss 5.6490 Accuracy 0.9931\n",
      "Epoch 10 Batch 1500 Loss 5.6459 Accuracy 0.9931\n",
      "Epoch 10 Batch 1550 Loss 5.6543 Accuracy 0.9931\n",
      "Epoch 10 Batch 1600 Loss 5.6505 Accuracy 0.9931\n",
      "Epoch 10 Batch 1650 Loss 5.6468 Accuracy 0.9931\n",
      "Epoch 10 Batch 1700 Loss 5.6541 Accuracy 0.9931\n",
      "Epoch 10 Batch 1750 Loss 5.6403 Accuracy 0.9931\n",
      "Epoch 10 Batch 1800 Loss 5.6424 Accuracy 0.9931\n",
      "Epoch 10 Batch 1850 Loss 5.6281 Accuracy 0.9932\n",
      "Epoch 10 Batch 1900 Loss 5.6188 Accuracy 0.9932\n",
      "Epoch 10 Batch 1950 Loss 5.6026 Accuracy 0.9932\n",
      "Epoch 10 Batch 2000 Loss 5.6097 Accuracy 0.9932\n",
      "Epoch 10 Batch 2050 Loss 5.6185 Accuracy 0.9932\n",
      "Epoch 10 Batch 2100 Loss 5.6133 Accuracy 0.9932\n",
      "Epoch 10 Batch 2150 Loss 5.6118 Accuracy 0.9932\n",
      "Epoch 10 Batch 2200 Loss 5.6179 Accuracy 0.9932\n",
      "Epoch 10 Batch 2250 Loss 5.6185 Accuracy 0.9932\n",
      "Epoch 10 Batch 2300 Loss 5.6146 Accuracy 0.9932\n",
      "Epoch 10 Batch 2350 Loss 5.6150 Accuracy 0.9932\n",
      "Epoch 10 Batch 2400 Loss 5.6152 Accuracy 0.9932\n",
      "Epoch 10 Batch 2450 Loss 5.6166 Accuracy 0.9932\n",
      "Epoch 10 Batch 2500 Loss 5.6240 Accuracy 0.9932\n",
      "Epoch 10 Batch 2550 Loss 5.6241 Accuracy 0.9932\n",
      "Epoch 10 Batch 2600 Loss 5.6190 Accuracy 0.9932\n",
      "Epoch 10 Batch 2650 Loss 5.6159 Accuracy 0.9932\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train\\ckpt-3\n",
      "Epoch 10 Loss 5.6161 Accuracy 0.9932\n",
      "Time taken for 1 epoch: 196.49999117851257 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 2.9610 Accuracy 0.9969\n",
      "Epoch 11 Batch 50 Loss 5.6147 Accuracy 0.9932\n",
      "Epoch 11 Batch 100 Loss 5.5147 Accuracy 0.9933\n",
      "Epoch 11 Batch 150 Loss 5.5740 Accuracy 0.9932\n",
      "Epoch 11 Batch 200 Loss 5.4984 Accuracy 0.9933\n",
      "Epoch 11 Batch 250 Loss 5.4453 Accuracy 0.9933\n",
      "Epoch 11 Batch 300 Loss 5.4631 Accuracy 0.9933\n",
      "Epoch 11 Batch 350 Loss 5.4711 Accuracy 0.9933\n",
      "Epoch 11 Batch 400 Loss 5.4531 Accuracy 0.9933\n",
      "Epoch 11 Batch 450 Loss 5.4944 Accuracy 0.9933\n",
      "Epoch 11 Batch 500 Loss 5.4793 Accuracy 0.9933\n",
      "Epoch 11 Batch 550 Loss 5.5065 Accuracy 0.9933\n",
      "Epoch 11 Batch 600 Loss 5.5312 Accuracy 0.9932\n",
      "Epoch 11 Batch 650 Loss 5.5317 Accuracy 0.9932\n",
      "Epoch 11 Batch 700 Loss 5.5240 Accuracy 0.9932\n",
      "Epoch 11 Batch 750 Loss 5.5083 Accuracy 0.9933\n",
      "Epoch 11 Batch 800 Loss 5.4804 Accuracy 0.9933\n",
      "Epoch 11 Batch 850 Loss 5.4818 Accuracy 0.9933\n",
      "Epoch 11 Batch 900 Loss 5.4808 Accuracy 0.9933\n",
      "Epoch 11 Batch 950 Loss 5.4885 Accuracy 0.9933\n",
      "Epoch 11 Batch 1000 Loss 5.4837 Accuracy 0.9933\n",
      "Epoch 11 Batch 1050 Loss 5.4651 Accuracy 0.9933\n",
      "Epoch 11 Batch 1100 Loss 5.4631 Accuracy 0.9933\n",
      "Epoch 11 Batch 1150 Loss 5.4468 Accuracy 0.9933\n",
      "Epoch 11 Batch 1200 Loss 5.4677 Accuracy 0.9933\n",
      "Epoch 11 Batch 1250 Loss 5.4560 Accuracy 0.9933\n",
      "Epoch 11 Batch 1300 Loss 5.4633 Accuracy 0.9933\n",
      "Epoch 11 Batch 1350 Loss 5.4515 Accuracy 0.9933\n",
      "Epoch 11 Batch 1400 Loss 5.4607 Accuracy 0.9933\n",
      "Epoch 11 Batch 1450 Loss 5.4476 Accuracy 0.9933\n",
      "Epoch 11 Batch 1500 Loss 5.4431 Accuracy 0.9934\n",
      "Epoch 11 Batch 1550 Loss 5.4507 Accuracy 0.9933\n",
      "Epoch 11 Batch 1600 Loss 5.4473 Accuracy 0.9933\n",
      "Epoch 11 Batch 1650 Loss 5.4435 Accuracy 0.9934\n",
      "Epoch 11 Batch 1700 Loss 5.4518 Accuracy 0.9933\n",
      "Epoch 11 Batch 1750 Loss 5.4394 Accuracy 0.9934\n",
      "Epoch 11 Batch 1800 Loss 5.4417 Accuracy 0.9934\n",
      "Epoch 11 Batch 1850 Loss 5.4287 Accuracy 0.9934\n",
      "Epoch 11 Batch 1900 Loss 5.4182 Accuracy 0.9934\n",
      "Epoch 11 Batch 1950 Loss 5.4008 Accuracy 0.9934\n",
      "Epoch 11 Batch 2000 Loss 5.4102 Accuracy 0.9934\n",
      "Epoch 11 Batch 2050 Loss 5.4183 Accuracy 0.9934\n",
      "Epoch 11 Batch 2100 Loss 5.4148 Accuracy 0.9934\n",
      "Epoch 11 Batch 2150 Loss 5.4169 Accuracy 0.9934\n",
      "Epoch 11 Batch 2200 Loss 5.4232 Accuracy 0.9934\n",
      "Epoch 11 Batch 2250 Loss 5.4238 Accuracy 0.9934\n",
      "Epoch 11 Batch 2300 Loss 5.4200 Accuracy 0.9934\n",
      "Epoch 11 Batch 2350 Loss 5.4202 Accuracy 0.9934\n",
      "Epoch 11 Batch 2400 Loss 5.4194 Accuracy 0.9934\n",
      "Epoch 11 Batch 2450 Loss 5.4198 Accuracy 0.9934\n",
      "Epoch 11 Batch 2500 Loss 5.4275 Accuracy 0.9934\n",
      "Epoch 11 Batch 2550 Loss 5.4267 Accuracy 0.9934\n",
      "Epoch 11 Batch 2600 Loss 5.4212 Accuracy 0.9934\n",
      "Epoch 11 Batch 2650 Loss 5.4180 Accuracy 0.9934\n",
      "Epoch 11 Loss 5.4183 Accuracy 0.9934\n",
      "Time taken for 1 epoch: 195.00993633270264 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 3.2435 Accuracy 0.9965\n",
      "Epoch 12 Batch 50 Loss 5.4611 Accuracy 0.9933\n",
      "Epoch 12 Batch 100 Loss 5.3455 Accuracy 0.9934\n",
      "Epoch 12 Batch 150 Loss 5.4242 Accuracy 0.9933\n",
      "Epoch 12 Batch 200 Loss 5.3208 Accuracy 0.9934\n",
      "Epoch 12 Batch 250 Loss 5.2846 Accuracy 0.9935\n",
      "Epoch 12 Batch 300 Loss 5.2914 Accuracy 0.9935\n",
      "Epoch 12 Batch 350 Loss 5.2823 Accuracy 0.9935\n",
      "Epoch 12 Batch 400 Loss 5.2639 Accuracy 0.9935\n",
      "Epoch 12 Batch 450 Loss 5.3085 Accuracy 0.9935\n",
      "Epoch 12 Batch 500 Loss 5.2905 Accuracy 0.9935\n",
      "Epoch 12 Batch 550 Loss 5.3155 Accuracy 0.9935\n",
      "Epoch 12 Batch 600 Loss 5.3418 Accuracy 0.9934\n",
      "Epoch 12 Batch 650 Loss 5.3381 Accuracy 0.9934\n",
      "Epoch 12 Batch 700 Loss 5.3310 Accuracy 0.9934\n",
      "Epoch 12 Batch 750 Loss 5.3243 Accuracy 0.9935\n",
      "Epoch 12 Batch 800 Loss 5.2985 Accuracy 0.9935\n",
      "Epoch 12 Batch 850 Loss 5.3019 Accuracy 0.9935\n",
      "Epoch 12 Batch 900 Loss 5.2953 Accuracy 0.9935\n",
      "Epoch 12 Batch 950 Loss 5.3020 Accuracy 0.9935\n",
      "Epoch 12 Batch 1000 Loss 5.2971 Accuracy 0.9935\n",
      "Epoch 12 Batch 1050 Loss 5.2808 Accuracy 0.9935\n",
      "Epoch 12 Batch 1100 Loss 5.2755 Accuracy 0.9935\n",
      "Epoch 12 Batch 1150 Loss 5.2589 Accuracy 0.9936\n",
      "Epoch 12 Batch 1200 Loss 5.2798 Accuracy 0.9935\n",
      "Epoch 12 Batch 1250 Loss 5.2660 Accuracy 0.9936\n",
      "Epoch 12 Batch 1300 Loss 5.2737 Accuracy 0.9935\n",
      "Epoch 12 Batch 1350 Loss 5.2643 Accuracy 0.9936\n",
      "Epoch 12 Batch 1400 Loss 5.2705 Accuracy 0.9935\n",
      "Epoch 12 Batch 1450 Loss 5.2584 Accuracy 0.9936\n",
      "Epoch 12 Batch 1500 Loss 5.2559 Accuracy 0.9936\n",
      "Epoch 12 Batch 1550 Loss 5.2617 Accuracy 0.9935\n",
      "Epoch 12 Batch 1600 Loss 5.2601 Accuracy 0.9935\n",
      "Epoch 12 Batch 1650 Loss 5.2574 Accuracy 0.9936\n",
      "Epoch 12 Batch 1700 Loss 5.2655 Accuracy 0.9935\n",
      "Epoch 12 Batch 1750 Loss 5.2531 Accuracy 0.9936\n",
      "Epoch 12 Batch 1800 Loss 5.2557 Accuracy 0.9936\n",
      "Epoch 12 Batch 1850 Loss 5.2424 Accuracy 0.9936\n",
      "Epoch 12 Batch 1900 Loss 5.2339 Accuracy 0.9936\n",
      "Epoch 12 Batch 1950 Loss 5.2189 Accuracy 0.9936\n",
      "Epoch 12 Batch 2000 Loss 5.2266 Accuracy 0.9936\n",
      "Epoch 12 Batch 2050 Loss 5.2355 Accuracy 0.9936\n",
      "Epoch 12 Batch 2100 Loss 5.2299 Accuracy 0.9936\n",
      "Epoch 12 Batch 2150 Loss 5.2312 Accuracy 0.9936\n",
      "Epoch 12 Batch 2200 Loss 5.2366 Accuracy 0.9936\n",
      "Epoch 12 Batch 2250 Loss 5.2385 Accuracy 0.9936\n",
      "Epoch 12 Batch 2300 Loss 5.2347 Accuracy 0.9936\n",
      "Epoch 12 Batch 2350 Loss 5.2336 Accuracy 0.9936\n",
      "Epoch 12 Batch 2400 Loss 5.2336 Accuracy 0.9936\n",
      "Epoch 12 Batch 2450 Loss 5.2365 Accuracy 0.9936\n",
      "Epoch 12 Batch 2500 Loss 5.2421 Accuracy 0.9936\n",
      "Epoch 12 Batch 2550 Loss 5.2399 Accuracy 0.9936\n",
      "Epoch 12 Batch 2600 Loss 5.2346 Accuracy 0.9936\n",
      "Epoch 12 Batch 2650 Loss 5.2307 Accuracy 0.9936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss 5.2307 Accuracy 0.9936\n",
      "Time taken for 1 epoch: 196.1765480041504 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 2.8147 Accuracy 0.9970\n",
      "Epoch 13 Batch 50 Loss 5.2693 Accuracy 0.9935\n",
      "Epoch 13 Batch 100 Loss 5.1500 Accuracy 0.9937\n",
      "Epoch 13 Batch 150 Loss 5.2429 Accuracy 0.9935\n",
      "Epoch 13 Batch 200 Loss 5.1335 Accuracy 0.9937\n",
      "Epoch 13 Batch 250 Loss 5.0945 Accuracy 0.9937\n",
      "Epoch 13 Batch 300 Loss 5.1163 Accuracy 0.9937\n",
      "Epoch 13 Batch 350 Loss 5.1089 Accuracy 0.9937\n",
      "Epoch 13 Batch 400 Loss 5.0898 Accuracy 0.9937\n",
      "Epoch 13 Batch 450 Loss 5.1341 Accuracy 0.9937\n",
      "Epoch 13 Batch 500 Loss 5.1173 Accuracy 0.9937\n",
      "Epoch 13 Batch 550 Loss 5.1441 Accuracy 0.9937\n",
      "Epoch 13 Batch 600 Loss 5.1715 Accuracy 0.9936\n",
      "Epoch 13 Batch 650 Loss 5.1738 Accuracy 0.9936\n",
      "Epoch 13 Batch 700 Loss 5.1706 Accuracy 0.9936\n",
      "Epoch 13 Batch 750 Loss 5.1617 Accuracy 0.9936\n",
      "Epoch 13 Batch 800 Loss 5.1365 Accuracy 0.9937\n",
      "Epoch 13 Batch 850 Loss 5.1385 Accuracy 0.9937\n",
      "Epoch 13 Batch 900 Loss 5.1334 Accuracy 0.9937\n",
      "Epoch 13 Batch 950 Loss 5.1407 Accuracy 0.9937\n",
      "Epoch 13 Batch 1000 Loss 5.1343 Accuracy 0.9937\n",
      "Epoch 13 Batch 1050 Loss 5.1168 Accuracy 0.9937\n",
      "Epoch 13 Batch 1100 Loss 5.1112 Accuracy 0.9937\n",
      "Epoch 13 Batch 1150 Loss 5.0949 Accuracy 0.9937\n",
      "Epoch 13 Batch 1200 Loss 5.1160 Accuracy 0.9937\n",
      "Epoch 13 Batch 1250 Loss 5.1047 Accuracy 0.9937\n",
      "Epoch 13 Batch 1300 Loss 5.1126 Accuracy 0.9937\n",
      "Epoch 13 Batch 1350 Loss 5.1035 Accuracy 0.9937\n",
      "Epoch 13 Batch 1400 Loss 5.1120 Accuracy 0.9937\n",
      "Epoch 13 Batch 1450 Loss 5.0990 Accuracy 0.9937\n",
      "Epoch 13 Batch 1500 Loss 5.0954 Accuracy 0.9937\n",
      "Epoch 13 Batch 1550 Loss 5.1004 Accuracy 0.9937\n",
      "Epoch 13 Batch 1600 Loss 5.0979 Accuracy 0.9937\n",
      "Epoch 13 Batch 1650 Loss 5.0955 Accuracy 0.9937\n",
      "Epoch 13 Batch 1700 Loss 5.1045 Accuracy 0.9937\n",
      "Epoch 13 Batch 1750 Loss 5.0929 Accuracy 0.9937\n",
      "Epoch 13 Batch 1800 Loss 5.0944 Accuracy 0.9937\n",
      "Epoch 13 Batch 1850 Loss 5.0821 Accuracy 0.9938\n",
      "Epoch 13 Batch 1900 Loss 5.0741 Accuracy 0.9938\n",
      "Epoch 13 Batch 1950 Loss 5.0598 Accuracy 0.9938\n",
      "Epoch 13 Batch 2000 Loss 5.0683 Accuracy 0.9938\n",
      "Epoch 13 Batch 2050 Loss 5.0779 Accuracy 0.9938\n",
      "Epoch 13 Batch 2100 Loss 5.0738 Accuracy 0.9938\n",
      "Epoch 13 Batch 2150 Loss 5.0770 Accuracy 0.9938\n",
      "Epoch 13 Batch 2200 Loss 5.0833 Accuracy 0.9938\n",
      "Epoch 13 Batch 2250 Loss 5.0852 Accuracy 0.9938\n",
      "Epoch 13 Batch 2300 Loss 5.0812 Accuracy 0.9938\n",
      "Epoch 13 Batch 2350 Loss 5.0793 Accuracy 0.9938\n",
      "Epoch 13 Batch 2400 Loss 5.0783 Accuracy 0.9938\n",
      "Epoch 13 Batch 2450 Loss 5.0803 Accuracy 0.9938\n",
      "Epoch 13 Batch 2500 Loss 5.0857 Accuracy 0.9937\n",
      "Epoch 13 Batch 2550 Loss 5.0841 Accuracy 0.9937\n",
      "Epoch 13 Batch 2600 Loss 5.0793 Accuracy 0.9938\n",
      "Epoch 13 Batch 2650 Loss 5.0758 Accuracy 0.9938\n",
      "Epoch 13 Loss 5.0769 Accuracy 0.9938\n",
      "Time taken for 1 epoch: 197.23370838165283 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 2.7218 Accuracy 0.9968\n",
      "Epoch 14 Batch 50 Loss 5.1596 Accuracy 0.9936\n",
      "Epoch 14 Batch 100 Loss 5.0613 Accuracy 0.9937\n",
      "Epoch 14 Batch 150 Loss 5.1293 Accuracy 0.9937\n",
      "Epoch 14 Batch 200 Loss 5.0073 Accuracy 0.9938\n",
      "Epoch 14 Batch 250 Loss 4.9756 Accuracy 0.9939\n",
      "Epoch 14 Batch 300 Loss 4.9785 Accuracy 0.9938\n",
      "Epoch 14 Batch 350 Loss 4.9845 Accuracy 0.9938\n",
      "Epoch 14 Batch 400 Loss 4.9693 Accuracy 0.9939\n",
      "Epoch 14 Batch 450 Loss 5.0172 Accuracy 0.9938\n",
      "Epoch 14 Batch 500 Loss 4.9953 Accuracy 0.9938\n",
      "Epoch 14 Batch 550 Loss 5.0178 Accuracy 0.9938\n",
      "Epoch 14 Batch 600 Loss 5.0480 Accuracy 0.9938\n",
      "Epoch 14 Batch 650 Loss 5.0470 Accuracy 0.9938\n",
      "Epoch 14 Batch 700 Loss 5.0370 Accuracy 0.9938\n",
      "Epoch 14 Batch 750 Loss 5.0252 Accuracy 0.9938\n",
      "Epoch 14 Batch 800 Loss 5.0011 Accuracy 0.9938\n",
      "Epoch 14 Batch 850 Loss 5.0043 Accuracy 0.9938\n",
      "Epoch 14 Batch 900 Loss 4.9981 Accuracy 0.9938\n",
      "Epoch 14 Batch 950 Loss 5.0028 Accuracy 0.9938\n",
      "Epoch 14 Batch 1000 Loss 5.0002 Accuracy 0.9938\n",
      "Epoch 14 Batch 1050 Loss 4.9828 Accuracy 0.9939\n",
      "Epoch 14 Batch 1100 Loss 4.9797 Accuracy 0.9939\n",
      "Epoch 14 Batch 1150 Loss 4.9658 Accuracy 0.9939\n",
      "Epoch 14 Batch 1200 Loss 4.9884 Accuracy 0.9939\n",
      "Epoch 14 Batch 1250 Loss 4.9763 Accuracy 0.9939\n",
      "Epoch 14 Batch 1300 Loss 4.9813 Accuracy 0.9939\n",
      "Epoch 14 Batch 1350 Loss 4.9724 Accuracy 0.9939\n",
      "Epoch 14 Batch 1400 Loss 4.9785 Accuracy 0.9939\n",
      "Epoch 14 Batch 1450 Loss 4.9652 Accuracy 0.9939\n",
      "Epoch 14 Batch 1500 Loss 4.9624 Accuracy 0.9939\n",
      "Epoch 14 Batch 1550 Loss 4.9683 Accuracy 0.9939\n",
      "Epoch 14 Batch 1600 Loss 4.9655 Accuracy 0.9939\n",
      "Epoch 14 Batch 1650 Loss 4.9632 Accuracy 0.9939\n",
      "Epoch 14 Batch 1700 Loss 4.9709 Accuracy 0.9939\n",
      "Epoch 14 Batch 1750 Loss 4.9612 Accuracy 0.9939\n",
      "Epoch 14 Batch 1800 Loss 4.9639 Accuracy 0.9939\n",
      "Epoch 14 Batch 1850 Loss 4.9524 Accuracy 0.9939\n",
      "Epoch 14 Batch 1900 Loss 4.9453 Accuracy 0.9939\n",
      "Epoch 14 Batch 1950 Loss 4.9301 Accuracy 0.9939\n",
      "Epoch 14 Batch 2000 Loss 4.9389 Accuracy 0.9939\n",
      "Epoch 14 Batch 2050 Loss 4.9472 Accuracy 0.9939\n",
      "Epoch 14 Batch 2100 Loss 4.9429 Accuracy 0.9939\n",
      "Epoch 14 Batch 2150 Loss 4.9461 Accuracy 0.9939\n",
      "Epoch 14 Batch 2200 Loss 4.9531 Accuracy 0.9939\n",
      "Epoch 14 Batch 2250 Loss 4.9566 Accuracy 0.9939\n",
      "Epoch 14 Batch 2300 Loss 4.9521 Accuracy 0.9939\n",
      "Epoch 14 Batch 2350 Loss 4.9516 Accuracy 0.9939\n",
      "Epoch 14 Batch 2400 Loss 4.9516 Accuracy 0.9939\n",
      "Epoch 14 Batch 2450 Loss 4.9532 Accuracy 0.9939\n",
      "Epoch 14 Batch 2500 Loss 4.9579 Accuracy 0.9939\n",
      "Epoch 14 Batch 2550 Loss 4.9568 Accuracy 0.9939\n",
      "Epoch 14 Batch 2600 Loss 4.9519 Accuracy 0.9939\n",
      "Epoch 14 Batch 2650 Loss 4.9476 Accuracy 0.9939\n",
      "Epoch 14 Loss 4.9491 Accuracy 0.9939\n",
      "Time taken for 1 epoch: 197.1195650100708 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 2.9570 Accuracy 0.9970\n",
      "Epoch 15 Batch 50 Loss 5.0205 Accuracy 0.9938\n",
      "Epoch 15 Batch 100 Loss 4.9189 Accuracy 0.9939\n",
      "Epoch 15 Batch 150 Loss 4.9880 Accuracy 0.9938\n",
      "Epoch 15 Batch 200 Loss 4.8655 Accuracy 0.9940\n",
      "Epoch 15 Batch 250 Loss 4.8371 Accuracy 0.9940\n",
      "Epoch 15 Batch 300 Loss 4.8506 Accuracy 0.9940\n",
      "Epoch 15 Batch 350 Loss 4.8499 Accuracy 0.9940\n",
      "Epoch 15 Batch 400 Loss 4.8398 Accuracy 0.9940\n",
      "Epoch 15 Batch 450 Loss 4.8866 Accuracy 0.9939\n",
      "Epoch 15 Batch 500 Loss 4.8663 Accuracy 0.9940\n",
      "Epoch 15 Batch 550 Loss 4.8892 Accuracy 0.9939\n",
      "Epoch 15 Batch 600 Loss 4.9158 Accuracy 0.9939\n",
      "Epoch 15 Batch 650 Loss 4.9151 Accuracy 0.9939\n",
      "Epoch 15 Batch 700 Loss 4.9034 Accuracy 0.9939\n",
      "Epoch 15 Batch 750 Loss 4.8913 Accuracy 0.9939\n",
      "Epoch 15 Batch 800 Loss 4.8667 Accuracy 0.9940\n",
      "Epoch 15 Batch 850 Loss 4.8699 Accuracy 0.9940\n",
      "Epoch 15 Batch 900 Loss 4.8637 Accuracy 0.9940\n",
      "Epoch 15 Batch 950 Loss 4.8695 Accuracy 0.9940\n",
      "Epoch 15 Batch 1000 Loss 4.8642 Accuracy 0.9940\n",
      "Epoch 15 Batch 1050 Loss 4.8466 Accuracy 0.9940\n",
      "Epoch 15 Batch 1100 Loss 4.8449 Accuracy 0.9940\n",
      "Epoch 15 Batch 1150 Loss 4.8284 Accuracy 0.9940\n",
      "Epoch 15 Batch 1200 Loss 4.8502 Accuracy 0.9940\n",
      "Epoch 15 Batch 1250 Loss 4.8394 Accuracy 0.9940\n",
      "Epoch 15 Batch 1300 Loss 4.8451 Accuracy 0.9940\n",
      "Epoch 15 Batch 1350 Loss 4.8357 Accuracy 0.9940\n",
      "Epoch 15 Batch 1400 Loss 4.8430 Accuracy 0.9940\n",
      "Epoch 15 Batch 1450 Loss 4.8331 Accuracy 0.9940\n",
      "Epoch 15 Batch 1500 Loss 4.8313 Accuracy 0.9940\n",
      "Epoch 15 Batch 1550 Loss 4.8378 Accuracy 0.9940\n",
      "Epoch 15 Batch 1600 Loss 4.8355 Accuracy 0.9940\n",
      "Epoch 15 Batch 1650 Loss 4.8304 Accuracy 0.9940\n",
      "Epoch 15 Batch 1700 Loss 4.8386 Accuracy 0.9940\n",
      "Epoch 15 Batch 1750 Loss 4.8269 Accuracy 0.9940\n",
      "Epoch 15 Batch 1800 Loss 4.8296 Accuracy 0.9940\n",
      "Epoch 15 Batch 1850 Loss 4.8181 Accuracy 0.9940\n",
      "Epoch 15 Batch 1900 Loss 4.8107 Accuracy 0.9941\n",
      "Epoch 15 Batch 1950 Loss 4.7974 Accuracy 0.9941\n",
      "Epoch 15 Batch 2000 Loss 4.8050 Accuracy 0.9941\n",
      "Epoch 15 Batch 2050 Loss 4.8135 Accuracy 0.9940\n",
      "Epoch 15 Batch 2100 Loss 4.8091 Accuracy 0.9941\n",
      "Epoch 15 Batch 2150 Loss 4.8107 Accuracy 0.9941\n",
      "Epoch 15 Batch 2200 Loss 4.8161 Accuracy 0.9940\n",
      "Epoch 15 Batch 2250 Loss 4.8186 Accuracy 0.9940\n",
      "Epoch 15 Batch 2300 Loss 4.8139 Accuracy 0.9941\n",
      "Epoch 15 Batch 2350 Loss 4.8128 Accuracy 0.9940\n",
      "Epoch 15 Batch 2400 Loss 4.8134 Accuracy 0.9940\n",
      "Epoch 15 Batch 2450 Loss 4.8144 Accuracy 0.9940\n",
      "Epoch 15 Batch 2500 Loss 4.8201 Accuracy 0.9940\n",
      "Epoch 15 Batch 2550 Loss 4.8187 Accuracy 0.9940\n",
      "Epoch 15 Batch 2600 Loss 4.8149 Accuracy 0.9940\n",
      "Epoch 15 Batch 2650 Loss 4.8105 Accuracy 0.9940\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/train\\ckpt-4\n",
      "Epoch 15 Loss 4.8112 Accuracy 0.9940\n",
      "Time taken for 1 epoch: 195.66349816322327 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 2.7414 Accuracy 0.9972\n",
      "Epoch 16 Batch 50 Loss 4.8133 Accuracy 0.9940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 100 Loss 4.7332 Accuracy 0.9941\n",
      "Epoch 16 Batch 150 Loss 4.8486 Accuracy 0.9940\n",
      "Epoch 16 Batch 200 Loss 4.7426 Accuracy 0.9941\n",
      "Epoch 16 Batch 250 Loss 4.7135 Accuracy 0.9942\n",
      "Epoch 16 Batch 300 Loss 4.7268 Accuracy 0.9941\n",
      "Epoch 16 Batch 350 Loss 4.7247 Accuracy 0.9941\n",
      "Epoch 16 Batch 400 Loss 4.7107 Accuracy 0.9942\n",
      "Epoch 16 Batch 450 Loss 4.7593 Accuracy 0.9941\n",
      "Epoch 16 Batch 500 Loss 4.7479 Accuracy 0.9941\n",
      "Epoch 16 Batch 550 Loss 4.7695 Accuracy 0.9941\n",
      "Epoch 16 Batch 600 Loss 4.7976 Accuracy 0.9941\n",
      "Epoch 16 Batch 650 Loss 4.7949 Accuracy 0.9941\n",
      "Epoch 16 Batch 700 Loss 4.7854 Accuracy 0.9941\n",
      "Epoch 16 Batch 750 Loss 4.7780 Accuracy 0.9941\n",
      "Epoch 16 Batch 800 Loss 4.7591 Accuracy 0.9941\n",
      "Epoch 16 Batch 850 Loss 4.7644 Accuracy 0.9941\n",
      "Epoch 16 Batch 900 Loss 4.7628 Accuracy 0.9941\n",
      "Epoch 16 Batch 950 Loss 4.7696 Accuracy 0.9941\n",
      "Epoch 16 Batch 1000 Loss 4.7670 Accuracy 0.9941\n",
      "Epoch 16 Batch 1050 Loss 4.7508 Accuracy 0.9941\n",
      "Epoch 16 Batch 1100 Loss 4.7478 Accuracy 0.9941\n",
      "Epoch 16 Batch 1150 Loss 4.7321 Accuracy 0.9942\n",
      "Epoch 16 Batch 1200 Loss 4.7515 Accuracy 0.9941\n",
      "Epoch 16 Batch 1250 Loss 4.7369 Accuracy 0.9941\n",
      "Epoch 16 Batch 1300 Loss 4.7434 Accuracy 0.9941\n",
      "Epoch 16 Batch 1350 Loss 4.7342 Accuracy 0.9941\n",
      "Epoch 16 Batch 1400 Loss 4.7384 Accuracy 0.9941\n",
      "Epoch 16 Batch 1450 Loss 4.7286 Accuracy 0.9942\n",
      "Epoch 16 Batch 1500 Loss 4.7248 Accuracy 0.9942\n",
      "Epoch 16 Batch 1550 Loss 4.7283 Accuracy 0.9942\n",
      "Epoch 16 Batch 1600 Loss 4.7267 Accuracy 0.9942\n",
      "Epoch 16 Batch 1650 Loss 4.7223 Accuracy 0.9942\n",
      "Epoch 16 Batch 1700 Loss 4.7297 Accuracy 0.9941\n",
      "Epoch 16 Batch 1750 Loss 4.7170 Accuracy 0.9942\n",
      "Epoch 16 Batch 1800 Loss 4.7184 Accuracy 0.9942\n",
      "Epoch 16 Batch 1850 Loss 4.7044 Accuracy 0.9942\n",
      "Epoch 16 Batch 1900 Loss 4.6971 Accuracy 0.9942\n",
      "Epoch 16 Batch 1950 Loss 4.6839 Accuracy 0.9942\n",
      "Epoch 16 Batch 2000 Loss 4.6930 Accuracy 0.9942\n",
      "Epoch 16 Batch 2050 Loss 4.7013 Accuracy 0.9942\n",
      "Epoch 16 Batch 2100 Loss 4.6978 Accuracy 0.9942\n",
      "Epoch 16 Batch 2150 Loss 4.7005 Accuracy 0.9942\n",
      "Epoch 16 Batch 2200 Loss 4.7057 Accuracy 0.9942\n",
      "Epoch 16 Batch 2250 Loss 4.7071 Accuracy 0.9942\n",
      "Epoch 16 Batch 2300 Loss 4.7021 Accuracy 0.9942\n",
      "Epoch 16 Batch 2350 Loss 4.7018 Accuracy 0.9942\n",
      "Epoch 16 Batch 2400 Loss 4.7032 Accuracy 0.9942\n",
      "Epoch 16 Batch 2450 Loss 4.7053 Accuracy 0.9942\n",
      "Epoch 16 Batch 2500 Loss 4.7110 Accuracy 0.9942\n",
      "Epoch 16 Batch 2550 Loss 4.7099 Accuracy 0.9942\n",
      "Epoch 16 Batch 2600 Loss 4.7041 Accuracy 0.9942\n",
      "Epoch 16 Batch 2650 Loss 4.7009 Accuracy 0.9942\n",
      "Epoch 16 Loss 4.7016 Accuracy 0.9942\n",
      "Time taken for 1 epoch: 196.02349090576172 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 2.8205 Accuracy 0.9968\n",
      "Epoch 17 Batch 50 Loss 4.7773 Accuracy 0.9940\n",
      "Epoch 17 Batch 100 Loss 4.7022 Accuracy 0.9941\n",
      "Epoch 17 Batch 150 Loss 4.7793 Accuracy 0.9941\n",
      "Epoch 17 Batch 200 Loss 4.6580 Accuracy 0.9942\n",
      "Epoch 17 Batch 250 Loss 4.6330 Accuracy 0.9942\n",
      "Epoch 17 Batch 300 Loss 4.6421 Accuracy 0.9942\n",
      "Epoch 17 Batch 350 Loss 4.6313 Accuracy 0.9942\n",
      "Epoch 17 Batch 400 Loss 4.6178 Accuracy 0.9942\n",
      "Epoch 17 Batch 450 Loss 4.6580 Accuracy 0.9942\n",
      "Epoch 17 Batch 500 Loss 4.6487 Accuracy 0.9942\n",
      "Epoch 17 Batch 550 Loss 4.6709 Accuracy 0.9942\n",
      "Epoch 17 Batch 600 Loss 4.6967 Accuracy 0.9941\n",
      "Epoch 17 Batch 650 Loss 4.6905 Accuracy 0.9941\n",
      "Epoch 17 Batch 700 Loss 4.6827 Accuracy 0.9942\n",
      "Epoch 17 Batch 750 Loss 4.6739 Accuracy 0.9942\n",
      "Epoch 17 Batch 800 Loss 4.6482 Accuracy 0.9942\n",
      "Epoch 17 Batch 850 Loss 4.6521 Accuracy 0.9942\n",
      "Epoch 17 Batch 900 Loss 4.6439 Accuracy 0.9942\n",
      "Epoch 17 Batch 950 Loss 4.6512 Accuracy 0.9942\n",
      "Epoch 17 Batch 1000 Loss 4.6454 Accuracy 0.9942\n",
      "Epoch 17 Batch 1050 Loss 4.6290 Accuracy 0.9942\n",
      "Epoch 17 Batch 1100 Loss 4.6276 Accuracy 0.9942\n",
      "Epoch 17 Batch 1150 Loss 4.6122 Accuracy 0.9943\n",
      "Epoch 17 Batch 1200 Loss 4.6281 Accuracy 0.9943\n",
      "Epoch 17 Batch 1250 Loss 4.6155 Accuracy 0.9943\n",
      "Epoch 17 Batch 1300 Loss 4.6195 Accuracy 0.9943\n",
      "Epoch 17 Batch 1350 Loss 4.6099 Accuracy 0.9943\n",
      "Epoch 17 Batch 1400 Loss 4.6150 Accuracy 0.9943\n",
      "Epoch 17 Batch 1450 Loss 4.6057 Accuracy 0.9943\n",
      "Epoch 17 Batch 1500 Loss 4.6029 Accuracy 0.9943\n",
      "Epoch 17 Batch 1550 Loss 4.6083 Accuracy 0.9943\n",
      "Epoch 17 Batch 1600 Loss 4.6077 Accuracy 0.9943\n",
      "Epoch 17 Batch 1650 Loss 4.6063 Accuracy 0.9943\n",
      "Epoch 17 Batch 1700 Loss 4.6155 Accuracy 0.9943\n",
      "Epoch 17 Batch 1750 Loss 4.6039 Accuracy 0.9943\n",
      "Epoch 17 Batch 1800 Loss 4.6073 Accuracy 0.9943\n",
      "Epoch 17 Batch 1850 Loss 4.5970 Accuracy 0.9943\n",
      "Epoch 17 Batch 1900 Loss 4.5898 Accuracy 0.9943\n",
      "Epoch 17 Batch 1950 Loss 4.5774 Accuracy 0.9943\n",
      "Epoch 17 Batch 2000 Loss 4.5855 Accuracy 0.9943\n",
      "Epoch 17 Batch 2050 Loss 4.5952 Accuracy 0.9943\n",
      "Epoch 17 Batch 2100 Loss 4.5910 Accuracy 0.9943\n",
      "Epoch 17 Batch 2150 Loss 4.5930 Accuracy 0.9943\n",
      "Epoch 17 Batch 2200 Loss 4.5981 Accuracy 0.9943\n",
      "Epoch 17 Batch 2250 Loss 4.6009 Accuracy 0.9943\n",
      "Epoch 17 Batch 2300 Loss 4.5960 Accuracy 0.9943\n",
      "Epoch 17 Batch 2350 Loss 4.5939 Accuracy 0.9943\n",
      "Epoch 17 Batch 2400 Loss 4.5934 Accuracy 0.9943\n",
      "Epoch 17 Batch 2450 Loss 4.5948 Accuracy 0.9943\n",
      "Epoch 17 Batch 2500 Loss 4.6003 Accuracy 0.9943\n",
      "Epoch 17 Batch 2550 Loss 4.6001 Accuracy 0.9943\n",
      "Epoch 17 Batch 2600 Loss 4.5958 Accuracy 0.9943\n",
      "Epoch 17 Batch 2650 Loss 4.5927 Accuracy 0.9943\n",
      "Epoch 17 Loss 4.5946 Accuracy 0.9943\n",
      "Time taken for 1 epoch: 196.35967540740967 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 3.1231 Accuracy 0.9964\n",
      "Epoch 18 Batch 50 Loss 4.6800 Accuracy 0.9941\n",
      "Epoch 18 Batch 100 Loss 4.5949 Accuracy 0.9943\n",
      "Epoch 18 Batch 150 Loss 4.6733 Accuracy 0.9942\n",
      "Epoch 18 Batch 200 Loss 4.5525 Accuracy 0.9943\n",
      "Epoch 18 Batch 250 Loss 4.5155 Accuracy 0.9944\n",
      "Epoch 18 Batch 300 Loss 4.5269 Accuracy 0.9943\n",
      "Epoch 18 Batch 350 Loss 4.5262 Accuracy 0.9943\n",
      "Epoch 18 Batch 400 Loss 4.5091 Accuracy 0.9944\n",
      "Epoch 18 Batch 450 Loss 4.5557 Accuracy 0.9943\n",
      "Epoch 18 Batch 500 Loss 4.5414 Accuracy 0.9943\n",
      "Epoch 18 Batch 550 Loss 4.5671 Accuracy 0.9943\n",
      "Epoch 18 Batch 600 Loss 4.5963 Accuracy 0.9943\n",
      "Epoch 18 Batch 650 Loss 4.5927 Accuracy 0.9943\n",
      "Epoch 18 Batch 700 Loss 4.5866 Accuracy 0.9943\n",
      "Epoch 18 Batch 750 Loss 4.5817 Accuracy 0.9943\n",
      "Epoch 18 Batch 800 Loss 4.5552 Accuracy 0.9943\n",
      "Epoch 18 Batch 850 Loss 4.5613 Accuracy 0.9943\n",
      "Epoch 18 Batch 900 Loss 4.5573 Accuracy 0.9943\n",
      "Epoch 18 Batch 950 Loss 4.5634 Accuracy 0.9943\n",
      "Epoch 18 Batch 1000 Loss 4.5601 Accuracy 0.9943\n",
      "Epoch 18 Batch 1050 Loss 4.5430 Accuracy 0.9943\n",
      "Epoch 18 Batch 1100 Loss 4.5412 Accuracy 0.9944\n",
      "Epoch 18 Batch 1150 Loss 4.5255 Accuracy 0.9944\n",
      "Epoch 18 Batch 1200 Loss 4.5441 Accuracy 0.9943\n",
      "Epoch 18 Batch 1250 Loss 4.5335 Accuracy 0.9944\n",
      "Epoch 18 Batch 1300 Loss 4.5398 Accuracy 0.9944\n",
      "Epoch 18 Batch 1350 Loss 4.5303 Accuracy 0.9944\n",
      "Epoch 18 Batch 1400 Loss 4.5338 Accuracy 0.9944\n",
      "Epoch 18 Batch 1450 Loss 4.5208 Accuracy 0.9944\n",
      "Epoch 18 Batch 1500 Loss 4.5180 Accuracy 0.9944\n",
      "Epoch 18 Batch 1550 Loss 4.5229 Accuracy 0.9944\n",
      "Epoch 18 Batch 1600 Loss 4.5202 Accuracy 0.9944\n",
      "Epoch 18 Batch 1650 Loss 4.5151 Accuracy 0.9944\n",
      "Epoch 18 Batch 1700 Loss 4.5245 Accuracy 0.9944\n",
      "Epoch 18 Batch 1750 Loss 4.5130 Accuracy 0.9944\n",
      "Epoch 18 Batch 1800 Loss 4.5125 Accuracy 0.9944\n",
      "Epoch 18 Batch 1850 Loss 4.5036 Accuracy 0.9944\n",
      "Epoch 18 Batch 1900 Loss 4.4961 Accuracy 0.9944\n",
      "Epoch 18 Batch 1950 Loss 4.4825 Accuracy 0.9944\n",
      "Epoch 18 Batch 2000 Loss 4.4893 Accuracy 0.9944\n",
      "Epoch 18 Batch 2050 Loss 4.4982 Accuracy 0.9944\n",
      "Epoch 18 Batch 2100 Loss 4.4949 Accuracy 0.9944\n",
      "Epoch 18 Batch 2150 Loss 4.4977 Accuracy 0.9944\n",
      "Epoch 18 Batch 2200 Loss 4.5021 Accuracy 0.9944\n",
      "Epoch 18 Batch 2250 Loss 4.5046 Accuracy 0.9944\n",
      "Epoch 18 Batch 2300 Loss 4.4990 Accuracy 0.9944\n",
      "Epoch 18 Batch 2350 Loss 4.4991 Accuracy 0.9944\n",
      "Epoch 18 Batch 2400 Loss 4.4992 Accuracy 0.9944\n",
      "Epoch 18 Batch 2450 Loss 4.5018 Accuracy 0.9944\n",
      "Epoch 18 Batch 2500 Loss 4.5076 Accuracy 0.9944\n",
      "Epoch 18 Batch 2550 Loss 4.5067 Accuracy 0.9944\n",
      "Epoch 18 Batch 2600 Loss 4.5023 Accuracy 0.9944\n",
      "Epoch 18 Batch 2650 Loss 4.4992 Accuracy 0.9944\n",
      "Epoch 18 Loss 4.5002 Accuracy 0.9944\n",
      "Time taken for 1 epoch: 195.66713643074036 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 2.7797 Accuracy 0.9968\n",
      "Epoch 19 Batch 50 Loss 4.5807 Accuracy 0.9943\n",
      "Epoch 19 Batch 100 Loss 4.4911 Accuracy 0.9944\n",
      "Epoch 19 Batch 150 Loss 4.5549 Accuracy 0.9943\n",
      "Epoch 19 Batch 200 Loss 4.4551 Accuracy 0.9944\n",
      "Epoch 19 Batch 250 Loss 4.4195 Accuracy 0.9945\n",
      "Epoch 19 Batch 300 Loss 4.4205 Accuracy 0.9945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 350 Loss 4.4196 Accuracy 0.9945\n",
      "Epoch 19 Batch 400 Loss 4.4141 Accuracy 0.9945\n",
      "Epoch 19 Batch 450 Loss 4.4650 Accuracy 0.9944\n",
      "Epoch 19 Batch 500 Loss 4.4559 Accuracy 0.9944\n",
      "Epoch 19 Batch 550 Loss 4.4781 Accuracy 0.9944\n",
      "Epoch 19 Batch 600 Loss 4.5019 Accuracy 0.9944\n",
      "Epoch 19 Batch 650 Loss 4.5017 Accuracy 0.9944\n",
      "Epoch 19 Batch 700 Loss 4.4959 Accuracy 0.9944\n",
      "Epoch 19 Batch 750 Loss 4.4862 Accuracy 0.9944\n",
      "Epoch 19 Batch 800 Loss 4.4625 Accuracy 0.9944\n",
      "Epoch 19 Batch 850 Loss 4.4683 Accuracy 0.9944\n",
      "Epoch 19 Batch 900 Loss 4.4631 Accuracy 0.9944\n",
      "Epoch 19 Batch 950 Loss 4.4721 Accuracy 0.9944\n",
      "Epoch 19 Batch 1000 Loss 4.4655 Accuracy 0.9944\n",
      "Epoch 19 Batch 1050 Loss 4.4470 Accuracy 0.9945\n",
      "Epoch 19 Batch 1100 Loss 4.4436 Accuracy 0.9945\n",
      "Epoch 19 Batch 1150 Loss 4.4276 Accuracy 0.9945\n",
      "Epoch 19 Batch 1200 Loss 4.4445 Accuracy 0.9945\n",
      "Epoch 19 Batch 1250 Loss 4.4333 Accuracy 0.9945\n",
      "Epoch 19 Batch 1300 Loss 4.4376 Accuracy 0.9945\n",
      "Epoch 19 Batch 1350 Loss 4.4282 Accuracy 0.9945\n",
      "Epoch 19 Batch 1400 Loss 4.4325 Accuracy 0.9945\n",
      "Epoch 19 Batch 1450 Loss 4.4209 Accuracy 0.9945\n",
      "Epoch 19 Batch 1500 Loss 4.4182 Accuracy 0.9945\n",
      "Epoch 19 Batch 1550 Loss 4.4238 Accuracy 0.9945\n",
      "Epoch 19 Batch 1600 Loss 4.4236 Accuracy 0.9945\n",
      "Epoch 19 Batch 1650 Loss 4.4197 Accuracy 0.9945\n",
      "Epoch 19 Batch 1700 Loss 4.4257 Accuracy 0.9945\n",
      "Epoch 19 Batch 1750 Loss 4.4141 Accuracy 0.9945\n",
      "Epoch 19 Batch 1800 Loss 4.4138 Accuracy 0.9945\n",
      "Epoch 19 Batch 1850 Loss 4.4018 Accuracy 0.9945\n",
      "Epoch 19 Batch 1900 Loss 4.3955 Accuracy 0.9945\n",
      "Epoch 19 Batch 1950 Loss 4.3822 Accuracy 0.9946\n",
      "Epoch 19 Batch 2000 Loss 4.3888 Accuracy 0.9945\n",
      "Epoch 19 Batch 2050 Loss 4.3978 Accuracy 0.9945\n",
      "Epoch 19 Batch 2100 Loss 4.3945 Accuracy 0.9945\n",
      "Epoch 19 Batch 2150 Loss 4.3974 Accuracy 0.9945\n",
      "Epoch 19 Batch 2200 Loss 4.4027 Accuracy 0.9945\n",
      "Epoch 19 Batch 2250 Loss 4.4054 Accuracy 0.9945\n",
      "Epoch 19 Batch 2300 Loss 4.4019 Accuracy 0.9945\n",
      "Epoch 19 Batch 2350 Loss 4.4014 Accuracy 0.9945\n",
      "Epoch 19 Batch 2400 Loss 4.4027 Accuracy 0.9945\n",
      "Epoch 19 Batch 2450 Loss 4.4053 Accuracy 0.9945\n",
      "Epoch 19 Batch 2500 Loss 4.4098 Accuracy 0.9945\n",
      "Epoch 19 Batch 2550 Loss 4.4086 Accuracy 0.9945\n",
      "Epoch 19 Batch 2600 Loss 4.4044 Accuracy 0.9945\n",
      "Epoch 19 Batch 2650 Loss 4.4023 Accuracy 0.9945\n",
      "Epoch 19 Loss 4.4042 Accuracy 0.9945\n",
      "Time taken for 1 epoch: 196.40640091896057 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 2.6364 Accuracy 0.9969\n",
      "Epoch 20 Batch 50 Loss 4.4642 Accuracy 0.9944\n",
      "Epoch 20 Batch 100 Loss 4.4053 Accuracy 0.9945\n",
      "Epoch 20 Batch 150 Loss 4.4561 Accuracy 0.9944\n",
      "Epoch 20 Batch 200 Loss 4.3603 Accuracy 0.9945\n",
      "Epoch 20 Batch 250 Loss 4.3316 Accuracy 0.9946\n",
      "Epoch 20 Batch 300 Loss 4.3437 Accuracy 0.9946\n",
      "Epoch 20 Batch 350 Loss 4.3491 Accuracy 0.9946\n",
      "Epoch 20 Batch 400 Loss 4.3382 Accuracy 0.9946\n",
      "Epoch 20 Batch 450 Loss 4.3795 Accuracy 0.9945\n",
      "Epoch 20 Batch 500 Loss 4.3604 Accuracy 0.9946\n",
      "Epoch 20 Batch 550 Loss 4.3777 Accuracy 0.9945\n",
      "Epoch 20 Batch 600 Loss 4.4011 Accuracy 0.9945\n",
      "Epoch 20 Batch 650 Loss 4.3969 Accuracy 0.9945\n",
      "Epoch 20 Batch 700 Loss 4.3955 Accuracy 0.9945\n",
      "Epoch 20 Batch 750 Loss 4.3887 Accuracy 0.9945\n",
      "Epoch 20 Batch 800 Loss 4.3692 Accuracy 0.9945\n",
      "Epoch 20 Batch 850 Loss 4.3732 Accuracy 0.9945\n",
      "Epoch 20 Batch 900 Loss 4.3714 Accuracy 0.9945\n",
      "Epoch 20 Batch 950 Loss 4.3772 Accuracy 0.9945\n",
      "Epoch 20 Batch 1000 Loss 4.3714 Accuracy 0.9945\n",
      "Epoch 20 Batch 1050 Loss 4.3581 Accuracy 0.9946\n",
      "Epoch 20 Batch 1100 Loss 4.3564 Accuracy 0.9946\n",
      "Epoch 20 Batch 1150 Loss 4.3427 Accuracy 0.9946\n",
      "Epoch 20 Batch 1200 Loss 4.3619 Accuracy 0.9946\n",
      "Epoch 20 Batch 1250 Loss 4.3512 Accuracy 0.9946\n",
      "Epoch 20 Batch 1300 Loss 4.3558 Accuracy 0.9946\n",
      "Epoch 20 Batch 1350 Loss 4.3454 Accuracy 0.9946\n",
      "Epoch 20 Batch 1400 Loss 4.3515 Accuracy 0.9946\n",
      "Epoch 20 Batch 1450 Loss 4.3427 Accuracy 0.9946\n",
      "Epoch 20 Batch 1500 Loss 4.3400 Accuracy 0.9946\n",
      "Epoch 20 Batch 1550 Loss 4.3451 Accuracy 0.9946\n",
      "Epoch 20 Batch 1600 Loss 4.3431 Accuracy 0.9946\n",
      "Epoch 20 Batch 1650 Loss 4.3398 Accuracy 0.9946\n",
      "Epoch 20 Batch 1700 Loss 4.3450 Accuracy 0.9946\n",
      "Epoch 20 Batch 1750 Loss 4.3352 Accuracy 0.9946\n",
      "Epoch 20 Batch 1800 Loss 4.3366 Accuracy 0.9946\n",
      "Epoch 20 Batch 1850 Loss 4.3254 Accuracy 0.9946\n",
      "Epoch 20 Batch 1900 Loss 4.3169 Accuracy 0.9946\n",
      "Epoch 20 Batch 1950 Loss 4.3039 Accuracy 0.9946\n",
      "Epoch 20 Batch 2000 Loss 4.3117 Accuracy 0.9946\n",
      "Epoch 20 Batch 2050 Loss 4.3205 Accuracy 0.9946\n",
      "Epoch 20 Batch 2100 Loss 4.3171 Accuracy 0.9946\n",
      "Epoch 20 Batch 2150 Loss 4.3202 Accuracy 0.9946\n",
      "Epoch 20 Batch 2200 Loss 4.3261 Accuracy 0.9946\n",
      "Epoch 20 Batch 2250 Loss 4.3296 Accuracy 0.9946\n",
      "Epoch 20 Batch 2300 Loss 4.3248 Accuracy 0.9946\n",
      "Epoch 20 Batch 2350 Loss 4.3241 Accuracy 0.9946\n",
      "Epoch 20 Batch 2400 Loss 4.3255 Accuracy 0.9946\n",
      "Epoch 20 Batch 2450 Loss 4.3277 Accuracy 0.9946\n",
      "Epoch 20 Batch 2500 Loss 4.3336 Accuracy 0.9946\n",
      "Epoch 20 Batch 2550 Loss 4.3325 Accuracy 0.9946\n",
      "Epoch 20 Batch 2600 Loss 4.3285 Accuracy 0.9946\n",
      "Epoch 20 Batch 2650 Loss 4.3259 Accuracy 0.9946\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/train\\ckpt-5\n",
      "Epoch 20 Loss 4.3269 Accuracy 0.9946\n",
      "Time taken for 1 epoch: 196.7202639579773 secs\n",
      "\n",
      "Epoch 21 Batch 0 Loss 2.5894 Accuracy 0.9970\n",
      "Epoch 21 Batch 50 Loss 4.3991 Accuracy 0.9945\n",
      "Epoch 21 Batch 100 Loss 4.3143 Accuracy 0.9946\n",
      "Epoch 21 Batch 150 Loss 4.3745 Accuracy 0.9945\n",
      "Epoch 21 Batch 200 Loss 4.2576 Accuracy 0.9947\n",
      "Epoch 21 Batch 250 Loss 4.2382 Accuracy 0.9947\n",
      "Epoch 21 Batch 300 Loss 4.2453 Accuracy 0.9947\n",
      "Epoch 21 Batch 350 Loss 4.2485 Accuracy 0.9947\n",
      "Epoch 21 Batch 400 Loss 4.2448 Accuracy 0.9947\n",
      "Epoch 21 Batch 450 Loss 4.2949 Accuracy 0.9946\n",
      "Epoch 21 Batch 500 Loss 4.2798 Accuracy 0.9947\n",
      "Epoch 21 Batch 550 Loss 4.2947 Accuracy 0.9946\n",
      "Epoch 21 Batch 600 Loss 4.3241 Accuracy 0.9946\n",
      "Epoch 21 Batch 650 Loss 4.3255 Accuracy 0.9946\n",
      "Epoch 21 Batch 700 Loss 4.3184 Accuracy 0.9946\n",
      "Epoch 21 Batch 750 Loss 4.3090 Accuracy 0.9946\n",
      "Epoch 21 Batch 800 Loss 4.2879 Accuracy 0.9947\n",
      "Epoch 21 Batch 850 Loss 4.2902 Accuracy 0.9947\n",
      "Epoch 21 Batch 900 Loss 4.2870 Accuracy 0.9947\n",
      "Epoch 21 Batch 950 Loss 4.2979 Accuracy 0.9946\n",
      "Epoch 21 Batch 1000 Loss 4.2922 Accuracy 0.9946\n",
      "Epoch 21 Batch 1050 Loss 4.2755 Accuracy 0.9947\n",
      "Epoch 21 Batch 1100 Loss 4.2741 Accuracy 0.9947\n",
      "Epoch 21 Batch 1150 Loss 4.2598 Accuracy 0.9947\n",
      "Epoch 21 Batch 1200 Loss 4.2794 Accuracy 0.9947\n",
      "Epoch 21 Batch 1250 Loss 4.2708 Accuracy 0.9947\n",
      "Epoch 21 Batch 1300 Loss 4.2767 Accuracy 0.9947\n",
      "Epoch 21 Batch 1350 Loss 4.2666 Accuracy 0.9947\n",
      "Epoch 21 Batch 1400 Loss 4.2713 Accuracy 0.9947\n",
      "Epoch 21 Batch 1450 Loss 4.2614 Accuracy 0.9947\n",
      "Epoch 21 Batch 1500 Loss 4.2600 Accuracy 0.9947\n",
      "Epoch 21 Batch 1550 Loss 4.2653 Accuracy 0.9947\n",
      "Epoch 21 Batch 1600 Loss 4.2665 Accuracy 0.9947\n",
      "Epoch 21 Batch 1650 Loss 4.2633 Accuracy 0.9947\n",
      "Epoch 21 Batch 1700 Loss 4.2716 Accuracy 0.9947\n",
      "Epoch 21 Batch 1750 Loss 4.2621 Accuracy 0.9947\n",
      "Epoch 21 Batch 1800 Loss 4.2630 Accuracy 0.9947\n",
      "Epoch 21 Batch 1850 Loss 4.2525 Accuracy 0.9947\n",
      "Epoch 21 Batch 1900 Loss 4.2460 Accuracy 0.9947\n",
      "Epoch 21 Batch 1950 Loss 4.2345 Accuracy 0.9947\n",
      "Epoch 21 Batch 2000 Loss 4.2433 Accuracy 0.9947\n",
      "Epoch 21 Batch 2050 Loss 4.2519 Accuracy 0.9947\n",
      "Epoch 21 Batch 2100 Loss 4.2490 Accuracy 0.9947\n",
      "Epoch 21 Batch 2150 Loss 4.2514 Accuracy 0.9947\n",
      "Epoch 21 Batch 2200 Loss 4.2567 Accuracy 0.9947\n",
      "Epoch 21 Batch 2250 Loss 4.2588 Accuracy 0.9947\n",
      "Epoch 21 Batch 2300 Loss 4.2536 Accuracy 0.9947\n",
      "Epoch 21 Batch 2350 Loss 4.2525 Accuracy 0.9947\n",
      "Epoch 21 Batch 2400 Loss 4.2547 Accuracy 0.9947\n",
      "Epoch 21 Batch 2450 Loss 4.2559 Accuracy 0.9947\n",
      "Epoch 21 Batch 2500 Loss 4.2615 Accuracy 0.9947\n",
      "Epoch 21 Batch 2550 Loss 4.2598 Accuracy 0.9947\n",
      "Epoch 21 Batch 2600 Loss 4.2553 Accuracy 0.9947\n",
      "Epoch 21 Batch 2650 Loss 4.2520 Accuracy 0.9947\n",
      "Epoch 21 Loss 4.2537 Accuracy 0.9947\n",
      "Time taken for 1 epoch: 196.92996668815613 secs\n",
      "\n",
      "Epoch 22 Batch 0 Loss 2.5695 Accuracy 0.9971\n",
      "Epoch 22 Batch 50 Loss 4.3650 Accuracy 0.9946\n",
      "Epoch 22 Batch 100 Loss 4.2578 Accuracy 0.9947\n",
      "Epoch 22 Batch 150 Loss 4.3107 Accuracy 0.9946\n",
      "Epoch 22 Batch 200 Loss 4.2071 Accuracy 0.9947\n",
      "Epoch 22 Batch 250 Loss 4.1879 Accuracy 0.9948\n",
      "Epoch 22 Batch 300 Loss 4.1928 Accuracy 0.9948\n",
      "Epoch 22 Batch 350 Loss 4.1959 Accuracy 0.9948\n",
      "Epoch 22 Batch 400 Loss 4.1835 Accuracy 0.9948\n",
      "Epoch 22 Batch 450 Loss 4.2240 Accuracy 0.9947\n",
      "Epoch 22 Batch 500 Loss 4.2009 Accuracy 0.9948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 550 Loss 4.2240 Accuracy 0.9947\n",
      "Epoch 22 Batch 600 Loss 4.2522 Accuracy 0.9947\n",
      "Epoch 22 Batch 650 Loss 4.2461 Accuracy 0.9947\n",
      "Epoch 22 Batch 700 Loss 4.2380 Accuracy 0.9947\n",
      "Epoch 22 Batch 750 Loss 4.2308 Accuracy 0.9947\n",
      "Epoch 22 Batch 800 Loss 4.2125 Accuracy 0.9947\n",
      "Epoch 22 Batch 850 Loss 4.2140 Accuracy 0.9947\n",
      "Epoch 22 Batch 900 Loss 4.2137 Accuracy 0.9947\n",
      "Epoch 22 Batch 950 Loss 4.2213 Accuracy 0.9947\n",
      "Epoch 22 Batch 1000 Loss 4.2195 Accuracy 0.9947\n",
      "Epoch 22 Batch 1050 Loss 4.2049 Accuracy 0.9948\n",
      "Epoch 22 Batch 1100 Loss 4.2028 Accuracy 0.9948\n",
      "Epoch 22 Batch 1150 Loss 4.1874 Accuracy 0.9948\n",
      "Epoch 22 Batch 1200 Loss 4.2094 Accuracy 0.9948\n",
      "Epoch 22 Batch 1250 Loss 4.1977 Accuracy 0.9948\n",
      "Epoch 22 Batch 1300 Loss 4.2035 Accuracy 0.9948\n",
      "Epoch 22 Batch 1350 Loss 4.1955 Accuracy 0.9948\n",
      "Epoch 22 Batch 1400 Loss 4.2009 Accuracy 0.9948\n",
      "Epoch 22 Batch 1450 Loss 4.1924 Accuracy 0.9948\n",
      "Epoch 22 Batch 1500 Loss 4.1898 Accuracy 0.9948\n",
      "Epoch 22 Batch 1550 Loss 4.1917 Accuracy 0.9948\n",
      "Epoch 22 Batch 1600 Loss 4.1914 Accuracy 0.9948\n",
      "Epoch 22 Batch 1650 Loss 4.1901 Accuracy 0.9948\n",
      "Epoch 22 Batch 1700 Loss 4.1967 Accuracy 0.9948\n",
      "Epoch 22 Batch 1750 Loss 4.1870 Accuracy 0.9948\n",
      "Epoch 22 Batch 1800 Loss 4.1873 Accuracy 0.9948\n",
      "Epoch 22 Batch 1850 Loss 4.1761 Accuracy 0.9948\n",
      "Epoch 22 Batch 1900 Loss 4.1704 Accuracy 0.9948\n",
      "Epoch 22 Batch 1950 Loss 4.1590 Accuracy 0.9948\n",
      "Epoch 22 Batch 2000 Loss 4.1667 Accuracy 0.9948\n",
      "Epoch 22 Batch 2050 Loss 4.1752 Accuracy 0.9948\n",
      "Epoch 22 Batch 2100 Loss 4.1718 Accuracy 0.9948\n",
      "Epoch 22 Batch 2150 Loss 4.1731 Accuracy 0.9948\n",
      "Epoch 22 Batch 2200 Loss 4.1777 Accuracy 0.9948\n",
      "Epoch 22 Batch 2250 Loss 4.1798 Accuracy 0.9948\n",
      "Epoch 22 Batch 2300 Loss 4.1749 Accuracy 0.9948\n",
      "Epoch 22 Batch 2350 Loss 4.1734 Accuracy 0.9948\n",
      "Epoch 22 Batch 2400 Loss 4.1743 Accuracy 0.9948\n",
      "Epoch 22 Batch 2450 Loss 4.1764 Accuracy 0.9948\n",
      "Epoch 22 Batch 2500 Loss 4.1803 Accuracy 0.9948\n",
      "Epoch 22 Batch 2550 Loss 4.1799 Accuracy 0.9948\n",
      "Epoch 22 Batch 2600 Loss 4.1754 Accuracy 0.9948\n",
      "Epoch 22 Batch 2650 Loss 4.1731 Accuracy 0.9948\n",
      "Epoch 22 Loss 4.1747 Accuracy 0.9948\n",
      "Time taken for 1 epoch: 197.28306818008423 secs\n",
      "\n",
      "Epoch 23 Batch 0 Loss 2.6006 Accuracy 0.9969\n",
      "Epoch 23 Batch 50 Loss 4.2912 Accuracy 0.9945\n",
      "Epoch 23 Batch 100 Loss 4.1954 Accuracy 0.9947\n",
      "Epoch 23 Batch 150 Loss 4.2436 Accuracy 0.9947\n",
      "Epoch 23 Batch 200 Loss 4.1279 Accuracy 0.9948\n",
      "Epoch 23 Batch 250 Loss 4.1089 Accuracy 0.9949\n",
      "Epoch 23 Batch 300 Loss 4.1101 Accuracy 0.9949\n",
      "Epoch 23 Batch 350 Loss 4.1044 Accuracy 0.9949\n",
      "Epoch 23 Batch 400 Loss 4.0967 Accuracy 0.9949\n",
      "Epoch 23 Batch 450 Loss 4.1483 Accuracy 0.9948\n",
      "Epoch 23 Batch 500 Loss 4.1338 Accuracy 0.9948\n",
      "Epoch 23 Batch 550 Loss 4.1552 Accuracy 0.9948\n",
      "Epoch 23 Batch 600 Loss 4.1813 Accuracy 0.9948\n",
      "Epoch 23 Batch 650 Loss 4.1780 Accuracy 0.9948\n",
      "Epoch 23 Batch 700 Loss 4.1765 Accuracy 0.9948\n",
      "Epoch 23 Batch 750 Loss 4.1706 Accuracy 0.9948\n",
      "Epoch 23 Batch 800 Loss 4.1479 Accuracy 0.9948\n",
      "Epoch 23 Batch 850 Loss 4.1524 Accuracy 0.9948\n",
      "Epoch 23 Batch 900 Loss 4.1483 Accuracy 0.9948\n",
      "Epoch 23 Batch 950 Loss 4.1530 Accuracy 0.9948\n",
      "Epoch 23 Batch 1000 Loss 4.1481 Accuracy 0.9948\n",
      "Epoch 23 Batch 1050 Loss 4.1302 Accuracy 0.9948\n",
      "Epoch 23 Batch 1100 Loss 4.1289 Accuracy 0.9948\n",
      "Epoch 23 Batch 1150 Loss 4.1137 Accuracy 0.9949\n",
      "Epoch 23 Batch 1200 Loss 4.1289 Accuracy 0.9948\n",
      "Epoch 23 Batch 1250 Loss 4.1168 Accuracy 0.9949\n",
      "Epoch 23 Batch 1300 Loss 4.1235 Accuracy 0.9949\n",
      "Epoch 23 Batch 1350 Loss 4.1143 Accuracy 0.9949\n",
      "Epoch 23 Batch 1400 Loss 4.1194 Accuracy 0.9949\n",
      "Epoch 23 Batch 1450 Loss 4.1080 Accuracy 0.9949\n",
      "Epoch 23 Batch 1500 Loss 4.1048 Accuracy 0.9949\n",
      "Epoch 23 Batch 1550 Loss 4.1085 Accuracy 0.9949\n",
      "Epoch 23 Batch 1600 Loss 4.1097 Accuracy 0.9949\n",
      "Epoch 23 Batch 1650 Loss 4.1092 Accuracy 0.9949\n",
      "Epoch 23 Batch 1700 Loss 4.1169 Accuracy 0.9949\n",
      "Epoch 23 Batch 1750 Loss 4.1080 Accuracy 0.9949\n",
      "Epoch 23 Batch 1800 Loss 4.1106 Accuracy 0.9949\n",
      "Epoch 23 Batch 1850 Loss 4.1014 Accuracy 0.9949\n",
      "Epoch 23 Batch 1900 Loss 4.0950 Accuracy 0.9949\n",
      "Epoch 23 Batch 1950 Loss 4.0829 Accuracy 0.9949\n",
      "Epoch 23 Batch 2000 Loss 4.0915 Accuracy 0.9949\n",
      "Epoch 23 Batch 2050 Loss 4.1004 Accuracy 0.9949\n",
      "Epoch 23 Batch 2100 Loss 4.0970 Accuracy 0.9949\n",
      "Epoch 23 Batch 2150 Loss 4.0990 Accuracy 0.9949\n",
      "Epoch 23 Batch 2200 Loss 4.1044 Accuracy 0.9949\n",
      "Epoch 23 Batch 2250 Loss 4.1062 Accuracy 0.9949\n",
      "Epoch 23 Batch 2300 Loss 4.1028 Accuracy 0.9949\n",
      "Epoch 23 Batch 2350 Loss 4.1024 Accuracy 0.9949\n",
      "Epoch 23 Batch 2400 Loss 4.1053 Accuracy 0.9949\n",
      "Epoch 23 Batch 2450 Loss 4.1079 Accuracy 0.9949\n",
      "Epoch 23 Batch 2500 Loss 4.1107 Accuracy 0.9949\n",
      "Epoch 23 Batch 2550 Loss 4.1105 Accuracy 0.9949\n",
      "Epoch 23 Batch 2600 Loss 4.1065 Accuracy 0.9949\n",
      "Epoch 23 Batch 2650 Loss 4.1047 Accuracy 0.9949\n",
      "Epoch 23 Loss 4.1061 Accuracy 0.9949\n",
      "Time taken for 1 epoch: 197.0664894580841 secs\n",
      "\n",
      "Epoch 24 Batch 0 Loss 2.2733 Accuracy 0.9973\n",
      "Epoch 24 Batch 50 Loss 4.1657 Accuracy 0.9948\n",
      "Epoch 24 Batch 100 Loss 4.0761 Accuracy 0.9949\n",
      "Epoch 24 Batch 150 Loss 4.1474 Accuracy 0.9948\n",
      "Epoch 24 Batch 200 Loss 4.0468 Accuracy 0.9949\n",
      "Epoch 24 Batch 250 Loss 4.0347 Accuracy 0.9950\n",
      "Epoch 24 Batch 300 Loss 4.0406 Accuracy 0.9950\n",
      "Epoch 24 Batch 350 Loss 4.0447 Accuracy 0.9949\n",
      "Epoch 24 Batch 400 Loss 4.0331 Accuracy 0.9950\n",
      "Epoch 24 Batch 450 Loss 4.0771 Accuracy 0.9949\n",
      "Epoch 24 Batch 500 Loss 4.0701 Accuracy 0.9949\n",
      "Epoch 24 Batch 550 Loss 4.0864 Accuracy 0.9949\n",
      "Epoch 24 Batch 600 Loss 4.1110 Accuracy 0.9949\n",
      "Epoch 24 Batch 650 Loss 4.1076 Accuracy 0.9949\n",
      "Epoch 24 Batch 700 Loss 4.1017 Accuracy 0.9949\n",
      "Epoch 24 Batch 750 Loss 4.0960 Accuracy 0.9949\n",
      "Epoch 24 Batch 800 Loss 4.0758 Accuracy 0.9949\n",
      "Epoch 24 Batch 850 Loss 4.0829 Accuracy 0.9949\n",
      "Epoch 24 Batch 900 Loss 4.0826 Accuracy 0.9949\n",
      "Epoch 24 Batch 950 Loss 4.0877 Accuracy 0.9949\n",
      "Epoch 24 Batch 1000 Loss 4.0836 Accuracy 0.9949\n",
      "Epoch 24 Batch 1050 Loss 4.0677 Accuracy 0.9949\n",
      "Epoch 24 Batch 1100 Loss 4.0687 Accuracy 0.9949\n",
      "Epoch 24 Batch 1150 Loss 4.0573 Accuracy 0.9949\n",
      "Epoch 24 Batch 1200 Loss 4.0735 Accuracy 0.9949\n",
      "Epoch 24 Batch 1250 Loss 4.0612 Accuracy 0.9949\n",
      "Epoch 24 Batch 1300 Loss 4.0653 Accuracy 0.9949\n",
      "Epoch 24 Batch 1350 Loss 4.0571 Accuracy 0.9949\n",
      "Epoch 24 Batch 1400 Loss 4.0610 Accuracy 0.9949\n",
      "Epoch 24 Batch 1450 Loss 4.0516 Accuracy 0.9949\n",
      "Epoch 24 Batch 1500 Loss 4.0475 Accuracy 0.9950\n",
      "Epoch 24 Batch 1550 Loss 4.0505 Accuracy 0.9949\n",
      "Epoch 24 Batch 1600 Loss 4.0504 Accuracy 0.9949\n",
      "Epoch 24 Batch 1650 Loss 4.0472 Accuracy 0.9949\n",
      "Epoch 24 Batch 1700 Loss 4.0560 Accuracy 0.9949\n",
      "Epoch 24 Batch 1750 Loss 4.0462 Accuracy 0.9950\n",
      "Epoch 24 Batch 1800 Loss 4.0487 Accuracy 0.9950\n",
      "Epoch 24 Batch 1850 Loss 4.0398 Accuracy 0.9950\n",
      "Epoch 24 Batch 1900 Loss 4.0342 Accuracy 0.9950\n",
      "Epoch 24 Batch 1950 Loss 4.0222 Accuracy 0.9950\n",
      "Epoch 24 Batch 2000 Loss 4.0296 Accuracy 0.9950\n",
      "Epoch 24 Batch 2050 Loss 4.0397 Accuracy 0.9950\n",
      "Epoch 24 Batch 2100 Loss 4.0366 Accuracy 0.9950\n",
      "Epoch 24 Batch 2150 Loss 4.0390 Accuracy 0.9950\n",
      "Epoch 24 Batch 2200 Loss 4.0437 Accuracy 0.9950\n",
      "Epoch 24 Batch 2250 Loss 4.0460 Accuracy 0.9950\n",
      "Epoch 24 Batch 2300 Loss 4.0400 Accuracy 0.9950\n",
      "Epoch 24 Batch 2350 Loss 4.0386 Accuracy 0.9950\n",
      "Epoch 24 Batch 2400 Loss 4.0404 Accuracy 0.9950\n",
      "Epoch 24 Batch 2450 Loss 4.0425 Accuracy 0.9950\n",
      "Epoch 24 Batch 2500 Loss 4.0463 Accuracy 0.9950\n",
      "Epoch 24 Batch 2550 Loss 4.0460 Accuracy 0.9950\n",
      "Epoch 24 Batch 2600 Loss 4.0412 Accuracy 0.9950\n",
      "Epoch 24 Batch 2650 Loss 4.0387 Accuracy 0.9950\n",
      "Epoch 24 Loss 4.0406 Accuracy 0.9950\n",
      "Time taken for 1 epoch: 196.16376185417175 secs\n",
      "\n",
      "Epoch 25 Batch 0 Loss 2.7940 Accuracy 0.9970\n",
      "Epoch 25 Batch 50 Loss 4.1688 Accuracy 0.9948\n",
      "Epoch 25 Batch 100 Loss 4.0550 Accuracy 0.9949\n",
      "Epoch 25 Batch 150 Loss 4.0985 Accuracy 0.9949\n",
      "Epoch 25 Batch 200 Loss 4.0024 Accuracy 0.9950\n",
      "Epoch 25 Batch 250 Loss 3.9781 Accuracy 0.9950\n",
      "Epoch 25 Batch 300 Loss 3.9890 Accuracy 0.9950\n",
      "Epoch 25 Batch 350 Loss 3.9959 Accuracy 0.9950\n",
      "Epoch 25 Batch 400 Loss 3.9802 Accuracy 0.9950\n",
      "Epoch 25 Batch 450 Loss 4.0268 Accuracy 0.9950\n",
      "Epoch 25 Batch 500 Loss 4.0101 Accuracy 0.9950\n",
      "Epoch 25 Batch 550 Loss 4.0364 Accuracy 0.9949\n",
      "Epoch 25 Batch 600 Loss 4.0622 Accuracy 0.9949\n",
      "Epoch 25 Batch 650 Loss 4.0628 Accuracy 0.9949\n",
      "Epoch 25 Batch 700 Loss 4.0587 Accuracy 0.9949\n",
      "Epoch 25 Batch 750 Loss 4.0539 Accuracy 0.9949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 800 Loss 4.0329 Accuracy 0.9950\n",
      "Epoch 25 Batch 850 Loss 4.0397 Accuracy 0.9950\n",
      "Epoch 25 Batch 900 Loss 4.0339 Accuracy 0.9950\n",
      "Epoch 25 Batch 950 Loss 4.0394 Accuracy 0.9950\n",
      "Epoch 25 Batch 1000 Loss 4.0349 Accuracy 0.9950\n",
      "Epoch 25 Batch 1050 Loss 4.0193 Accuracy 0.9950\n",
      "Epoch 25 Batch 1100 Loss 4.0161 Accuracy 0.9950\n",
      "Epoch 25 Batch 1150 Loss 4.0027 Accuracy 0.9950\n",
      "Epoch 25 Batch 1200 Loss 4.0188 Accuracy 0.9950\n",
      "Epoch 25 Batch 1250 Loss 4.0095 Accuracy 0.9950\n",
      "Epoch 25 Batch 1300 Loss 4.0112 Accuracy 0.9950\n",
      "Epoch 25 Batch 1350 Loss 4.0034 Accuracy 0.9950\n",
      "Epoch 25 Batch 1400 Loss 4.0079 Accuracy 0.9950\n",
      "Epoch 25 Batch 1450 Loss 3.9955 Accuracy 0.9950\n",
      "Epoch 25 Batch 1500 Loss 3.9929 Accuracy 0.9950\n",
      "Epoch 25 Batch 1550 Loss 3.9961 Accuracy 0.9950\n",
      "Epoch 25 Batch 1600 Loss 3.9964 Accuracy 0.9950\n",
      "Epoch 25 Batch 1650 Loss 3.9931 Accuracy 0.9950\n",
      "Epoch 25 Batch 1700 Loss 3.9989 Accuracy 0.9950\n",
      "Epoch 25 Batch 1750 Loss 3.9902 Accuracy 0.9950\n",
      "Epoch 25 Batch 1800 Loss 3.9915 Accuracy 0.9950\n",
      "Epoch 25 Batch 1850 Loss 3.9820 Accuracy 0.9950\n",
      "Epoch 25 Batch 1900 Loss 3.9754 Accuracy 0.9950\n",
      "Epoch 25 Batch 1950 Loss 3.9638 Accuracy 0.9951\n",
      "Epoch 25 Batch 2000 Loss 3.9712 Accuracy 0.9950\n",
      "Epoch 25 Batch 2050 Loss 3.9793 Accuracy 0.9950\n",
      "Epoch 25 Batch 2100 Loss 3.9767 Accuracy 0.9950\n",
      "Epoch 25 Batch 2150 Loss 3.9780 Accuracy 0.9950\n",
      "Epoch 25 Batch 2200 Loss 3.9827 Accuracy 0.9950\n",
      "Epoch 25 Batch 2250 Loss 3.9866 Accuracy 0.9950\n",
      "Epoch 25 Batch 2300 Loss 3.9819 Accuracy 0.9950\n",
      "Epoch 25 Batch 2350 Loss 3.9809 Accuracy 0.9950\n",
      "Epoch 25 Batch 2400 Loss 3.9818 Accuracy 0.9950\n",
      "Epoch 25 Batch 2450 Loss 3.9832 Accuracy 0.9950\n",
      "Epoch 25 Batch 2500 Loss 3.9861 Accuracy 0.9950\n",
      "Epoch 25 Batch 2550 Loss 3.9854 Accuracy 0.9950\n",
      "Epoch 25 Batch 2600 Loss 3.9816 Accuracy 0.9950\n",
      "Epoch 25 Batch 2650 Loss 3.9787 Accuracy 0.9950\n",
      "Saving checkpoint for epoch 25 at ./checkpoints/train\\ckpt-6\n",
      "Epoch 25 Loss 3.9802 Accuracy 0.9950\n",
      "Time taken for 1 epoch: 195.5731976032257 secs\n",
      "\n",
      "Epoch 26 Batch 0 Loss 2.3040 Accuracy 0.9974\n",
      "Epoch 26 Batch 50 Loss 4.0406 Accuracy 0.9949\n",
      "Epoch 26 Batch 100 Loss 3.9695 Accuracy 0.9950\n",
      "Epoch 26 Batch 150 Loss 4.0186 Accuracy 0.9950\n",
      "Epoch 26 Batch 200 Loss 3.9132 Accuracy 0.9951\n",
      "Epoch 26 Batch 250 Loss 3.9033 Accuracy 0.9951\n",
      "Epoch 26 Batch 300 Loss 3.9165 Accuracy 0.9951\n",
      "Epoch 26 Batch 350 Loss 3.9163 Accuracy 0.9951\n",
      "Epoch 26 Batch 400 Loss 3.9124 Accuracy 0.9951\n",
      "Epoch 26 Batch 450 Loss 3.9615 Accuracy 0.9950\n",
      "Epoch 26 Batch 500 Loss 3.9490 Accuracy 0.9951\n",
      "Epoch 26 Batch 550 Loss 3.9658 Accuracy 0.9950\n",
      "Epoch 26 Batch 600 Loss 3.9849 Accuracy 0.9950\n",
      "Epoch 26 Batch 650 Loss 3.9852 Accuracy 0.9950\n",
      "Epoch 26 Batch 700 Loss 3.9803 Accuracy 0.9950\n",
      "Epoch 26 Batch 750 Loss 3.9788 Accuracy 0.9950\n",
      "Epoch 26 Batch 800 Loss 3.9559 Accuracy 0.9951\n",
      "Epoch 26 Batch 850 Loss 3.9594 Accuracy 0.9951\n",
      "Epoch 26 Batch 900 Loss 3.9580 Accuracy 0.9951\n",
      "Epoch 26 Batch 950 Loss 3.9658 Accuracy 0.9951\n",
      "Epoch 26 Batch 1000 Loss 3.9612 Accuracy 0.9951\n",
      "Epoch 26 Batch 1050 Loss 3.9471 Accuracy 0.9951\n",
      "Epoch 26 Batch 1100 Loss 3.9472 Accuracy 0.9951\n",
      "Epoch 26 Batch 1150 Loss 3.9336 Accuracy 0.9951\n",
      "Epoch 26 Batch 1200 Loss 3.9518 Accuracy 0.9951\n",
      "Epoch 26 Batch 1250 Loss 3.9420 Accuracy 0.9951\n",
      "Epoch 26 Batch 1300 Loss 3.9458 Accuracy 0.9951\n",
      "Epoch 26 Batch 1350 Loss 3.9381 Accuracy 0.9951\n",
      "Epoch 26 Batch 1400 Loss 3.9445 Accuracy 0.9951\n",
      "Epoch 26 Batch 1450 Loss 3.9327 Accuracy 0.9951\n",
      "Epoch 26 Batch 1500 Loss 3.9296 Accuracy 0.9951\n",
      "Epoch 26 Batch 1550 Loss 3.9340 Accuracy 0.9951\n",
      "Epoch 26 Batch 1600 Loss 3.9329 Accuracy 0.9951\n",
      "Epoch 26 Batch 1650 Loss 3.9314 Accuracy 0.9951\n",
      "Epoch 26 Batch 1700 Loss 3.9369 Accuracy 0.9951\n",
      "Epoch 26 Batch 1750 Loss 3.9278 Accuracy 0.9951\n",
      "Epoch 26 Batch 1800 Loss 3.9296 Accuracy 0.9951\n",
      "Epoch 26 Batch 1850 Loss 3.9192 Accuracy 0.9951\n",
      "Epoch 26 Batch 1900 Loss 3.9134 Accuracy 0.9951\n",
      "Epoch 26 Batch 1950 Loss 3.9028 Accuracy 0.9951\n",
      "Epoch 26 Batch 2000 Loss 3.9088 Accuracy 0.9951\n",
      "Epoch 26 Batch 2050 Loss 3.9168 Accuracy 0.9951\n",
      "Epoch 26 Batch 2100 Loss 3.9140 Accuracy 0.9951\n",
      "Epoch 26 Batch 2150 Loss 3.9167 Accuracy 0.9951\n",
      "Epoch 26 Batch 2200 Loss 3.9221 Accuracy 0.9951\n",
      "Epoch 26 Batch 2250 Loss 3.9246 Accuracy 0.9951\n",
      "Epoch 26 Batch 2300 Loss 3.9210 Accuracy 0.9951\n",
      "Epoch 26 Batch 2350 Loss 3.9203 Accuracy 0.9951\n",
      "Epoch 26 Batch 2400 Loss 3.9216 Accuracy 0.9951\n",
      "Epoch 26 Batch 2450 Loss 3.9225 Accuracy 0.9951\n",
      "Epoch 26 Batch 2500 Loss 3.9258 Accuracy 0.9951\n",
      "Epoch 26 Batch 2550 Loss 3.9245 Accuracy 0.9951\n",
      "Epoch 26 Batch 2600 Loss 3.9206 Accuracy 0.9951\n",
      "Epoch 26 Batch 2650 Loss 3.9178 Accuracy 0.9951\n",
      "Epoch 26 Loss 3.9195 Accuracy 0.9951\n",
      "Time taken for 1 epoch: 195.84672451019287 secs\n",
      "\n",
      "Epoch 27 Batch 0 Loss 2.5922 Accuracy 0.9971\n",
      "Epoch 27 Batch 50 Loss 4.0430 Accuracy 0.9949\n",
      "Epoch 27 Batch 100 Loss 3.9415 Accuracy 0.9951\n",
      "Epoch 27 Batch 150 Loss 3.9946 Accuracy 0.9950\n",
      "Epoch 27 Batch 200 Loss 3.8867 Accuracy 0.9951\n",
      "Epoch 27 Batch 250 Loss 3.8718 Accuracy 0.9951\n",
      "Epoch 27 Batch 300 Loss 3.8772 Accuracy 0.9951\n",
      "Epoch 27 Batch 350 Loss 3.8737 Accuracy 0.9951\n",
      "Epoch 27 Batch 400 Loss 3.8588 Accuracy 0.9952\n",
      "Epoch 27 Batch 450 Loss 3.8991 Accuracy 0.9951\n",
      "Epoch 27 Batch 500 Loss 3.8859 Accuracy 0.9951\n",
      "Epoch 27 Batch 550 Loss 3.9068 Accuracy 0.9951\n",
      "Epoch 27 Batch 600 Loss 3.9282 Accuracy 0.9951\n",
      "Epoch 27 Batch 650 Loss 3.9277 Accuracy 0.9951\n",
      "Epoch 27 Batch 700 Loss 3.9249 Accuracy 0.9951\n",
      "Epoch 27 Batch 750 Loss 3.9198 Accuracy 0.9951\n",
      "Epoch 27 Batch 800 Loss 3.9024 Accuracy 0.9951\n",
      "Epoch 27 Batch 850 Loss 3.9061 Accuracy 0.9951\n",
      "Epoch 27 Batch 900 Loss 3.9031 Accuracy 0.9951\n",
      "Epoch 27 Batch 950 Loss 3.9115 Accuracy 0.9951\n",
      "Epoch 27 Batch 1000 Loss 3.9072 Accuracy 0.9951\n",
      "Epoch 27 Batch 1050 Loss 3.8932 Accuracy 0.9951\n",
      "Epoch 27 Batch 1100 Loss 3.8911 Accuracy 0.9951\n",
      "Epoch 27 Batch 1150 Loss 3.8765 Accuracy 0.9952\n",
      "Epoch 27 Batch 1200 Loss 3.8937 Accuracy 0.9951\n",
      "Epoch 27 Batch 1250 Loss 3.8829 Accuracy 0.9951\n",
      "Epoch 27 Batch 1300 Loss 3.8861 Accuracy 0.9951\n",
      "Epoch 27 Batch 1350 Loss 3.8799 Accuracy 0.9952\n",
      "Epoch 27 Batch 1400 Loss 3.8841 Accuracy 0.9951\n",
      "Epoch 27 Batch 1450 Loss 3.8759 Accuracy 0.9952\n",
      "Epoch 27 Batch 1500 Loss 3.8761 Accuracy 0.9952\n",
      "Epoch 27 Batch 1550 Loss 3.8790 Accuracy 0.9951\n",
      "Epoch 27 Batch 1600 Loss 3.8784 Accuracy 0.9951\n",
      "Epoch 27 Batch 1650 Loss 3.8769 Accuracy 0.9952\n",
      "Epoch 27 Batch 1700 Loss 3.8821 Accuracy 0.9951\n",
      "Epoch 27 Batch 1750 Loss 3.8734 Accuracy 0.9952\n",
      "Epoch 27 Batch 1800 Loss 3.8751 Accuracy 0.9952\n",
      "Epoch 27 Batch 1850 Loss 3.8668 Accuracy 0.9952\n",
      "Epoch 27 Batch 1900 Loss 3.8623 Accuracy 0.9952\n",
      "Epoch 27 Batch 1950 Loss 3.8508 Accuracy 0.9952\n",
      "Epoch 27 Batch 2000 Loss 3.8565 Accuracy 0.9952\n",
      "Epoch 27 Batch 2050 Loss 3.8661 Accuracy 0.9952\n",
      "Epoch 27 Batch 2100 Loss 3.8618 Accuracy 0.9952\n",
      "Epoch 27 Batch 2150 Loss 3.8660 Accuracy 0.9952\n",
      "Epoch 27 Batch 2200 Loss 3.8712 Accuracy 0.9952\n",
      "Epoch 27 Batch 2250 Loss 3.8733 Accuracy 0.9952\n",
      "Epoch 27 Batch 2300 Loss 3.8691 Accuracy 0.9952\n",
      "Epoch 27 Batch 2350 Loss 3.8693 Accuracy 0.9952\n",
      "Epoch 27 Batch 2400 Loss 3.8719 Accuracy 0.9952\n",
      "Epoch 27 Batch 2450 Loss 3.8747 Accuracy 0.9952\n",
      "Epoch 27 Batch 2500 Loss 3.8784 Accuracy 0.9952\n",
      "Epoch 27 Batch 2550 Loss 3.8770 Accuracy 0.9952\n",
      "Epoch 27 Batch 2600 Loss 3.8733 Accuracy 0.9952\n",
      "Epoch 27 Batch 2650 Loss 3.8708 Accuracy 0.9952\n",
      "Epoch 27 Loss 3.8724 Accuracy 0.9952\n",
      "Time taken for 1 epoch: 195.36989760398865 secs\n",
      "\n",
      "Epoch 28 Batch 0 Loss 2.5051 Accuracy 0.9972\n",
      "Epoch 28 Batch 50 Loss 3.9671 Accuracy 0.9951\n",
      "Epoch 28 Batch 100 Loss 3.9161 Accuracy 0.9951\n",
      "Epoch 28 Batch 150 Loss 3.9702 Accuracy 0.9951\n",
      "Epoch 28 Batch 200 Loss 3.8567 Accuracy 0.9952\n",
      "Epoch 28 Batch 250 Loss 3.8366 Accuracy 0.9952\n",
      "Epoch 28 Batch 300 Loss 3.8488 Accuracy 0.9952\n",
      "Epoch 28 Batch 350 Loss 3.8350 Accuracy 0.9952\n",
      "Epoch 28 Batch 400 Loss 3.8258 Accuracy 0.9952\n",
      "Epoch 28 Batch 450 Loss 3.8697 Accuracy 0.9952\n",
      "Epoch 28 Batch 500 Loss 3.8508 Accuracy 0.9952\n",
      "Epoch 28 Batch 550 Loss 3.8697 Accuracy 0.9952\n",
      "Epoch 28 Batch 600 Loss 3.8898 Accuracy 0.9951\n",
      "Epoch 28 Batch 650 Loss 3.8939 Accuracy 0.9951\n",
      "Epoch 28 Batch 700 Loss 3.8878 Accuracy 0.9951\n",
      "Epoch 28 Batch 750 Loss 3.8848 Accuracy 0.9951\n",
      "Epoch 28 Batch 800 Loss 3.8638 Accuracy 0.9952\n",
      "Epoch 28 Batch 850 Loss 3.8676 Accuracy 0.9952\n",
      "Epoch 28 Batch 900 Loss 3.8607 Accuracy 0.9952\n",
      "Epoch 28 Batch 950 Loss 3.8663 Accuracy 0.9952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 1000 Loss 3.8625 Accuracy 0.9952\n",
      "Epoch 28 Batch 1050 Loss 3.8455 Accuracy 0.9952\n",
      "Epoch 28 Batch 1100 Loss 3.8415 Accuracy 0.9952\n",
      "Epoch 28 Batch 1150 Loss 3.8280 Accuracy 0.9952\n",
      "Epoch 28 Batch 1200 Loss 3.8459 Accuracy 0.9952\n",
      "Epoch 28 Batch 1250 Loss 3.8354 Accuracy 0.9952\n",
      "Epoch 28 Batch 1300 Loss 3.8408 Accuracy 0.9952\n",
      "Epoch 28 Batch 1350 Loss 3.8335 Accuracy 0.9952\n",
      "Epoch 28 Batch 1400 Loss 3.8389 Accuracy 0.9952\n",
      "Epoch 28 Batch 1450 Loss 3.8305 Accuracy 0.9952\n",
      "Epoch 28 Batch 1500 Loss 3.8307 Accuracy 0.9952\n",
      "Epoch 28 Batch 1550 Loss 3.8334 Accuracy 0.9952\n",
      "Epoch 28 Batch 1600 Loss 3.8327 Accuracy 0.9952\n",
      "Epoch 28 Batch 1650 Loss 3.8296 Accuracy 0.9952\n",
      "Epoch 28 Batch 1700 Loss 3.8366 Accuracy 0.9952\n",
      "Epoch 28 Batch 1750 Loss 3.8275 Accuracy 0.9952\n",
      "Epoch 28 Batch 1800 Loss 3.8302 Accuracy 0.9952\n",
      "Epoch 28 Batch 1850 Loss 3.8201 Accuracy 0.9952\n",
      "Epoch 28 Batch 1900 Loss 3.8136 Accuracy 0.9952\n",
      "Epoch 28 Batch 1950 Loss 3.8023 Accuracy 0.9953\n",
      "Epoch 28 Batch 2000 Loss 3.8088 Accuracy 0.9952\n",
      "Epoch 28 Batch 2050 Loss 3.8180 Accuracy 0.9952\n",
      "Epoch 28 Batch 2100 Loss 3.8155 Accuracy 0.9952\n",
      "Epoch 28 Batch 2150 Loss 3.8166 Accuracy 0.9952\n",
      "Epoch 28 Batch 2200 Loss 3.8215 Accuracy 0.9952\n",
      "Epoch 28 Batch 2250 Loss 3.8241 Accuracy 0.9952\n",
      "Epoch 28 Batch 2300 Loss 3.8208 Accuracy 0.9952\n",
      "Epoch 28 Batch 2350 Loss 3.8191 Accuracy 0.9952\n",
      "Epoch 28 Batch 2400 Loss 3.8204 Accuracy 0.9952\n",
      "Epoch 28 Batch 2450 Loss 3.8217 Accuracy 0.9952\n",
      "Epoch 28 Batch 2500 Loss 3.8253 Accuracy 0.9952\n",
      "Epoch 28 Batch 2550 Loss 3.8229 Accuracy 0.9952\n",
      "Epoch 28 Batch 2600 Loss 3.8189 Accuracy 0.9952\n",
      "Epoch 28 Batch 2650 Loss 3.8160 Accuracy 0.9952\n",
      "Epoch 28 Loss 3.8168 Accuracy 0.9952\n",
      "Time taken for 1 epoch: 195.53010201454163 secs\n",
      "\n",
      "Epoch 29 Batch 0 Loss 2.5337 Accuracy 0.9971\n",
      "Epoch 29 Batch 50 Loss 3.9051 Accuracy 0.9951\n",
      "Epoch 29 Batch 100 Loss 3.8474 Accuracy 0.9952\n",
      "Epoch 29 Batch 150 Loss 3.9051 Accuracy 0.9951\n",
      "Epoch 29 Batch 200 Loss 3.8179 Accuracy 0.9952\n",
      "Epoch 29 Batch 250 Loss 3.7981 Accuracy 0.9952\n",
      "Epoch 29 Batch 300 Loss 3.7903 Accuracy 0.9953\n",
      "Epoch 29 Batch 350 Loss 3.7918 Accuracy 0.9953\n",
      "Epoch 29 Batch 400 Loss 3.7822 Accuracy 0.9953\n",
      "Epoch 29 Batch 450 Loss 3.8239 Accuracy 0.9952\n",
      "Epoch 29 Batch 500 Loss 3.8020 Accuracy 0.9952\n",
      "Epoch 29 Batch 550 Loss 3.8185 Accuracy 0.9952\n",
      "Epoch 29 Batch 600 Loss 3.8418 Accuracy 0.9952\n",
      "Epoch 29 Batch 650 Loss 3.8412 Accuracy 0.9952\n",
      "Epoch 29 Batch 700 Loss 3.8365 Accuracy 0.9952\n",
      "Epoch 29 Batch 750 Loss 3.8319 Accuracy 0.9952\n",
      "Epoch 29 Batch 800 Loss 3.8130 Accuracy 0.9952\n",
      "Epoch 29 Batch 850 Loss 3.8178 Accuracy 0.9952\n",
      "Epoch 29 Batch 900 Loss 3.8185 Accuracy 0.9952\n",
      "Epoch 29 Batch 950 Loss 3.8242 Accuracy 0.9952\n",
      "Epoch 29 Batch 1000 Loss 3.8198 Accuracy 0.9952\n",
      "Epoch 29 Batch 1050 Loss 3.8053 Accuracy 0.9953\n",
      "Epoch 29 Batch 1100 Loss 3.8036 Accuracy 0.9953\n",
      "Epoch 29 Batch 1150 Loss 3.7926 Accuracy 0.9953\n",
      "Epoch 29 Batch 1200 Loss 3.8058 Accuracy 0.9952\n",
      "Epoch 29 Batch 1250 Loss 3.7977 Accuracy 0.9953\n",
      "Epoch 29 Batch 1300 Loss 3.8015 Accuracy 0.9953\n",
      "Epoch 29 Batch 1350 Loss 3.7929 Accuracy 0.9953\n",
      "Epoch 29 Batch 1400 Loss 3.7989 Accuracy 0.9953\n",
      "Epoch 29 Batch 1450 Loss 3.7910 Accuracy 0.9953\n",
      "Epoch 29 Batch 1500 Loss 3.7870 Accuracy 0.9953\n",
      "Epoch 29 Batch 1550 Loss 3.7875 Accuracy 0.9953\n",
      "Epoch 29 Batch 1600 Loss 3.7853 Accuracy 0.9953\n",
      "Epoch 29 Batch 1650 Loss 3.7828 Accuracy 0.9953\n",
      "Epoch 29 Batch 1700 Loss 3.7870 Accuracy 0.9953\n",
      "Epoch 29 Batch 1750 Loss 3.7777 Accuracy 0.9953\n",
      "Epoch 29 Batch 1800 Loss 3.7819 Accuracy 0.9953\n",
      "Epoch 29 Batch 1850 Loss 3.7717 Accuracy 0.9953\n",
      "Epoch 29 Batch 1900 Loss 3.7649 Accuracy 0.9953\n",
      "Epoch 29 Batch 1950 Loss 3.7550 Accuracy 0.9953\n",
      "Epoch 29 Batch 2000 Loss 3.7619 Accuracy 0.9953\n",
      "Epoch 29 Batch 2050 Loss 3.7702 Accuracy 0.9953\n",
      "Epoch 29 Batch 2100 Loss 3.7659 Accuracy 0.9953\n",
      "Epoch 29 Batch 2150 Loss 3.7691 Accuracy 0.9953\n",
      "Epoch 29 Batch 2200 Loss 3.7737 Accuracy 0.9953\n",
      "Epoch 29 Batch 2250 Loss 3.7757 Accuracy 0.9953\n",
      "Epoch 29 Batch 2300 Loss 3.7713 Accuracy 0.9953\n",
      "Epoch 29 Batch 2350 Loss 3.7712 Accuracy 0.9953\n",
      "Epoch 29 Batch 2400 Loss 3.7734 Accuracy 0.9953\n",
      "Epoch 29 Batch 2450 Loss 3.7753 Accuracy 0.9953\n",
      "Epoch 29 Batch 2500 Loss 3.7787 Accuracy 0.9953\n",
      "Epoch 29 Batch 2550 Loss 3.7780 Accuracy 0.9953\n",
      "Epoch 29 Batch 2600 Loss 3.7737 Accuracy 0.9953\n",
      "Epoch 29 Batch 2650 Loss 3.7704 Accuracy 0.9953\n",
      "Epoch 29 Loss 3.7733 Accuracy 0.9953\n",
      "Time taken for 1 epoch: 195.7398796081543 secs\n",
      "\n",
      "Epoch 30 Batch 0 Loss 2.4169 Accuracy 0.9972\n",
      "Epoch 30 Batch 50 Loss 3.8205 Accuracy 0.9952\n",
      "Epoch 30 Batch 100 Loss 3.8083 Accuracy 0.9952\n",
      "Epoch 30 Batch 150 Loss 3.8304 Accuracy 0.9952\n",
      "Epoch 30 Batch 200 Loss 3.7394 Accuracy 0.9953\n",
      "Epoch 30 Batch 250 Loss 3.7289 Accuracy 0.9953\n",
      "Epoch 30 Batch 300 Loss 3.7364 Accuracy 0.9953\n",
      "Epoch 30 Batch 350 Loss 3.7356 Accuracy 0.9953\n",
      "Epoch 30 Batch 400 Loss 3.7280 Accuracy 0.9953\n",
      "Epoch 30 Batch 450 Loss 3.7682 Accuracy 0.9953\n",
      "Epoch 30 Batch 500 Loss 3.7483 Accuracy 0.9953\n",
      "Epoch 30 Batch 550 Loss 3.7641 Accuracy 0.9953\n",
      "Epoch 30 Batch 600 Loss 3.7872 Accuracy 0.9953\n",
      "Epoch 30 Batch 650 Loss 3.7880 Accuracy 0.9953\n",
      "Epoch 30 Batch 700 Loss 3.7818 Accuracy 0.9953\n",
      "Epoch 30 Batch 750 Loss 3.7801 Accuracy 0.9953\n",
      "Epoch 30 Batch 800 Loss 3.7577 Accuracy 0.9953\n",
      "Epoch 30 Batch 850 Loss 3.7620 Accuracy 0.9953\n",
      "Epoch 30 Batch 900 Loss 3.7601 Accuracy 0.9953\n",
      "Epoch 30 Batch 950 Loss 3.7675 Accuracy 0.9953\n",
      "Epoch 30 Batch 1000 Loss 3.7628 Accuracy 0.9953\n",
      "Epoch 30 Batch 1050 Loss 3.7485 Accuracy 0.9953\n",
      "Epoch 30 Batch 1100 Loss 3.7468 Accuracy 0.9953\n",
      "Epoch 30 Batch 1150 Loss 3.7335 Accuracy 0.9953\n",
      "Epoch 30 Batch 1200 Loss 3.7490 Accuracy 0.9953\n",
      "Epoch 30 Batch 1250 Loss 3.7398 Accuracy 0.9953\n",
      "Epoch 30 Batch 1300 Loss 3.7451 Accuracy 0.9953\n",
      "Epoch 30 Batch 1350 Loss 3.7392 Accuracy 0.9953\n",
      "Epoch 30 Batch 1400 Loss 3.7420 Accuracy 0.9953\n",
      "Epoch 30 Batch 1450 Loss 3.7314 Accuracy 0.9953\n",
      "Epoch 30 Batch 1500 Loss 3.7301 Accuracy 0.9953\n",
      "Epoch 30 Batch 1550 Loss 3.7331 Accuracy 0.9953\n",
      "Epoch 30 Batch 1600 Loss 3.7336 Accuracy 0.9953\n",
      "Epoch 30 Batch 1650 Loss 3.7317 Accuracy 0.9953\n",
      "Epoch 30 Batch 1700 Loss 3.7373 Accuracy 0.9953\n",
      "Epoch 30 Batch 1750 Loss 3.7303 Accuracy 0.9953\n",
      "Epoch 30 Batch 1800 Loss 3.7321 Accuracy 0.9953\n",
      "Epoch 30 Batch 1850 Loss 3.7228 Accuracy 0.9953\n",
      "Epoch 30 Batch 1900 Loss 3.7174 Accuracy 0.9954\n",
      "Epoch 30 Batch 1950 Loss 3.7050 Accuracy 0.9954\n",
      "Epoch 30 Batch 2000 Loss 3.7124 Accuracy 0.9954\n",
      "Epoch 30 Batch 2050 Loss 3.7205 Accuracy 0.9954\n",
      "Epoch 30 Batch 2100 Loss 3.7185 Accuracy 0.9954\n",
      "Epoch 30 Batch 2150 Loss 3.7202 Accuracy 0.9954\n",
      "Epoch 30 Batch 2200 Loss 3.7257 Accuracy 0.9953\n",
      "Epoch 30 Batch 2250 Loss 3.7270 Accuracy 0.9953\n",
      "Epoch 30 Batch 2300 Loss 3.7241 Accuracy 0.9954\n",
      "Epoch 30 Batch 2350 Loss 3.7244 Accuracy 0.9953\n",
      "Epoch 30 Batch 2400 Loss 3.7274 Accuracy 0.9953\n",
      "Epoch 30 Batch 2450 Loss 3.7300 Accuracy 0.9953\n",
      "Epoch 30 Batch 2500 Loss 3.7334 Accuracy 0.9953\n",
      "Epoch 30 Batch 2550 Loss 3.7318 Accuracy 0.9953\n",
      "Epoch 30 Batch 2600 Loss 3.7281 Accuracy 0.9953\n",
      "Epoch 30 Batch 2650 Loss 3.7257 Accuracy 0.9953\n",
      "Saving checkpoint for epoch 30 at ./checkpoints/train\\ckpt-7\n",
      "Epoch 30 Loss 3.7273 Accuracy 0.9953\n",
      "Time taken for 1 epoch: 196.3065004348755 secs\n",
      "\n",
      "Epoch 31 Batch 0 Loss 2.2693 Accuracy 0.9972\n",
      "Epoch 31 Batch 50 Loss 3.7403 Accuracy 0.9953\n",
      "Epoch 31 Batch 100 Loss 3.7176 Accuracy 0.9954\n",
      "Epoch 31 Batch 150 Loss 3.7951 Accuracy 0.9953\n",
      "Epoch 31 Batch 200 Loss 3.6861 Accuracy 0.9954\n",
      "Epoch 31 Batch 250 Loss 3.6685 Accuracy 0.9954\n",
      "Epoch 31 Batch 300 Loss 3.6721 Accuracy 0.9954\n",
      "Epoch 31 Batch 350 Loss 3.6792 Accuracy 0.9954\n",
      "Epoch 31 Batch 400 Loss 3.6769 Accuracy 0.9954\n",
      "Epoch 31 Batch 450 Loss 3.7155 Accuracy 0.9953\n",
      "Epoch 31 Batch 500 Loss 3.7022 Accuracy 0.9954\n",
      "Epoch 31 Batch 550 Loss 3.7207 Accuracy 0.9953\n",
      "Epoch 31 Batch 600 Loss 3.7418 Accuracy 0.9953\n",
      "Epoch 31 Batch 650 Loss 3.7339 Accuracy 0.9953\n",
      "Epoch 31 Batch 700 Loss 3.7313 Accuracy 0.9953\n",
      "Epoch 31 Batch 750 Loss 3.7286 Accuracy 0.9953\n",
      "Epoch 31 Batch 800 Loss 3.7105 Accuracy 0.9954\n",
      "Epoch 31 Batch 850 Loss 3.7135 Accuracy 0.9954\n",
      "Epoch 31 Batch 900 Loss 3.7118 Accuracy 0.9953\n",
      "Epoch 31 Batch 950 Loss 3.7169 Accuracy 0.9953\n",
      "Epoch 31 Batch 1000 Loss 3.7135 Accuracy 0.9953\n",
      "Epoch 31 Batch 1050 Loss 3.7002 Accuracy 0.9954\n",
      "Epoch 31 Batch 1100 Loss 3.7010 Accuracy 0.9954\n",
      "Epoch 31 Batch 1150 Loss 3.6883 Accuracy 0.9954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 1200 Loss 3.7071 Accuracy 0.9954\n",
      "Epoch 31 Batch 1250 Loss 3.6996 Accuracy 0.9954\n",
      "Epoch 31 Batch 1300 Loss 3.7046 Accuracy 0.9954\n",
      "Epoch 31 Batch 1350 Loss 3.6961 Accuracy 0.9954\n",
      "Epoch 31 Batch 1400 Loss 3.6992 Accuracy 0.9954\n",
      "Epoch 31 Batch 1450 Loss 3.6897 Accuracy 0.9954\n",
      "Epoch 31 Batch 1500 Loss 3.6883 Accuracy 0.9954\n",
      "Epoch 31 Batch 1550 Loss 3.6913 Accuracy 0.9954\n",
      "Epoch 31 Batch 1600 Loss 3.6913 Accuracy 0.9954\n",
      "Epoch 31 Batch 1650 Loss 3.6899 Accuracy 0.9954\n",
      "Epoch 31 Batch 1700 Loss 3.6944 Accuracy 0.9954\n",
      "Epoch 31 Batch 1750 Loss 3.6867 Accuracy 0.9954\n",
      "Epoch 31 Batch 1800 Loss 3.6892 Accuracy 0.9954\n",
      "Epoch 31 Batch 1850 Loss 3.6790 Accuracy 0.9954\n",
      "Epoch 31 Batch 1900 Loss 3.6734 Accuracy 0.9954\n",
      "Epoch 31 Batch 1950 Loss 3.6636 Accuracy 0.9954\n",
      "Epoch 31 Batch 2000 Loss 3.6718 Accuracy 0.9954\n",
      "Epoch 31 Batch 2050 Loss 3.6801 Accuracy 0.9954\n",
      "Epoch 31 Batch 2100 Loss 3.6777 Accuracy 0.9954\n",
      "Epoch 31 Batch 2150 Loss 3.6807 Accuracy 0.9954\n",
      "Epoch 31 Batch 2200 Loss 3.6858 Accuracy 0.9954\n",
      "Epoch 31 Batch 2250 Loss 3.6881 Accuracy 0.9954\n",
      "Epoch 31 Batch 2300 Loss 3.6832 Accuracy 0.9954\n",
      "Epoch 31 Batch 2350 Loss 3.6814 Accuracy 0.9954\n",
      "Epoch 31 Batch 2400 Loss 3.6837 Accuracy 0.9954\n",
      "Epoch 31 Batch 2450 Loss 3.6859 Accuracy 0.9954\n",
      "Epoch 31 Batch 2500 Loss 3.6879 Accuracy 0.9954\n",
      "Epoch 31 Batch 2550 Loss 3.6881 Accuracy 0.9954\n",
      "Epoch 31 Batch 2600 Loss 3.6845 Accuracy 0.9954\n",
      "Epoch 31 Batch 2650 Loss 3.6818 Accuracy 0.9954\n",
      "Epoch 31 Loss 3.6830 Accuracy 0.9954\n",
      "Time taken for 1 epoch: 205.2301230430603 secs\n",
      "\n",
      "Epoch 32 Batch 0 Loss 2.3569 Accuracy 0.9974\n",
      "Epoch 32 Batch 50 Loss 3.7331 Accuracy 0.9954\n",
      "Epoch 32 Batch 100 Loss 3.7049 Accuracy 0.9954\n",
      "Epoch 32 Batch 150 Loss 3.7600 Accuracy 0.9953\n",
      "Epoch 32 Batch 200 Loss 3.6596 Accuracy 0.9954\n",
      "Epoch 32 Batch 250 Loss 3.6453 Accuracy 0.9954\n",
      "Epoch 32 Batch 300 Loss 3.6455 Accuracy 0.9954\n",
      "Epoch 32 Batch 350 Loss 3.6391 Accuracy 0.9954\n",
      "Epoch 32 Batch 400 Loss 3.6357 Accuracy 0.9954\n",
      "Epoch 32 Batch 450 Loss 3.6777 Accuracy 0.9954\n",
      "Epoch 32 Batch 500 Loss 3.6648 Accuracy 0.9954\n",
      "Epoch 32 Batch 550 Loss 3.6809 Accuracy 0.9954\n",
      "Epoch 32 Batch 600 Loss 3.6996 Accuracy 0.9954\n",
      "Epoch 32 Batch 650 Loss 3.6972 Accuracy 0.9954\n",
      "Epoch 32 Batch 700 Loss 3.6933 Accuracy 0.9954\n",
      "Epoch 32 Batch 750 Loss 3.6880 Accuracy 0.9954\n",
      "Epoch 32 Batch 800 Loss 3.6697 Accuracy 0.9954\n",
      "Epoch 32 Batch 850 Loss 3.6763 Accuracy 0.9954\n",
      "Epoch 32 Batch 900 Loss 3.6721 Accuracy 0.9954\n",
      "Epoch 32 Batch 950 Loss 3.6802 Accuracy 0.9954\n",
      "Epoch 32 Batch 1000 Loss 3.6746 Accuracy 0.9954\n",
      "Epoch 32 Batch 1050 Loss 3.6608 Accuracy 0.9954\n",
      "Epoch 32 Batch 1100 Loss 3.6609 Accuracy 0.9954\n",
      "Epoch 32 Batch 1150 Loss 3.6510 Accuracy 0.9954\n",
      "Epoch 32 Batch 1200 Loss 3.6686 Accuracy 0.9954\n",
      "Epoch 32 Batch 1250 Loss 3.6605 Accuracy 0.9954\n",
      "Epoch 32 Batch 1300 Loss 3.6611 Accuracy 0.9954\n",
      "Epoch 32 Batch 1350 Loss 3.6544 Accuracy 0.9954\n",
      "Epoch 32 Batch 1400 Loss 3.6581 Accuracy 0.9954\n",
      "Epoch 32 Batch 1450 Loss 3.6471 Accuracy 0.9954\n",
      "Epoch 32 Batch 1500 Loss 3.6452 Accuracy 0.9954\n",
      "Epoch 32 Batch 1550 Loss 3.6459 Accuracy 0.9954\n",
      "Epoch 32 Batch 1600 Loss 3.6456 Accuracy 0.9954\n",
      "Epoch 32 Batch 1650 Loss 3.6427 Accuracy 0.9954\n",
      "Epoch 32 Batch 1700 Loss 3.6480 Accuracy 0.9954\n",
      "Epoch 32 Batch 1750 Loss 3.6400 Accuracy 0.9954\n",
      "Epoch 32 Batch 1800 Loss 3.6425 Accuracy 0.9954\n",
      "Epoch 32 Batch 1850 Loss 3.6332 Accuracy 0.9955\n",
      "Epoch 32 Batch 1900 Loss 3.6277 Accuracy 0.9955\n",
      "Epoch 32 Batch 1950 Loss 3.6168 Accuracy 0.9955\n",
      "Epoch 32 Batch 2000 Loss 3.6228 Accuracy 0.9955\n",
      "Epoch 32 Batch 2050 Loss 3.6310 Accuracy 0.9955\n",
      "Epoch 32 Batch 2100 Loss 3.6291 Accuracy 0.9955\n",
      "Epoch 32 Batch 2150 Loss 3.6316 Accuracy 0.9955\n",
      "Epoch 32 Batch 2200 Loss 3.6376 Accuracy 0.9955\n",
      "Epoch 32 Batch 2250 Loss 3.6403 Accuracy 0.9954\n",
      "Epoch 32 Batch 2300 Loss 3.6371 Accuracy 0.9955\n",
      "Epoch 32 Batch 2350 Loss 3.6363 Accuracy 0.9955\n",
      "Epoch 32 Batch 2400 Loss 3.6379 Accuracy 0.9955\n",
      "Epoch 32 Batch 2450 Loss 3.6412 Accuracy 0.9954\n",
      "Epoch 32 Batch 2500 Loss 3.6445 Accuracy 0.9954\n",
      "Epoch 32 Batch 2550 Loss 3.6438 Accuracy 0.9954\n",
      "Epoch 32 Batch 2600 Loss 3.6410 Accuracy 0.9954\n",
      "Epoch 32 Batch 2650 Loss 3.6378 Accuracy 0.9955\n",
      "Epoch 32 Loss 3.6389 Accuracy 0.9955\n",
      "Time taken for 1 epoch: 213.34674072265625 secs\n",
      "\n",
      "Epoch 33 Batch 0 Loss 2.2418 Accuracy 0.9972\n",
      "Epoch 33 Batch 50 Loss 3.7245 Accuracy 0.9953\n",
      "Epoch 33 Batch 100 Loss 3.6766 Accuracy 0.9954\n",
      "Epoch 33 Batch 150 Loss 3.7221 Accuracy 0.9953\n",
      "Epoch 33 Batch 200 Loss 3.6126 Accuracy 0.9955\n",
      "Epoch 33 Batch 250 Loss 3.6029 Accuracy 0.9955\n",
      "Epoch 33 Batch 300 Loss 3.6016 Accuracy 0.9955\n",
      "Epoch 33 Batch 350 Loss 3.6021 Accuracy 0.9955\n",
      "Epoch 33 Batch 400 Loss 3.5900 Accuracy 0.9955\n",
      "Epoch 33 Batch 450 Loss 3.6275 Accuracy 0.9955\n",
      "Epoch 33 Batch 500 Loss 3.6156 Accuracy 0.9955\n",
      "Epoch 33 Batch 550 Loss 3.6416 Accuracy 0.9954\n",
      "Epoch 33 Batch 600 Loss 3.6591 Accuracy 0.9954\n",
      "Epoch 33 Batch 650 Loss 3.6596 Accuracy 0.9954\n",
      "Epoch 33 Batch 700 Loss 3.6531 Accuracy 0.9954\n",
      "Epoch 33 Batch 750 Loss 3.6480 Accuracy 0.9954\n",
      "Epoch 33 Batch 800 Loss 3.6284 Accuracy 0.9955\n",
      "Epoch 33 Batch 850 Loss 3.6311 Accuracy 0.9955\n",
      "Epoch 33 Batch 900 Loss 3.6329 Accuracy 0.9955\n",
      "Epoch 33 Batch 950 Loss 3.6382 Accuracy 0.9955\n",
      "Epoch 33 Batch 1000 Loss 3.6355 Accuracy 0.9955\n",
      "Epoch 33 Batch 1050 Loss 3.6218 Accuracy 0.9955\n",
      "Epoch 33 Batch 1100 Loss 3.6193 Accuracy 0.9955\n",
      "Epoch 33 Batch 1150 Loss 3.6054 Accuracy 0.9955\n",
      "Epoch 33 Batch 1200 Loss 3.6213 Accuracy 0.9955\n",
      "Epoch 33 Batch 1250 Loss 3.6106 Accuracy 0.9955\n",
      "Epoch 33 Batch 1300 Loss 3.6132 Accuracy 0.9955\n",
      "Epoch 33 Batch 1350 Loss 3.6068 Accuracy 0.9955\n",
      "Epoch 33 Batch 1400 Loss 3.6093 Accuracy 0.9955\n",
      "Epoch 33 Batch 1450 Loss 3.6004 Accuracy 0.9955\n",
      "Epoch 33 Batch 1500 Loss 3.5978 Accuracy 0.9955\n",
      "Epoch 33 Batch 1550 Loss 3.6009 Accuracy 0.9955\n",
      "Epoch 33 Batch 1600 Loss 3.6010 Accuracy 0.9955\n",
      "Epoch 33 Batch 1650 Loss 3.5995 Accuracy 0.9955\n",
      "Epoch 33 Batch 1700 Loss 3.6045 Accuracy 0.9955\n",
      "Epoch 33 Batch 1750 Loss 3.5977 Accuracy 0.9955\n",
      "Epoch 33 Batch 1800 Loss 3.5980 Accuracy 0.9955\n",
      "Epoch 33 Batch 1850 Loss 3.5895 Accuracy 0.9955\n",
      "Epoch 33 Batch 1900 Loss 3.5847 Accuracy 0.9955\n",
      "Epoch 33 Batch 1950 Loss 3.5747 Accuracy 0.9955\n",
      "Epoch 33 Batch 2000 Loss 3.5811 Accuracy 0.9955\n",
      "Epoch 33 Batch 2050 Loss 3.5916 Accuracy 0.9955\n",
      "Epoch 33 Batch 2100 Loss 3.5888 Accuracy 0.9955\n",
      "Epoch 33 Batch 2150 Loss 3.5909 Accuracy 0.9955\n",
      "Epoch 33 Batch 2200 Loss 3.5961 Accuracy 0.9955\n",
      "Epoch 33 Batch 2250 Loss 3.5975 Accuracy 0.9955\n",
      "Epoch 33 Batch 2300 Loss 3.5934 Accuracy 0.9955\n",
      "Epoch 33 Batch 2350 Loss 3.5929 Accuracy 0.9955\n",
      "Epoch 33 Batch 2400 Loss 3.5951 Accuracy 0.9955\n",
      "Epoch 33 Batch 2450 Loss 3.5959 Accuracy 0.9955\n",
      "Epoch 33 Batch 2500 Loss 3.5990 Accuracy 0.9955\n",
      "Epoch 33 Batch 2550 Loss 3.5971 Accuracy 0.9955\n",
      "Epoch 33 Batch 2600 Loss 3.5941 Accuracy 0.9955\n",
      "Epoch 33 Batch 2650 Loss 3.5912 Accuracy 0.9955\n",
      "Epoch 33 Loss 3.5928 Accuracy 0.9955\n",
      "Time taken for 1 epoch: 197.12644124031067 secs\n",
      "\n",
      "Epoch 34 Batch 0 Loss 2.4051 Accuracy 0.9974\n",
      "Epoch 34 Batch 50 Loss 3.5905 Accuracy 0.9955\n",
      "Epoch 34 Batch 100 Loss 3.5949 Accuracy 0.9955\n",
      "Epoch 34 Batch 150 Loss 3.6460 Accuracy 0.9954\n",
      "Epoch 34 Batch 200 Loss 3.5570 Accuracy 0.9956\n",
      "Epoch 34 Batch 250 Loss 3.5442 Accuracy 0.9956\n",
      "Epoch 34 Batch 300 Loss 3.5621 Accuracy 0.9955\n",
      "Epoch 34 Batch 350 Loss 3.5651 Accuracy 0.9955\n",
      "Epoch 34 Batch 400 Loss 3.5559 Accuracy 0.9955\n",
      "Epoch 34 Batch 450 Loss 3.5950 Accuracy 0.9955\n",
      "Epoch 34 Batch 500 Loss 3.5801 Accuracy 0.9955\n",
      "Epoch 34 Batch 550 Loss 3.5983 Accuracy 0.9955\n",
      "Epoch 34 Batch 600 Loss 3.6230 Accuracy 0.9955\n",
      "Epoch 34 Batch 650 Loss 3.6182 Accuracy 0.9955\n",
      "Epoch 34 Batch 700 Loss 3.6111 Accuracy 0.9955\n",
      "Epoch 34 Batch 750 Loss 3.6076 Accuracy 0.9955\n",
      "Epoch 34 Batch 800 Loss 3.5889 Accuracy 0.9955\n",
      "Epoch 34 Batch 850 Loss 3.5936 Accuracy 0.9955\n",
      "Epoch 34 Batch 900 Loss 3.5953 Accuracy 0.9955\n",
      "Epoch 34 Batch 950 Loss 3.6038 Accuracy 0.9955\n",
      "Epoch 34 Batch 1000 Loss 3.6029 Accuracy 0.9955\n",
      "Epoch 34 Batch 1050 Loss 3.5892 Accuracy 0.9955\n",
      "Epoch 34 Batch 1100 Loss 3.5902 Accuracy 0.9955\n",
      "Epoch 34 Batch 1150 Loss 3.5780 Accuracy 0.9955\n",
      "Epoch 34 Batch 1200 Loss 3.5955 Accuracy 0.9955\n",
      "Epoch 34 Batch 1250 Loss 3.5844 Accuracy 0.9955\n",
      "Epoch 34 Batch 1300 Loss 3.5875 Accuracy 0.9955\n",
      "Epoch 34 Batch 1350 Loss 3.5819 Accuracy 0.9955\n",
      "Epoch 34 Batch 1400 Loss 3.5860 Accuracy 0.9955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 1450 Loss 3.5771 Accuracy 0.9955\n",
      "Epoch 34 Batch 1500 Loss 3.5743 Accuracy 0.9955\n",
      "Epoch 34 Batch 1550 Loss 3.5783 Accuracy 0.9955\n",
      "Epoch 34 Batch 1600 Loss 3.5779 Accuracy 0.9955\n",
      "Epoch 34 Batch 1650 Loss 3.5761 Accuracy 0.9955\n",
      "Epoch 34 Batch 1700 Loss 3.5804 Accuracy 0.9955\n",
      "Epoch 34 Batch 1750 Loss 3.5717 Accuracy 0.9955\n",
      "Epoch 34 Batch 1800 Loss 3.5720 Accuracy 0.9955\n",
      "Epoch 34 Batch 1850 Loss 3.5624 Accuracy 0.9956\n",
      "Epoch 34 Batch 1900 Loss 3.5572 Accuracy 0.9956\n",
      "Epoch 34 Batch 1950 Loss 3.5462 Accuracy 0.9956\n",
      "Epoch 34 Batch 2000 Loss 3.5528 Accuracy 0.9956\n",
      "Epoch 34 Batch 2050 Loss 3.5616 Accuracy 0.9956\n",
      "Epoch 34 Batch 2100 Loss 3.5590 Accuracy 0.9956\n",
      "Epoch 34 Batch 2150 Loss 3.5592 Accuracy 0.9956\n",
      "Epoch 34 Batch 2200 Loss 3.5647 Accuracy 0.9956\n",
      "Epoch 34 Batch 2250 Loss 3.5678 Accuracy 0.9955\n",
      "Epoch 34 Batch 2300 Loss 3.5643 Accuracy 0.9955\n",
      "Epoch 34 Batch 2350 Loss 3.5648 Accuracy 0.9955\n",
      "Epoch 34 Batch 2400 Loss 3.5668 Accuracy 0.9955\n",
      "Epoch 34 Batch 2450 Loss 3.5683 Accuracy 0.9955\n",
      "Epoch 34 Batch 2500 Loss 3.5720 Accuracy 0.9955\n",
      "Epoch 34 Batch 2550 Loss 3.5711 Accuracy 0.9955\n",
      "Epoch 34 Batch 2600 Loss 3.5679 Accuracy 0.9955\n",
      "Epoch 34 Batch 2650 Loss 3.5648 Accuracy 0.9955\n",
      "Epoch 34 Loss 3.5673 Accuracy 0.9955\n",
      "Time taken for 1 epoch: 195.99341869354248 secs\n",
      "\n",
      "Epoch 35 Batch 0 Loss 2.0714 Accuracy 0.9976\n",
      "Epoch 35 Batch 50 Loss 3.5820 Accuracy 0.9955\n",
      "Epoch 35 Batch 100 Loss 3.5348 Accuracy 0.9956\n",
      "Epoch 35 Batch 150 Loss 3.5784 Accuracy 0.9955\n",
      "Epoch 35 Batch 200 Loss 3.4908 Accuracy 0.9956\n",
      "Epoch 35 Batch 250 Loss 3.4814 Accuracy 0.9956\n",
      "Epoch 35 Batch 300 Loss 3.4832 Accuracy 0.9956\n",
      "Epoch 35 Batch 350 Loss 3.4877 Accuracy 0.9956\n",
      "Epoch 35 Batch 400 Loss 3.4814 Accuracy 0.9956\n",
      "Epoch 35 Batch 450 Loss 3.5264 Accuracy 0.9956\n",
      "Epoch 35 Batch 500 Loss 3.5153 Accuracy 0.9956\n",
      "Epoch 35 Batch 550 Loss 3.5386 Accuracy 0.9956\n",
      "Epoch 35 Batch 600 Loss 3.5549 Accuracy 0.9956\n",
      "Epoch 35 Batch 650 Loss 3.5513 Accuracy 0.9956\n",
      "Epoch 35 Batch 700 Loss 3.5505 Accuracy 0.9956\n",
      "Epoch 35 Batch 750 Loss 3.5504 Accuracy 0.9956\n",
      "Epoch 35 Batch 800 Loss 3.5314 Accuracy 0.9956\n",
      "Epoch 35 Batch 850 Loss 3.5385 Accuracy 0.9956\n",
      "Epoch 35 Batch 900 Loss 3.5381 Accuracy 0.9956\n",
      "Epoch 35 Batch 950 Loss 3.5465 Accuracy 0.9956\n",
      "Epoch 35 Batch 1000 Loss 3.5427 Accuracy 0.9956\n",
      "Epoch 35 Batch 1050 Loss 3.5288 Accuracy 0.9956\n",
      "Epoch 35 Batch 1100 Loss 3.5268 Accuracy 0.9956\n",
      "Epoch 35 Batch 1150 Loss 3.5157 Accuracy 0.9956\n",
      "Epoch 35 Batch 1200 Loss 3.5327 Accuracy 0.9956\n",
      "Epoch 35 Batch 1250 Loss 3.5228 Accuracy 0.9956\n",
      "Epoch 35 Batch 1300 Loss 3.5279 Accuracy 0.9956\n",
      "Epoch 35 Batch 1350 Loss 3.5226 Accuracy 0.9956\n",
      "Epoch 35 Batch 1400 Loss 3.5282 Accuracy 0.9956\n",
      "Epoch 35 Batch 1450 Loss 3.5195 Accuracy 0.9956\n",
      "Epoch 35 Batch 1500 Loss 3.5183 Accuracy 0.9956\n",
      "Epoch 35 Batch 1550 Loss 3.5193 Accuracy 0.9956\n",
      "Epoch 35 Batch 1600 Loss 3.5199 Accuracy 0.9956\n",
      "Epoch 35 Batch 1650 Loss 3.5196 Accuracy 0.9956\n",
      "Epoch 35 Batch 1700 Loss 3.5253 Accuracy 0.9956\n",
      "Epoch 35 Batch 1750 Loss 3.5186 Accuracy 0.9956\n",
      "Epoch 35 Batch 1800 Loss 3.5200 Accuracy 0.9956\n",
      "Epoch 35 Batch 1850 Loss 3.5110 Accuracy 0.9956\n",
      "Epoch 35 Batch 1900 Loss 3.5048 Accuracy 0.9956\n",
      "Epoch 35 Batch 1950 Loss 3.4959 Accuracy 0.9956\n",
      "Epoch 35 Batch 2000 Loss 3.5027 Accuracy 0.9956\n",
      "Epoch 35 Batch 2050 Loss 3.5115 Accuracy 0.9956\n",
      "Epoch 35 Batch 2100 Loss 3.5097 Accuracy 0.9956\n",
      "Epoch 35 Batch 2150 Loss 3.5105 Accuracy 0.9956\n",
      "Epoch 35 Batch 2200 Loss 3.5157 Accuracy 0.9956\n",
      "Epoch 35 Batch 2250 Loss 3.5186 Accuracy 0.9956\n",
      "Epoch 35 Batch 2300 Loss 3.5143 Accuracy 0.9956\n",
      "Epoch 35 Batch 2350 Loss 3.5143 Accuracy 0.9956\n",
      "Epoch 35 Batch 2400 Loss 3.5169 Accuracy 0.9956\n",
      "Epoch 35 Batch 2450 Loss 3.5188 Accuracy 0.9956\n",
      "Epoch 35 Batch 2500 Loss 3.5228 Accuracy 0.9956\n",
      "Epoch 35 Batch 2550 Loss 3.5222 Accuracy 0.9956\n",
      "Epoch 35 Batch 2600 Loss 3.5191 Accuracy 0.9956\n",
      "Epoch 35 Batch 2650 Loss 3.5170 Accuracy 0.9956\n",
      "Saving checkpoint for epoch 35 at ./checkpoints/train\\ckpt-8\n",
      "Epoch 35 Loss 3.5184 Accuracy 0.9956\n",
      "Time taken for 1 epoch: 198.88018989562988 secs\n",
      "\n",
      "Epoch 36 Batch 0 Loss 2.5759 Accuracy 0.9969\n",
      "Epoch 36 Batch 50 Loss 3.5791 Accuracy 0.9955\n",
      "Epoch 36 Batch 100 Loss 3.5368 Accuracy 0.9955\n",
      "Epoch 36 Batch 150 Loss 3.5706 Accuracy 0.9955\n",
      "Epoch 36 Batch 200 Loss 3.4838 Accuracy 0.9956\n",
      "Epoch 36 Batch 250 Loss 3.4749 Accuracy 0.9956\n",
      "Epoch 36 Batch 300 Loss 3.4835 Accuracy 0.9956\n",
      "Epoch 36 Batch 350 Loss 3.4869 Accuracy 0.9956\n",
      "Epoch 36 Batch 400 Loss 3.4874 Accuracy 0.9956\n",
      "Epoch 36 Batch 450 Loss 3.5300 Accuracy 0.9956\n",
      "Epoch 36 Batch 500 Loss 3.5117 Accuracy 0.9956\n",
      "Epoch 36 Batch 550 Loss 3.5247 Accuracy 0.9956\n",
      "Epoch 36 Batch 600 Loss 3.5412 Accuracy 0.9956\n",
      "Epoch 36 Batch 650 Loss 3.5384 Accuracy 0.9956\n",
      "Epoch 36 Batch 700 Loss 3.5377 Accuracy 0.9956\n",
      "Epoch 36 Batch 750 Loss 3.5344 Accuracy 0.9956\n",
      "Epoch 36 Batch 800 Loss 3.5151 Accuracy 0.9956\n",
      "Epoch 36 Batch 850 Loss 3.5194 Accuracy 0.9956\n",
      "Epoch 36 Batch 900 Loss 3.5184 Accuracy 0.9956\n",
      "Epoch 36 Batch 950 Loss 3.5235 Accuracy 0.9956\n",
      "Epoch 36 Batch 1000 Loss 3.5182 Accuracy 0.9956\n",
      "Epoch 36 Batch 1050 Loss 3.5087 Accuracy 0.9956\n",
      "Epoch 36 Batch 1100 Loss 3.5071 Accuracy 0.9956\n",
      "Epoch 36 Batch 1150 Loss 3.4926 Accuracy 0.9956\n",
      "Epoch 36 Batch 1200 Loss 3.5110 Accuracy 0.9956\n",
      "Epoch 36 Batch 1250 Loss 3.5032 Accuracy 0.9956\n",
      "Epoch 36 Batch 1300 Loss 3.5060 Accuracy 0.9956\n",
      "Epoch 36 Batch 1350 Loss 3.5016 Accuracy 0.9956\n",
      "Epoch 36 Batch 1400 Loss 3.5060 Accuracy 0.9956\n",
      "Epoch 36 Batch 1450 Loss 3.4974 Accuracy 0.9956\n",
      "Epoch 36 Batch 1500 Loss 3.4962 Accuracy 0.9956\n",
      "Epoch 36 Batch 1550 Loss 3.5007 Accuracy 0.9956\n",
      "Epoch 36 Batch 1600 Loss 3.5029 Accuracy 0.9956\n",
      "Epoch 36 Batch 1650 Loss 3.5013 Accuracy 0.9956\n",
      "Epoch 36 Batch 1700 Loss 3.5071 Accuracy 0.9956\n",
      "Epoch 36 Batch 1750 Loss 3.4978 Accuracy 0.9956\n",
      "Epoch 36 Batch 1800 Loss 3.5001 Accuracy 0.9956\n",
      "Epoch 36 Batch 1850 Loss 3.4893 Accuracy 0.9956\n",
      "Epoch 36 Batch 1900 Loss 3.4825 Accuracy 0.9957\n",
      "Epoch 36 Batch 1950 Loss 3.4703 Accuracy 0.9957\n",
      "Epoch 36 Batch 2000 Loss 3.4781 Accuracy 0.9957\n",
      "Epoch 36 Batch 2050 Loss 3.4855 Accuracy 0.9956\n",
      "Epoch 36 Batch 2100 Loss 3.4824 Accuracy 0.9957\n",
      "Epoch 36 Batch 2150 Loss 3.4846 Accuracy 0.9957\n",
      "Epoch 36 Batch 2200 Loss 3.4893 Accuracy 0.9956\n",
      "Epoch 36 Batch 2250 Loss 3.4915 Accuracy 0.9956\n",
      "Epoch 36 Batch 2300 Loss 3.4881 Accuracy 0.9956\n",
      "Epoch 36 Batch 2350 Loss 3.4885 Accuracy 0.9956\n",
      "Epoch 36 Batch 2400 Loss 3.4907 Accuracy 0.9956\n",
      "Epoch 36 Batch 2450 Loss 3.4924 Accuracy 0.9956\n",
      "Epoch 36 Batch 2500 Loss 3.4954 Accuracy 0.9956\n",
      "Epoch 36 Batch 2550 Loss 3.4946 Accuracy 0.9956\n",
      "Epoch 36 Batch 2600 Loss 3.4906 Accuracy 0.9956\n",
      "Epoch 36 Batch 2650 Loss 3.4876 Accuracy 0.9956\n",
      "Epoch 36 Loss 3.4888 Accuracy 0.9956\n",
      "Time taken for 1 epoch: 195.29011917114258 secs\n",
      "\n",
      "Epoch 37 Batch 0 Loss 2.4854 Accuracy 0.9970\n",
      "Epoch 37 Batch 50 Loss 3.5327 Accuracy 0.9956\n",
      "Epoch 37 Batch 100 Loss 3.5055 Accuracy 0.9956\n",
      "Epoch 37 Batch 150 Loss 3.5395 Accuracy 0.9956\n",
      "Epoch 37 Batch 200 Loss 3.4376 Accuracy 0.9957\n",
      "Epoch 37 Batch 250 Loss 3.4137 Accuracy 0.9957\n",
      "Epoch 37 Batch 300 Loss 3.4212 Accuracy 0.9957\n",
      "Epoch 37 Batch 350 Loss 3.4306 Accuracy 0.9957\n",
      "Epoch 37 Batch 400 Loss 3.4272 Accuracy 0.9957\n",
      "Epoch 37 Batch 450 Loss 3.4728 Accuracy 0.9956\n",
      "Epoch 37 Batch 500 Loss 3.4569 Accuracy 0.9957\n",
      "Epoch 37 Batch 550 Loss 3.4781 Accuracy 0.9956\n",
      "Epoch 37 Batch 600 Loss 3.5011 Accuracy 0.9956\n",
      "Epoch 37 Batch 650 Loss 3.4973 Accuracy 0.9956\n",
      "Epoch 37 Batch 700 Loss 3.4941 Accuracy 0.9956\n",
      "Epoch 37 Batch 750 Loss 3.4955 Accuracy 0.9956\n",
      "Epoch 37 Batch 800 Loss 3.4810 Accuracy 0.9956\n",
      "Epoch 37 Batch 850 Loss 3.4871 Accuracy 0.9956\n",
      "Epoch 37 Batch 900 Loss 3.4873 Accuracy 0.9956\n",
      "Epoch 37 Batch 950 Loss 3.4904 Accuracy 0.9956\n",
      "Epoch 37 Batch 1000 Loss 3.4870 Accuracy 0.9956\n",
      "Epoch 37 Batch 1050 Loss 3.4739 Accuracy 0.9957\n",
      "Epoch 37 Batch 1100 Loss 3.4718 Accuracy 0.9957\n",
      "Epoch 37 Batch 1150 Loss 3.4594 Accuracy 0.9957\n",
      "Epoch 37 Batch 1200 Loss 3.4749 Accuracy 0.9957\n",
      "Epoch 37 Batch 1250 Loss 3.4659 Accuracy 0.9957\n",
      "Epoch 37 Batch 1300 Loss 3.4676 Accuracy 0.9957\n",
      "Epoch 37 Batch 1350 Loss 3.4603 Accuracy 0.9957\n",
      "Epoch 37 Batch 1400 Loss 3.4665 Accuracy 0.9957\n",
      "Epoch 37 Batch 1450 Loss 3.4565 Accuracy 0.9957\n",
      "Epoch 37 Batch 1500 Loss 3.4571 Accuracy 0.9957\n",
      "Epoch 37 Batch 1550 Loss 3.4608 Accuracy 0.9957\n",
      "Epoch 37 Batch 1600 Loss 3.4601 Accuracy 0.9957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 1650 Loss 3.4605 Accuracy 0.9957\n",
      "Epoch 37 Batch 1700 Loss 3.4653 Accuracy 0.9957\n",
      "Epoch 37 Batch 1750 Loss 3.4575 Accuracy 0.9957\n",
      "Epoch 37 Batch 1800 Loss 3.4584 Accuracy 0.9957\n",
      "Epoch 37 Batch 1850 Loss 3.4489 Accuracy 0.9957\n",
      "Epoch 37 Batch 1900 Loss 3.4435 Accuracy 0.9957\n",
      "Epoch 37 Batch 1950 Loss 3.4342 Accuracy 0.9957\n",
      "Epoch 37 Batch 2000 Loss 3.4405 Accuracy 0.9957\n",
      "Epoch 37 Batch 2050 Loss 3.4495 Accuracy 0.9957\n",
      "Epoch 37 Batch 2100 Loss 3.4472 Accuracy 0.9957\n",
      "Epoch 37 Batch 2150 Loss 3.4507 Accuracy 0.9957\n",
      "Epoch 37 Batch 2200 Loss 3.4548 Accuracy 0.9957\n",
      "Epoch 37 Batch 2250 Loss 3.4572 Accuracy 0.9957\n",
      "Epoch 37 Batch 2300 Loss 3.4543 Accuracy 0.9957\n",
      "Epoch 37 Batch 2350 Loss 3.4541 Accuracy 0.9957\n",
      "Epoch 37 Batch 2400 Loss 3.4569 Accuracy 0.9957\n",
      "Epoch 37 Batch 2450 Loss 3.4585 Accuracy 0.9957\n",
      "Epoch 37 Batch 2500 Loss 3.4618 Accuracy 0.9957\n",
      "Epoch 37 Batch 2550 Loss 3.4615 Accuracy 0.9957\n",
      "Epoch 37 Batch 2600 Loss 3.4571 Accuracy 0.9957\n",
      "Epoch 37 Batch 2650 Loss 3.4534 Accuracy 0.9957\n",
      "Epoch 37 Loss 3.4558 Accuracy 0.9957\n",
      "Time taken for 1 epoch: 195.51652073860168 secs\n",
      "\n",
      "Epoch 38 Batch 0 Loss 1.9997 Accuracy 0.9976\n",
      "Epoch 38 Batch 50 Loss 3.5003 Accuracy 0.9956\n",
      "Epoch 38 Batch 100 Loss 3.4515 Accuracy 0.9957\n",
      "Epoch 38 Batch 150 Loss 3.5097 Accuracy 0.9956\n",
      "Epoch 38 Batch 200 Loss 3.4120 Accuracy 0.9957\n",
      "Epoch 38 Batch 250 Loss 3.3926 Accuracy 0.9957\n",
      "Epoch 38 Batch 300 Loss 3.3945 Accuracy 0.9957\n",
      "Epoch 38 Batch 350 Loss 3.3956 Accuracy 0.9957\n",
      "Epoch 38 Batch 400 Loss 3.3877 Accuracy 0.9958\n",
      "Epoch 38 Batch 450 Loss 3.4275 Accuracy 0.9957\n",
      "Epoch 38 Batch 500 Loss 3.4093 Accuracy 0.9957\n",
      "Epoch 38 Batch 550 Loss 3.4304 Accuracy 0.9957\n",
      "Epoch 38 Batch 600 Loss 3.4520 Accuracy 0.9957\n",
      "Epoch 38 Batch 650 Loss 3.4469 Accuracy 0.9957\n",
      "Epoch 38 Batch 700 Loss 3.4464 Accuracy 0.9957\n",
      "Epoch 38 Batch 750 Loss 3.4458 Accuracy 0.9957\n",
      "Epoch 38 Batch 800 Loss 3.4306 Accuracy 0.9957\n",
      "Epoch 38 Batch 850 Loss 3.4399 Accuracy 0.9957\n",
      "Epoch 38 Batch 900 Loss 3.4400 Accuracy 0.9957\n",
      "Epoch 38 Batch 950 Loss 3.4477 Accuracy 0.9957\n",
      "Epoch 38 Batch 1000 Loss 3.4469 Accuracy 0.9957\n",
      "Epoch 38 Batch 1050 Loss 3.4335 Accuracy 0.9957\n",
      "Epoch 38 Batch 1100 Loss 3.4307 Accuracy 0.9957\n",
      "Epoch 38 Batch 1150 Loss 3.4186 Accuracy 0.9957\n",
      "Epoch 38 Batch 1200 Loss 3.4334 Accuracy 0.9957\n",
      "Epoch 38 Batch 1250 Loss 3.4280 Accuracy 0.9957\n",
      "Epoch 38 Batch 1300 Loss 3.4327 Accuracy 0.9957\n",
      "Epoch 38 Batch 1350 Loss 3.4258 Accuracy 0.9957\n",
      "Epoch 38 Batch 1400 Loss 3.4291 Accuracy 0.9957\n",
      "Epoch 38 Batch 1450 Loss 3.4223 Accuracy 0.9957\n",
      "Epoch 38 Batch 1500 Loss 3.4204 Accuracy 0.9957\n",
      "Epoch 38 Batch 1550 Loss 3.4241 Accuracy 0.9957\n",
      "Epoch 38 Batch 1600 Loss 3.4241 Accuracy 0.9957\n",
      "Epoch 38 Batch 1650 Loss 3.4220 Accuracy 0.9957\n",
      "Epoch 38 Batch 1700 Loss 3.4268 Accuracy 0.9957\n",
      "Epoch 38 Batch 1750 Loss 3.4208 Accuracy 0.9957\n",
      "Epoch 38 Batch 1800 Loss 3.4231 Accuracy 0.9957\n",
      "Epoch 38 Batch 1850 Loss 3.4150 Accuracy 0.9957\n",
      "Epoch 38 Batch 1900 Loss 3.4093 Accuracy 0.9957\n",
      "Epoch 38 Batch 1950 Loss 3.3981 Accuracy 0.9958\n",
      "Epoch 38 Batch 2000 Loss 3.4042 Accuracy 0.9957\n",
      "Epoch 38 Batch 2050 Loss 3.4115 Accuracy 0.9957\n",
      "Epoch 38 Batch 2100 Loss 3.4074 Accuracy 0.9957\n",
      "Epoch 38 Batch 2150 Loss 3.4100 Accuracy 0.9957\n",
      "Epoch 38 Batch 2200 Loss 3.4156 Accuracy 0.9957\n",
      "Epoch 38 Batch 2250 Loss 3.4181 Accuracy 0.9957\n",
      "Epoch 38 Batch 2300 Loss 3.4145 Accuracy 0.9957\n",
      "Epoch 38 Batch 2350 Loss 3.4142 Accuracy 0.9957\n",
      "Epoch 38 Batch 2400 Loss 3.4160 Accuracy 0.9957\n",
      "Epoch 38 Batch 2450 Loss 3.4179 Accuracy 0.9957\n",
      "Epoch 38 Batch 2500 Loss 3.4197 Accuracy 0.9957\n",
      "Epoch 38 Batch 2550 Loss 3.4195 Accuracy 0.9957\n",
      "Epoch 38 Batch 2600 Loss 3.4170 Accuracy 0.9957\n",
      "Epoch 38 Batch 2650 Loss 3.4143 Accuracy 0.9957\n",
      "Epoch 38 Loss 3.4155 Accuracy 0.9957\n",
      "Time taken for 1 epoch: 195.87642765045166 secs\n",
      "\n",
      "Epoch 39 Batch 0 Loss 2.3469 Accuracy 0.9973\n",
      "Epoch 39 Batch 50 Loss 3.5027 Accuracy 0.9956\n",
      "Epoch 39 Batch 100 Loss 3.4392 Accuracy 0.9957\n",
      "Epoch 39 Batch 150 Loss 3.4722 Accuracy 0.9956\n",
      "Epoch 39 Batch 200 Loss 3.3800 Accuracy 0.9957\n",
      "Epoch 39 Batch 250 Loss 3.3742 Accuracy 0.9958\n",
      "Epoch 39 Batch 300 Loss 3.3793 Accuracy 0.9958\n",
      "Epoch 39 Batch 350 Loss 3.3732 Accuracy 0.9958\n",
      "Epoch 39 Batch 400 Loss 3.3653 Accuracy 0.9958\n",
      "Epoch 39 Batch 450 Loss 3.4105 Accuracy 0.9957\n",
      "Epoch 39 Batch 500 Loss 3.3997 Accuracy 0.9957\n",
      "Epoch 39 Batch 550 Loss 3.4207 Accuracy 0.9957\n",
      "Epoch 39 Batch 600 Loss 3.4360 Accuracy 0.9957\n",
      "Epoch 39 Batch 650 Loss 3.4335 Accuracy 0.9957\n",
      "Epoch 39 Batch 700 Loss 3.4318 Accuracy 0.9957\n",
      "Epoch 39 Batch 750 Loss 3.4325 Accuracy 0.9957\n",
      "Epoch 39 Batch 800 Loss 3.4125 Accuracy 0.9957\n",
      "Epoch 39 Batch 850 Loss 3.4193 Accuracy 0.9957\n",
      "Epoch 39 Batch 900 Loss 3.4196 Accuracy 0.9957\n",
      "Epoch 39 Batch 950 Loss 3.4205 Accuracy 0.9957\n",
      "Epoch 39 Batch 1000 Loss 3.4174 Accuracy 0.9957\n",
      "Epoch 39 Batch 1050 Loss 3.4037 Accuracy 0.9957\n",
      "Epoch 39 Batch 1100 Loss 3.4053 Accuracy 0.9957\n",
      "Epoch 39 Batch 1150 Loss 3.3940 Accuracy 0.9958\n",
      "Epoch 39 Batch 1200 Loss 3.4084 Accuracy 0.9957\n",
      "Epoch 39 Batch 1250 Loss 3.4011 Accuracy 0.9957\n",
      "Epoch 39 Batch 1300 Loss 3.4051 Accuracy 0.9957\n",
      "Epoch 39 Batch 1350 Loss 3.3998 Accuracy 0.9957\n",
      "Epoch 39 Batch 1400 Loss 3.4039 Accuracy 0.9957\n",
      "Epoch 39 Batch 1450 Loss 3.3940 Accuracy 0.9958\n",
      "Epoch 39 Batch 1500 Loss 3.3908 Accuracy 0.9958\n",
      "Epoch 39 Batch 1550 Loss 3.3936 Accuracy 0.9958\n",
      "Epoch 39 Batch 1600 Loss 3.3940 Accuracy 0.9958\n",
      "Epoch 39 Batch 1650 Loss 3.3931 Accuracy 0.9958\n",
      "Epoch 39 Batch 1700 Loss 3.3986 Accuracy 0.9958\n",
      "Epoch 39 Batch 1750 Loss 3.3900 Accuracy 0.9958\n",
      "Epoch 39 Batch 1800 Loss 3.3922 Accuracy 0.9958\n",
      "Epoch 39 Batch 1850 Loss 3.3825 Accuracy 0.9958\n",
      "Epoch 39 Batch 1900 Loss 3.3755 Accuracy 0.9958\n",
      "Epoch 39 Batch 1950 Loss 3.3641 Accuracy 0.9958\n",
      "Epoch 39 Batch 2000 Loss 3.3708 Accuracy 0.9958\n",
      "Epoch 39 Batch 2050 Loss 3.3799 Accuracy 0.9958\n",
      "Epoch 39 Batch 2100 Loss 3.3784 Accuracy 0.9958\n",
      "Epoch 39 Batch 2150 Loss 3.3812 Accuracy 0.9958\n",
      "Epoch 39 Batch 2200 Loss 3.3851 Accuracy 0.9958\n",
      "Epoch 39 Batch 2250 Loss 3.3880 Accuracy 0.9958\n",
      "Epoch 39 Batch 2300 Loss 3.3840 Accuracy 0.9958\n",
      "Epoch 39 Batch 2350 Loss 3.3844 Accuracy 0.9958\n",
      "Epoch 39 Batch 2400 Loss 3.3884 Accuracy 0.9958\n",
      "Epoch 39 Batch 2450 Loss 3.3912 Accuracy 0.9958\n",
      "Epoch 39 Batch 2500 Loss 3.3956 Accuracy 0.9958\n",
      "Epoch 39 Batch 2550 Loss 3.3947 Accuracy 0.9958\n",
      "Epoch 39 Batch 2600 Loss 3.3923 Accuracy 0.9958\n",
      "Epoch 39 Batch 2650 Loss 3.3898 Accuracy 0.9958\n",
      "Epoch 39 Loss 3.3911 Accuracy 0.9958\n",
      "Time taken for 1 epoch: 195.34043502807617 secs\n",
      "\n",
      "Epoch 40 Batch 0 Loss 2.2456 Accuracy 0.9974\n",
      "Epoch 40 Batch 50 Loss 3.4353 Accuracy 0.9957\n",
      "Epoch 40 Batch 100 Loss 3.4138 Accuracy 0.9957\n",
      "Epoch 40 Batch 150 Loss 3.4711 Accuracy 0.9957\n",
      "Epoch 40 Batch 200 Loss 3.3705 Accuracy 0.9958\n",
      "Epoch 40 Batch 250 Loss 3.3553 Accuracy 0.9958\n",
      "Epoch 40 Batch 300 Loss 3.3622 Accuracy 0.9958\n",
      "Epoch 40 Batch 350 Loss 3.3697 Accuracy 0.9958\n",
      "Epoch 40 Batch 400 Loss 3.3669 Accuracy 0.9958\n",
      "Epoch 40 Batch 450 Loss 3.4021 Accuracy 0.9957\n",
      "Epoch 40 Batch 500 Loss 3.3889 Accuracy 0.9958\n",
      "Epoch 40 Batch 550 Loss 3.4034 Accuracy 0.9957\n",
      "Epoch 40 Batch 600 Loss 3.4198 Accuracy 0.9957\n",
      "Epoch 40 Batch 650 Loss 3.4160 Accuracy 0.9957\n",
      "Epoch 40 Batch 700 Loss 3.4126 Accuracy 0.9957\n",
      "Epoch 40 Batch 750 Loss 3.4079 Accuracy 0.9957\n",
      "Epoch 40 Batch 800 Loss 3.3904 Accuracy 0.9958\n",
      "Epoch 40 Batch 850 Loss 3.3934 Accuracy 0.9958\n",
      "Epoch 40 Batch 900 Loss 3.3921 Accuracy 0.9958\n",
      "Epoch 40 Batch 950 Loss 3.3992 Accuracy 0.9958\n",
      "Epoch 40 Batch 1000 Loss 3.3973 Accuracy 0.9958\n",
      "Epoch 40 Batch 1050 Loss 3.3829 Accuracy 0.9958\n",
      "Epoch 40 Batch 1100 Loss 3.3829 Accuracy 0.9958\n",
      "Epoch 40 Batch 1150 Loss 3.3707 Accuracy 0.9958\n",
      "Epoch 40 Batch 1200 Loss 3.3875 Accuracy 0.9958\n",
      "Epoch 40 Batch 1250 Loss 3.3801 Accuracy 0.9958\n",
      "Epoch 40 Batch 1300 Loss 3.3835 Accuracy 0.9958\n",
      "Epoch 40 Batch 1350 Loss 3.3755 Accuracy 0.9958\n",
      "Epoch 40 Batch 1400 Loss 3.3800 Accuracy 0.9958\n",
      "Epoch 40 Batch 1450 Loss 3.3707 Accuracy 0.9958\n",
      "Epoch 40 Batch 1500 Loss 3.3672 Accuracy 0.9958\n",
      "Epoch 40 Batch 1550 Loss 3.3692 Accuracy 0.9958\n",
      "Epoch 40 Batch 1600 Loss 3.3690 Accuracy 0.9958\n",
      "Epoch 40 Batch 1650 Loss 3.3686 Accuracy 0.9958\n",
      "Epoch 40 Batch 1700 Loss 3.3735 Accuracy 0.9958\n",
      "Epoch 40 Batch 1750 Loss 3.3664 Accuracy 0.9958\n",
      "Epoch 40 Batch 1800 Loss 3.3687 Accuracy 0.9958\n",
      "Epoch 40 Batch 1850 Loss 3.3614 Accuracy 0.9958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 1900 Loss 3.3557 Accuracy 0.9958\n",
      "Epoch 40 Batch 1950 Loss 3.3456 Accuracy 0.9958\n",
      "Epoch 40 Batch 2000 Loss 3.3516 Accuracy 0.9958\n",
      "Epoch 40 Batch 2050 Loss 3.3601 Accuracy 0.9958\n",
      "Epoch 40 Batch 2100 Loss 3.3577 Accuracy 0.9958\n",
      "Epoch 40 Batch 2150 Loss 3.3593 Accuracy 0.9958\n",
      "Epoch 40 Batch 2200 Loss 3.3638 Accuracy 0.9958\n",
      "Epoch 40 Batch 2250 Loss 3.3662 Accuracy 0.9958\n",
      "Epoch 40 Batch 2300 Loss 3.3616 Accuracy 0.9958\n",
      "Epoch 40 Batch 2350 Loss 3.3617 Accuracy 0.9958\n",
      "Epoch 40 Batch 2400 Loss 3.3644 Accuracy 0.9958\n",
      "Epoch 40 Batch 2450 Loss 3.3656 Accuracy 0.9958\n",
      "Epoch 40 Batch 2500 Loss 3.3676 Accuracy 0.9958\n",
      "Epoch 40 Batch 2550 Loss 3.3675 Accuracy 0.9958\n",
      "Epoch 40 Batch 2600 Loss 3.3640 Accuracy 0.9958\n",
      "Epoch 40 Batch 2650 Loss 3.3612 Accuracy 0.9958\n",
      "Saving checkpoint for epoch 40 at ./checkpoints/train\\ckpt-9\n",
      "Epoch 40 Loss 3.3625 Accuracy 0.9958\n",
      "Time taken for 1 epoch: 196.6831774711609 secs\n",
      "\n",
      "Epoch 41 Batch 0 Loss 2.3064 Accuracy 0.9974\n",
      "Epoch 41 Batch 50 Loss 3.4298 Accuracy 0.9957\n",
      "Epoch 41 Batch 100 Loss 3.4037 Accuracy 0.9957\n",
      "Epoch 41 Batch 150 Loss 3.4490 Accuracy 0.9957\n",
      "Epoch 41 Batch 200 Loss 3.3447 Accuracy 0.9958\n",
      "Epoch 41 Batch 250 Loss 3.3396 Accuracy 0.9958\n",
      "Epoch 41 Batch 300 Loss 3.3378 Accuracy 0.9958\n",
      "Epoch 41 Batch 350 Loss 3.3364 Accuracy 0.9958\n",
      "Epoch 41 Batch 400 Loss 3.3272 Accuracy 0.9958\n",
      "Epoch 41 Batch 450 Loss 3.3647 Accuracy 0.9958\n",
      "Epoch 41 Batch 500 Loss 3.3554 Accuracy 0.9958\n",
      "Epoch 41 Batch 550 Loss 3.3710 Accuracy 0.9958\n",
      "Epoch 41 Batch 600 Loss 3.3866 Accuracy 0.9958\n",
      "Epoch 41 Batch 650 Loss 3.3796 Accuracy 0.9958\n",
      "Epoch 41 Batch 700 Loss 3.3786 Accuracy 0.9958\n",
      "Epoch 41 Batch 750 Loss 3.3773 Accuracy 0.9958\n",
      "Epoch 41 Batch 800 Loss 3.3631 Accuracy 0.9958\n",
      "Epoch 41 Batch 850 Loss 3.3673 Accuracy 0.9958\n",
      "Epoch 41 Batch 900 Loss 3.3668 Accuracy 0.9958\n",
      "Epoch 41 Batch 950 Loss 3.3752 Accuracy 0.9958\n",
      "Epoch 41 Batch 1000 Loss 3.3734 Accuracy 0.9958\n",
      "Epoch 41 Batch 1050 Loss 3.3627 Accuracy 0.9958\n",
      "Epoch 41 Batch 1100 Loss 3.3620 Accuracy 0.9958\n",
      "Epoch 41 Batch 1150 Loss 3.3515 Accuracy 0.9958\n",
      "Epoch 41 Batch 1200 Loss 3.3654 Accuracy 0.9958\n",
      "Epoch 41 Batch 1250 Loss 3.3562 Accuracy 0.9958\n",
      "Epoch 41 Batch 1300 Loss 3.3564 Accuracy 0.9958\n",
      "Epoch 41 Batch 1350 Loss 3.3540 Accuracy 0.9958\n",
      "Epoch 41 Batch 1400 Loss 3.3565 Accuracy 0.9958\n",
      "Epoch 41 Batch 1450 Loss 3.3479 Accuracy 0.9958\n",
      "Epoch 41 Batch 1500 Loss 3.3452 Accuracy 0.9958\n",
      "Epoch 41 Batch 1550 Loss 3.3483 Accuracy 0.9958\n",
      "Epoch 41 Batch 1600 Loss 3.3470 Accuracy 0.9958\n",
      "Epoch 41 Batch 1650 Loss 3.3449 Accuracy 0.9958\n",
      "Epoch 41 Batch 1700 Loss 3.3484 Accuracy 0.9958\n",
      "Epoch 41 Batch 1750 Loss 3.3421 Accuracy 0.9958\n",
      "Epoch 41 Batch 1800 Loss 3.3422 Accuracy 0.9958\n",
      "Epoch 41 Batch 1850 Loss 3.3331 Accuracy 0.9958\n",
      "Epoch 41 Batch 1900 Loss 3.3272 Accuracy 0.9958\n",
      "Epoch 41 Batch 1950 Loss 3.3169 Accuracy 0.9959\n",
      "Epoch 41 Batch 2000 Loss 3.3211 Accuracy 0.9959\n",
      "Epoch 41 Batch 2050 Loss 3.3293 Accuracy 0.9958\n",
      "Epoch 41 Batch 2100 Loss 3.3262 Accuracy 0.9959\n",
      "Epoch 41 Batch 2150 Loss 3.3293 Accuracy 0.9958\n",
      "Epoch 41 Batch 2200 Loss 3.3334 Accuracy 0.9958\n",
      "Epoch 41 Batch 2250 Loss 3.3369 Accuracy 0.9958\n",
      "Epoch 41 Batch 2300 Loss 3.3327 Accuracy 0.9958\n",
      "Epoch 41 Batch 2350 Loss 3.3318 Accuracy 0.9958\n",
      "Epoch 41 Batch 2400 Loss 3.3337 Accuracy 0.9958\n",
      "Epoch 41 Batch 2450 Loss 3.3355 Accuracy 0.9958\n",
      "Epoch 41 Batch 2500 Loss 3.3382 Accuracy 0.9958\n",
      "Epoch 41 Batch 2550 Loss 3.3376 Accuracy 0.9958\n",
      "Epoch 41 Batch 2600 Loss 3.3349 Accuracy 0.9958\n",
      "Epoch 41 Batch 2650 Loss 3.3319 Accuracy 0.9958\n",
      "Epoch 41 Loss 3.3342 Accuracy 0.9958\n",
      "Time taken for 1 epoch: 197.48329091072083 secs\n",
      "\n",
      "Epoch 42 Batch 0 Loss 2.2952 Accuracy 0.9974\n",
      "Epoch 42 Batch 50 Loss 3.3522 Accuracy 0.9958\n",
      "Epoch 42 Batch 100 Loss 3.3454 Accuracy 0.9958\n",
      "Epoch 42 Batch 150 Loss 3.4027 Accuracy 0.9958\n",
      "Epoch 42 Batch 200 Loss 3.3197 Accuracy 0.9959\n",
      "Epoch 42 Batch 250 Loss 3.3028 Accuracy 0.9959\n",
      "Epoch 42 Batch 300 Loss 3.3041 Accuracy 0.9959\n",
      "Epoch 42 Batch 350 Loss 3.3023 Accuracy 0.9959\n",
      "Epoch 42 Batch 400 Loss 3.2930 Accuracy 0.9959\n",
      "Epoch 42 Batch 450 Loss 3.3294 Accuracy 0.9958\n",
      "Epoch 42 Batch 500 Loss 3.3195 Accuracy 0.9959\n",
      "Epoch 42 Batch 550 Loss 3.3349 Accuracy 0.9958\n",
      "Epoch 42 Batch 600 Loss 3.3560 Accuracy 0.9958\n",
      "Epoch 42 Batch 650 Loss 3.3545 Accuracy 0.9958\n",
      "Epoch 42 Batch 700 Loss 3.3489 Accuracy 0.9958\n",
      "Epoch 42 Batch 750 Loss 3.3465 Accuracy 0.9958\n",
      "Epoch 42 Batch 800 Loss 3.3299 Accuracy 0.9958\n",
      "Epoch 42 Batch 850 Loss 3.3372 Accuracy 0.9958\n",
      "Epoch 42 Batch 900 Loss 3.3374 Accuracy 0.9958\n",
      "Epoch 42 Batch 950 Loss 3.3431 Accuracy 0.9958\n",
      "Epoch 42 Batch 1000 Loss 3.3380 Accuracy 0.9958\n",
      "Epoch 42 Batch 1050 Loss 3.3272 Accuracy 0.9958\n",
      "Epoch 42 Batch 1100 Loss 3.3223 Accuracy 0.9959\n",
      "Epoch 42 Batch 1150 Loss 3.3104 Accuracy 0.9959\n",
      "Epoch 42 Batch 1200 Loss 3.3245 Accuracy 0.9958\n",
      "Epoch 42 Batch 1250 Loss 3.3177 Accuracy 0.9959\n",
      "Epoch 42 Batch 1300 Loss 3.3197 Accuracy 0.9959\n",
      "Epoch 42 Batch 1350 Loss 3.3136 Accuracy 0.9959\n",
      "Epoch 42 Batch 1400 Loss 3.3155 Accuracy 0.9959\n",
      "Epoch 42 Batch 1450 Loss 3.3066 Accuracy 0.9959\n",
      "Epoch 42 Batch 1500 Loss 3.3049 Accuracy 0.9959\n",
      "Epoch 42 Batch 1550 Loss 3.3058 Accuracy 0.9959\n",
      "Epoch 42 Batch 1600 Loss 3.3057 Accuracy 0.9959\n",
      "Epoch 42 Batch 1650 Loss 3.3058 Accuracy 0.9959\n",
      "Epoch 42 Batch 1700 Loss 3.3091 Accuracy 0.9959\n",
      "Epoch 42 Batch 1750 Loss 3.3015 Accuracy 0.9959\n",
      "Epoch 42 Batch 1800 Loss 3.3033 Accuracy 0.9959\n",
      "Epoch 42 Batch 1850 Loss 3.2942 Accuracy 0.9959\n",
      "Epoch 42 Batch 1900 Loss 3.2881 Accuracy 0.9959\n",
      "Epoch 42 Batch 1950 Loss 3.2790 Accuracy 0.9959\n",
      "Epoch 42 Batch 2000 Loss 3.2862 Accuracy 0.9959\n",
      "Epoch 42 Batch 2050 Loss 3.2941 Accuracy 0.9959\n",
      "Epoch 42 Batch 2100 Loss 3.2917 Accuracy 0.9959\n",
      "Epoch 42 Batch 2150 Loss 3.2941 Accuracy 0.9959\n",
      "Epoch 42 Batch 2200 Loss 3.2986 Accuracy 0.9959\n",
      "Epoch 42 Batch 2250 Loss 3.3017 Accuracy 0.9959\n",
      "Epoch 42 Batch 2300 Loss 3.2973 Accuracy 0.9959\n",
      "Epoch 42 Batch 2350 Loss 3.2975 Accuracy 0.9959\n",
      "Epoch 42 Batch 2400 Loss 3.3008 Accuracy 0.9959\n",
      "Epoch 42 Batch 2450 Loss 3.3036 Accuracy 0.9959\n",
      "Epoch 42 Batch 2500 Loss 3.3063 Accuracy 0.9959\n",
      "Epoch 42 Batch 2550 Loss 3.3044 Accuracy 0.9959\n",
      "Epoch 42 Batch 2600 Loss 3.3013 Accuracy 0.9959\n",
      "Epoch 42 Batch 2650 Loss 3.2986 Accuracy 0.9959\n",
      "Epoch 42 Loss 3.3016 Accuracy 0.9959\n",
      "Time taken for 1 epoch: 195.71336150169373 secs\n",
      "\n",
      "Epoch 43 Batch 0 Loss 2.1154 Accuracy 0.9974\n",
      "Epoch 43 Batch 50 Loss 3.3304 Accuracy 0.9958\n",
      "Epoch 43 Batch 100 Loss 3.3435 Accuracy 0.9958\n",
      "Epoch 43 Batch 150 Loss 3.3817 Accuracy 0.9958\n",
      "Epoch 43 Batch 200 Loss 3.2870 Accuracy 0.9959\n",
      "Epoch 43 Batch 250 Loss 3.2690 Accuracy 0.9959\n",
      "Epoch 43 Batch 300 Loss 3.2755 Accuracy 0.9959\n",
      "Epoch 43 Batch 350 Loss 3.2796 Accuracy 0.9959\n",
      "Epoch 43 Batch 400 Loss 3.2717 Accuracy 0.9959\n",
      "Epoch 43 Batch 450 Loss 3.3117 Accuracy 0.9959\n",
      "Epoch 43 Batch 500 Loss 3.2967 Accuracy 0.9959\n",
      "Epoch 43 Batch 550 Loss 3.3123 Accuracy 0.9959\n",
      "Epoch 43 Batch 600 Loss 3.3279 Accuracy 0.9959\n",
      "Epoch 43 Batch 650 Loss 3.3225 Accuracy 0.9959\n",
      "Epoch 43 Batch 700 Loss 3.3207 Accuracy 0.9959\n",
      "Epoch 43 Batch 750 Loss 3.3189 Accuracy 0.9959\n",
      "Epoch 43 Batch 800 Loss 3.3030 Accuracy 0.9959\n",
      "Epoch 43 Batch 850 Loss 3.3084 Accuracy 0.9959\n",
      "Epoch 43 Batch 900 Loss 3.3128 Accuracy 0.9959\n",
      "Epoch 43 Batch 950 Loss 3.3162 Accuracy 0.9959\n",
      "Epoch 43 Batch 1000 Loss 3.3142 Accuracy 0.9959\n",
      "Epoch 43 Batch 1050 Loss 3.3005 Accuracy 0.9959\n",
      "Epoch 43 Batch 1100 Loss 3.3015 Accuracy 0.9959\n",
      "Epoch 43 Batch 1150 Loss 3.2898 Accuracy 0.9959\n",
      "Epoch 43 Batch 1200 Loss 3.3030 Accuracy 0.9959\n",
      "Epoch 43 Batch 1250 Loss 3.2922 Accuracy 0.9959\n",
      "Epoch 43 Batch 1300 Loss 3.2950 Accuracy 0.9959\n",
      "Epoch 43 Batch 1350 Loss 3.2888 Accuracy 0.9959\n",
      "Epoch 43 Batch 1400 Loss 3.2934 Accuracy 0.9959\n",
      "Epoch 43 Batch 1450 Loss 3.2863 Accuracy 0.9959\n",
      "Epoch 43 Batch 1500 Loss 3.2835 Accuracy 0.9959\n",
      "Epoch 43 Batch 1550 Loss 3.2865 Accuracy 0.9959\n",
      "Epoch 43 Batch 1600 Loss 3.2880 Accuracy 0.9959\n",
      "Epoch 43 Batch 1650 Loss 3.2872 Accuracy 0.9959\n",
      "Epoch 43 Batch 1700 Loss 3.2897 Accuracy 0.9959\n",
      "Epoch 43 Batch 1750 Loss 3.2808 Accuracy 0.9959\n",
      "Epoch 43 Batch 1800 Loss 3.2818 Accuracy 0.9959\n",
      "Epoch 43 Batch 1850 Loss 3.2738 Accuracy 0.9959\n",
      "Epoch 43 Batch 1900 Loss 3.2688 Accuracy 0.9959\n",
      "Epoch 43 Batch 1950 Loss 3.2579 Accuracy 0.9959\n",
      "Epoch 43 Batch 2000 Loss 3.2640 Accuracy 0.9959\n",
      "Epoch 43 Batch 2050 Loss 3.2722 Accuracy 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 2100 Loss 3.2693 Accuracy 0.9959\n",
      "Epoch 43 Batch 2150 Loss 3.2724 Accuracy 0.9959\n",
      "Epoch 43 Batch 2200 Loss 3.2773 Accuracy 0.9959\n",
      "Epoch 43 Batch 2250 Loss 3.2795 Accuracy 0.9959\n",
      "Epoch 43 Batch 2300 Loss 3.2758 Accuracy 0.9959\n",
      "Epoch 43 Batch 2350 Loss 3.2766 Accuracy 0.9959\n",
      "Epoch 43 Batch 2400 Loss 3.2788 Accuracy 0.9959\n",
      "Epoch 43 Batch 2450 Loss 3.2809 Accuracy 0.9959\n",
      "Epoch 43 Batch 2500 Loss 3.2845 Accuracy 0.9959\n",
      "Epoch 43 Batch 2550 Loss 3.2844 Accuracy 0.9959\n",
      "Epoch 43 Batch 2600 Loss 3.2818 Accuracy 0.9959\n",
      "Epoch 43 Batch 2650 Loss 3.2803 Accuracy 0.9959\n",
      "Epoch 43 Loss 3.2811 Accuracy 0.9959\n",
      "Time taken for 1 epoch: 195.39999985694885 secs\n",
      "\n",
      "Epoch 44 Batch 0 Loss 1.9892 Accuracy 0.9979\n",
      "Epoch 44 Batch 50 Loss 3.3695 Accuracy 0.9958\n",
      "Epoch 44 Batch 100 Loss 3.3451 Accuracy 0.9958\n",
      "Epoch 44 Batch 150 Loss 3.3602 Accuracy 0.9958\n",
      "Epoch 44 Batch 200 Loss 3.2639 Accuracy 0.9959\n",
      "Epoch 44 Batch 250 Loss 3.2539 Accuracy 0.9959\n",
      "Epoch 44 Batch 300 Loss 3.2539 Accuracy 0.9959\n",
      "Epoch 44 Batch 350 Loss 3.2525 Accuracy 0.9959\n",
      "Epoch 44 Batch 400 Loss 3.2474 Accuracy 0.9959\n",
      "Epoch 44 Batch 450 Loss 3.2917 Accuracy 0.9959\n",
      "Epoch 44 Batch 500 Loss 3.2790 Accuracy 0.9959\n",
      "Epoch 44 Batch 550 Loss 3.2949 Accuracy 0.9959\n",
      "Epoch 44 Batch 600 Loss 3.3159 Accuracy 0.9959\n",
      "Epoch 44 Batch 650 Loss 3.3119 Accuracy 0.9959\n",
      "Epoch 44 Batch 700 Loss 3.3065 Accuracy 0.9959\n",
      "Epoch 44 Batch 750 Loss 3.3025 Accuracy 0.9959\n",
      "Epoch 44 Batch 800 Loss 3.2883 Accuracy 0.9959\n",
      "Epoch 44 Batch 850 Loss 3.2942 Accuracy 0.9959\n",
      "Epoch 44 Batch 900 Loss 3.2916 Accuracy 0.9959\n",
      "Epoch 44 Batch 950 Loss 3.2979 Accuracy 0.9959\n",
      "Epoch 44 Batch 1000 Loss 3.2942 Accuracy 0.9959\n",
      "Epoch 44 Batch 1050 Loss 3.2808 Accuracy 0.9959\n",
      "Epoch 44 Batch 1100 Loss 3.2802 Accuracy 0.9959\n",
      "Epoch 44 Batch 1150 Loss 3.2712 Accuracy 0.9959\n",
      "Epoch 44 Batch 1200 Loss 3.2863 Accuracy 0.9959\n",
      "Epoch 44 Batch 1250 Loss 3.2790 Accuracy 0.9959\n",
      "Epoch 44 Batch 1300 Loss 3.2826 Accuracy 0.9959\n",
      "Epoch 44 Batch 1350 Loss 3.2763 Accuracy 0.9959\n",
      "Epoch 44 Batch 1400 Loss 3.2800 Accuracy 0.9959\n",
      "Epoch 44 Batch 1450 Loss 3.2700 Accuracy 0.9959\n",
      "Epoch 44 Batch 1500 Loss 3.2677 Accuracy 0.9959\n",
      "Epoch 44 Batch 1550 Loss 3.2696 Accuracy 0.9959\n",
      "Epoch 44 Batch 1600 Loss 3.2697 Accuracy 0.9959\n",
      "Epoch 44 Batch 1650 Loss 3.2691 Accuracy 0.9959\n",
      "Epoch 44 Batch 1700 Loss 3.2734 Accuracy 0.9959\n",
      "Epoch 44 Batch 1750 Loss 3.2658 Accuracy 0.9959\n",
      "Epoch 44 Batch 1800 Loss 3.2673 Accuracy 0.9959\n",
      "Epoch 44 Batch 1850 Loss 3.2581 Accuracy 0.9959\n",
      "Epoch 44 Batch 1900 Loss 3.2528 Accuracy 0.9959\n",
      "Epoch 44 Batch 1950 Loss 3.2430 Accuracy 0.9960\n",
      "Epoch 44 Batch 2000 Loss 3.2497 Accuracy 0.9959\n",
      "Epoch 44 Batch 2050 Loss 3.2573 Accuracy 0.9959\n",
      "Epoch 44 Batch 2100 Loss 3.2544 Accuracy 0.9959\n",
      "Epoch 44 Batch 2150 Loss 3.2565 Accuracy 0.9959\n",
      "Epoch 44 Batch 2200 Loss 3.2610 Accuracy 0.9959\n",
      "Epoch 44 Batch 2250 Loss 3.2632 Accuracy 0.9959\n",
      "Epoch 44 Batch 2300 Loss 3.2593 Accuracy 0.9959\n",
      "Epoch 44 Batch 2350 Loss 3.2591 Accuracy 0.9959\n",
      "Epoch 44 Batch 2400 Loss 3.2616 Accuracy 0.9959\n",
      "Epoch 44 Batch 2450 Loss 3.2633 Accuracy 0.9959\n",
      "Epoch 44 Batch 2500 Loss 3.2658 Accuracy 0.9959\n",
      "Epoch 44 Batch 2550 Loss 3.2649 Accuracy 0.9959\n",
      "Epoch 44 Batch 2600 Loss 3.2612 Accuracy 0.9959\n",
      "Epoch 44 Batch 2650 Loss 3.2584 Accuracy 0.9959\n",
      "Epoch 44 Loss 3.2598 Accuracy 0.9959\n",
      "Time taken for 1 epoch: 195.75345706939697 secs\n",
      "\n",
      "Epoch 45 Batch 0 Loss 2.3788 Accuracy 0.9975\n",
      "Epoch 45 Batch 50 Loss 3.3027 Accuracy 0.9959\n",
      "Epoch 45 Batch 100 Loss 3.2877 Accuracy 0.9959\n",
      "Epoch 45 Batch 150 Loss 3.3323 Accuracy 0.9959\n",
      "Epoch 45 Batch 200 Loss 3.2399 Accuracy 0.9960\n",
      "Epoch 45 Batch 250 Loss 3.2170 Accuracy 0.9960\n",
      "Epoch 45 Batch 300 Loss 3.2136 Accuracy 0.9960\n",
      "Epoch 45 Batch 350 Loss 3.2170 Accuracy 0.9960\n",
      "Epoch 45 Batch 400 Loss 3.2071 Accuracy 0.9960\n",
      "Epoch 45 Batch 450 Loss 3.2465 Accuracy 0.9960\n",
      "Epoch 45 Batch 500 Loss 3.2313 Accuracy 0.9960\n",
      "Epoch 45 Batch 550 Loss 3.2450 Accuracy 0.9960\n",
      "Epoch 45 Batch 600 Loss 3.2648 Accuracy 0.9959\n",
      "Epoch 45 Batch 650 Loss 3.2635 Accuracy 0.9959\n",
      "Epoch 45 Batch 700 Loss 3.2566 Accuracy 0.9959\n",
      "Epoch 45 Batch 750 Loss 3.2530 Accuracy 0.9959\n",
      "Epoch 45 Batch 800 Loss 3.2389 Accuracy 0.9960\n",
      "Epoch 45 Batch 850 Loss 3.2489 Accuracy 0.9960\n",
      "Epoch 45 Batch 900 Loss 3.2509 Accuracy 0.9959\n",
      "Epoch 45 Batch 950 Loss 3.2560 Accuracy 0.9959\n",
      "Epoch 45 Batch 1000 Loss 3.2527 Accuracy 0.9959\n",
      "Epoch 45 Batch 1050 Loss 3.2401 Accuracy 0.9960\n",
      "Epoch 45 Batch 1100 Loss 3.2370 Accuracy 0.9960\n",
      "Epoch 45 Batch 1150 Loss 3.2279 Accuracy 0.9960\n",
      "Epoch 45 Batch 1200 Loss 3.2436 Accuracy 0.9960\n",
      "Epoch 45 Batch 1250 Loss 3.2360 Accuracy 0.9960\n",
      "Epoch 45 Batch 1300 Loss 3.2396 Accuracy 0.9960\n",
      "Epoch 45 Batch 1350 Loss 3.2339 Accuracy 0.9960\n",
      "Epoch 45 Batch 1400 Loss 3.2376 Accuracy 0.9960\n",
      "Epoch 45 Batch 1450 Loss 3.2295 Accuracy 0.9960\n",
      "Epoch 45 Batch 1500 Loss 3.2275 Accuracy 0.9960\n",
      "Epoch 45 Batch 1550 Loss 3.2302 Accuracy 0.9960\n",
      "Epoch 45 Batch 1600 Loss 3.2322 Accuracy 0.9960\n",
      "Epoch 45 Batch 1650 Loss 3.2321 Accuracy 0.9960\n",
      "Epoch 45 Batch 1700 Loss 3.2373 Accuracy 0.9960\n",
      "Epoch 45 Batch 1750 Loss 3.2305 Accuracy 0.9960\n",
      "Epoch 45 Batch 1800 Loss 3.2316 Accuracy 0.9960\n",
      "Epoch 45 Batch 1850 Loss 3.2228 Accuracy 0.9960\n",
      "Epoch 45 Batch 1900 Loss 3.2190 Accuracy 0.9960\n",
      "Epoch 45 Batch 1950 Loss 3.2094 Accuracy 0.9960\n",
      "Epoch 45 Batch 2000 Loss 3.2143 Accuracy 0.9960\n",
      "Epoch 45 Batch 2050 Loss 3.2219 Accuracy 0.9960\n",
      "Epoch 45 Batch 2100 Loss 3.2188 Accuracy 0.9960\n",
      "Epoch 45 Batch 2150 Loss 3.2214 Accuracy 0.9960\n",
      "Epoch 45 Batch 2200 Loss 3.2256 Accuracy 0.9960\n",
      "Epoch 45 Batch 2250 Loss 3.2274 Accuracy 0.9960\n",
      "Epoch 45 Batch 2300 Loss 3.2225 Accuracy 0.9960\n",
      "Epoch 45 Batch 2350 Loss 3.2223 Accuracy 0.9960\n",
      "Epoch 45 Batch 2400 Loss 3.2251 Accuracy 0.9960\n",
      "Epoch 45 Batch 2450 Loss 3.2267 Accuracy 0.9960\n",
      "Epoch 45 Batch 2500 Loss 3.2293 Accuracy 0.9960\n",
      "Epoch 45 Batch 2550 Loss 3.2280 Accuracy 0.9960\n",
      "Epoch 45 Batch 2600 Loss 3.2255 Accuracy 0.9960\n",
      "Epoch 45 Batch 2650 Loss 3.2237 Accuracy 0.9960\n",
      "Saving checkpoint for epoch 45 at ./checkpoints/train\\ckpt-10\n",
      "Epoch 45 Loss 3.2254 Accuracy 0.9960\n",
      "Time taken for 1 epoch: 195.7395477294922 secs\n",
      "\n",
      "Epoch 46 Batch 0 Loss 2.4498 Accuracy 0.9971\n",
      "Epoch 46 Batch 50 Loss 3.3390 Accuracy 0.9958\n",
      "Epoch 46 Batch 100 Loss 3.2727 Accuracy 0.9959\n",
      "Epoch 46 Batch 150 Loss 3.2965 Accuracy 0.9959\n",
      "Epoch 46 Batch 200 Loss 3.2186 Accuracy 0.9960\n",
      "Epoch 46 Batch 250 Loss 3.1991 Accuracy 0.9960\n",
      "Epoch 46 Batch 300 Loss 3.1957 Accuracy 0.9960\n",
      "Epoch 46 Batch 350 Loss 3.1948 Accuracy 0.9960\n",
      "Epoch 46 Batch 400 Loss 3.1938 Accuracy 0.9960\n",
      "Epoch 46 Batch 450 Loss 3.2338 Accuracy 0.9959\n",
      "Epoch 46 Batch 500 Loss 3.2146 Accuracy 0.9960\n",
      "Epoch 46 Batch 550 Loss 3.2310 Accuracy 0.9959\n",
      "Epoch 46 Batch 600 Loss 3.2484 Accuracy 0.9959\n",
      "Epoch 46 Batch 650 Loss 3.2455 Accuracy 0.9959\n",
      "Epoch 46 Batch 700 Loss 3.2425 Accuracy 0.9959\n",
      "Epoch 46 Batch 750 Loss 3.2415 Accuracy 0.9959\n",
      "Epoch 46 Batch 800 Loss 3.2250 Accuracy 0.9960\n",
      "Epoch 46 Batch 850 Loss 3.2312 Accuracy 0.9960\n",
      "Epoch 46 Batch 900 Loss 3.2301 Accuracy 0.9960\n",
      "Epoch 46 Batch 950 Loss 3.2350 Accuracy 0.9960\n",
      "Epoch 46 Batch 1000 Loss 3.2285 Accuracy 0.9960\n",
      "Epoch 46 Batch 1050 Loss 3.2164 Accuracy 0.9960\n",
      "Epoch 46 Batch 1100 Loss 3.2172 Accuracy 0.9960\n",
      "Epoch 46 Batch 1150 Loss 3.2083 Accuracy 0.9960\n",
      "Epoch 46 Batch 1200 Loss 3.2216 Accuracy 0.9960\n",
      "Epoch 46 Batch 1250 Loss 3.2143 Accuracy 0.9960\n",
      "Epoch 46 Batch 1300 Loss 3.2159 Accuracy 0.9960\n",
      "Epoch 46 Batch 1350 Loss 3.2110 Accuracy 0.9960\n",
      "Epoch 46 Batch 1400 Loss 3.2152 Accuracy 0.9960\n",
      "Epoch 46 Batch 1450 Loss 3.2064 Accuracy 0.9960\n",
      "Epoch 46 Batch 1500 Loss 3.2051 Accuracy 0.9960\n",
      "Epoch 46 Batch 1550 Loss 3.2080 Accuracy 0.9960\n",
      "Epoch 46 Batch 1600 Loss 3.2088 Accuracy 0.9960\n",
      "Epoch 46 Batch 1650 Loss 3.2076 Accuracy 0.9960\n",
      "Epoch 46 Batch 1700 Loss 3.2124 Accuracy 0.9960\n",
      "Epoch 46 Batch 1750 Loss 3.2066 Accuracy 0.9960\n",
      "Epoch 46 Batch 1800 Loss 3.2086 Accuracy 0.9960\n",
      "Epoch 46 Batch 1850 Loss 3.1994 Accuracy 0.9960\n",
      "Epoch 46 Batch 1900 Loss 3.1937 Accuracy 0.9960\n",
      "Epoch 46 Batch 1950 Loss 3.1836 Accuracy 0.9960\n",
      "Epoch 46 Batch 2000 Loss 3.1897 Accuracy 0.9960\n",
      "Epoch 46 Batch 2050 Loss 3.1969 Accuracy 0.9960\n",
      "Epoch 46 Batch 2100 Loss 3.1947 Accuracy 0.9960\n",
      "Epoch 46 Batch 2150 Loss 3.1968 Accuracy 0.9960\n",
      "Epoch 46 Batch 2200 Loss 3.2008 Accuracy 0.9960\n",
      "Epoch 46 Batch 2250 Loss 3.2027 Accuracy 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 2300 Loss 3.1989 Accuracy 0.9960\n",
      "Epoch 46 Batch 2350 Loss 3.1980 Accuracy 0.9960\n",
      "Epoch 46 Batch 2400 Loss 3.1990 Accuracy 0.9960\n",
      "Epoch 46 Batch 2450 Loss 3.2011 Accuracy 0.9960\n",
      "Epoch 46 Batch 2500 Loss 3.2039 Accuracy 0.9960\n",
      "Epoch 46 Batch 2550 Loss 3.2020 Accuracy 0.9960\n",
      "Epoch 46 Batch 2600 Loss 3.1989 Accuracy 0.9960\n",
      "Epoch 46 Batch 2650 Loss 3.1965 Accuracy 0.9960\n",
      "Epoch 46 Loss 3.1986 Accuracy 0.9960\n",
      "Time taken for 1 epoch: 195.77045607566833 secs\n",
      "\n",
      "Epoch 47 Batch 0 Loss 2.0852 Accuracy 0.9976\n",
      "Epoch 47 Batch 50 Loss 3.2265 Accuracy 0.9960\n",
      "Epoch 47 Batch 100 Loss 3.2200 Accuracy 0.9960\n",
      "Epoch 47 Batch 150 Loss 3.2658 Accuracy 0.9959\n",
      "Epoch 47 Batch 200 Loss 3.1713 Accuracy 0.9960\n",
      "Epoch 47 Batch 250 Loss 3.1704 Accuracy 0.9960\n",
      "Epoch 47 Batch 300 Loss 3.1764 Accuracy 0.9960\n",
      "Epoch 47 Batch 350 Loss 3.1622 Accuracy 0.9960\n",
      "Epoch 47 Batch 400 Loss 3.1554 Accuracy 0.9961\n",
      "Epoch 47 Batch 450 Loss 3.1936 Accuracy 0.9960\n",
      "Epoch 47 Batch 500 Loss 3.1825 Accuracy 0.9960\n",
      "Epoch 47 Batch 550 Loss 3.1993 Accuracy 0.9960\n",
      "Epoch 47 Batch 600 Loss 3.2141 Accuracy 0.9960\n",
      "Epoch 47 Batch 650 Loss 3.2114 Accuracy 0.9960\n",
      "Epoch 47 Batch 700 Loss 3.2045 Accuracy 0.9960\n",
      "Epoch 47 Batch 750 Loss 3.2040 Accuracy 0.9960\n",
      "Epoch 47 Batch 800 Loss 3.1885 Accuracy 0.9960\n",
      "Epoch 47 Batch 850 Loss 3.1955 Accuracy 0.9960\n",
      "Epoch 47 Batch 900 Loss 3.1945 Accuracy 0.9960\n",
      "Epoch 47 Batch 950 Loss 3.2035 Accuracy 0.9960\n",
      "Epoch 47 Batch 1000 Loss 3.2016 Accuracy 0.9960\n",
      "Epoch 47 Batch 1050 Loss 3.1882 Accuracy 0.9960\n",
      "Epoch 47 Batch 1100 Loss 3.1859 Accuracy 0.9960\n",
      "Epoch 47 Batch 1150 Loss 3.1770 Accuracy 0.9960\n",
      "Epoch 47 Batch 1200 Loss 3.1925 Accuracy 0.9960\n",
      "Epoch 47 Batch 1250 Loss 3.1841 Accuracy 0.9960\n",
      "Epoch 47 Batch 1300 Loss 3.1874 Accuracy 0.9960\n",
      "Epoch 47 Batch 1350 Loss 3.1829 Accuracy 0.9960\n",
      "Epoch 47 Batch 1400 Loss 3.1853 Accuracy 0.9960\n",
      "Epoch 47 Batch 1450 Loss 3.1795 Accuracy 0.9960\n",
      "Epoch 47 Batch 1500 Loss 3.1772 Accuracy 0.9960\n",
      "Epoch 47 Batch 1550 Loss 3.1788 Accuracy 0.9960\n",
      "Epoch 47 Batch 1600 Loss 3.1794 Accuracy 0.9960\n",
      "Epoch 47 Batch 1650 Loss 3.1785 Accuracy 0.9960\n",
      "Epoch 47 Batch 1700 Loss 3.1844 Accuracy 0.9960\n",
      "Epoch 47 Batch 1750 Loss 3.1774 Accuracy 0.9960\n",
      "Epoch 47 Batch 1800 Loss 3.1795 Accuracy 0.9960\n",
      "Epoch 47 Batch 1850 Loss 3.1726 Accuracy 0.9960\n",
      "Epoch 47 Batch 1900 Loss 3.1666 Accuracy 0.9961\n",
      "Epoch 47 Batch 1950 Loss 3.1574 Accuracy 0.9961\n",
      "Epoch 47 Batch 2000 Loss 3.1647 Accuracy 0.9961\n",
      "Epoch 47 Batch 2050 Loss 3.1732 Accuracy 0.9960\n",
      "Epoch 47 Batch 2100 Loss 3.1705 Accuracy 0.9960\n",
      "Epoch 47 Batch 2150 Loss 3.1709 Accuracy 0.9960\n",
      "Epoch 47 Batch 2200 Loss 3.1744 Accuracy 0.9960\n",
      "Epoch 47 Batch 2250 Loss 3.1755 Accuracy 0.9960\n",
      "Epoch 47 Batch 2300 Loss 3.1721 Accuracy 0.9960\n",
      "Epoch 47 Batch 2350 Loss 3.1717 Accuracy 0.9960\n",
      "Epoch 47 Batch 2400 Loss 3.1748 Accuracy 0.9960\n",
      "Epoch 47 Batch 2450 Loss 3.1762 Accuracy 0.9960\n",
      "Epoch 47 Batch 2500 Loss 3.1789 Accuracy 0.9960\n",
      "Epoch 47 Batch 2550 Loss 3.1786 Accuracy 0.9960\n",
      "Epoch 47 Batch 2600 Loss 3.1758 Accuracy 0.9960\n",
      "Epoch 47 Batch 2650 Loss 3.1738 Accuracy 0.9960\n",
      "Epoch 47 Loss 3.1743 Accuracy 0.9960\n",
      "Time taken for 1 epoch: 195.49002265930176 secs\n",
      "\n",
      "Epoch 48 Batch 0 Loss 2.2925 Accuracy 0.9973\n",
      "Epoch 48 Batch 50 Loss 3.1500 Accuracy 0.9961\n",
      "Epoch 48 Batch 100 Loss 3.1731 Accuracy 0.9961\n",
      "Epoch 48 Batch 150 Loss 3.2352 Accuracy 0.9960\n",
      "Epoch 48 Batch 200 Loss 3.1304 Accuracy 0.9961\n",
      "Epoch 48 Batch 250 Loss 3.1097 Accuracy 0.9961\n",
      "Epoch 48 Batch 300 Loss 3.1149 Accuracy 0.9961\n",
      "Epoch 48 Batch 350 Loss 3.1153 Accuracy 0.9961\n",
      "Epoch 48 Batch 400 Loss 3.1103 Accuracy 0.9961\n",
      "Epoch 48 Batch 450 Loss 3.1521 Accuracy 0.9961\n",
      "Epoch 48 Batch 500 Loss 3.1413 Accuracy 0.9961\n",
      "Epoch 48 Batch 550 Loss 3.1608 Accuracy 0.9961\n",
      "Epoch 48 Batch 600 Loss 3.1784 Accuracy 0.9960\n",
      "Epoch 48 Batch 650 Loss 3.1753 Accuracy 0.9960\n",
      "Epoch 48 Batch 700 Loss 3.1695 Accuracy 0.9961\n",
      "Epoch 48 Batch 750 Loss 3.1718 Accuracy 0.9961\n",
      "Epoch 48 Batch 800 Loss 3.1572 Accuracy 0.9961\n",
      "Epoch 48 Batch 850 Loss 3.1621 Accuracy 0.9961\n",
      "Epoch 48 Batch 900 Loss 3.1661 Accuracy 0.9961\n",
      "Epoch 48 Batch 950 Loss 3.1724 Accuracy 0.9961\n",
      "Epoch 48 Batch 1000 Loss 3.1711 Accuracy 0.9961\n",
      "Epoch 48 Batch 1050 Loss 3.1580 Accuracy 0.9961\n",
      "Epoch 48 Batch 1100 Loss 3.1567 Accuracy 0.9961\n",
      "Epoch 48 Batch 1150 Loss 3.1478 Accuracy 0.9961\n",
      "Epoch 48 Batch 1200 Loss 3.1622 Accuracy 0.9961\n",
      "Epoch 48 Batch 1250 Loss 3.1546 Accuracy 0.9961\n",
      "Epoch 48 Batch 1300 Loss 3.1584 Accuracy 0.9961\n",
      "Epoch 48 Batch 1350 Loss 3.1536 Accuracy 0.9961\n",
      "Epoch 48 Batch 1400 Loss 3.1567 Accuracy 0.9961\n",
      "Epoch 48 Batch 1450 Loss 3.1496 Accuracy 0.9961\n",
      "Epoch 48 Batch 1500 Loss 3.1477 Accuracy 0.9961\n",
      "Epoch 48 Batch 1550 Loss 3.1513 Accuracy 0.9961\n",
      "Epoch 48 Batch 1600 Loss 3.1519 Accuracy 0.9961\n",
      "Epoch 48 Batch 1650 Loss 3.1510 Accuracy 0.9961\n",
      "Epoch 48 Batch 1700 Loss 3.1524 Accuracy 0.9961\n",
      "Epoch 48 Batch 1750 Loss 3.1452 Accuracy 0.9961\n",
      "Epoch 48 Batch 1800 Loss 3.1495 Accuracy 0.9961\n",
      "Epoch 48 Batch 1850 Loss 3.1404 Accuracy 0.9961\n",
      "Epoch 48 Batch 1900 Loss 3.1354 Accuracy 0.9961\n",
      "Epoch 48 Batch 1950 Loss 3.1260 Accuracy 0.9961\n",
      "Epoch 48 Batch 2000 Loss 3.1319 Accuracy 0.9961\n",
      "Epoch 48 Batch 2050 Loss 3.1395 Accuracy 0.9961\n",
      "Epoch 48 Batch 2100 Loss 3.1373 Accuracy 0.9961\n",
      "Epoch 48 Batch 2150 Loss 3.1402 Accuracy 0.9961\n",
      "Epoch 48 Batch 2200 Loss 3.1460 Accuracy 0.9961\n",
      "Epoch 48 Batch 2250 Loss 3.1483 Accuracy 0.9961\n",
      "Epoch 48 Batch 2300 Loss 3.1445 Accuracy 0.9961\n",
      "Epoch 48 Batch 2350 Loss 3.1442 Accuracy 0.9961\n",
      "Epoch 48 Batch 2400 Loss 3.1488 Accuracy 0.9961\n",
      "Epoch 48 Batch 2450 Loss 3.1501 Accuracy 0.9961\n",
      "Epoch 48 Batch 2500 Loss 3.1527 Accuracy 0.9961\n",
      "Epoch 48 Batch 2550 Loss 3.1526 Accuracy 0.9961\n",
      "Epoch 48 Batch 2600 Loss 3.1502 Accuracy 0.9961\n",
      "Epoch 48 Batch 2650 Loss 3.1494 Accuracy 0.9961\n",
      "Epoch 48 Loss 3.1516 Accuracy 0.9961\n",
      "Time taken for 1 epoch: 195.08965134620667 secs\n",
      "\n",
      "Epoch 49 Batch 0 Loss 2.1447 Accuracy 0.9973\n",
      "Epoch 49 Batch 50 Loss 3.1709 Accuracy 0.9961\n",
      "Epoch 49 Batch 100 Loss 3.1376 Accuracy 0.9961\n",
      "Epoch 49 Batch 150 Loss 3.1936 Accuracy 0.9960\n",
      "Epoch 49 Batch 200 Loss 3.0958 Accuracy 0.9961\n",
      "Epoch 49 Batch 250 Loss 3.0914 Accuracy 0.9961\n",
      "Epoch 49 Batch 300 Loss 3.0999 Accuracy 0.9961\n",
      "Epoch 49 Batch 350 Loss 3.1024 Accuracy 0.9961\n",
      "Epoch 49 Batch 400 Loss 3.1015 Accuracy 0.9961\n",
      "Epoch 49 Batch 450 Loss 3.1413 Accuracy 0.9961\n",
      "Epoch 49 Batch 500 Loss 3.1274 Accuracy 0.9961\n",
      "Epoch 49 Batch 550 Loss 3.1443 Accuracy 0.9961\n",
      "Epoch 49 Batch 600 Loss 3.1617 Accuracy 0.9961\n",
      "Epoch 49 Batch 650 Loss 3.1587 Accuracy 0.9961\n",
      "Epoch 49 Batch 700 Loss 3.1566 Accuracy 0.9961\n",
      "Epoch 49 Batch 750 Loss 3.1570 Accuracy 0.9961\n",
      "Epoch 49 Batch 800 Loss 3.1399 Accuracy 0.9961\n",
      "Epoch 49 Batch 850 Loss 3.1441 Accuracy 0.9961\n",
      "Epoch 49 Batch 900 Loss 3.1458 Accuracy 0.9961\n",
      "Epoch 49 Batch 950 Loss 3.1507 Accuracy 0.9961\n",
      "Epoch 49 Batch 1000 Loss 3.1459 Accuracy 0.9961\n",
      "Epoch 49 Batch 1050 Loss 3.1341 Accuracy 0.9961\n",
      "Epoch 49 Batch 1100 Loss 3.1358 Accuracy 0.9961\n",
      "Epoch 49 Batch 1150 Loss 3.1249 Accuracy 0.9961\n",
      "Epoch 49 Batch 1200 Loss 3.1389 Accuracy 0.9961\n",
      "Epoch 49 Batch 1250 Loss 3.1330 Accuracy 0.9961\n",
      "Epoch 49 Batch 1300 Loss 3.1374 Accuracy 0.9961\n",
      "Epoch 49 Batch 1350 Loss 3.1330 Accuracy 0.9961\n",
      "Epoch 49 Batch 1400 Loss 3.1361 Accuracy 0.9961\n",
      "Epoch 49 Batch 1450 Loss 3.1300 Accuracy 0.9961\n",
      "Epoch 49 Batch 1500 Loss 3.1281 Accuracy 0.9961\n",
      "Epoch 49 Batch 1550 Loss 3.1311 Accuracy 0.9961\n",
      "Epoch 49 Batch 1600 Loss 3.1328 Accuracy 0.9961\n",
      "Epoch 49 Batch 1650 Loss 3.1304 Accuracy 0.9961\n",
      "Epoch 49 Batch 1700 Loss 3.1367 Accuracy 0.9961\n",
      "Epoch 49 Batch 1750 Loss 3.1294 Accuracy 0.9961\n",
      "Epoch 49 Batch 1800 Loss 3.1325 Accuracy 0.9961\n",
      "Epoch 49 Batch 1850 Loss 3.1242 Accuracy 0.9961\n",
      "Epoch 49 Batch 1900 Loss 3.1200 Accuracy 0.9961\n",
      "Epoch 49 Batch 1950 Loss 3.1112 Accuracy 0.9961\n",
      "Epoch 49 Batch 2000 Loss 3.1177 Accuracy 0.9961\n",
      "Epoch 49 Batch 2050 Loss 3.1249 Accuracy 0.9961\n",
      "Epoch 49 Batch 2100 Loss 3.1230 Accuracy 0.9961\n",
      "Epoch 49 Batch 2150 Loss 3.1253 Accuracy 0.9961\n",
      "Epoch 49 Batch 2200 Loss 3.1291 Accuracy 0.9961\n",
      "Epoch 49 Batch 2250 Loss 3.1319 Accuracy 0.9961\n",
      "Epoch 49 Batch 2300 Loss 3.1292 Accuracy 0.9961\n",
      "Epoch 49 Batch 2350 Loss 3.1297 Accuracy 0.9961\n",
      "Epoch 49 Batch 2400 Loss 3.1321 Accuracy 0.9961\n",
      "Epoch 49 Batch 2450 Loss 3.1340 Accuracy 0.9961\n",
      "Epoch 49 Batch 2500 Loss 3.1370 Accuracy 0.9961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 2550 Loss 3.1360 Accuracy 0.9961\n",
      "Epoch 49 Batch 2600 Loss 3.1338 Accuracy 0.9961\n",
      "Epoch 49 Batch 2650 Loss 3.1300 Accuracy 0.9961\n",
      "Epoch 49 Loss 3.1310 Accuracy 0.9961\n",
      "Time taken for 1 epoch: 196.55030393600464 secs\n",
      "\n",
      "Epoch 50 Batch 0 Loss 1.8736 Accuracy 0.9976\n",
      "Epoch 50 Batch 50 Loss 3.1611 Accuracy 0.9960\n",
      "Epoch 50 Batch 100 Loss 3.1566 Accuracy 0.9961\n",
      "Epoch 50 Batch 150 Loss 3.1973 Accuracy 0.9960\n",
      "Epoch 50 Batch 200 Loss 3.1003 Accuracy 0.9961\n",
      "Epoch 50 Batch 250 Loss 3.0810 Accuracy 0.9962\n",
      "Epoch 50 Batch 300 Loss 3.0901 Accuracy 0.9962\n",
      "Epoch 50 Batch 350 Loss 3.0923 Accuracy 0.9961\n",
      "Epoch 50 Batch 400 Loss 3.0896 Accuracy 0.9961\n",
      "Epoch 50 Batch 450 Loss 3.1373 Accuracy 0.9961\n",
      "Epoch 50 Batch 500 Loss 3.1185 Accuracy 0.9961\n",
      "Epoch 50 Batch 550 Loss 3.1356 Accuracy 0.9961\n",
      "Epoch 50 Batch 600 Loss 3.1485 Accuracy 0.9961\n",
      "Epoch 50 Batch 650 Loss 3.1464 Accuracy 0.9961\n",
      "Epoch 50 Batch 700 Loss 3.1461 Accuracy 0.9961\n",
      "Epoch 50 Batch 750 Loss 3.1451 Accuracy 0.9961\n",
      "Epoch 50 Batch 800 Loss 3.1300 Accuracy 0.9961\n",
      "Epoch 50 Batch 850 Loss 3.1391 Accuracy 0.9961\n",
      "Epoch 50 Batch 900 Loss 3.1375 Accuracy 0.9961\n",
      "Epoch 50 Batch 950 Loss 3.1459 Accuracy 0.9961\n",
      "Epoch 50 Batch 1000 Loss 3.1441 Accuracy 0.9961\n",
      "Epoch 50 Batch 1050 Loss 3.1322 Accuracy 0.9961\n",
      "Epoch 50 Batch 1100 Loss 3.1292 Accuracy 0.9961\n",
      "Epoch 50 Batch 1150 Loss 3.1196 Accuracy 0.9961\n",
      "Epoch 50 Batch 1200 Loss 3.1335 Accuracy 0.9961\n",
      "Epoch 50 Batch 1250 Loss 3.1273 Accuracy 0.9961\n",
      "Epoch 50 Batch 1300 Loss 3.1284 Accuracy 0.9961\n",
      "Epoch 50 Batch 1350 Loss 3.1211 Accuracy 0.9961\n",
      "Epoch 50 Batch 1400 Loss 3.1243 Accuracy 0.9961\n",
      "Epoch 50 Batch 1450 Loss 3.1143 Accuracy 0.9961\n",
      "Epoch 50 Batch 1500 Loss 3.1145 Accuracy 0.9961\n",
      "Epoch 50 Batch 1550 Loss 3.1166 Accuracy 0.9961\n",
      "Epoch 50 Batch 1600 Loss 3.1182 Accuracy 0.9961\n",
      "Epoch 50 Batch 1650 Loss 3.1168 Accuracy 0.9961\n",
      "Epoch 50 Batch 1700 Loss 3.1202 Accuracy 0.9961\n",
      "Epoch 50 Batch 1750 Loss 3.1137 Accuracy 0.9961\n",
      "Epoch 50 Batch 1800 Loss 3.1155 Accuracy 0.9961\n",
      "Epoch 50 Batch 1850 Loss 3.1085 Accuracy 0.9961\n",
      "Epoch 50 Batch 1900 Loss 3.1038 Accuracy 0.9961\n",
      "Epoch 50 Batch 1950 Loss 3.0954 Accuracy 0.9962\n",
      "Epoch 50 Batch 2000 Loss 3.1011 Accuracy 0.9961\n",
      "Epoch 50 Batch 2050 Loss 3.1083 Accuracy 0.9961\n",
      "Epoch 50 Batch 2100 Loss 3.1045 Accuracy 0.9961\n",
      "Epoch 50 Batch 2150 Loss 3.1074 Accuracy 0.9961\n",
      "Epoch 50 Batch 2200 Loss 3.1115 Accuracy 0.9961\n",
      "Epoch 50 Batch 2250 Loss 3.1136 Accuracy 0.9961\n",
      "Epoch 50 Batch 2300 Loss 3.1094 Accuracy 0.9961\n",
      "Epoch 50 Batch 2350 Loss 3.1084 Accuracy 0.9961\n",
      "Epoch 50 Batch 2400 Loss 3.1100 Accuracy 0.9961\n",
      "Epoch 50 Batch 2450 Loss 3.1121 Accuracy 0.9961\n",
      "Epoch 50 Batch 2500 Loss 3.1152 Accuracy 0.9961\n",
      "Epoch 50 Batch 2550 Loss 3.1145 Accuracy 0.9961\n",
      "Epoch 50 Batch 2600 Loss 3.1108 Accuracy 0.9961\n",
      "Epoch 50 Batch 2650 Loss 3.1085 Accuracy 0.9961\n",
      "Saving checkpoint for epoch 50 at ./checkpoints/train\\ckpt-11\n",
      "Epoch 50 Loss 3.1111 Accuracy 0.9961\n",
      "Time taken for 1 epoch: 211.92316484451294 secs\n",
      "\n",
      "Epoch 51 Batch 0 Loss 2.2760 Accuracy 0.9975\n",
      "Epoch 51 Batch 50 Loss 3.1521 Accuracy 0.9960\n",
      "Epoch 51 Batch 100 Loss 3.1487 Accuracy 0.9961\n",
      "Epoch 51 Batch 150 Loss 3.1768 Accuracy 0.9960\n",
      "Epoch 51 Batch 200 Loss 3.1089 Accuracy 0.9961\n",
      "Epoch 51 Batch 250 Loss 3.0891 Accuracy 0.9962\n",
      "Epoch 51 Batch 300 Loss 3.0875 Accuracy 0.9962\n",
      "Epoch 51 Batch 350 Loss 3.0897 Accuracy 0.9961\n",
      "Epoch 51 Batch 400 Loss 3.0857 Accuracy 0.9961\n",
      "Epoch 51 Batch 450 Loss 3.1220 Accuracy 0.9961\n",
      "Epoch 51 Batch 500 Loss 3.1096 Accuracy 0.9961\n",
      "Epoch 51 Batch 550 Loss 3.1242 Accuracy 0.9961\n",
      "Epoch 51 Batch 600 Loss 3.1371 Accuracy 0.9961\n",
      "Epoch 51 Batch 650 Loss 3.1361 Accuracy 0.9961\n",
      "Epoch 51 Batch 700 Loss 3.1272 Accuracy 0.9961\n",
      "Epoch 51 Batch 750 Loss 3.1262 Accuracy 0.9961\n",
      "Epoch 51 Batch 800 Loss 3.1101 Accuracy 0.9961\n",
      "Epoch 51 Batch 850 Loss 3.1150 Accuracy 0.9961\n",
      "Epoch 51 Batch 900 Loss 3.1154 Accuracy 0.9961\n",
      "Epoch 51 Batch 950 Loss 3.1221 Accuracy 0.9961\n",
      "Epoch 51 Batch 1000 Loss 3.1183 Accuracy 0.9961\n",
      "Epoch 51 Batch 1050 Loss 3.1073 Accuracy 0.9961\n",
      "Epoch 51 Batch 1100 Loss 3.1072 Accuracy 0.9961\n",
      "Epoch 51 Batch 1150 Loss 3.0961 Accuracy 0.9961\n",
      "Epoch 51 Batch 1200 Loss 3.1113 Accuracy 0.9961\n",
      "Epoch 51 Batch 1250 Loss 3.1030 Accuracy 0.9961\n",
      "Epoch 51 Batch 1300 Loss 3.1044 Accuracy 0.9961\n",
      "Epoch 51 Batch 1350 Loss 3.0985 Accuracy 0.9961\n",
      "Epoch 51 Batch 1400 Loss 3.1015 Accuracy 0.9961\n",
      "Epoch 51 Batch 1450 Loss 3.0945 Accuracy 0.9961\n",
      "Epoch 51 Batch 1500 Loss 3.0924 Accuracy 0.9962\n",
      "Epoch 51 Batch 1550 Loss 3.0942 Accuracy 0.9961\n",
      "Epoch 51 Batch 1600 Loss 3.0963 Accuracy 0.9961\n",
      "Epoch 51 Batch 1650 Loss 3.0959 Accuracy 0.9961\n",
      "Epoch 51 Batch 1700 Loss 3.1000 Accuracy 0.9961\n",
      "Epoch 51 Batch 1750 Loss 3.0927 Accuracy 0.9962\n",
      "Epoch 51 Batch 1800 Loss 3.0951 Accuracy 0.9962\n",
      "Epoch 51 Batch 1850 Loss 3.0860 Accuracy 0.9962\n",
      "Epoch 51 Batch 1900 Loss 3.0814 Accuracy 0.9962\n",
      "Epoch 51 Batch 1950 Loss 3.0733 Accuracy 0.9962\n",
      "Epoch 51 Batch 2000 Loss 3.0790 Accuracy 0.9962\n",
      "Epoch 51 Batch 2050 Loss 3.0873 Accuracy 0.9962\n",
      "Epoch 51 Batch 2100 Loss 3.0841 Accuracy 0.9962\n",
      "Epoch 51 Batch 2150 Loss 3.0855 Accuracy 0.9962\n",
      "Epoch 51 Batch 2200 Loss 3.0910 Accuracy 0.9962\n",
      "Epoch 51 Batch 2250 Loss 3.0949 Accuracy 0.9962\n",
      "Epoch 51 Batch 2300 Loss 3.0914 Accuracy 0.9962\n",
      "Epoch 51 Batch 2350 Loss 3.0918 Accuracy 0.9962\n",
      "Epoch 51 Batch 2400 Loss 3.0938 Accuracy 0.9962\n",
      "Epoch 51 Batch 2450 Loss 3.0961 Accuracy 0.9961\n",
      "Epoch 51 Batch 2500 Loss 3.0978 Accuracy 0.9961\n",
      "Epoch 51 Batch 2550 Loss 3.0971 Accuracy 0.9961\n",
      "Epoch 51 Batch 2600 Loss 3.0942 Accuracy 0.9961\n",
      "Epoch 51 Batch 2650 Loss 3.0919 Accuracy 0.9962\n",
      "Epoch 51 Loss 3.0936 Accuracy 0.9961\n",
      "Time taken for 1 epoch: 194.9098436832428 secs\n",
      "\n",
      "Epoch 52 Batch 0 Loss 1.9751 Accuracy 0.9975\n",
      "Epoch 52 Batch 50 Loss 3.1265 Accuracy 0.9961\n",
      "Epoch 52 Batch 100 Loss 3.1057 Accuracy 0.9961\n",
      "Epoch 52 Batch 150 Loss 3.1244 Accuracy 0.9961\n",
      "Epoch 52 Batch 200 Loss 3.0430 Accuracy 0.9962\n",
      "Epoch 52 Batch 250 Loss 3.0365 Accuracy 0.9962\n",
      "Epoch 52 Batch 300 Loss 3.0477 Accuracy 0.9962\n",
      "Epoch 52 Batch 350 Loss 3.0535 Accuracy 0.9962\n",
      "Epoch 52 Batch 400 Loss 3.0528 Accuracy 0.9962\n",
      "Epoch 52 Batch 450 Loss 3.0886 Accuracy 0.9961\n",
      "Epoch 52 Batch 500 Loss 3.0689 Accuracy 0.9962\n",
      "Epoch 52 Batch 550 Loss 3.0893 Accuracy 0.9961\n",
      "Epoch 52 Batch 600 Loss 3.1037 Accuracy 0.9961\n",
      "Epoch 52 Batch 650 Loss 3.0961 Accuracy 0.9961\n",
      "Epoch 52 Batch 700 Loss 3.0970 Accuracy 0.9961\n",
      "Epoch 52 Batch 750 Loss 3.1029 Accuracy 0.9961\n",
      "Epoch 52 Batch 800 Loss 3.0864 Accuracy 0.9962\n",
      "Epoch 52 Batch 850 Loss 3.0899 Accuracy 0.9961\n",
      "Epoch 52 Batch 900 Loss 3.0895 Accuracy 0.9962\n",
      "Epoch 52 Batch 950 Loss 3.0939 Accuracy 0.9961\n",
      "Epoch 52 Batch 1000 Loss 3.0890 Accuracy 0.9962\n",
      "Epoch 52 Batch 1050 Loss 3.0788 Accuracy 0.9962\n",
      "Epoch 52 Batch 1100 Loss 3.0766 Accuracy 0.9962\n",
      "Epoch 52 Batch 1150 Loss 3.0662 Accuracy 0.9962\n",
      "Epoch 52 Batch 1200 Loss 3.0816 Accuracy 0.9962\n",
      "Epoch 52 Batch 1250 Loss 3.0774 Accuracy 0.9962\n",
      "Epoch 52 Batch 1300 Loss 3.0790 Accuracy 0.9962\n",
      "Epoch 52 Batch 1350 Loss 3.0732 Accuracy 0.9962\n",
      "Epoch 52 Batch 1400 Loss 3.0760 Accuracy 0.9962\n",
      "Epoch 52 Batch 1450 Loss 3.0675 Accuracy 0.9962\n",
      "Epoch 52 Batch 1500 Loss 3.0653 Accuracy 0.9962\n",
      "Epoch 52 Batch 1550 Loss 3.0679 Accuracy 0.9962\n",
      "Epoch 52 Batch 1600 Loss 3.0674 Accuracy 0.9962\n",
      "Epoch 52 Batch 1650 Loss 3.0660 Accuracy 0.9962\n",
      "Epoch 52 Batch 1700 Loss 3.0688 Accuracy 0.9962\n",
      "Epoch 52 Batch 1750 Loss 3.0619 Accuracy 0.9962\n",
      "Epoch 52 Batch 1800 Loss 3.0634 Accuracy 0.9962\n",
      "Epoch 52 Batch 1850 Loss 3.0560 Accuracy 0.9962\n",
      "Epoch 52 Batch 1900 Loss 3.0516 Accuracy 0.9962\n",
      "Epoch 52 Batch 1950 Loss 3.0424 Accuracy 0.9962\n",
      "Epoch 52 Batch 2000 Loss 3.0495 Accuracy 0.9962\n",
      "Epoch 52 Batch 2050 Loss 3.0567 Accuracy 0.9962\n",
      "Epoch 52 Batch 2100 Loss 3.0541 Accuracy 0.9962\n",
      "Epoch 52 Batch 2150 Loss 3.0574 Accuracy 0.9962\n",
      "Epoch 52 Batch 2200 Loss 3.0617 Accuracy 0.9962\n",
      "Epoch 52 Batch 2250 Loss 3.0640 Accuracy 0.9962\n",
      "Epoch 52 Batch 2300 Loss 3.0609 Accuracy 0.9962\n",
      "Epoch 52 Batch 2350 Loss 3.0597 Accuracy 0.9962\n",
      "Epoch 52 Batch 2400 Loss 3.0627 Accuracy 0.9962\n",
      "Epoch 52 Batch 2450 Loss 3.0658 Accuracy 0.9962\n",
      "Epoch 52 Batch 2500 Loss 3.0685 Accuracy 0.9962\n",
      "Epoch 52 Batch 2550 Loss 3.0675 Accuracy 0.9962\n",
      "Epoch 52 Batch 2600 Loss 3.0641 Accuracy 0.9962\n",
      "Epoch 52 Batch 2650 Loss 3.0621 Accuracy 0.9962\n",
      "Epoch 52 Loss 3.0636 Accuracy 0.9962\n",
      "Time taken for 1 epoch: 195.18698573112488 secs\n",
      "\n",
      "Epoch 53 Batch 0 Loss 2.0736 Accuracy 0.9975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 50 Loss 3.1214 Accuracy 0.9961\n",
      "Epoch 53 Batch 100 Loss 3.0828 Accuracy 0.9962\n",
      "Epoch 53 Batch 150 Loss 3.1183 Accuracy 0.9961\n",
      "Epoch 53 Batch 200 Loss 3.0358 Accuracy 0.9962\n",
      "Epoch 53 Batch 250 Loss 3.0250 Accuracy 0.9962\n",
      "Epoch 53 Batch 300 Loss 3.0373 Accuracy 0.9962\n",
      "Epoch 53 Batch 350 Loss 3.0300 Accuracy 0.9962\n",
      "Epoch 53 Batch 400 Loss 3.0358 Accuracy 0.9962\n",
      "Epoch 53 Batch 450 Loss 3.0699 Accuracy 0.9962\n",
      "Epoch 53 Batch 500 Loss 3.0622 Accuracy 0.9962\n",
      "Epoch 53 Batch 550 Loss 3.0783 Accuracy 0.9962\n",
      "Epoch 53 Batch 600 Loss 3.0899 Accuracy 0.9961\n",
      "Epoch 53 Batch 650 Loss 3.0878 Accuracy 0.9961\n",
      "Epoch 53 Batch 700 Loss 3.0857 Accuracy 0.9962\n",
      "Epoch 53 Batch 750 Loss 3.0803 Accuracy 0.9962\n",
      "Epoch 53 Batch 800 Loss 3.0660 Accuracy 0.9962\n",
      "Epoch 53 Batch 850 Loss 3.0717 Accuracy 0.9962\n",
      "Epoch 53 Batch 900 Loss 3.0712 Accuracy 0.9962\n",
      "Epoch 53 Batch 950 Loss 3.0783 Accuracy 0.9962\n",
      "Epoch 53 Batch 1000 Loss 3.0746 Accuracy 0.9962\n",
      "Epoch 53 Batch 1050 Loss 3.0641 Accuracy 0.9962\n",
      "Epoch 53 Batch 1100 Loss 3.0617 Accuracy 0.9962\n",
      "Epoch 53 Batch 1150 Loss 3.0526 Accuracy 0.9962\n",
      "Epoch 53 Batch 1200 Loss 3.0641 Accuracy 0.9962\n",
      "Epoch 53 Batch 1250 Loss 3.0594 Accuracy 0.9962\n",
      "Epoch 53 Batch 1300 Loss 3.0616 Accuracy 0.9962\n",
      "Epoch 53 Batch 1350 Loss 3.0548 Accuracy 0.9962\n",
      "Epoch 53 Batch 1400 Loss 3.0570 Accuracy 0.9962\n",
      "Epoch 53 Batch 1450 Loss 3.0489 Accuracy 0.9962\n",
      "Epoch 53 Batch 1500 Loss 3.0467 Accuracy 0.9962\n",
      "Epoch 53 Batch 1550 Loss 3.0478 Accuracy 0.9962\n",
      "Epoch 53 Batch 1600 Loss 3.0502 Accuracy 0.9962\n",
      "Epoch 53 Batch 1650 Loss 3.0501 Accuracy 0.9962\n",
      "Epoch 53 Batch 1700 Loss 3.0558 Accuracy 0.9962\n",
      "Epoch 53 Batch 1750 Loss 3.0459 Accuracy 0.9962\n",
      "Epoch 53 Batch 1800 Loss 3.0477 Accuracy 0.9962\n",
      "Epoch 53 Batch 1850 Loss 3.0397 Accuracy 0.9962\n",
      "Epoch 53 Batch 1900 Loss 3.0361 Accuracy 0.9962\n",
      "Epoch 53 Batch 1950 Loss 3.0259 Accuracy 0.9962\n",
      "Epoch 53 Batch 2000 Loss 3.0319 Accuracy 0.9962\n",
      "Epoch 53 Batch 2050 Loss 3.0395 Accuracy 0.9962\n",
      "Epoch 53 Batch 2100 Loss 3.0382 Accuracy 0.9962\n",
      "Epoch 53 Batch 2150 Loss 3.0398 Accuracy 0.9962\n",
      "Epoch 53 Batch 2200 Loss 3.0434 Accuracy 0.9962\n",
      "Epoch 53 Batch 2250 Loss 3.0454 Accuracy 0.9962\n",
      "Epoch 53 Batch 2300 Loss 3.0421 Accuracy 0.9962\n",
      "Epoch 53 Batch 2350 Loss 3.0407 Accuracy 0.9962\n",
      "Epoch 53 Batch 2400 Loss 3.0429 Accuracy 0.9962\n",
      "Epoch 53 Batch 2450 Loss 3.0448 Accuracy 0.9962\n",
      "Epoch 53 Batch 2500 Loss 3.0477 Accuracy 0.9962\n",
      "Epoch 53 Batch 2550 Loss 3.0476 Accuracy 0.9962\n",
      "Epoch 53 Batch 2600 Loss 3.0451 Accuracy 0.9962\n",
      "Epoch 53 Batch 2650 Loss 3.0443 Accuracy 0.9962\n",
      "Epoch 53 Loss 3.0464 Accuracy 0.9962\n",
      "Time taken for 1 epoch: 195.23627996444702 secs\n",
      "\n",
      "Epoch 54 Batch 0 Loss 2.2018 Accuracy 0.9972\n",
      "Epoch 54 Batch 50 Loss 3.0865 Accuracy 0.9961\n",
      "Epoch 54 Batch 100 Loss 3.0395 Accuracy 0.9962\n",
      "Epoch 54 Batch 150 Loss 3.0809 Accuracy 0.9962\n",
      "Epoch 54 Batch 200 Loss 3.0005 Accuracy 0.9963\n",
      "Epoch 54 Batch 250 Loss 2.9957 Accuracy 0.9963\n",
      "Epoch 54 Batch 300 Loss 3.0022 Accuracy 0.9963\n",
      "Epoch 54 Batch 350 Loss 3.0071 Accuracy 0.9963\n",
      "Epoch 54 Batch 400 Loss 3.0029 Accuracy 0.9963\n",
      "Epoch 54 Batch 450 Loss 3.0381 Accuracy 0.9962\n",
      "Epoch 54 Batch 500 Loss 3.0286 Accuracy 0.9962\n",
      "Epoch 54 Batch 550 Loss 3.0444 Accuracy 0.9962\n",
      "Epoch 54 Batch 600 Loss 3.0564 Accuracy 0.9962\n",
      "Epoch 54 Batch 650 Loss 3.0555 Accuracy 0.9962\n",
      "Epoch 54 Batch 700 Loss 3.0531 Accuracy 0.9962\n",
      "Epoch 54 Batch 750 Loss 3.0556 Accuracy 0.9962\n",
      "Epoch 54 Batch 800 Loss 3.0434 Accuracy 0.9962\n",
      "Epoch 54 Batch 850 Loss 3.0509 Accuracy 0.9962\n",
      "Epoch 54 Batch 900 Loss 3.0483 Accuracy 0.9962\n",
      "Epoch 54 Batch 950 Loss 3.0547 Accuracy 0.9962\n",
      "Epoch 54 Batch 1000 Loss 3.0529 Accuracy 0.9962\n",
      "Epoch 54 Batch 1050 Loss 3.0392 Accuracy 0.9962\n",
      "Epoch 54 Batch 1100 Loss 3.0362 Accuracy 0.9962\n",
      "Epoch 54 Batch 1150 Loss 3.0284 Accuracy 0.9962\n",
      "Epoch 54 Batch 1200 Loss 3.0409 Accuracy 0.9962\n",
      "Epoch 54 Batch 1250 Loss 3.0338 Accuracy 0.9962\n",
      "Epoch 54 Batch 1300 Loss 3.0367 Accuracy 0.9962\n",
      "Epoch 54 Batch 1350 Loss 3.0319 Accuracy 0.9962\n",
      "Epoch 54 Batch 1400 Loss 3.0353 Accuracy 0.9962\n",
      "Epoch 54 Batch 1450 Loss 3.0281 Accuracy 0.9962\n",
      "Epoch 54 Batch 1500 Loss 3.0278 Accuracy 0.9962\n",
      "Epoch 54 Batch 1550 Loss 3.0292 Accuracy 0.9962\n",
      "Epoch 54 Batch 1600 Loss 3.0298 Accuracy 0.9962\n",
      "Epoch 54 Batch 1650 Loss 3.0287 Accuracy 0.9962\n",
      "Epoch 54 Batch 1700 Loss 3.0323 Accuracy 0.9962\n",
      "Epoch 54 Batch 1750 Loss 3.0254 Accuracy 0.9962\n",
      "Epoch 54 Batch 1800 Loss 3.0269 Accuracy 0.9962\n",
      "Epoch 54 Batch 1850 Loss 3.0192 Accuracy 0.9962\n",
      "Epoch 54 Batch 1900 Loss 3.0157 Accuracy 0.9962\n",
      "Epoch 54 Batch 1950 Loss 3.0063 Accuracy 0.9963\n",
      "Epoch 54 Batch 2000 Loss 3.0138 Accuracy 0.9963\n",
      "Epoch 54 Batch 2050 Loss 3.0203 Accuracy 0.9962\n",
      "Epoch 54 Batch 2100 Loss 3.0163 Accuracy 0.9962\n",
      "Epoch 54 Batch 2150 Loss 3.0201 Accuracy 0.9962\n",
      "Epoch 54 Batch 2200 Loss 3.0252 Accuracy 0.9962\n",
      "Epoch 54 Batch 2250 Loss 3.0285 Accuracy 0.9962\n",
      "Epoch 54 Batch 2300 Loss 3.0262 Accuracy 0.9962\n",
      "Epoch 54 Batch 2350 Loss 3.0255 Accuracy 0.9962\n",
      "Epoch 54 Batch 2400 Loss 3.0277 Accuracy 0.9962\n",
      "Epoch 54 Batch 2450 Loss 3.0309 Accuracy 0.9962\n",
      "Epoch 54 Batch 2500 Loss 3.0326 Accuracy 0.9962\n",
      "Epoch 54 Batch 2550 Loss 3.0312 Accuracy 0.9962\n",
      "Epoch 54 Batch 2600 Loss 3.0290 Accuracy 0.9962\n",
      "Epoch 54 Batch 2650 Loss 3.0268 Accuracy 0.9962\n",
      "Epoch 54 Loss 3.0272 Accuracy 0.9962\n",
      "Time taken for 1 epoch: 195.22372484207153 secs\n",
      "\n",
      "Epoch 55 Batch 0 Loss 2.1197 Accuracy 0.9973\n",
      "Epoch 55 Batch 50 Loss 3.0901 Accuracy 0.9962\n",
      "Epoch 55 Batch 100 Loss 3.0582 Accuracy 0.9962\n",
      "Epoch 55 Batch 150 Loss 3.0865 Accuracy 0.9961\n",
      "Epoch 55 Batch 200 Loss 3.0021 Accuracy 0.9963\n",
      "Epoch 55 Batch 250 Loss 2.9914 Accuracy 0.9963\n",
      "Epoch 55 Batch 300 Loss 2.9916 Accuracy 0.9963\n",
      "Epoch 55 Batch 350 Loss 2.9972 Accuracy 0.9963\n",
      "Epoch 55 Batch 400 Loss 2.9980 Accuracy 0.9963\n",
      "Epoch 55 Batch 450 Loss 3.0326 Accuracy 0.9962\n",
      "Epoch 55 Batch 500 Loss 3.0146 Accuracy 0.9962\n",
      "Epoch 55 Batch 550 Loss 3.0381 Accuracy 0.9962\n",
      "Epoch 55 Batch 600 Loss 3.0542 Accuracy 0.9962\n",
      "Epoch 55 Batch 650 Loss 3.0484 Accuracy 0.9962\n",
      "Epoch 55 Batch 700 Loss 3.0398 Accuracy 0.9962\n",
      "Epoch 55 Batch 750 Loss 3.0391 Accuracy 0.9962\n",
      "Epoch 55 Batch 800 Loss 3.0237 Accuracy 0.9962\n",
      "Epoch 55 Batch 850 Loss 3.0299 Accuracy 0.9962\n",
      "Epoch 55 Batch 900 Loss 3.0328 Accuracy 0.9962\n",
      "Epoch 55 Batch 950 Loss 3.0399 Accuracy 0.9962\n",
      "Epoch 55 Batch 1000 Loss 3.0361 Accuracy 0.9962\n",
      "Epoch 55 Batch 1050 Loss 3.0274 Accuracy 0.9962\n",
      "Epoch 55 Batch 1100 Loss 3.0265 Accuracy 0.9962\n",
      "Epoch 55 Batch 1150 Loss 3.0168 Accuracy 0.9962\n",
      "Epoch 55 Batch 1200 Loss 3.0311 Accuracy 0.9962\n",
      "Epoch 55 Batch 1250 Loss 3.0237 Accuracy 0.9962\n",
      "Epoch 55 Batch 1300 Loss 3.0243 Accuracy 0.9962\n",
      "Epoch 55 Batch 1350 Loss 3.0189 Accuracy 0.9962\n",
      "Epoch 55 Batch 1400 Loss 3.0205 Accuracy 0.9962\n",
      "Epoch 55 Batch 1450 Loss 3.0134 Accuracy 0.9963\n",
      "Epoch 55 Batch 1500 Loss 3.0118 Accuracy 0.9963\n",
      "Epoch 55 Batch 1550 Loss 3.0138 Accuracy 0.9963\n",
      "Epoch 55 Batch 1600 Loss 3.0155 Accuracy 0.9962\n",
      "Epoch 55 Batch 1650 Loss 3.0147 Accuracy 0.9963\n",
      "Epoch 55 Batch 1700 Loss 3.0194 Accuracy 0.9962\n",
      "Epoch 55 Batch 1750 Loss 3.0138 Accuracy 0.9963\n",
      "Epoch 55 Batch 1800 Loss 3.0148 Accuracy 0.9963\n",
      "Epoch 55 Batch 1850 Loss 3.0074 Accuracy 0.9963\n",
      "Epoch 55 Batch 1900 Loss 3.0017 Accuracy 0.9963\n",
      "Epoch 55 Batch 1950 Loss 2.9921 Accuracy 0.9963\n",
      "Epoch 55 Batch 2000 Loss 2.9978 Accuracy 0.9963\n",
      "Epoch 55 Batch 2050 Loss 3.0049 Accuracy 0.9963\n",
      "Epoch 55 Batch 2100 Loss 3.0017 Accuracy 0.9963\n",
      "Epoch 55 Batch 2150 Loss 3.0041 Accuracy 0.9963\n",
      "Epoch 55 Batch 2200 Loss 3.0072 Accuracy 0.9963\n",
      "Epoch 55 Batch 2250 Loss 3.0084 Accuracy 0.9963\n",
      "Epoch 55 Batch 2300 Loss 3.0062 Accuracy 0.9963\n",
      "Epoch 55 Batch 2350 Loss 3.0061 Accuracy 0.9963\n",
      "Epoch 55 Batch 2400 Loss 3.0083 Accuracy 0.9963\n",
      "Epoch 55 Batch 2450 Loss 3.0101 Accuracy 0.9963\n",
      "Epoch 55 Batch 2500 Loss 3.0139 Accuracy 0.9963\n",
      "Epoch 55 Batch 2550 Loss 3.0138 Accuracy 0.9963\n",
      "Epoch 55 Batch 2600 Loss 3.0112 Accuracy 0.9963\n",
      "Epoch 55 Batch 2650 Loss 3.0086 Accuracy 0.9963\n",
      "Saving checkpoint for epoch 55 at ./checkpoints/train\\ckpt-12\n",
      "Epoch 55 Loss 3.0105 Accuracy 0.9963\n",
      "Time taken for 1 epoch: 195.2566373348236 secs\n",
      "\n",
      "Epoch 56 Batch 0 Loss 2.4053 Accuracy 0.9973\n",
      "Epoch 56 Batch 50 Loss 3.0305 Accuracy 0.9962\n",
      "Epoch 56 Batch 100 Loss 2.9892 Accuracy 0.9963\n",
      "Epoch 56 Batch 150 Loss 3.0351 Accuracy 0.9962\n",
      "Epoch 56 Batch 200 Loss 2.9596 Accuracy 0.9963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Batch 250 Loss 2.9457 Accuracy 0.9964\n",
      "Epoch 56 Batch 300 Loss 2.9584 Accuracy 0.9963\n",
      "Epoch 56 Batch 350 Loss 2.9566 Accuracy 0.9963\n",
      "Epoch 56 Batch 400 Loss 2.9569 Accuracy 0.9963\n",
      "Epoch 56 Batch 450 Loss 2.9910 Accuracy 0.9963\n",
      "Epoch 56 Batch 500 Loss 2.9801 Accuracy 0.9963\n",
      "Epoch 56 Batch 550 Loss 3.0009 Accuracy 0.9963\n",
      "Epoch 56 Batch 600 Loss 3.0171 Accuracy 0.9962\n",
      "Epoch 56 Batch 650 Loss 3.0173 Accuracy 0.9962\n",
      "Epoch 56 Batch 700 Loss 3.0160 Accuracy 0.9963\n",
      "Epoch 56 Batch 750 Loss 3.0135 Accuracy 0.9963\n",
      "Epoch 56 Batch 800 Loss 2.9925 Accuracy 0.9963\n",
      "Epoch 56 Batch 850 Loss 2.9994 Accuracy 0.9963\n",
      "Epoch 56 Batch 900 Loss 3.0004 Accuracy 0.9963\n",
      "Epoch 56 Batch 950 Loss 3.0095 Accuracy 0.9963\n",
      "Epoch 56 Batch 1000 Loss 3.0062 Accuracy 0.9963\n",
      "Epoch 56 Batch 1050 Loss 2.9945 Accuracy 0.9963\n",
      "Epoch 56 Batch 1100 Loss 2.9940 Accuracy 0.9963\n",
      "Epoch 56 Batch 1150 Loss 2.9859 Accuracy 0.9963\n",
      "Epoch 56 Batch 1200 Loss 3.0010 Accuracy 0.9963\n",
      "Epoch 56 Batch 1250 Loss 2.9932 Accuracy 0.9963\n",
      "Epoch 56 Batch 1300 Loss 2.9960 Accuracy 0.9963\n",
      "Epoch 56 Batch 1350 Loss 2.9906 Accuracy 0.9963\n",
      "Epoch 56 Batch 1400 Loss 2.9938 Accuracy 0.9963\n",
      "Epoch 56 Batch 1450 Loss 2.9863 Accuracy 0.9963\n",
      "Epoch 56 Batch 1500 Loss 2.9857 Accuracy 0.9963\n",
      "Epoch 56 Batch 1550 Loss 2.9890 Accuracy 0.9963\n",
      "Epoch 56 Batch 1600 Loss 2.9899 Accuracy 0.9963\n",
      "Epoch 56 Batch 1650 Loss 2.9887 Accuracy 0.9963\n",
      "Epoch 56 Batch 1700 Loss 2.9923 Accuracy 0.9963\n",
      "Epoch 56 Batch 1750 Loss 2.9858 Accuracy 0.9963\n",
      "Epoch 56 Batch 1800 Loss 2.9889 Accuracy 0.9963\n",
      "Epoch 56 Batch 1850 Loss 2.9807 Accuracy 0.9963\n",
      "Epoch 56 Batch 1900 Loss 2.9769 Accuracy 0.9963\n",
      "Epoch 56 Batch 1950 Loss 2.9670 Accuracy 0.9963\n",
      "Epoch 56 Batch 2000 Loss 2.9724 Accuracy 0.9963\n",
      "Epoch 56 Batch 2050 Loss 2.9814 Accuracy 0.9963\n",
      "Epoch 56 Batch 2100 Loss 2.9794 Accuracy 0.9963\n",
      "Epoch 56 Batch 2150 Loss 2.9836 Accuracy 0.9963\n",
      "Epoch 56 Batch 2200 Loss 2.9879 Accuracy 0.9963\n",
      "Epoch 56 Batch 2250 Loss 2.9910 Accuracy 0.9963\n",
      "Epoch 56 Batch 2300 Loss 2.9881 Accuracy 0.9963\n",
      "Epoch 56 Batch 2350 Loss 2.9884 Accuracy 0.9963\n",
      "Epoch 56 Batch 2400 Loss 2.9912 Accuracy 0.9963\n",
      "Epoch 56 Batch 2450 Loss 2.9932 Accuracy 0.9963\n",
      "Epoch 56 Batch 2500 Loss 2.9945 Accuracy 0.9963\n",
      "Epoch 56 Batch 2550 Loss 2.9938 Accuracy 0.9963\n",
      "Epoch 56 Batch 2600 Loss 2.9902 Accuracy 0.9963\n",
      "Epoch 56 Batch 2650 Loss 2.9878 Accuracy 0.9963\n",
      "Epoch 56 Loss 2.9899 Accuracy 0.9963\n",
      "Time taken for 1 epoch: 195.82973456382751 secs\n",
      "\n",
      "Epoch 57 Batch 0 Loss 2.2307 Accuracy 0.9972\n",
      "Epoch 57 Batch 50 Loss 3.0612 Accuracy 0.9962\n",
      "Epoch 57 Batch 100 Loss 3.0198 Accuracy 0.9962\n",
      "Epoch 57 Batch 150 Loss 3.0507 Accuracy 0.9962\n",
      "Epoch 57 Batch 200 Loss 2.9537 Accuracy 0.9963\n",
      "Epoch 57 Batch 250 Loss 2.9506 Accuracy 0.9963\n",
      "Epoch 57 Batch 300 Loss 2.9517 Accuracy 0.9963\n",
      "Epoch 57 Batch 350 Loss 2.9586 Accuracy 0.9963\n",
      "Epoch 57 Batch 400 Loss 2.9557 Accuracy 0.9963\n",
      "Epoch 57 Batch 450 Loss 2.9914 Accuracy 0.9963\n",
      "Epoch 57 Batch 500 Loss 2.9801 Accuracy 0.9963\n",
      "Epoch 57 Batch 550 Loss 2.9980 Accuracy 0.9963\n",
      "Epoch 57 Batch 600 Loss 3.0098 Accuracy 0.9962\n",
      "Epoch 57 Batch 650 Loss 3.0046 Accuracy 0.9962\n",
      "Epoch 57 Batch 700 Loss 3.0025 Accuracy 0.9963\n",
      "Epoch 57 Batch 750 Loss 3.0021 Accuracy 0.9963\n",
      "Epoch 57 Batch 800 Loss 2.9857 Accuracy 0.9963\n",
      "Epoch 57 Batch 850 Loss 2.9895 Accuracy 0.9963\n",
      "Epoch 57 Batch 900 Loss 2.9921 Accuracy 0.9963\n",
      "Epoch 57 Batch 950 Loss 2.9966 Accuracy 0.9963\n",
      "Epoch 57 Batch 1000 Loss 2.9918 Accuracy 0.9963\n",
      "Epoch 57 Batch 1050 Loss 2.9806 Accuracy 0.9963\n",
      "Epoch 57 Batch 1100 Loss 2.9780 Accuracy 0.9963\n",
      "Epoch 57 Batch 1150 Loss 2.9694 Accuracy 0.9963\n",
      "Epoch 57 Batch 1200 Loss 2.9824 Accuracy 0.9963\n",
      "Epoch 57 Batch 1250 Loss 2.9756 Accuracy 0.9963\n",
      "Epoch 57 Batch 1300 Loss 2.9800 Accuracy 0.9963\n",
      "Epoch 57 Batch 1350 Loss 2.9756 Accuracy 0.9963\n",
      "Epoch 57 Batch 1400 Loss 2.9784 Accuracy 0.9963\n",
      "Epoch 57 Batch 1450 Loss 2.9725 Accuracy 0.9963\n",
      "Epoch 57 Batch 1500 Loss 2.9711 Accuracy 0.9963\n",
      "Epoch 57 Batch 1550 Loss 2.9740 Accuracy 0.9963\n",
      "Epoch 57 Batch 1600 Loss 2.9763 Accuracy 0.9963\n",
      "Epoch 57 Batch 1650 Loss 2.9750 Accuracy 0.9963\n",
      "Epoch 57 Batch 1700 Loss 2.9776 Accuracy 0.9963\n",
      "Epoch 57 Batch 1750 Loss 2.9714 Accuracy 0.9963\n",
      "Epoch 57 Batch 1800 Loss 2.9734 Accuracy 0.9963\n",
      "Epoch 57 Batch 1850 Loss 2.9659 Accuracy 0.9963\n",
      "Epoch 57 Batch 1900 Loss 2.9613 Accuracy 0.9963\n",
      "Epoch 57 Batch 1950 Loss 2.9514 Accuracy 0.9963\n",
      "Epoch 57 Batch 2000 Loss 2.9567 Accuracy 0.9963\n",
      "Epoch 57 Batch 2050 Loss 2.9645 Accuracy 0.9963\n",
      "Epoch 57 Batch 2100 Loss 2.9617 Accuracy 0.9963\n",
      "Epoch 57 Batch 2150 Loss 2.9634 Accuracy 0.9963\n",
      "Epoch 57 Batch 2200 Loss 2.9667 Accuracy 0.9963\n",
      "Epoch 57 Batch 2250 Loss 2.9694 Accuracy 0.9963\n",
      "Epoch 57 Batch 2300 Loss 2.9667 Accuracy 0.9963\n",
      "Epoch 57 Batch 2350 Loss 2.9654 Accuracy 0.9963\n",
      "Epoch 57 Batch 2400 Loss 2.9690 Accuracy 0.9963\n",
      "Epoch 57 Batch 2450 Loss 2.9708 Accuracy 0.9963\n",
      "Epoch 57 Batch 2500 Loss 2.9740 Accuracy 0.9963\n",
      "Epoch 57 Batch 2550 Loss 2.9734 Accuracy 0.9963\n",
      "Epoch 57 Batch 2600 Loss 2.9700 Accuracy 0.9963\n",
      "Epoch 57 Batch 2650 Loss 2.9681 Accuracy 0.9963\n",
      "Epoch 57 Loss 2.9706 Accuracy 0.9963\n",
      "Time taken for 1 epoch: 195.34351205825806 secs\n",
      "\n",
      "Epoch 58 Batch 0 Loss 2.0025 Accuracy 0.9978\n",
      "Epoch 58 Batch 50 Loss 3.0475 Accuracy 0.9962\n",
      "Epoch 58 Batch 100 Loss 3.0203 Accuracy 0.9962\n",
      "Epoch 58 Batch 150 Loss 3.0516 Accuracy 0.9962\n",
      "Epoch 58 Batch 200 Loss 2.9713 Accuracy 0.9963\n",
      "Epoch 58 Batch 250 Loss 2.9601 Accuracy 0.9963\n",
      "Epoch 58 Batch 300 Loss 2.9636 Accuracy 0.9963\n",
      "Epoch 58 Batch 350 Loss 2.9683 Accuracy 0.9963\n",
      "Epoch 58 Batch 400 Loss 2.9612 Accuracy 0.9963\n",
      "Epoch 58 Batch 450 Loss 3.0011 Accuracy 0.9963\n",
      "Epoch 58 Batch 500 Loss 2.9845 Accuracy 0.9963\n",
      "Epoch 58 Batch 550 Loss 3.0004 Accuracy 0.9963\n",
      "Epoch 58 Batch 600 Loss 3.0144 Accuracy 0.9962\n",
      "Epoch 58 Batch 650 Loss 3.0061 Accuracy 0.9963\n",
      "Epoch 58 Batch 700 Loss 3.0059 Accuracy 0.9963\n",
      "Epoch 58 Batch 750 Loss 3.0040 Accuracy 0.9963\n",
      "Epoch 58 Batch 800 Loss 2.9866 Accuracy 0.9963\n",
      "Epoch 58 Batch 850 Loss 2.9887 Accuracy 0.9963\n",
      "Epoch 58 Batch 900 Loss 2.9867 Accuracy 0.9963\n",
      "Epoch 58 Batch 950 Loss 2.9898 Accuracy 0.9963\n",
      "Epoch 58 Batch 1000 Loss 2.9848 Accuracy 0.9963\n",
      "Epoch 58 Batch 1050 Loss 2.9741 Accuracy 0.9963\n",
      "Epoch 58 Batch 1100 Loss 2.9740 Accuracy 0.9963\n",
      "Epoch 58 Batch 1150 Loss 2.9647 Accuracy 0.9963\n",
      "Epoch 58 Batch 1200 Loss 2.9791 Accuracy 0.9963\n",
      "Epoch 58 Batch 1250 Loss 2.9718 Accuracy 0.9963\n",
      "Epoch 58 Batch 1300 Loss 2.9753 Accuracy 0.9963\n",
      "Epoch 58 Batch 1350 Loss 2.9696 Accuracy 0.9963\n",
      "Epoch 58 Batch 1400 Loss 2.9722 Accuracy 0.9963\n",
      "Epoch 58 Batch 1450 Loss 2.9651 Accuracy 0.9963\n",
      "Epoch 58 Batch 1500 Loss 2.9641 Accuracy 0.9963\n",
      "Epoch 58 Batch 1550 Loss 2.9680 Accuracy 0.9963\n",
      "Epoch 58 Batch 1600 Loss 2.9681 Accuracy 0.9963\n",
      "Epoch 58 Batch 1650 Loss 2.9677 Accuracy 0.9963\n",
      "Epoch 58 Batch 1700 Loss 2.9711 Accuracy 0.9963\n",
      "Epoch 58 Batch 1750 Loss 2.9659 Accuracy 0.9963\n",
      "Epoch 58 Batch 1800 Loss 2.9667 Accuracy 0.9963\n",
      "Epoch 58 Batch 1850 Loss 2.9599 Accuracy 0.9963\n",
      "Epoch 58 Batch 1900 Loss 2.9552 Accuracy 0.9963\n",
      "Epoch 58 Batch 1950 Loss 2.9458 Accuracy 0.9963\n",
      "Epoch 58 Batch 2000 Loss 2.9508 Accuracy 0.9963\n",
      "Epoch 58 Batch 2050 Loss 2.9596 Accuracy 0.9963\n",
      "Epoch 58 Batch 2100 Loss 2.9577 Accuracy 0.9963\n",
      "Epoch 58 Batch 2150 Loss 2.9609 Accuracy 0.9963\n",
      "Epoch 58 Batch 2200 Loss 2.9651 Accuracy 0.9963\n",
      "Epoch 58 Batch 2250 Loss 2.9672 Accuracy 0.9963\n",
      "Epoch 58 Batch 2300 Loss 2.9644 Accuracy 0.9963\n",
      "Epoch 58 Batch 2350 Loss 2.9636 Accuracy 0.9963\n",
      "Epoch 58 Batch 2400 Loss 2.9660 Accuracy 0.9963\n",
      "Epoch 58 Batch 2450 Loss 2.9687 Accuracy 0.9963\n",
      "Epoch 58 Batch 2500 Loss 2.9706 Accuracy 0.9963\n",
      "Epoch 58 Batch 2550 Loss 2.9700 Accuracy 0.9963\n",
      "Epoch 58 Batch 2600 Loss 2.9668 Accuracy 0.9963\n",
      "Epoch 58 Batch 2650 Loss 2.9653 Accuracy 0.9963\n",
      "Epoch 58 Loss 2.9671 Accuracy 0.9963\n",
      "Time taken for 1 epoch: 195.8264422416687 secs\n",
      "\n",
      "Epoch 59 Batch 0 Loss 1.9514 Accuracy 0.9976\n",
      "Epoch 59 Batch 50 Loss 3.0276 Accuracy 0.9962\n",
      "Epoch 59 Batch 100 Loss 2.9853 Accuracy 0.9963\n",
      "Epoch 59 Batch 150 Loss 3.0145 Accuracy 0.9962\n",
      "Epoch 59 Batch 200 Loss 2.9391 Accuracy 0.9963\n",
      "Epoch 59 Batch 250 Loss 2.9323 Accuracy 0.9964\n",
      "Epoch 59 Batch 300 Loss 2.9320 Accuracy 0.9964\n",
      "Epoch 59 Batch 350 Loss 2.9337 Accuracy 0.9963\n",
      "Epoch 59 Batch 400 Loss 2.9239 Accuracy 0.9964\n",
      "Epoch 59 Batch 450 Loss 2.9630 Accuracy 0.9963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Batch 500 Loss 2.9499 Accuracy 0.9963\n",
      "Epoch 59 Batch 550 Loss 2.9697 Accuracy 0.9963\n",
      "Epoch 59 Batch 600 Loss 2.9851 Accuracy 0.9963\n",
      "Epoch 59 Batch 650 Loss 2.9820 Accuracy 0.9963\n",
      "Epoch 59 Batch 700 Loss 2.9818 Accuracy 0.9963\n",
      "Epoch 59 Batch 750 Loss 2.9804 Accuracy 0.9963\n",
      "Epoch 59 Batch 800 Loss 2.9647 Accuracy 0.9963\n",
      "Epoch 59 Batch 850 Loss 2.9707 Accuracy 0.9963\n",
      "Epoch 59 Batch 900 Loss 2.9706 Accuracy 0.9963\n",
      "Epoch 59 Batch 950 Loss 2.9750 Accuracy 0.9963\n",
      "Epoch 59 Batch 1000 Loss 2.9699 Accuracy 0.9963\n",
      "Epoch 59 Batch 1050 Loss 2.9583 Accuracy 0.9963\n",
      "Epoch 59 Batch 1100 Loss 2.9546 Accuracy 0.9963\n",
      "Epoch 59 Batch 1150 Loss 2.9441 Accuracy 0.9963\n",
      "Epoch 59 Batch 1200 Loss 2.9576 Accuracy 0.9963\n",
      "Epoch 59 Batch 1250 Loss 2.9524 Accuracy 0.9963\n",
      "Epoch 59 Batch 1300 Loss 2.9580 Accuracy 0.9963\n",
      "Epoch 59 Batch 1350 Loss 2.9545 Accuracy 0.9963\n",
      "Epoch 59 Batch 1400 Loss 2.9582 Accuracy 0.9963\n",
      "Epoch 59 Batch 1450 Loss 2.9529 Accuracy 0.9963\n",
      "Epoch 59 Batch 1500 Loss 2.9501 Accuracy 0.9963\n",
      "Epoch 59 Batch 1550 Loss 2.9522 Accuracy 0.9963\n",
      "Epoch 59 Batch 1600 Loss 2.9513 Accuracy 0.9963\n",
      "Epoch 59 Batch 1650 Loss 2.9508 Accuracy 0.9963\n",
      "Epoch 59 Batch 1700 Loss 2.9530 Accuracy 0.9963\n",
      "Epoch 59 Batch 1750 Loss 2.9450 Accuracy 0.9963\n",
      "Epoch 59 Batch 1800 Loss 2.9458 Accuracy 0.9963\n",
      "Epoch 59 Batch 1850 Loss 2.9374 Accuracy 0.9964\n",
      "Epoch 59 Batch 1900 Loss 2.9333 Accuracy 0.9964\n",
      "Epoch 59 Batch 1950 Loss 2.9239 Accuracy 0.9964\n",
      "Epoch 59 Batch 2000 Loss 2.9284 Accuracy 0.9964\n",
      "Epoch 59 Batch 2050 Loss 2.9352 Accuracy 0.9964\n",
      "Epoch 59 Batch 2100 Loss 2.9326 Accuracy 0.9964\n",
      "Epoch 59 Batch 2150 Loss 2.9345 Accuracy 0.9964\n",
      "Epoch 59 Batch 2200 Loss 2.9382 Accuracy 0.9964\n",
      "Epoch 59 Batch 2250 Loss 2.9408 Accuracy 0.9964\n",
      "Epoch 59 Batch 2300 Loss 2.9369 Accuracy 0.9964\n",
      "Epoch 59 Batch 2350 Loss 2.9361 Accuracy 0.9964\n",
      "Epoch 59 Batch 2400 Loss 2.9381 Accuracy 0.9964\n",
      "Epoch 59 Batch 2450 Loss 2.9411 Accuracy 0.9964\n",
      "Epoch 59 Batch 2500 Loss 2.9447 Accuracy 0.9963\n",
      "Epoch 59 Batch 2550 Loss 2.9433 Accuracy 0.9963\n",
      "Epoch 59 Batch 2600 Loss 2.9407 Accuracy 0.9964\n",
      "Epoch 59 Batch 2650 Loss 2.9380 Accuracy 0.9964\n",
      "Epoch 59 Loss 2.9409 Accuracy 0.9964\n",
      "Time taken for 1 epoch: 195.5537257194519 secs\n",
      "\n",
      "Epoch 60 Batch 0 Loss 1.9641 Accuracy 0.9977\n",
      "Epoch 60 Batch 50 Loss 2.9631 Accuracy 0.9963\n",
      "Epoch 60 Batch 100 Loss 2.9793 Accuracy 0.9963\n",
      "Epoch 60 Batch 150 Loss 3.0229 Accuracy 0.9963\n",
      "Epoch 60 Batch 200 Loss 2.9340 Accuracy 0.9964\n",
      "Epoch 60 Batch 250 Loss 2.9228 Accuracy 0.9964\n",
      "Epoch 60 Batch 300 Loss 2.9230 Accuracy 0.9964\n",
      "Epoch 60 Batch 350 Loss 2.9244 Accuracy 0.9964\n",
      "Epoch 60 Batch 400 Loss 2.9264 Accuracy 0.9964\n",
      "Epoch 60 Batch 450 Loss 2.9646 Accuracy 0.9963\n",
      "Epoch 60 Batch 500 Loss 2.9518 Accuracy 0.9963\n",
      "Epoch 60 Batch 550 Loss 2.9674 Accuracy 0.9963\n",
      "Epoch 60 Batch 600 Loss 2.9815 Accuracy 0.9963\n",
      "Epoch 60 Batch 650 Loss 2.9752 Accuracy 0.9963\n",
      "Epoch 60 Batch 700 Loss 2.9684 Accuracy 0.9963\n",
      "Epoch 60 Batch 750 Loss 2.9682 Accuracy 0.9963\n",
      "Epoch 60 Batch 800 Loss 2.9552 Accuracy 0.9963\n",
      "Epoch 60 Batch 850 Loss 2.9585 Accuracy 0.9963\n",
      "Epoch 60 Batch 900 Loss 2.9594 Accuracy 0.9963\n",
      "Epoch 60 Batch 950 Loss 2.9664 Accuracy 0.9963\n",
      "Epoch 60 Batch 1000 Loss 2.9652 Accuracy 0.9963\n",
      "Epoch 60 Batch 1050 Loss 2.9533 Accuracy 0.9963\n",
      "Epoch 60 Batch 1100 Loss 2.9539 Accuracy 0.9963\n",
      "Epoch 60 Batch 1150 Loss 2.9435 Accuracy 0.9964\n",
      "Epoch 60 Batch 1200 Loss 2.9544 Accuracy 0.9963\n",
      "Epoch 60 Batch 1250 Loss 2.9477 Accuracy 0.9964\n",
      "Epoch 60 Batch 1300 Loss 2.9471 Accuracy 0.9964\n",
      "Epoch 60 Batch 1350 Loss 2.9426 Accuracy 0.9964\n",
      "Epoch 60 Batch 1400 Loss 2.9451 Accuracy 0.9964\n",
      "Epoch 60 Batch 1450 Loss 2.9373 Accuracy 0.9964\n",
      "Epoch 60 Batch 1500 Loss 2.9364 Accuracy 0.9964\n",
      "Epoch 60 Batch 1550 Loss 2.9396 Accuracy 0.9964\n",
      "Epoch 60 Batch 1600 Loss 2.9390 Accuracy 0.9964\n",
      "Epoch 60 Batch 1650 Loss 2.9404 Accuracy 0.9964\n",
      "Epoch 60 Batch 1700 Loss 2.9432 Accuracy 0.9964\n",
      "Epoch 60 Batch 1750 Loss 2.9351 Accuracy 0.9964\n",
      "Epoch 60 Batch 1800 Loss 2.9359 Accuracy 0.9964\n",
      "Epoch 60 Batch 1850 Loss 2.9279 Accuracy 0.9964\n",
      "Epoch 60 Batch 1900 Loss 2.9225 Accuracy 0.9964\n",
      "Epoch 60 Batch 1950 Loss 2.9122 Accuracy 0.9964\n",
      "Epoch 60 Batch 2000 Loss 2.9182 Accuracy 0.9964\n",
      "Epoch 60 Batch 2050 Loss 2.9243 Accuracy 0.9964\n",
      "Epoch 60 Batch 2100 Loss 2.9226 Accuracy 0.9964\n",
      "Epoch 60 Batch 2150 Loss 2.9254 Accuracy 0.9964\n",
      "Epoch 60 Batch 2200 Loss 2.9287 Accuracy 0.9964\n",
      "Epoch 60 Batch 2250 Loss 2.9314 Accuracy 0.9964\n",
      "Epoch 60 Batch 2300 Loss 2.9274 Accuracy 0.9964\n",
      "Epoch 60 Batch 2350 Loss 2.9282 Accuracy 0.9964\n",
      "Epoch 60 Batch 2400 Loss 2.9310 Accuracy 0.9964\n",
      "Epoch 60 Batch 2450 Loss 2.9333 Accuracy 0.9964\n",
      "Epoch 60 Batch 2500 Loss 2.9362 Accuracy 0.9964\n",
      "Epoch 60 Batch 2550 Loss 2.9353 Accuracy 0.9964\n",
      "Epoch 60 Batch 2600 Loss 2.9322 Accuracy 0.9964\n",
      "Epoch 60 Batch 2650 Loss 2.9292 Accuracy 0.9964\n",
      "Saving checkpoint for epoch 60 at ./checkpoints/train\\ckpt-13\n",
      "Epoch 60 Loss 2.9311 Accuracy 0.9964\n",
      "Time taken for 1 epoch: 196.62641739845276 secs\n",
      "\n",
      "Epoch 61 Batch 0 Loss 2.1400 Accuracy 0.9975\n",
      "Epoch 61 Batch 50 Loss 2.9550 Accuracy 0.9963\n",
      "Epoch 61 Batch 100 Loss 2.9412 Accuracy 0.9963\n",
      "Epoch 61 Batch 150 Loss 2.9703 Accuracy 0.9963\n",
      "Epoch 61 Batch 200 Loss 2.8926 Accuracy 0.9964\n",
      "Epoch 61 Batch 250 Loss 2.8840 Accuracy 0.9964\n",
      "Epoch 61 Batch 300 Loss 2.8831 Accuracy 0.9964\n",
      "Epoch 61 Batch 350 Loss 2.8818 Accuracy 0.9964\n",
      "Epoch 61 Batch 400 Loss 2.8777 Accuracy 0.9964\n",
      "Epoch 61 Batch 450 Loss 2.9143 Accuracy 0.9964\n",
      "Epoch 61 Batch 500 Loss 2.9024 Accuracy 0.9964\n",
      "Epoch 61 Batch 550 Loss 2.9170 Accuracy 0.9964\n",
      "Epoch 61 Batch 600 Loss 2.9393 Accuracy 0.9964\n",
      "Epoch 61 Batch 650 Loss 2.9371 Accuracy 0.9964\n",
      "Epoch 61 Batch 700 Loss 2.9330 Accuracy 0.9964\n",
      "Epoch 61 Batch 750 Loss 2.9323 Accuracy 0.9964\n",
      "Epoch 61 Batch 800 Loss 2.9174 Accuracy 0.9964\n",
      "Epoch 61 Batch 850 Loss 2.9211 Accuracy 0.9964\n",
      "Epoch 61 Batch 900 Loss 2.9220 Accuracy 0.9964\n",
      "Epoch 61 Batch 950 Loss 2.9248 Accuracy 0.9964\n",
      "Epoch 61 Batch 1000 Loss 2.9206 Accuracy 0.9964\n",
      "Epoch 61 Batch 1050 Loss 2.9121 Accuracy 0.9964\n",
      "Epoch 61 Batch 1100 Loss 2.9126 Accuracy 0.9964\n",
      "Epoch 61 Batch 1150 Loss 2.9036 Accuracy 0.9964\n",
      "Epoch 61 Batch 1200 Loss 2.9141 Accuracy 0.9964\n",
      "Epoch 61 Batch 1250 Loss 2.9073 Accuracy 0.9964\n",
      "Epoch 61 Batch 1300 Loss 2.9068 Accuracy 0.9964\n",
      "Epoch 61 Batch 1350 Loss 2.9014 Accuracy 0.9964\n",
      "Epoch 61 Batch 1400 Loss 2.9078 Accuracy 0.9964\n",
      "Epoch 61 Batch 1450 Loss 2.8998 Accuracy 0.9964\n",
      "Epoch 61 Batch 1500 Loss 2.8966 Accuracy 0.9964\n",
      "Epoch 61 Batch 1550 Loss 2.8979 Accuracy 0.9964\n",
      "Epoch 61 Batch 1600 Loss 2.8978 Accuracy 0.9964\n",
      "Epoch 61 Batch 1650 Loss 2.8995 Accuracy 0.9964\n",
      "Epoch 61 Batch 1700 Loss 2.9035 Accuracy 0.9964\n",
      "Epoch 61 Batch 1750 Loss 2.8987 Accuracy 0.9964\n",
      "Epoch 61 Batch 1800 Loss 2.9007 Accuracy 0.9964\n",
      "Epoch 61 Batch 1850 Loss 2.8918 Accuracy 0.9964\n",
      "Epoch 61 Batch 1900 Loss 2.8889 Accuracy 0.9964\n",
      "Epoch 61 Batch 1950 Loss 2.8799 Accuracy 0.9964\n",
      "Epoch 61 Batch 2000 Loss 2.8879 Accuracy 0.9964\n",
      "Epoch 61 Batch 2050 Loss 2.8963 Accuracy 0.9964\n",
      "Epoch 61 Batch 2100 Loss 2.8944 Accuracy 0.9964\n",
      "Epoch 61 Batch 2150 Loss 2.8949 Accuracy 0.9964\n",
      "Epoch 61 Batch 2200 Loss 2.9008 Accuracy 0.9964\n",
      "Epoch 61 Batch 2250 Loss 2.9022 Accuracy 0.9964\n",
      "Epoch 61 Batch 2300 Loss 2.9006 Accuracy 0.9964\n",
      "Epoch 61 Batch 2350 Loss 2.9003 Accuracy 0.9964\n",
      "Epoch 61 Batch 2400 Loss 2.9035 Accuracy 0.9964\n",
      "Epoch 61 Batch 2450 Loss 2.9065 Accuracy 0.9964\n",
      "Epoch 61 Batch 2500 Loss 2.9093 Accuracy 0.9964\n",
      "Epoch 61 Batch 2550 Loss 2.9101 Accuracy 0.9964\n",
      "Epoch 61 Batch 2600 Loss 2.9066 Accuracy 0.9964\n",
      "Epoch 61 Batch 2650 Loss 2.9051 Accuracy 0.9964\n",
      "Epoch 61 Loss 2.9054 Accuracy 0.9964\n",
      "Time taken for 1 epoch: 196.17669105529785 secs\n",
      "\n",
      "Epoch 62 Batch 0 Loss 2.0614 Accuracy 0.9977\n",
      "Epoch 62 Batch 50 Loss 2.9274 Accuracy 0.9963\n",
      "Epoch 62 Batch 100 Loss 2.9192 Accuracy 0.9964\n",
      "Epoch 62 Batch 150 Loss 2.9246 Accuracy 0.9963\n",
      "Epoch 62 Batch 200 Loss 2.8586 Accuracy 0.9964\n",
      "Epoch 62 Batch 250 Loss 2.8497 Accuracy 0.9965\n",
      "Epoch 62 Batch 300 Loss 2.8547 Accuracy 0.9964\n",
      "Epoch 62 Batch 350 Loss 2.8491 Accuracy 0.9965\n",
      "Epoch 62 Batch 400 Loss 2.8471 Accuracy 0.9965\n",
      "Epoch 62 Batch 450 Loss 2.8795 Accuracy 0.9964\n",
      "Epoch 62 Batch 500 Loss 2.8682 Accuracy 0.9964\n",
      "Epoch 62 Batch 550 Loss 2.8846 Accuracy 0.9964\n",
      "Epoch 62 Batch 600 Loss 2.8994 Accuracy 0.9964\n",
      "Epoch 62 Batch 650 Loss 2.9006 Accuracy 0.9964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 700 Loss 2.8958 Accuracy 0.9964\n",
      "Epoch 62 Batch 750 Loss 2.8936 Accuracy 0.9964\n",
      "Epoch 62 Batch 800 Loss 2.8846 Accuracy 0.9964\n",
      "Epoch 62 Batch 850 Loss 2.8872 Accuracy 0.9964\n",
      "Epoch 62 Batch 900 Loss 2.8881 Accuracy 0.9964\n",
      "Epoch 62 Batch 950 Loss 2.8920 Accuracy 0.9964\n",
      "Epoch 62 Batch 1000 Loss 2.8871 Accuracy 0.9964\n",
      "Epoch 62 Batch 1050 Loss 2.8765 Accuracy 0.9964\n",
      "Epoch 62 Batch 1100 Loss 2.8778 Accuracy 0.9964\n",
      "Epoch 62 Batch 1150 Loss 2.8683 Accuracy 0.9964\n",
      "Epoch 62 Batch 1200 Loss 2.8815 Accuracy 0.9964\n",
      "Epoch 62 Batch 1250 Loss 2.8736 Accuracy 0.9964\n",
      "Epoch 62 Batch 1300 Loss 2.8751 Accuracy 0.9964\n",
      "Epoch 62 Batch 1350 Loss 2.8711 Accuracy 0.9964\n",
      "Epoch 62 Batch 1400 Loss 2.8754 Accuracy 0.9964\n",
      "Epoch 62 Batch 1450 Loss 2.8694 Accuracy 0.9964\n",
      "Epoch 62 Batch 1500 Loss 2.8687 Accuracy 0.9964\n",
      "Epoch 62 Batch 1550 Loss 2.8714 Accuracy 0.9964\n",
      "Epoch 62 Batch 1600 Loss 2.8711 Accuracy 0.9964\n",
      "Epoch 62 Batch 1650 Loss 2.8730 Accuracy 0.9964\n",
      "Epoch 62 Batch 1700 Loss 2.8761 Accuracy 0.9964\n",
      "Epoch 62 Batch 1750 Loss 2.8708 Accuracy 0.9964\n",
      "Epoch 62 Batch 1800 Loss 2.8719 Accuracy 0.9964\n",
      "Epoch 62 Batch 1850 Loss 2.8660 Accuracy 0.9964\n",
      "Epoch 62 Batch 1900 Loss 2.8616 Accuracy 0.9965\n",
      "Epoch 62 Batch 1950 Loss 2.8537 Accuracy 0.9965\n",
      "Epoch 62 Batch 2000 Loss 2.8596 Accuracy 0.9965\n",
      "Epoch 62 Batch 2050 Loss 2.8676 Accuracy 0.9964\n",
      "Epoch 62 Batch 2100 Loss 2.8658 Accuracy 0.9964\n",
      "Epoch 62 Batch 2150 Loss 2.8694 Accuracy 0.9964\n",
      "Epoch 62 Batch 2200 Loss 2.8724 Accuracy 0.9964\n",
      "Epoch 62 Batch 2250 Loss 2.8747 Accuracy 0.9964\n",
      "Epoch 62 Batch 2300 Loss 2.8718 Accuracy 0.9964\n",
      "Epoch 62 Batch 2350 Loss 2.8722 Accuracy 0.9964\n",
      "Epoch 62 Batch 2400 Loss 2.8739 Accuracy 0.9964\n",
      "Epoch 62 Batch 2450 Loss 2.8762 Accuracy 0.9964\n",
      "Epoch 62 Batch 2500 Loss 2.8786 Accuracy 0.9964\n",
      "Epoch 62 Batch 2550 Loss 2.8782 Accuracy 0.9964\n",
      "Epoch 62 Batch 2600 Loss 2.8754 Accuracy 0.9964\n",
      "Epoch 62 Batch 2650 Loss 2.8732 Accuracy 0.9964\n",
      "Epoch 62 Loss 2.8739 Accuracy 0.9964\n",
      "Time taken for 1 epoch: 195.36016273498535 secs\n",
      "\n",
      "Epoch 63 Batch 0 Loss 2.0412 Accuracy 0.9973\n",
      "Epoch 63 Batch 50 Loss 2.9265 Accuracy 0.9963\n",
      "Epoch 63 Batch 100 Loss 2.9263 Accuracy 0.9963\n",
      "Epoch 63 Batch 150 Loss 2.9487 Accuracy 0.9963\n",
      "Epoch 63 Batch 200 Loss 2.8659 Accuracy 0.9964\n",
      "Epoch 63 Batch 250 Loss 2.8522 Accuracy 0.9964\n",
      "Epoch 63 Batch 300 Loss 2.8485 Accuracy 0.9965\n",
      "Epoch 63 Batch 350 Loss 2.8497 Accuracy 0.9965\n",
      "Epoch 63 Batch 400 Loss 2.8495 Accuracy 0.9964\n",
      "Epoch 63 Batch 450 Loss 2.8891 Accuracy 0.9964\n",
      "Epoch 63 Batch 500 Loss 2.8777 Accuracy 0.9964\n",
      "Epoch 63 Batch 550 Loss 2.8976 Accuracy 0.9964\n",
      "Epoch 63 Batch 600 Loss 2.9106 Accuracy 0.9964\n",
      "Epoch 63 Batch 650 Loss 2.9062 Accuracy 0.9964\n",
      "Epoch 63 Batch 700 Loss 2.8982 Accuracy 0.9964\n",
      "Epoch 63 Batch 750 Loss 2.9016 Accuracy 0.9964\n",
      "Epoch 63 Batch 800 Loss 2.8850 Accuracy 0.9964\n",
      "Epoch 63 Batch 850 Loss 2.8908 Accuracy 0.9964\n",
      "Epoch 63 Batch 900 Loss 2.8925 Accuracy 0.9964\n",
      "Epoch 63 Batch 950 Loss 2.8982 Accuracy 0.9964\n",
      "Epoch 63 Batch 1000 Loss 2.8936 Accuracy 0.9964\n",
      "Epoch 63 Batch 1050 Loss 2.8835 Accuracy 0.9964\n",
      "Epoch 63 Batch 1100 Loss 2.8809 Accuracy 0.9964\n",
      "Epoch 63 Batch 1150 Loss 2.8714 Accuracy 0.9964\n",
      "Epoch 63 Batch 1200 Loss 2.8870 Accuracy 0.9964\n",
      "Epoch 63 Batch 1250 Loss 2.8795 Accuracy 0.9964\n",
      "Epoch 63 Batch 1300 Loss 2.8828 Accuracy 0.9964\n",
      "Epoch 63 Batch 1350 Loss 2.8784 Accuracy 0.9964\n",
      "Epoch 63 Batch 1400 Loss 2.8813 Accuracy 0.9964\n",
      "Epoch 63 Batch 1450 Loss 2.8752 Accuracy 0.9964\n",
      "Epoch 63 Batch 1500 Loss 2.8744 Accuracy 0.9964\n",
      "Epoch 63 Batch 1550 Loss 2.8763 Accuracy 0.9964\n",
      "Epoch 63 Batch 1600 Loss 2.8771 Accuracy 0.9964\n",
      "Epoch 63 Batch 1650 Loss 2.8772 Accuracy 0.9964\n",
      "Epoch 63 Batch 1700 Loss 2.8825 Accuracy 0.9964\n",
      "Epoch 63 Batch 1750 Loss 2.8765 Accuracy 0.9964\n",
      "Epoch 63 Batch 1800 Loss 2.8785 Accuracy 0.9964\n",
      "Epoch 63 Batch 1850 Loss 2.8697 Accuracy 0.9964\n",
      "Epoch 63 Batch 1900 Loss 2.8643 Accuracy 0.9964\n",
      "Epoch 63 Batch 1950 Loss 2.8561 Accuracy 0.9965\n",
      "Epoch 63 Batch 2000 Loss 2.8610 Accuracy 0.9965\n",
      "Epoch 63 Batch 2050 Loss 2.8679 Accuracy 0.9964\n",
      "Epoch 63 Batch 2100 Loss 2.8671 Accuracy 0.9964\n",
      "Epoch 63 Batch 2150 Loss 2.8690 Accuracy 0.9964\n",
      "Epoch 63 Batch 2200 Loss 2.8736 Accuracy 0.9964\n",
      "Epoch 63 Batch 2250 Loss 2.8759 Accuracy 0.9964\n",
      "Epoch 63 Batch 2300 Loss 2.8720 Accuracy 0.9964\n",
      "Epoch 63 Batch 2350 Loss 2.8719 Accuracy 0.9964\n",
      "Epoch 63 Batch 2400 Loss 2.8742 Accuracy 0.9964\n",
      "Epoch 63 Batch 2450 Loss 2.8771 Accuracy 0.9964\n",
      "Epoch 63 Batch 2500 Loss 2.8810 Accuracy 0.9964\n",
      "Epoch 63 Batch 2550 Loss 2.8803 Accuracy 0.9964\n",
      "Epoch 63 Batch 2600 Loss 2.8782 Accuracy 0.9964\n",
      "Epoch 63 Batch 2650 Loss 2.8763 Accuracy 0.9964\n",
      "Epoch 63 Loss 2.8776 Accuracy 0.9964\n",
      "Time taken for 1 epoch: 195.68970465660095 secs\n",
      "\n",
      "Epoch 64 Batch 0 Loss 1.9143 Accuracy 0.9978\n",
      "Epoch 64 Batch 50 Loss 2.8869 Accuracy 0.9964\n",
      "Epoch 64 Batch 100 Loss 2.8800 Accuracy 0.9964\n",
      "Epoch 64 Batch 150 Loss 2.9162 Accuracy 0.9964\n",
      "Epoch 64 Batch 200 Loss 2.8471 Accuracy 0.9965\n",
      "Epoch 64 Batch 250 Loss 2.8391 Accuracy 0.9965\n",
      "Epoch 64 Batch 300 Loss 2.8351 Accuracy 0.9965\n",
      "Epoch 64 Batch 350 Loss 2.8386 Accuracy 0.9965\n",
      "Epoch 64 Batch 400 Loss 2.8449 Accuracy 0.9965\n",
      "Epoch 64 Batch 450 Loss 2.8796 Accuracy 0.9964\n",
      "Epoch 64 Batch 500 Loss 2.8705 Accuracy 0.9964\n",
      "Epoch 64 Batch 550 Loss 2.8814 Accuracy 0.9964\n",
      "Epoch 64 Batch 600 Loss 2.8967 Accuracy 0.9964\n",
      "Epoch 64 Batch 650 Loss 2.8936 Accuracy 0.9964\n",
      "Epoch 64 Batch 700 Loss 2.8916 Accuracy 0.9964\n",
      "Epoch 64 Batch 750 Loss 2.8915 Accuracy 0.9964\n",
      "Epoch 64 Batch 800 Loss 2.8767 Accuracy 0.9964\n",
      "Epoch 64 Batch 850 Loss 2.8810 Accuracy 0.9964\n",
      "Epoch 64 Batch 900 Loss 2.8786 Accuracy 0.9964\n",
      "Epoch 64 Batch 950 Loss 2.8836 Accuracy 0.9964\n",
      "Epoch 64 Batch 1000 Loss 2.8825 Accuracy 0.9964\n",
      "Epoch 64 Batch 1050 Loss 2.8733 Accuracy 0.9964\n",
      "Epoch 64 Batch 1100 Loss 2.8721 Accuracy 0.9964\n",
      "Epoch 64 Batch 1150 Loss 2.8633 Accuracy 0.9964\n",
      "Epoch 64 Batch 1200 Loss 2.8758 Accuracy 0.9964\n",
      "Epoch 64 Batch 1250 Loss 2.8692 Accuracy 0.9964\n",
      "Epoch 64 Batch 1300 Loss 2.8725 Accuracy 0.9964\n",
      "Epoch 64 Batch 1350 Loss 2.8663 Accuracy 0.9964\n",
      "Epoch 64 Batch 1400 Loss 2.8689 Accuracy 0.9964\n",
      "Epoch 64 Batch 1450 Loss 2.8630 Accuracy 0.9964\n",
      "Epoch 64 Batch 1500 Loss 2.8601 Accuracy 0.9965\n",
      "Epoch 64 Batch 1550 Loss 2.8624 Accuracy 0.9964\n",
      "Epoch 64 Batch 1600 Loss 2.8643 Accuracy 0.9964\n",
      "Epoch 64 Batch 1650 Loss 2.8642 Accuracy 0.9964\n",
      "Epoch 64 Batch 1700 Loss 2.8676 Accuracy 0.9964\n",
      "Epoch 64 Batch 1750 Loss 2.8609 Accuracy 0.9965\n",
      "Epoch 64 Batch 1800 Loss 2.8627 Accuracy 0.9965\n",
      "Epoch 64 Batch 1850 Loss 2.8559 Accuracy 0.9965\n",
      "Epoch 64 Batch 1900 Loss 2.8509 Accuracy 0.9965\n",
      "Epoch 64 Batch 1950 Loss 2.8422 Accuracy 0.9965\n",
      "Epoch 64 Batch 2000 Loss 2.8483 Accuracy 0.9965\n",
      "Epoch 64 Batch 2050 Loss 2.8546 Accuracy 0.9965\n",
      "Epoch 64 Batch 2100 Loss 2.8515 Accuracy 0.9965\n",
      "Epoch 64 Batch 2150 Loss 2.8543 Accuracy 0.9965\n",
      "Epoch 64 Batch 2200 Loss 2.8572 Accuracy 0.9965\n",
      "Epoch 64 Batch 2250 Loss 2.8591 Accuracy 0.9965\n",
      "Epoch 64 Batch 2300 Loss 2.8559 Accuracy 0.9965\n",
      "Epoch 64 Batch 2350 Loss 2.8554 Accuracy 0.9965\n",
      "Epoch 64 Batch 2400 Loss 2.8571 Accuracy 0.9965\n",
      "Epoch 64 Batch 2450 Loss 2.8603 Accuracy 0.9965\n",
      "Epoch 64 Batch 2500 Loss 2.8626 Accuracy 0.9965\n",
      "Epoch 64 Batch 2550 Loss 2.8613 Accuracy 0.9965\n",
      "Epoch 64 Batch 2600 Loss 2.8581 Accuracy 0.9965\n",
      "Epoch 64 Batch 2650 Loss 2.8557 Accuracy 0.9965\n",
      "Epoch 64 Loss 2.8566 Accuracy 0.9965\n",
      "Time taken for 1 epoch: 195.35365462303162 secs\n",
      "\n",
      "Epoch 65 Batch 0 Loss 2.0958 Accuracy 0.9976\n",
      "Epoch 65 Batch 50 Loss 2.9246 Accuracy 0.9963\n",
      "Epoch 65 Batch 100 Loss 2.8964 Accuracy 0.9964\n",
      "Epoch 65 Batch 150 Loss 2.9171 Accuracy 0.9964\n",
      "Epoch 65 Batch 200 Loss 2.8266 Accuracy 0.9965\n",
      "Epoch 65 Batch 250 Loss 2.8238 Accuracy 0.9965\n",
      "Epoch 65 Batch 300 Loss 2.8217 Accuracy 0.9965\n",
      "Epoch 65 Batch 350 Loss 2.8194 Accuracy 0.9965\n",
      "Epoch 65 Batch 400 Loss 2.8137 Accuracy 0.9965\n",
      "Epoch 65 Batch 450 Loss 2.8533 Accuracy 0.9965\n",
      "Epoch 65 Batch 500 Loss 2.8395 Accuracy 0.9965\n",
      "Epoch 65 Batch 550 Loss 2.8605 Accuracy 0.9964\n",
      "Epoch 65 Batch 600 Loss 2.8731 Accuracy 0.9964\n",
      "Epoch 65 Batch 650 Loss 2.8722 Accuracy 0.9964\n",
      "Epoch 65 Batch 700 Loss 2.8686 Accuracy 0.9964\n",
      "Epoch 65 Batch 750 Loss 2.8701 Accuracy 0.9964\n",
      "Epoch 65 Batch 800 Loss 2.8580 Accuracy 0.9965\n",
      "Epoch 65 Batch 850 Loss 2.8656 Accuracy 0.9964\n",
      "Epoch 65 Batch 900 Loss 2.8645 Accuracy 0.9964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Batch 950 Loss 2.8689 Accuracy 0.9964\n",
      "Epoch 65 Batch 1000 Loss 2.8660 Accuracy 0.9964\n",
      "Epoch 65 Batch 1050 Loss 2.8523 Accuracy 0.9965\n",
      "Epoch 65 Batch 1100 Loss 2.8502 Accuracy 0.9965\n",
      "Epoch 65 Batch 1150 Loss 2.8387 Accuracy 0.9965\n",
      "Epoch 65 Batch 1200 Loss 2.8495 Accuracy 0.9965\n",
      "Epoch 65 Batch 1250 Loss 2.8434 Accuracy 0.9965\n",
      "Epoch 65 Batch 1300 Loss 2.8449 Accuracy 0.9965\n",
      "Epoch 65 Batch 1350 Loss 2.8403 Accuracy 0.9965\n",
      "Epoch 65 Batch 1400 Loss 2.8430 Accuracy 0.9965\n",
      "Epoch 65 Batch 1450 Loss 2.8365 Accuracy 0.9965\n",
      "Epoch 65 Batch 1500 Loss 2.8361 Accuracy 0.9965\n",
      "Epoch 65 Batch 1550 Loss 2.8375 Accuracy 0.9965\n",
      "Epoch 65 Batch 1600 Loss 2.8402 Accuracy 0.9965\n",
      "Epoch 65 Batch 1650 Loss 2.8408 Accuracy 0.9965\n",
      "Epoch 65 Batch 1700 Loss 2.8426 Accuracy 0.9965\n",
      "Epoch 65 Batch 1750 Loss 2.8378 Accuracy 0.9965\n",
      "Epoch 65 Batch 1800 Loss 2.8377 Accuracy 0.9965\n",
      "Epoch 65 Batch 1850 Loss 2.8312 Accuracy 0.9965\n",
      "Epoch 65 Batch 1900 Loss 2.8300 Accuracy 0.9965\n",
      "Epoch 65 Batch 1950 Loss 2.8203 Accuracy 0.9965\n",
      "Epoch 65 Batch 2000 Loss 2.8263 Accuracy 0.9965\n",
      "Epoch 65 Batch 2050 Loss 2.8332 Accuracy 0.9965\n",
      "Epoch 65 Batch 2100 Loss 2.8308 Accuracy 0.9965\n",
      "Epoch 65 Batch 2150 Loss 2.8340 Accuracy 0.9965\n",
      "Epoch 65 Batch 2200 Loss 2.8379 Accuracy 0.9965\n",
      "Epoch 65 Batch 2250 Loss 2.8407 Accuracy 0.9965\n",
      "Epoch 65 Batch 2300 Loss 2.8383 Accuracy 0.9965\n",
      "Epoch 65 Batch 2350 Loss 2.8380 Accuracy 0.9965\n",
      "Epoch 65 Batch 2400 Loss 2.8402 Accuracy 0.9965\n",
      "Epoch 65 Batch 2450 Loss 2.8434 Accuracy 0.9965\n",
      "Epoch 65 Batch 2500 Loss 2.8456 Accuracy 0.9965\n",
      "Epoch 65 Batch 2550 Loss 2.8455 Accuracy 0.9965\n",
      "Epoch 65 Batch 2600 Loss 2.8427 Accuracy 0.9965\n",
      "Epoch 65 Batch 2650 Loss 2.8406 Accuracy 0.9965\n",
      "Saving checkpoint for epoch 65 at ./checkpoints/train\\ckpt-14\n",
      "Epoch 65 Loss 2.8418 Accuracy 0.9965\n",
      "Time taken for 1 epoch: 195.83315658569336 secs\n",
      "\n",
      "Epoch 66 Batch 0 Loss 2.2023 Accuracy 0.9975\n",
      "Epoch 66 Batch 50 Loss 2.8421 Accuracy 0.9965\n",
      "Epoch 66 Batch 100 Loss 2.8358 Accuracy 0.9965\n",
      "Epoch 66 Batch 150 Loss 2.8593 Accuracy 0.9964\n",
      "Epoch 66 Batch 200 Loss 2.7931 Accuracy 0.9965\n",
      "Epoch 66 Batch 250 Loss 2.7771 Accuracy 0.9966\n",
      "Epoch 66 Batch 300 Loss 2.7746 Accuracy 0.9966\n",
      "Epoch 66 Batch 350 Loss 2.7867 Accuracy 0.9965\n",
      "Epoch 66 Batch 400 Loss 2.7857 Accuracy 0.9965\n",
      "Epoch 66 Batch 450 Loss 2.8270 Accuracy 0.9965\n",
      "Epoch 66 Batch 500 Loss 2.8147 Accuracy 0.9965\n",
      "Epoch 66 Batch 550 Loss 2.8314 Accuracy 0.9965\n",
      "Epoch 66 Batch 600 Loss 2.8447 Accuracy 0.9965\n",
      "Epoch 66 Batch 650 Loss 2.8460 Accuracy 0.9965\n",
      "Epoch 66 Batch 700 Loss 2.8452 Accuracy 0.9965\n",
      "Epoch 66 Batch 750 Loss 2.8475 Accuracy 0.9965\n",
      "Epoch 66 Batch 800 Loss 2.8331 Accuracy 0.9965\n",
      "Epoch 66 Batch 850 Loss 2.8395 Accuracy 0.9965\n",
      "Epoch 66 Batch 900 Loss 2.8388 Accuracy 0.9965\n",
      "Epoch 66 Batch 950 Loss 2.8454 Accuracy 0.9965\n",
      "Epoch 66 Batch 1000 Loss 2.8412 Accuracy 0.9965\n",
      "Epoch 66 Batch 1050 Loss 2.8308 Accuracy 0.9965\n",
      "Epoch 66 Batch 1100 Loss 2.8312 Accuracy 0.9965\n",
      "Epoch 66 Batch 1150 Loss 2.8230 Accuracy 0.9965\n",
      "Epoch 66 Batch 1200 Loss 2.8351 Accuracy 0.9965\n",
      "Epoch 66 Batch 1250 Loss 2.8286 Accuracy 0.9965\n",
      "Epoch 66 Batch 1300 Loss 2.8311 Accuracy 0.9965\n",
      "Epoch 66 Batch 1350 Loss 2.8250 Accuracy 0.9965\n",
      "Epoch 66 Batch 1400 Loss 2.8298 Accuracy 0.9965\n",
      "Epoch 66 Batch 1450 Loss 2.8230 Accuracy 0.9965\n",
      "Epoch 66 Batch 1500 Loss 2.8203 Accuracy 0.9965\n",
      "Epoch 66 Batch 1550 Loss 2.8228 Accuracy 0.9965\n",
      "Epoch 66 Batch 1600 Loss 2.8247 Accuracy 0.9965\n",
      "Epoch 66 Batch 1650 Loss 2.8252 Accuracy 0.9965\n",
      "Epoch 66 Batch 1700 Loss 2.8275 Accuracy 0.9965\n",
      "Epoch 66 Batch 1750 Loss 2.8218 Accuracy 0.9965\n",
      "Epoch 66 Batch 1800 Loss 2.8241 Accuracy 0.9965\n",
      "Epoch 66 Batch 1850 Loss 2.8165 Accuracy 0.9965\n",
      "Epoch 66 Batch 1900 Loss 2.8126 Accuracy 0.9965\n",
      "Epoch 66 Batch 1950 Loss 2.8052 Accuracy 0.9965\n",
      "Epoch 66 Batch 2000 Loss 2.8114 Accuracy 0.9965\n",
      "Epoch 66 Batch 2050 Loss 2.8183 Accuracy 0.9965\n",
      "Epoch 66 Batch 2100 Loss 2.8174 Accuracy 0.9965\n",
      "Epoch 66 Batch 2150 Loss 2.8191 Accuracy 0.9965\n",
      "Epoch 66 Batch 2200 Loss 2.8227 Accuracy 0.9965\n",
      "Epoch 66 Batch 2250 Loss 2.8248 Accuracy 0.9965\n",
      "Epoch 66 Batch 2300 Loss 2.8220 Accuracy 0.9965\n",
      "Epoch 66 Batch 2350 Loss 2.8217 Accuracy 0.9965\n",
      "Epoch 66 Batch 2400 Loss 2.8241 Accuracy 0.9965\n",
      "Epoch 66 Batch 2450 Loss 2.8272 Accuracy 0.9965\n",
      "Epoch 66 Batch 2500 Loss 2.8293 Accuracy 0.9965\n",
      "Epoch 66 Batch 2550 Loss 2.8294 Accuracy 0.9965\n",
      "Epoch 66 Batch 2600 Loss 2.8263 Accuracy 0.9965\n",
      "Epoch 66 Batch 2650 Loss 2.8237 Accuracy 0.9965\n",
      "Epoch 66 Loss 2.8243 Accuracy 0.9965\n",
      "Time taken for 1 epoch: 196.16336488723755 secs\n",
      "\n",
      "Epoch 67 Batch 0 Loss 1.6800 Accuracy 0.9981\n",
      "Epoch 67 Batch 50 Loss 2.8036 Accuracy 0.9965\n",
      "Epoch 67 Batch 100 Loss 2.8319 Accuracy 0.9965\n",
      "Epoch 67 Batch 150 Loss 2.8645 Accuracy 0.9964\n",
      "Epoch 67 Batch 200 Loss 2.7936 Accuracy 0.9965\n",
      "Epoch 67 Batch 250 Loss 2.7897 Accuracy 0.9965\n",
      "Epoch 67 Batch 300 Loss 2.7945 Accuracy 0.9965\n",
      "Epoch 67 Batch 350 Loss 2.7985 Accuracy 0.9965\n",
      "Epoch 67 Batch 400 Loss 2.8022 Accuracy 0.9965\n",
      "Epoch 67 Batch 450 Loss 2.8339 Accuracy 0.9965\n",
      "Epoch 67 Batch 500 Loss 2.8219 Accuracy 0.9965\n",
      "Epoch 67 Batch 550 Loss 2.8423 Accuracy 0.9965\n",
      "Epoch 67 Batch 600 Loss 2.8571 Accuracy 0.9965\n",
      "Epoch 67 Batch 650 Loss 2.8509 Accuracy 0.9965\n",
      "Epoch 67 Batch 700 Loss 2.8509 Accuracy 0.9965\n",
      "Epoch 67 Batch 750 Loss 2.8503 Accuracy 0.9965\n",
      "Epoch 67 Batch 800 Loss 2.8343 Accuracy 0.9965\n",
      "Epoch 67 Batch 850 Loss 2.8396 Accuracy 0.9965\n",
      "Epoch 67 Batch 900 Loss 2.8382 Accuracy 0.9965\n",
      "Epoch 67 Batch 950 Loss 2.8427 Accuracy 0.9965\n",
      "Epoch 67 Batch 1000 Loss 2.8400 Accuracy 0.9965\n",
      "Epoch 67 Batch 1050 Loss 2.8269 Accuracy 0.9965\n",
      "Epoch 67 Batch 1100 Loss 2.8246 Accuracy 0.9965\n",
      "Epoch 67 Batch 1150 Loss 2.8158 Accuracy 0.9965\n",
      "Epoch 67 Batch 1200 Loss 2.8288 Accuracy 0.9965\n",
      "Epoch 67 Batch 1250 Loss 2.8215 Accuracy 0.9965\n",
      "Epoch 67 Batch 1300 Loss 2.8243 Accuracy 0.9965\n",
      "Epoch 67 Batch 1350 Loss 2.8201 Accuracy 0.9965\n",
      "Epoch 67 Batch 1400 Loss 2.8209 Accuracy 0.9965\n",
      "Epoch 67 Batch 1450 Loss 2.8128 Accuracy 0.9965\n",
      "Epoch 67 Batch 1500 Loss 2.8116 Accuracy 0.9965\n",
      "Epoch 67 Batch 1550 Loss 2.8139 Accuracy 0.9965\n",
      "Epoch 67 Batch 1600 Loss 2.8161 Accuracy 0.9965\n",
      "Epoch 67 Batch 1650 Loss 2.8151 Accuracy 0.9965\n",
      "Epoch 67 Batch 1700 Loss 2.8187 Accuracy 0.9965\n",
      "Epoch 67 Batch 1750 Loss 2.8119 Accuracy 0.9965\n",
      "Epoch 67 Batch 1800 Loss 2.8132 Accuracy 0.9965\n",
      "Epoch 67 Batch 1850 Loss 2.8046 Accuracy 0.9965\n",
      "Epoch 67 Batch 1900 Loss 2.8011 Accuracy 0.9965\n",
      "Epoch 67 Batch 1950 Loss 2.7926 Accuracy 0.9965\n",
      "Epoch 67 Batch 2000 Loss 2.7974 Accuracy 0.9965\n",
      "Epoch 67 Batch 2050 Loss 2.8057 Accuracy 0.9965\n",
      "Epoch 67 Batch 2100 Loss 2.8034 Accuracy 0.9965\n",
      "Epoch 67 Batch 2150 Loss 2.8048 Accuracy 0.9965\n",
      "Epoch 67 Batch 2200 Loss 2.8103 Accuracy 0.9965\n",
      "Epoch 67 Batch 2250 Loss 2.8115 Accuracy 0.9965\n",
      "Epoch 67 Batch 2300 Loss 2.8086 Accuracy 0.9965\n",
      "Epoch 67 Batch 2350 Loss 2.8095 Accuracy 0.9965\n",
      "Epoch 67 Batch 2400 Loss 2.8119 Accuracy 0.9965\n",
      "Epoch 67 Batch 2450 Loss 2.8128 Accuracy 0.9965\n",
      "Epoch 67 Batch 2500 Loss 2.8157 Accuracy 0.9965\n",
      "Epoch 67 Batch 2550 Loss 2.8164 Accuracy 0.9965\n",
      "Epoch 67 Batch 2600 Loss 2.8144 Accuracy 0.9965\n",
      "Epoch 67 Batch 2650 Loss 2.8125 Accuracy 0.9965\n",
      "Epoch 67 Loss 2.8143 Accuracy 0.9965\n",
      "Time taken for 1 epoch: 196.10672283172607 secs\n",
      "\n",
      "Epoch 68 Batch 0 Loss 1.7590 Accuracy 0.9977\n",
      "Epoch 68 Batch 50 Loss 2.8119 Accuracy 0.9965\n",
      "Epoch 68 Batch 100 Loss 2.8019 Accuracy 0.9965\n",
      "Epoch 68 Batch 150 Loss 2.8427 Accuracy 0.9964\n",
      "Epoch 68 Batch 200 Loss 2.7707 Accuracy 0.9965\n",
      "Epoch 68 Batch 250 Loss 2.7671 Accuracy 0.9966\n",
      "Epoch 68 Batch 300 Loss 2.7700 Accuracy 0.9966\n",
      "Epoch 68 Batch 350 Loss 2.7683 Accuracy 0.9966\n",
      "Epoch 68 Batch 400 Loss 2.7656 Accuracy 0.9966\n",
      "Epoch 68 Batch 450 Loss 2.8139 Accuracy 0.9965\n",
      "Epoch 68 Batch 500 Loss 2.7989 Accuracy 0.9965\n",
      "Epoch 68 Batch 550 Loss 2.8129 Accuracy 0.9965\n",
      "Epoch 68 Batch 600 Loss 2.8270 Accuracy 0.9965\n",
      "Epoch 68 Batch 650 Loss 2.8268 Accuracy 0.9965\n",
      "Epoch 68 Batch 700 Loss 2.8228 Accuracy 0.9965\n",
      "Epoch 68 Batch 750 Loss 2.8202 Accuracy 0.9965\n",
      "Epoch 68 Batch 800 Loss 2.8053 Accuracy 0.9965\n",
      "Epoch 68 Batch 850 Loss 2.8129 Accuracy 0.9965\n",
      "Epoch 68 Batch 900 Loss 2.8133 Accuracy 0.9965\n",
      "Epoch 68 Batch 950 Loss 2.8183 Accuracy 0.9965\n",
      "Epoch 68 Batch 1000 Loss 2.8153 Accuracy 0.9965\n",
      "Epoch 68 Batch 1050 Loss 2.8068 Accuracy 0.9965\n",
      "Epoch 68 Batch 1100 Loss 2.8045 Accuracy 0.9965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 1150 Loss 2.7987 Accuracy 0.9965\n",
      "Epoch 68 Batch 1200 Loss 2.8101 Accuracy 0.9965\n",
      "Epoch 68 Batch 1250 Loss 2.8035 Accuracy 0.9965\n",
      "Epoch 68 Batch 1300 Loss 2.8065 Accuracy 0.9965\n",
      "Epoch 68 Batch 1350 Loss 2.8023 Accuracy 0.9965\n",
      "Epoch 68 Batch 1400 Loss 2.8040 Accuracy 0.9965\n",
      "Epoch 68 Batch 1450 Loss 2.7967 Accuracy 0.9965\n",
      "Epoch 68 Batch 1500 Loss 2.7948 Accuracy 0.9965\n",
      "Epoch 68 Batch 1550 Loss 2.7960 Accuracy 0.9965\n",
      "Epoch 68 Batch 1600 Loss 2.7980 Accuracy 0.9965\n",
      "Epoch 68 Batch 1650 Loss 2.7962 Accuracy 0.9965\n",
      "Epoch 68 Batch 1700 Loss 2.7990 Accuracy 0.9965\n",
      "Epoch 68 Batch 1750 Loss 2.7925 Accuracy 0.9965\n",
      "Epoch 68 Batch 1800 Loss 2.7973 Accuracy 0.9965\n",
      "Epoch 68 Batch 1850 Loss 2.7903 Accuracy 0.9965\n",
      "Epoch 68 Batch 1900 Loss 2.7865 Accuracy 0.9965\n",
      "Epoch 68 Batch 1950 Loss 2.7782 Accuracy 0.9966\n",
      "Epoch 68 Batch 2000 Loss 2.7834 Accuracy 0.9965\n",
      "Epoch 68 Batch 2050 Loss 2.7899 Accuracy 0.9965\n",
      "Epoch 68 Batch 2100 Loss 2.7877 Accuracy 0.9965\n",
      "Epoch 68 Batch 2150 Loss 2.7893 Accuracy 0.9965\n",
      "Epoch 68 Batch 2200 Loss 2.7937 Accuracy 0.9965\n",
      "Epoch 68 Batch 2250 Loss 2.7958 Accuracy 0.9965\n",
      "Epoch 68 Batch 2300 Loss 2.7922 Accuracy 0.9965\n",
      "Epoch 68 Batch 2350 Loss 2.7932 Accuracy 0.9965\n",
      "Epoch 68 Batch 2400 Loss 2.7947 Accuracy 0.9965\n",
      "Epoch 68 Batch 2450 Loss 2.7974 Accuracy 0.9965\n",
      "Epoch 68 Batch 2500 Loss 2.8007 Accuracy 0.9965\n",
      "Epoch 68 Batch 2550 Loss 2.7997 Accuracy 0.9965\n",
      "Epoch 68 Batch 2600 Loss 2.7960 Accuracy 0.9965\n",
      "Epoch 68 Batch 2650 Loss 2.7942 Accuracy 0.9965\n",
      "Epoch 68 Loss 2.7952 Accuracy 0.9965\n",
      "Time taken for 1 epoch: 196.3698263168335 secs\n",
      "\n",
      "Epoch 69 Batch 0 Loss 1.9186 Accuracy 0.9978\n",
      "Epoch 69 Batch 50 Loss 2.8689 Accuracy 0.9964\n",
      "Epoch 69 Batch 100 Loss 2.8234 Accuracy 0.9965\n",
      "Epoch 69 Batch 150 Loss 2.8488 Accuracy 0.9965\n",
      "Epoch 69 Batch 200 Loss 2.7754 Accuracy 0.9965\n",
      "Epoch 69 Batch 250 Loss 2.7822 Accuracy 0.9965\n",
      "Epoch 69 Batch 300 Loss 2.7769 Accuracy 0.9965\n",
      "Epoch 69 Batch 350 Loss 2.7683 Accuracy 0.9966\n",
      "Epoch 69 Batch 400 Loss 2.7623 Accuracy 0.9966\n",
      "Epoch 69 Batch 450 Loss 2.7956 Accuracy 0.9965\n",
      "Epoch 69 Batch 500 Loss 2.7825 Accuracy 0.9965\n",
      "Epoch 69 Batch 550 Loss 2.7982 Accuracy 0.9965\n",
      "Epoch 69 Batch 600 Loss 2.8154 Accuracy 0.9965\n",
      "Epoch 69 Batch 650 Loss 2.8126 Accuracy 0.9965\n",
      "Epoch 69 Batch 700 Loss 2.8122 Accuracy 0.9965\n",
      "Epoch 69 Batch 750 Loss 2.8124 Accuracy 0.9965\n",
      "Epoch 69 Batch 800 Loss 2.7966 Accuracy 0.9965\n",
      "Epoch 69 Batch 850 Loss 2.8045 Accuracy 0.9965\n",
      "Epoch 69 Batch 900 Loss 2.8003 Accuracy 0.9965\n",
      "Epoch 69 Batch 950 Loss 2.8043 Accuracy 0.9965\n",
      "Epoch 69 Batch 1000 Loss 2.8014 Accuracy 0.9965\n",
      "Epoch 69 Batch 1050 Loss 2.7922 Accuracy 0.9965\n",
      "Epoch 69 Batch 1100 Loss 2.7916 Accuracy 0.9965\n",
      "Epoch 69 Batch 1150 Loss 2.7818 Accuracy 0.9965\n",
      "Epoch 69 Batch 1200 Loss 2.7942 Accuracy 0.9965\n",
      "Epoch 69 Batch 1250 Loss 2.7885 Accuracy 0.9965\n",
      "Epoch 69 Batch 1300 Loss 2.7901 Accuracy 0.9965\n",
      "Epoch 69 Batch 1350 Loss 2.7853 Accuracy 0.9965\n",
      "Epoch 69 Batch 1400 Loss 2.7899 Accuracy 0.9965\n",
      "Epoch 69 Batch 1450 Loss 2.7839 Accuracy 0.9965\n",
      "Epoch 69 Batch 1500 Loss 2.7809 Accuracy 0.9966\n",
      "Epoch 69 Batch 1550 Loss 2.7836 Accuracy 0.9965\n",
      "Epoch 69 Batch 1600 Loss 2.7844 Accuracy 0.9965\n",
      "Epoch 69 Batch 1650 Loss 2.7842 Accuracy 0.9966\n",
      "Epoch 69 Batch 1700 Loss 2.7869 Accuracy 0.9965\n",
      "Epoch 69 Batch 1750 Loss 2.7792 Accuracy 0.9966\n",
      "Epoch 69 Batch 1800 Loss 2.7800 Accuracy 0.9966\n",
      "Epoch 69 Batch 1850 Loss 2.7730 Accuracy 0.9966\n",
      "Epoch 69 Batch 1900 Loss 2.7703 Accuracy 0.9966\n",
      "Epoch 69 Batch 1950 Loss 2.7629 Accuracy 0.9966\n",
      "Epoch 69 Batch 2000 Loss 2.7673 Accuracy 0.9966\n",
      "Epoch 69 Batch 2050 Loss 2.7747 Accuracy 0.9966\n",
      "Epoch 69 Batch 2100 Loss 2.7725 Accuracy 0.9966\n",
      "Epoch 69 Batch 2150 Loss 2.7740 Accuracy 0.9966\n",
      "Epoch 69 Batch 2200 Loss 2.7796 Accuracy 0.9966\n",
      "Epoch 69 Batch 2250 Loss 2.7828 Accuracy 0.9966\n",
      "Epoch 69 Batch 2300 Loss 2.7797 Accuracy 0.9966\n",
      "Epoch 69 Batch 2350 Loss 2.7814 Accuracy 0.9966\n",
      "Epoch 69 Batch 2400 Loss 2.7843 Accuracy 0.9966\n",
      "Epoch 69 Batch 2450 Loss 2.7864 Accuracy 0.9966\n",
      "Epoch 69 Batch 2500 Loss 2.7884 Accuracy 0.9965\n",
      "Epoch 69 Batch 2550 Loss 2.7883 Accuracy 0.9965\n",
      "Epoch 69 Batch 2600 Loss 2.7870 Accuracy 0.9966\n",
      "Epoch 69 Batch 2650 Loss 2.7851 Accuracy 0.9966\n",
      "Epoch 69 Loss 2.7865 Accuracy 0.9966\n",
      "Time taken for 1 epoch: 197.26331901550293 secs\n",
      "\n",
      "Epoch 70 Batch 0 Loss 1.9800 Accuracy 0.9974\n",
      "Epoch 70 Batch 50 Loss 2.8342 Accuracy 0.9965\n",
      "Epoch 70 Batch 100 Loss 2.8241 Accuracy 0.9965\n",
      "Epoch 70 Batch 150 Loss 2.8533 Accuracy 0.9964\n",
      "Epoch 70 Batch 200 Loss 2.7694 Accuracy 0.9966\n",
      "Epoch 70 Batch 250 Loss 2.7583 Accuracy 0.9966\n",
      "Epoch 70 Batch 300 Loss 2.7559 Accuracy 0.9966\n",
      "Epoch 70 Batch 350 Loss 2.7595 Accuracy 0.9966\n",
      "Epoch 70 Batch 400 Loss 2.7573 Accuracy 0.9966\n",
      "Epoch 70 Batch 450 Loss 2.7973 Accuracy 0.9965\n",
      "Epoch 70 Batch 500 Loss 2.7843 Accuracy 0.9966\n",
      "Epoch 70 Batch 550 Loss 2.7965 Accuracy 0.9965\n",
      "Epoch 70 Batch 600 Loss 2.8129 Accuracy 0.9965\n",
      "Epoch 70 Batch 650 Loss 2.8145 Accuracy 0.9965\n",
      "Epoch 70 Batch 700 Loss 2.8119 Accuracy 0.9965\n",
      "Epoch 70 Batch 750 Loss 2.8123 Accuracy 0.9965\n",
      "Epoch 70 Batch 800 Loss 2.7961 Accuracy 0.9965\n",
      "Epoch 70 Batch 850 Loss 2.7998 Accuracy 0.9965\n",
      "Epoch 70 Batch 900 Loss 2.7994 Accuracy 0.9965\n",
      "Epoch 70 Batch 950 Loss 2.8028 Accuracy 0.9965\n",
      "Epoch 70 Batch 1000 Loss 2.7973 Accuracy 0.9965\n",
      "Epoch 70 Batch 1050 Loss 2.7872 Accuracy 0.9966\n",
      "Epoch 70 Batch 1100 Loss 2.7883 Accuracy 0.9966\n",
      "Epoch 70 Batch 1150 Loss 2.7772 Accuracy 0.9966\n",
      "Epoch 70 Batch 1200 Loss 2.7891 Accuracy 0.9966\n",
      "Epoch 70 Batch 1250 Loss 2.7831 Accuracy 0.9966\n",
      "Epoch 70 Batch 1300 Loss 2.7846 Accuracy 0.9966\n",
      "Epoch 70 Batch 1350 Loss 2.7813 Accuracy 0.9966\n",
      "Epoch 70 Batch 1400 Loss 2.7853 Accuracy 0.9966\n",
      "Epoch 70 Batch 1450 Loss 2.7800 Accuracy 0.9966\n",
      "Epoch 70 Batch 1500 Loss 2.7771 Accuracy 0.9966\n",
      "Epoch 70 Batch 1550 Loss 2.7790 Accuracy 0.9966\n",
      "Epoch 70 Batch 1600 Loss 2.7799 Accuracy 0.9966\n",
      "Epoch 70 Batch 1650 Loss 2.7797 Accuracy 0.9966\n",
      "Epoch 70 Batch 1700 Loss 2.7834 Accuracy 0.9966\n",
      "Epoch 70 Batch 1750 Loss 2.7771 Accuracy 0.9966\n",
      "Epoch 70 Batch 1800 Loss 2.7788 Accuracy 0.9966\n",
      "Epoch 70 Batch 1850 Loss 2.7703 Accuracy 0.9966\n",
      "Epoch 70 Batch 1900 Loss 2.7671 Accuracy 0.9966\n",
      "Epoch 70 Batch 1950 Loss 2.7584 Accuracy 0.9966\n",
      "Epoch 70 Batch 2000 Loss 2.7647 Accuracy 0.9966\n",
      "Epoch 70 Batch 2050 Loss 2.7712 Accuracy 0.9966\n",
      "Epoch 70 Batch 2100 Loss 2.7680 Accuracy 0.9966\n",
      "Epoch 70 Batch 2150 Loss 2.7697 Accuracy 0.9966\n",
      "Epoch 70 Batch 2200 Loss 2.7727 Accuracy 0.9966\n",
      "Epoch 70 Batch 2250 Loss 2.7740 Accuracy 0.9966\n",
      "Epoch 70 Batch 2300 Loss 2.7701 Accuracy 0.9966\n",
      "Epoch 70 Batch 2350 Loss 2.7703 Accuracy 0.9966\n",
      "Epoch 70 Batch 2400 Loss 2.7715 Accuracy 0.9966\n",
      "Epoch 70 Batch 2450 Loss 2.7741 Accuracy 0.9966\n",
      "Epoch 70 Batch 2500 Loss 2.7756 Accuracy 0.9966\n",
      "Epoch 70 Batch 2550 Loss 2.7743 Accuracy 0.9966\n",
      "Epoch 70 Batch 2600 Loss 2.7729 Accuracy 0.9966\n",
      "Epoch 70 Batch 2650 Loss 2.7710 Accuracy 0.9966\n",
      "Saving checkpoint for epoch 70 at ./checkpoints/train\\ckpt-15\n",
      "Epoch 70 Loss 2.7728 Accuracy 0.9966\n",
      "Time taken for 1 epoch: 196.2669608592987 secs\n",
      "\n",
      "Epoch 71 Batch 0 Loss 2.0859 Accuracy 0.9974\n",
      "Epoch 71 Batch 50 Loss 2.7866 Accuracy 0.9966\n",
      "Epoch 71 Batch 100 Loss 2.7835 Accuracy 0.9965\n",
      "Epoch 71 Batch 150 Loss 2.8143 Accuracy 0.9965\n",
      "Epoch 71 Batch 200 Loss 2.7498 Accuracy 0.9966\n",
      "Epoch 71 Batch 250 Loss 2.7436 Accuracy 0.9966\n",
      "Epoch 71 Batch 300 Loss 2.7628 Accuracy 0.9966\n",
      "Epoch 71 Batch 350 Loss 2.7563 Accuracy 0.9966\n",
      "Epoch 71 Batch 400 Loss 2.7522 Accuracy 0.9966\n",
      "Epoch 71 Batch 450 Loss 2.7833 Accuracy 0.9965\n",
      "Epoch 71 Batch 500 Loss 2.7747 Accuracy 0.9966\n",
      "Epoch 71 Batch 550 Loss 2.7923 Accuracy 0.9965\n",
      "Epoch 71 Batch 600 Loss 2.8028 Accuracy 0.9965\n",
      "Epoch 71 Batch 650 Loss 2.7967 Accuracy 0.9965\n",
      "Epoch 71 Batch 700 Loss 2.7926 Accuracy 0.9965\n",
      "Epoch 71 Batch 750 Loss 2.7952 Accuracy 0.9965\n",
      "Epoch 71 Batch 800 Loss 2.7820 Accuracy 0.9965\n",
      "Epoch 71 Batch 850 Loss 2.7853 Accuracy 0.9965\n",
      "Epoch 71 Batch 900 Loss 2.7820 Accuracy 0.9965\n",
      "Epoch 71 Batch 950 Loss 2.7863 Accuracy 0.9965\n",
      "Epoch 71 Batch 1000 Loss 2.7814 Accuracy 0.9966\n",
      "Epoch 71 Batch 1050 Loss 2.7701 Accuracy 0.9966\n",
      "Epoch 71 Batch 1100 Loss 2.7722 Accuracy 0.9966\n",
      "Epoch 71 Batch 1150 Loss 2.7659 Accuracy 0.9966\n",
      "Epoch 71 Batch 1200 Loss 2.7733 Accuracy 0.9966\n",
      "Epoch 71 Batch 1250 Loss 2.7686 Accuracy 0.9966\n",
      "Epoch 71 Batch 1300 Loss 2.7718 Accuracy 0.9966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 1350 Loss 2.7665 Accuracy 0.9966\n",
      "Epoch 71 Batch 1400 Loss 2.7683 Accuracy 0.9966\n",
      "Epoch 71 Batch 1450 Loss 2.7628 Accuracy 0.9966\n",
      "Epoch 71 Batch 1500 Loss 2.7612 Accuracy 0.9966\n",
      "Epoch 71 Batch 1550 Loss 2.7640 Accuracy 0.9966\n",
      "Epoch 71 Batch 1600 Loss 2.7663 Accuracy 0.9966\n",
      "Epoch 71 Batch 1650 Loss 2.7665 Accuracy 0.9966\n",
      "Epoch 71 Batch 1700 Loss 2.7692 Accuracy 0.9966\n",
      "Epoch 71 Batch 1750 Loss 2.7640 Accuracy 0.9966\n",
      "Epoch 71 Batch 1800 Loss 2.7635 Accuracy 0.9966\n",
      "Epoch 71 Batch 1850 Loss 2.7565 Accuracy 0.9966\n",
      "Epoch 71 Batch 1900 Loss 2.7524 Accuracy 0.9966\n",
      "Epoch 71 Batch 1950 Loss 2.7438 Accuracy 0.9966\n",
      "Epoch 71 Batch 2000 Loss 2.7495 Accuracy 0.9966\n",
      "Epoch 71 Batch 2050 Loss 2.7570 Accuracy 0.9966\n",
      "Epoch 71 Batch 2100 Loss 2.7559 Accuracy 0.9966\n",
      "Epoch 71 Batch 2150 Loss 2.7577 Accuracy 0.9966\n",
      "Epoch 71 Batch 2200 Loss 2.7609 Accuracy 0.9966\n",
      "Epoch 71 Batch 2250 Loss 2.7618 Accuracy 0.9966\n",
      "Epoch 71 Batch 2300 Loss 2.7581 Accuracy 0.9966\n",
      "Epoch 71 Batch 2350 Loss 2.7591 Accuracy 0.9966\n",
      "Epoch 71 Batch 2400 Loss 2.7597 Accuracy 0.9966\n",
      "Epoch 71 Batch 2450 Loss 2.7619 Accuracy 0.9966\n",
      "Epoch 71 Batch 2500 Loss 2.7636 Accuracy 0.9966\n",
      "Epoch 71 Batch 2550 Loss 2.7618 Accuracy 0.9966\n",
      "Epoch 71 Batch 2600 Loss 2.7596 Accuracy 0.9966\n",
      "Epoch 71 Batch 2650 Loss 2.7565 Accuracy 0.9966\n",
      "Epoch 71 Loss 2.7577 Accuracy 0.9966\n",
      "Time taken for 1 epoch: 195.6932339668274 secs\n",
      "\n",
      "Epoch 72 Batch 0 Loss 1.5902 Accuracy 0.9981\n",
      "Epoch 72 Batch 50 Loss 2.8078 Accuracy 0.9965\n",
      "Epoch 72 Batch 100 Loss 2.7834 Accuracy 0.9966\n",
      "Epoch 72 Batch 150 Loss 2.7983 Accuracy 0.9965\n",
      "Epoch 72 Batch 200 Loss 2.7259 Accuracy 0.9966\n",
      "Epoch 72 Batch 250 Loss 2.7196 Accuracy 0.9966\n",
      "Epoch 72 Batch 300 Loss 2.7260 Accuracy 0.9966\n",
      "Epoch 72 Batch 350 Loss 2.7334 Accuracy 0.9966\n",
      "Epoch 72 Batch 400 Loss 2.7280 Accuracy 0.9966\n",
      "Epoch 72 Batch 450 Loss 2.7600 Accuracy 0.9966\n",
      "Epoch 72 Batch 500 Loss 2.7531 Accuracy 0.9966\n",
      "Epoch 72 Batch 550 Loss 2.7690 Accuracy 0.9966\n",
      "Epoch 72 Batch 600 Loss 2.7809 Accuracy 0.9966\n",
      "Epoch 72 Batch 650 Loss 2.7769 Accuracy 0.9966\n",
      "Epoch 72 Batch 700 Loss 2.7787 Accuracy 0.9966\n",
      "Epoch 72 Batch 750 Loss 2.7794 Accuracy 0.9966\n",
      "Epoch 72 Batch 800 Loss 2.7685 Accuracy 0.9966\n",
      "Epoch 72 Batch 850 Loss 2.7706 Accuracy 0.9966\n",
      "Epoch 72 Batch 900 Loss 2.7712 Accuracy 0.9966\n",
      "Epoch 72 Batch 950 Loss 2.7734 Accuracy 0.9966\n",
      "Epoch 72 Batch 1000 Loss 2.7714 Accuracy 0.9966\n",
      "Epoch 72 Batch 1050 Loss 2.7618 Accuracy 0.9966\n",
      "Epoch 72 Batch 1100 Loss 2.7601 Accuracy 0.9966\n",
      "Epoch 72 Batch 1150 Loss 2.7530 Accuracy 0.9966\n",
      "Epoch 72 Batch 1200 Loss 2.7638 Accuracy 0.9966\n",
      "Epoch 72 Batch 1250 Loss 2.7594 Accuracy 0.9966\n",
      "Epoch 72 Batch 1300 Loss 2.7592 Accuracy 0.9966\n",
      "Epoch 72 Batch 1350 Loss 2.7567 Accuracy 0.9966\n",
      "Epoch 72 Batch 1400 Loss 2.7589 Accuracy 0.9966\n",
      "Epoch 72 Batch 1450 Loss 2.7516 Accuracy 0.9966\n",
      "Epoch 72 Batch 1500 Loss 2.7502 Accuracy 0.9966\n",
      "Epoch 72 Batch 1550 Loss 2.7529 Accuracy 0.9966\n",
      "Epoch 72 Batch 1600 Loss 2.7536 Accuracy 0.9966\n",
      "Epoch 72 Batch 1650 Loss 2.7548 Accuracy 0.9966\n",
      "Epoch 72 Batch 1700 Loss 2.7571 Accuracy 0.9966\n",
      "Epoch 72 Batch 1750 Loss 2.7511 Accuracy 0.9966\n",
      "Epoch 72 Batch 1800 Loss 2.7531 Accuracy 0.9966\n",
      "Epoch 72 Batch 1850 Loss 2.7455 Accuracy 0.9966\n",
      "Epoch 72 Batch 1900 Loss 2.7415 Accuracy 0.9966\n",
      "Epoch 72 Batch 1950 Loss 2.7340 Accuracy 0.9966\n",
      "Epoch 72 Batch 2000 Loss 2.7392 Accuracy 0.9966\n",
      "Epoch 72 Batch 2050 Loss 2.7470 Accuracy 0.9966\n",
      "Epoch 72 Batch 2100 Loss 2.7452 Accuracy 0.9966\n",
      "Epoch 72 Batch 2150 Loss 2.7474 Accuracy 0.9966\n",
      "Epoch 72 Batch 2200 Loss 2.7506 Accuracy 0.9966\n",
      "Epoch 72 Batch 2250 Loss 2.7519 Accuracy 0.9966\n",
      "Epoch 72 Batch 2300 Loss 2.7487 Accuracy 0.9966\n",
      "Epoch 72 Batch 2350 Loss 2.7491 Accuracy 0.9966\n",
      "Epoch 72 Batch 2400 Loss 2.7512 Accuracy 0.9966\n",
      "Epoch 72 Batch 2450 Loss 2.7525 Accuracy 0.9966\n",
      "Epoch 72 Batch 2500 Loss 2.7555 Accuracy 0.9966\n",
      "Epoch 72 Batch 2550 Loss 2.7544 Accuracy 0.9966\n",
      "Epoch 72 Batch 2600 Loss 2.7508 Accuracy 0.9966\n",
      "Epoch 72 Batch 2650 Loss 2.7491 Accuracy 0.9966\n",
      "Epoch 72 Loss 2.7502 Accuracy 0.9966\n",
      "Time taken for 1 epoch: 195.80975651741028 secs\n",
      "\n",
      "Epoch 73 Batch 0 Loss 1.9528 Accuracy 0.9977\n",
      "Epoch 73 Batch 50 Loss 2.8066 Accuracy 0.9965\n",
      "Epoch 73 Batch 100 Loss 2.7852 Accuracy 0.9965\n",
      "Epoch 73 Batch 150 Loss 2.8314 Accuracy 0.9965\n",
      "Epoch 73 Batch 200 Loss 2.7488 Accuracy 0.9966\n",
      "Epoch 73 Batch 250 Loss 2.7215 Accuracy 0.9966\n",
      "Epoch 73 Batch 300 Loss 2.7236 Accuracy 0.9966\n",
      "Epoch 73 Batch 350 Loss 2.7325 Accuracy 0.9966\n",
      "Epoch 73 Batch 400 Loss 2.7294 Accuracy 0.9966\n",
      "Epoch 73 Batch 450 Loss 2.7635 Accuracy 0.9966\n",
      "Epoch 73 Batch 500 Loss 2.7507 Accuracy 0.9966\n",
      "Epoch 73 Batch 550 Loss 2.7598 Accuracy 0.9966\n",
      "Epoch 73 Batch 600 Loss 2.7765 Accuracy 0.9966\n",
      "Epoch 73 Batch 650 Loss 2.7691 Accuracy 0.9966\n",
      "Epoch 73 Batch 700 Loss 2.7691 Accuracy 0.9966\n",
      "Epoch 73 Batch 750 Loss 2.7707 Accuracy 0.9966\n",
      "Epoch 73 Batch 800 Loss 2.7577 Accuracy 0.9966\n",
      "Epoch 73 Batch 850 Loss 2.7614 Accuracy 0.9966\n",
      "Epoch 73 Batch 900 Loss 2.7594 Accuracy 0.9966\n",
      "Epoch 73 Batch 950 Loss 2.7660 Accuracy 0.9966\n",
      "Epoch 73 Batch 1000 Loss 2.7628 Accuracy 0.9966\n",
      "Epoch 73 Batch 1050 Loss 2.7504 Accuracy 0.9966\n",
      "Epoch 73 Batch 1100 Loss 2.7494 Accuracy 0.9966\n",
      "Epoch 73 Batch 1150 Loss 2.7413 Accuracy 0.9966\n",
      "Epoch 73 Batch 1200 Loss 2.7533 Accuracy 0.9966\n",
      "Epoch 73 Batch 1250 Loss 2.7455 Accuracy 0.9966\n",
      "Epoch 73 Batch 1300 Loss 2.7479 Accuracy 0.9966\n",
      "Epoch 73 Batch 1350 Loss 2.7423 Accuracy 0.9966\n",
      "Epoch 73 Batch 1400 Loss 2.7432 Accuracy 0.9966\n",
      "Epoch 73 Batch 1450 Loss 2.7359 Accuracy 0.9966\n",
      "Epoch 73 Batch 1500 Loss 2.7319 Accuracy 0.9966\n",
      "Epoch 73 Batch 1550 Loss 2.7335 Accuracy 0.9966\n",
      "Epoch 73 Batch 1600 Loss 2.7349 Accuracy 0.9966\n",
      "Epoch 73 Batch 1650 Loss 2.7338 Accuracy 0.9966\n",
      "Epoch 73 Batch 1700 Loss 2.7383 Accuracy 0.9966\n",
      "Epoch 73 Batch 1750 Loss 2.7325 Accuracy 0.9966\n",
      "Epoch 73 Batch 1800 Loss 2.7335 Accuracy 0.9966\n",
      "Epoch 73 Batch 1850 Loss 2.7254 Accuracy 0.9966\n",
      "Epoch 73 Batch 1900 Loss 2.7223 Accuracy 0.9966\n",
      "Epoch 73 Batch 1950 Loss 2.7141 Accuracy 0.9966\n",
      "Epoch 73 Batch 2000 Loss 2.7196 Accuracy 0.9966\n",
      "Epoch 73 Batch 2050 Loss 2.7261 Accuracy 0.9966\n",
      "Epoch 73 Batch 2100 Loss 2.7235 Accuracy 0.9966\n",
      "Epoch 73 Batch 2150 Loss 2.7256 Accuracy 0.9966\n",
      "Epoch 73 Batch 2200 Loss 2.7293 Accuracy 0.9966\n",
      "Epoch 73 Batch 2250 Loss 2.7324 Accuracy 0.9966\n",
      "Epoch 73 Batch 2300 Loss 2.7293 Accuracy 0.9966\n",
      "Epoch 73 Batch 2350 Loss 2.7287 Accuracy 0.9966\n",
      "Epoch 73 Batch 2400 Loss 2.7313 Accuracy 0.9966\n",
      "Epoch 73 Batch 2450 Loss 2.7327 Accuracy 0.9966\n",
      "Epoch 73 Batch 2500 Loss 2.7359 Accuracy 0.9966\n",
      "Epoch 73 Batch 2550 Loss 2.7355 Accuracy 0.9966\n",
      "Epoch 73 Batch 2600 Loss 2.7331 Accuracy 0.9966\n",
      "Epoch 73 Batch 2650 Loss 2.7311 Accuracy 0.9966\n",
      "Epoch 73 Loss 2.7320 Accuracy 0.9966\n",
      "Time taken for 1 epoch: 195.58014011383057 secs\n",
      "\n",
      "Epoch 74 Batch 0 Loss 1.8633 Accuracy 0.9979\n",
      "Epoch 74 Batch 50 Loss 2.7685 Accuracy 0.9966\n",
      "Epoch 74 Batch 100 Loss 2.7372 Accuracy 0.9966\n",
      "Epoch 74 Batch 150 Loss 2.7688 Accuracy 0.9966\n",
      "Epoch 74 Batch 200 Loss 2.7048 Accuracy 0.9967\n",
      "Epoch 74 Batch 250 Loss 2.6973 Accuracy 0.9967\n",
      "Epoch 74 Batch 300 Loss 2.6956 Accuracy 0.9967\n",
      "Epoch 74 Batch 350 Loss 2.6965 Accuracy 0.9967\n",
      "Epoch 74 Batch 400 Loss 2.6951 Accuracy 0.9967\n",
      "Epoch 74 Batch 450 Loss 2.7320 Accuracy 0.9966\n",
      "Epoch 74 Batch 500 Loss 2.7186 Accuracy 0.9966\n",
      "Epoch 74 Batch 550 Loss 2.7317 Accuracy 0.9966\n",
      "Epoch 74 Batch 600 Loss 2.7475 Accuracy 0.9966\n",
      "Epoch 74 Batch 650 Loss 2.7512 Accuracy 0.9966\n",
      "Epoch 74 Batch 700 Loss 2.7509 Accuracy 0.9966\n",
      "Epoch 74 Batch 750 Loss 2.7534 Accuracy 0.9966\n",
      "Epoch 74 Batch 800 Loss 2.7359 Accuracy 0.9966\n",
      "Epoch 74 Batch 850 Loss 2.7402 Accuracy 0.9966\n",
      "Epoch 74 Batch 900 Loss 2.7401 Accuracy 0.9966\n",
      "Epoch 74 Batch 950 Loss 2.7434 Accuracy 0.9966\n",
      "Epoch 74 Batch 1000 Loss 2.7411 Accuracy 0.9966\n",
      "Epoch 74 Batch 1050 Loss 2.7318 Accuracy 0.9966\n",
      "Epoch 74 Batch 1100 Loss 2.7301 Accuracy 0.9966\n",
      "Epoch 74 Batch 1150 Loss 2.7220 Accuracy 0.9966\n",
      "Epoch 74 Batch 1200 Loss 2.7351 Accuracy 0.9966\n",
      "Epoch 74 Batch 1250 Loss 2.7286 Accuracy 0.9966\n",
      "Epoch 74 Batch 1300 Loss 2.7283 Accuracy 0.9966\n",
      "Epoch 74 Batch 1350 Loss 2.7248 Accuracy 0.9966\n",
      "Epoch 74 Batch 1400 Loss 2.7279 Accuracy 0.9966\n",
      "Epoch 74 Batch 1450 Loss 2.7225 Accuracy 0.9966\n",
      "Epoch 74 Batch 1500 Loss 2.7223 Accuracy 0.9966\n",
      "Epoch 74 Batch 1550 Loss 2.7226 Accuracy 0.9966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Batch 1600 Loss 2.7222 Accuracy 0.9966\n",
      "Epoch 74 Batch 1650 Loss 2.7227 Accuracy 0.9966\n",
      "Epoch 74 Batch 1700 Loss 2.7266 Accuracy 0.9966\n",
      "Epoch 74 Batch 1750 Loss 2.7207 Accuracy 0.9966\n",
      "Epoch 74 Batch 1800 Loss 2.7217 Accuracy 0.9966\n",
      "Epoch 74 Batch 1850 Loss 2.7144 Accuracy 0.9966\n",
      "Epoch 74 Batch 1900 Loss 2.7105 Accuracy 0.9967\n",
      "Epoch 74 Batch 1950 Loss 2.7022 Accuracy 0.9967\n",
      "Epoch 74 Batch 2000 Loss 2.7056 Accuracy 0.9967\n",
      "Epoch 74 Batch 2050 Loss 2.7125 Accuracy 0.9967\n",
      "Epoch 74 Batch 2100 Loss 2.7107 Accuracy 0.9967\n",
      "Epoch 74 Batch 2150 Loss 2.7122 Accuracy 0.9967\n",
      "Epoch 74 Batch 2200 Loss 2.7169 Accuracy 0.9966\n",
      "Epoch 74 Batch 2250 Loss 2.7193 Accuracy 0.9966\n",
      "Epoch 74 Batch 2300 Loss 2.7164 Accuracy 0.9966\n",
      "Epoch 74 Batch 2350 Loss 2.7158 Accuracy 0.9966\n",
      "Epoch 74 Batch 2400 Loss 2.7193 Accuracy 0.9966\n",
      "Epoch 74 Batch 2450 Loss 2.7216 Accuracy 0.9966\n",
      "Epoch 74 Batch 2500 Loss 2.7239 Accuracy 0.9966\n",
      "Epoch 74 Batch 2550 Loss 2.7225 Accuracy 0.9966\n",
      "Epoch 74 Batch 2600 Loss 2.7201 Accuracy 0.9966\n",
      "Epoch 74 Batch 2650 Loss 2.7175 Accuracy 0.9966\n",
      "Epoch 74 Loss 2.7190 Accuracy 0.9966\n",
      "Time taken for 1 epoch: 195.61011052131653 secs\n",
      "\n",
      "Epoch 75 Batch 0 Loss 2.0581 Accuracy 0.9974\n",
      "Epoch 75 Batch 50 Loss 2.7200 Accuracy 0.9966\n",
      "Epoch 75 Batch 100 Loss 2.7186 Accuracy 0.9966\n",
      "Epoch 75 Batch 150 Loss 2.7463 Accuracy 0.9966\n",
      "Epoch 75 Batch 200 Loss 2.6817 Accuracy 0.9967\n",
      "Epoch 75 Batch 250 Loss 2.6654 Accuracy 0.9967\n",
      "Epoch 75 Batch 300 Loss 2.6669 Accuracy 0.9967\n",
      "Epoch 75 Batch 350 Loss 2.6745 Accuracy 0.9967\n",
      "Epoch 75 Batch 400 Loss 2.6690 Accuracy 0.9967\n",
      "Epoch 75 Batch 450 Loss 2.7019 Accuracy 0.9966\n",
      "Epoch 75 Batch 500 Loss 2.6920 Accuracy 0.9967\n",
      "Epoch 75 Batch 550 Loss 2.7076 Accuracy 0.9966\n",
      "Epoch 75 Batch 600 Loss 2.7195 Accuracy 0.9966\n",
      "Epoch 75 Batch 650 Loss 2.7207 Accuracy 0.9966\n",
      "Epoch 75 Batch 700 Loss 2.7213 Accuracy 0.9966\n",
      "Epoch 75 Batch 750 Loss 2.7261 Accuracy 0.9966\n",
      "Epoch 75 Batch 800 Loss 2.7162 Accuracy 0.9966\n",
      "Epoch 75 Batch 850 Loss 2.7210 Accuracy 0.9966\n",
      "Epoch 75 Batch 900 Loss 2.7197 Accuracy 0.9966\n",
      "Epoch 75 Batch 950 Loss 2.7234 Accuracy 0.9966\n",
      "Epoch 75 Batch 1000 Loss 2.7229 Accuracy 0.9966\n",
      "Epoch 75 Batch 1050 Loss 2.7147 Accuracy 0.9966\n",
      "Epoch 75 Batch 1100 Loss 2.7123 Accuracy 0.9966\n",
      "Epoch 75 Batch 1150 Loss 2.7022 Accuracy 0.9967\n",
      "Epoch 75 Batch 1200 Loss 2.7143 Accuracy 0.9966\n",
      "Epoch 75 Batch 1250 Loss 2.7091 Accuracy 0.9966\n",
      "Epoch 75 Batch 1300 Loss 2.7129 Accuracy 0.9966\n",
      "Epoch 75 Batch 1350 Loss 2.7091 Accuracy 0.9966\n",
      "Epoch 75 Batch 1400 Loss 2.7100 Accuracy 0.9966\n",
      "Epoch 75 Batch 1450 Loss 2.7032 Accuracy 0.9967\n",
      "Epoch 75 Batch 1500 Loss 2.7012 Accuracy 0.9967\n",
      "Epoch 75 Batch 1550 Loss 2.7028 Accuracy 0.9967\n",
      "Epoch 75 Batch 1600 Loss 2.7036 Accuracy 0.9967\n",
      "Epoch 75 Batch 1650 Loss 2.7025 Accuracy 0.9967\n",
      "Epoch 75 Batch 1700 Loss 2.7053 Accuracy 0.9967\n",
      "Epoch 75 Batch 1750 Loss 2.6980 Accuracy 0.9967\n",
      "Epoch 75 Batch 1800 Loss 2.6991 Accuracy 0.9967\n",
      "Epoch 75 Batch 1850 Loss 2.6910 Accuracy 0.9967\n",
      "Epoch 75 Batch 1900 Loss 2.6867 Accuracy 0.9967\n",
      "Epoch 75 Batch 1950 Loss 2.6787 Accuracy 0.9967\n",
      "Epoch 75 Batch 2000 Loss 2.6827 Accuracy 0.9967\n",
      "Epoch 75 Batch 2050 Loss 2.6915 Accuracy 0.9967\n",
      "Epoch 75 Batch 2100 Loss 2.6907 Accuracy 0.9967\n",
      "Epoch 75 Batch 2150 Loss 2.6912 Accuracy 0.9967\n",
      "Epoch 75 Batch 2200 Loss 2.6955 Accuracy 0.9967\n",
      "Epoch 75 Batch 2250 Loss 2.6977 Accuracy 0.9967\n",
      "Epoch 75 Batch 2300 Loss 2.6951 Accuracy 0.9967\n",
      "Epoch 75 Batch 2350 Loss 2.6950 Accuracy 0.9967\n",
      "Epoch 75 Batch 2400 Loss 2.6962 Accuracy 0.9967\n",
      "Epoch 75 Batch 2450 Loss 2.6985 Accuracy 0.9967\n",
      "Epoch 75 Batch 2500 Loss 2.7015 Accuracy 0.9967\n",
      "Epoch 75 Batch 2550 Loss 2.7009 Accuracy 0.9967\n",
      "Epoch 75 Batch 2600 Loss 2.6981 Accuracy 0.9967\n",
      "Epoch 75 Batch 2650 Loss 2.6962 Accuracy 0.9967\n",
      "Saving checkpoint for epoch 75 at ./checkpoints/train\\ckpt-16\n",
      "Epoch 75 Loss 2.6972 Accuracy 0.9967\n",
      "Time taken for 1 epoch: 195.58638715744019 secs\n",
      "\n",
      "Epoch 76 Batch 0 Loss 1.8931 Accuracy 0.9977\n",
      "Epoch 76 Batch 50 Loss 2.7444 Accuracy 0.9966\n",
      "Epoch 76 Batch 100 Loss 2.7183 Accuracy 0.9966\n",
      "Epoch 76 Batch 150 Loss 2.7464 Accuracy 0.9966\n",
      "Epoch 76 Batch 200 Loss 2.6872 Accuracy 0.9967\n",
      "Epoch 76 Batch 250 Loss 2.6688 Accuracy 0.9967\n",
      "Epoch 76 Batch 300 Loss 2.6785 Accuracy 0.9967\n",
      "Epoch 76 Batch 350 Loss 2.6847 Accuracy 0.9967\n",
      "Epoch 76 Batch 400 Loss 2.6800 Accuracy 0.9967\n",
      "Epoch 76 Batch 450 Loss 2.7161 Accuracy 0.9966\n",
      "Epoch 76 Batch 500 Loss 2.7042 Accuracy 0.9967\n",
      "Epoch 76 Batch 550 Loss 2.7134 Accuracy 0.9966\n",
      "Epoch 76 Batch 600 Loss 2.7257 Accuracy 0.9966\n",
      "Epoch 76 Batch 650 Loss 2.7261 Accuracy 0.9966\n",
      "Epoch 76 Batch 700 Loss 2.7274 Accuracy 0.9966\n",
      "Epoch 76 Batch 750 Loss 2.7235 Accuracy 0.9966\n",
      "Epoch 76 Batch 800 Loss 2.7113 Accuracy 0.9967\n",
      "Epoch 76 Batch 850 Loss 2.7131 Accuracy 0.9966\n",
      "Epoch 76 Batch 900 Loss 2.7131 Accuracy 0.9966\n",
      "Epoch 76 Batch 950 Loss 2.7193 Accuracy 0.9966\n",
      "Epoch 76 Batch 1000 Loss 2.7164 Accuracy 0.9966\n",
      "Epoch 76 Batch 1050 Loss 2.7061 Accuracy 0.9967\n",
      "Epoch 76 Batch 1100 Loss 2.7049 Accuracy 0.9967\n",
      "Epoch 76 Batch 1150 Loss 2.6938 Accuracy 0.9967\n",
      "Epoch 76 Batch 1200 Loss 2.7055 Accuracy 0.9967\n",
      "Epoch 76 Batch 1250 Loss 2.6974 Accuracy 0.9967\n",
      "Epoch 76 Batch 1300 Loss 2.6964 Accuracy 0.9967\n",
      "Epoch 76 Batch 1350 Loss 2.6913 Accuracy 0.9967\n",
      "Epoch 76 Batch 1400 Loss 2.6960 Accuracy 0.9967\n",
      "Epoch 76 Batch 1450 Loss 2.6888 Accuracy 0.9967\n",
      "Epoch 76 Batch 1500 Loss 2.6890 Accuracy 0.9967\n",
      "Epoch 76 Batch 1550 Loss 2.6918 Accuracy 0.9967\n",
      "Epoch 76 Batch 1600 Loss 2.6920 Accuracy 0.9967\n",
      "Epoch 76 Batch 1650 Loss 2.6906 Accuracy 0.9967\n",
      "Epoch 76 Batch 1700 Loss 2.6950 Accuracy 0.9967\n",
      "Epoch 76 Batch 1750 Loss 2.6907 Accuracy 0.9967\n",
      "Epoch 76 Batch 1800 Loss 2.6935 Accuracy 0.9967\n",
      "Epoch 76 Batch 1850 Loss 2.6859 Accuracy 0.9967\n",
      "Epoch 76 Batch 1900 Loss 2.6812 Accuracy 0.9967\n",
      "Epoch 76 Batch 1950 Loss 2.6725 Accuracy 0.9967\n",
      "Epoch 76 Batch 2000 Loss 2.6775 Accuracy 0.9967\n",
      "Epoch 76 Batch 2050 Loss 2.6845 Accuracy 0.9967\n",
      "Epoch 76 Batch 2100 Loss 2.6825 Accuracy 0.9967\n",
      "Epoch 76 Batch 2150 Loss 2.6841 Accuracy 0.9967\n",
      "Epoch 76 Batch 2200 Loss 2.6878 Accuracy 0.9967\n",
      "Epoch 76 Batch 2250 Loss 2.6892 Accuracy 0.9967\n",
      "Epoch 76 Batch 2300 Loss 2.6867 Accuracy 0.9967\n",
      "Epoch 76 Batch 2350 Loss 2.6869 Accuracy 0.9967\n",
      "Epoch 76 Batch 2400 Loss 2.6889 Accuracy 0.9967\n",
      "Epoch 76 Batch 2450 Loss 2.6913 Accuracy 0.9967\n",
      "Epoch 76 Batch 2500 Loss 2.6942 Accuracy 0.9967\n",
      "Epoch 76 Batch 2550 Loss 2.6937 Accuracy 0.9967\n",
      "Epoch 76 Batch 2600 Loss 2.6913 Accuracy 0.9967\n",
      "Epoch 76 Batch 2650 Loss 2.6899 Accuracy 0.9967\n",
      "Epoch 76 Loss 2.6916 Accuracy 0.9967\n",
      "Time taken for 1 epoch: 195.58346724510193 secs\n",
      "\n",
      "Epoch 77 Batch 0 Loss 1.8557 Accuracy 0.9976\n",
      "Epoch 77 Batch 50 Loss 2.7117 Accuracy 0.9966\n",
      "Epoch 77 Batch 100 Loss 2.7020 Accuracy 0.9966\n",
      "Epoch 77 Batch 150 Loss 2.7267 Accuracy 0.9966\n",
      "Epoch 77 Batch 200 Loss 2.6685 Accuracy 0.9967\n",
      "Epoch 77 Batch 250 Loss 2.6615 Accuracy 0.9967\n",
      "Epoch 77 Batch 300 Loss 2.6688 Accuracy 0.9967\n",
      "Epoch 77 Batch 350 Loss 2.6757 Accuracy 0.9967\n",
      "Epoch 77 Batch 400 Loss 2.6813 Accuracy 0.9967\n",
      "Epoch 77 Batch 450 Loss 2.7092 Accuracy 0.9966\n",
      "Epoch 77 Batch 500 Loss 2.6995 Accuracy 0.9967\n",
      "Epoch 77 Batch 550 Loss 2.7127 Accuracy 0.9966\n",
      "Epoch 77 Batch 600 Loss 2.7245 Accuracy 0.9966\n",
      "Epoch 77 Batch 650 Loss 2.7214 Accuracy 0.9966\n",
      "Epoch 77 Batch 700 Loss 2.7165 Accuracy 0.9966\n",
      "Epoch 77 Batch 750 Loss 2.7196 Accuracy 0.9966\n",
      "Epoch 77 Batch 800 Loss 2.7043 Accuracy 0.9967\n",
      "Epoch 77 Batch 850 Loss 2.7072 Accuracy 0.9967\n",
      "Epoch 77 Batch 900 Loss 2.7079 Accuracy 0.9967\n",
      "Epoch 77 Batch 950 Loss 2.7138 Accuracy 0.9966\n",
      "Epoch 77 Batch 1000 Loss 2.7087 Accuracy 0.9967\n",
      "Epoch 77 Batch 1050 Loss 2.6979 Accuracy 0.9967\n",
      "Epoch 77 Batch 1100 Loss 2.6979 Accuracy 0.9967\n",
      "Epoch 77 Batch 1150 Loss 2.6892 Accuracy 0.9967\n",
      "Epoch 77 Batch 1200 Loss 2.7011 Accuracy 0.9967\n",
      "Epoch 77 Batch 1250 Loss 2.6960 Accuracy 0.9967\n",
      "Epoch 77 Batch 1300 Loss 2.6964 Accuracy 0.9967\n",
      "Epoch 77 Batch 1350 Loss 2.6907 Accuracy 0.9967\n",
      "Epoch 77 Batch 1400 Loss 2.6930 Accuracy 0.9967\n",
      "Epoch 77 Batch 1450 Loss 2.6880 Accuracy 0.9967\n",
      "Epoch 77 Batch 1500 Loss 2.6854 Accuracy 0.9967\n",
      "Epoch 77 Batch 1550 Loss 2.6886 Accuracy 0.9967\n",
      "Epoch 77 Batch 1600 Loss 2.6872 Accuracy 0.9967\n",
      "Epoch 77 Batch 1650 Loss 2.6863 Accuracy 0.9967\n",
      "Epoch 77 Batch 1700 Loss 2.6884 Accuracy 0.9967\n",
      "Epoch 77 Batch 1750 Loss 2.6835 Accuracy 0.9967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Batch 1800 Loss 2.6831 Accuracy 0.9967\n",
      "Epoch 77 Batch 1850 Loss 2.6764 Accuracy 0.9967\n",
      "Epoch 77 Batch 1900 Loss 2.6720 Accuracy 0.9967\n",
      "Epoch 77 Batch 1950 Loss 2.6622 Accuracy 0.9967\n",
      "Epoch 77 Batch 2000 Loss 2.6667 Accuracy 0.9967\n",
      "Epoch 77 Batch 2050 Loss 2.6760 Accuracy 0.9967\n",
      "Epoch 77 Batch 2100 Loss 2.6735 Accuracy 0.9967\n",
      "Epoch 77 Batch 2150 Loss 2.6771 Accuracy 0.9967\n",
      "Epoch 77 Batch 2200 Loss 2.6799 Accuracy 0.9967\n",
      "Epoch 77 Batch 2250 Loss 2.6806 Accuracy 0.9967\n",
      "Epoch 77 Batch 2300 Loss 2.6779 Accuracy 0.9967\n",
      "Epoch 77 Batch 2350 Loss 2.6788 Accuracy 0.9967\n",
      "Epoch 77 Batch 2400 Loss 2.6816 Accuracy 0.9967\n",
      "Epoch 77 Batch 2450 Loss 2.6826 Accuracy 0.9967\n",
      "Epoch 77 Batch 2500 Loss 2.6848 Accuracy 0.9967\n",
      "Epoch 77 Batch 2550 Loss 2.6840 Accuracy 0.9967\n",
      "Epoch 77 Batch 2600 Loss 2.6813 Accuracy 0.9967\n",
      "Epoch 77 Batch 2650 Loss 2.6794 Accuracy 0.9967\n",
      "Epoch 77 Loss 2.6810 Accuracy 0.9967\n",
      "Time taken for 1 epoch: 196.58994793891907 secs\n",
      "\n",
      "Epoch 78 Batch 0 Loss 1.6923 Accuracy 0.9979\n",
      "Epoch 78 Batch 50 Loss 2.7212 Accuracy 0.9966\n",
      "Epoch 78 Batch 100 Loss 2.7166 Accuracy 0.9966\n",
      "Epoch 78 Batch 150 Loss 2.7433 Accuracy 0.9966\n",
      "Epoch 78 Batch 200 Loss 2.6739 Accuracy 0.9967\n",
      "Epoch 78 Batch 250 Loss 2.6768 Accuracy 0.9967\n",
      "Epoch 78 Batch 300 Loss 2.6691 Accuracy 0.9967\n",
      "Epoch 78 Batch 350 Loss 2.6722 Accuracy 0.9967\n",
      "Epoch 78 Batch 400 Loss 2.6645 Accuracy 0.9967\n",
      "Epoch 78 Batch 450 Loss 2.6975 Accuracy 0.9967\n",
      "Epoch 78 Batch 500 Loss 2.6887 Accuracy 0.9967\n",
      "Epoch 78 Batch 550 Loss 2.7028 Accuracy 0.9967\n",
      "Epoch 78 Batch 600 Loss 2.7153 Accuracy 0.9966\n",
      "Epoch 78 Batch 650 Loss 2.7151 Accuracy 0.9966\n",
      "Epoch 78 Batch 700 Loss 2.7126 Accuracy 0.9966\n",
      "Epoch 78 Batch 750 Loss 2.7105 Accuracy 0.9966\n",
      "Epoch 78 Batch 800 Loss 2.6963 Accuracy 0.9967\n",
      "Epoch 78 Batch 850 Loss 2.7006 Accuracy 0.9967\n",
      "Epoch 78 Batch 900 Loss 2.6995 Accuracy 0.9967\n",
      "Epoch 78 Batch 950 Loss 2.7043 Accuracy 0.9967\n",
      "Epoch 78 Batch 1000 Loss 2.7003 Accuracy 0.9967\n",
      "Epoch 78 Batch 1050 Loss 2.6904 Accuracy 0.9967\n",
      "Epoch 78 Batch 1100 Loss 2.6878 Accuracy 0.9967\n",
      "Epoch 78 Batch 1150 Loss 2.6809 Accuracy 0.9967\n",
      "Epoch 78 Batch 1200 Loss 2.6927 Accuracy 0.9967\n",
      "Epoch 78 Batch 1250 Loss 2.6856 Accuracy 0.9967\n",
      "Epoch 78 Batch 1300 Loss 2.6892 Accuracy 0.9967\n",
      "Epoch 78 Batch 1350 Loss 2.6827 Accuracy 0.9967\n",
      "Epoch 78 Batch 1400 Loss 2.6860 Accuracy 0.9967\n",
      "Epoch 78 Batch 1450 Loss 2.6797 Accuracy 0.9967\n",
      "Epoch 78 Batch 1500 Loss 2.6765 Accuracy 0.9967\n",
      "Epoch 78 Batch 1550 Loss 2.6767 Accuracy 0.9967\n",
      "Epoch 78 Batch 1600 Loss 2.6777 Accuracy 0.9967\n",
      "Epoch 78 Batch 1650 Loss 2.6788 Accuracy 0.9967\n",
      "Epoch 78 Batch 1700 Loss 2.6822 Accuracy 0.9967\n",
      "Epoch 78 Batch 1750 Loss 2.6774 Accuracy 0.9967\n",
      "Epoch 78 Batch 1800 Loss 2.6801 Accuracy 0.9967\n",
      "Epoch 78 Batch 1850 Loss 2.6718 Accuracy 0.9967\n",
      "Epoch 78 Batch 1900 Loss 2.6679 Accuracy 0.9967\n",
      "Epoch 78 Batch 1950 Loss 2.6595 Accuracy 0.9967\n",
      "Epoch 78 Batch 2000 Loss 2.6634 Accuracy 0.9967\n",
      "Epoch 78 Batch 2050 Loss 2.6701 Accuracy 0.9967\n",
      "Epoch 78 Batch 2100 Loss 2.6687 Accuracy 0.9967\n",
      "Epoch 78 Batch 2150 Loss 2.6701 Accuracy 0.9967\n",
      "Epoch 78 Batch 2200 Loss 2.6736 Accuracy 0.9967\n",
      "Epoch 78 Batch 2250 Loss 2.6762 Accuracy 0.9967\n",
      "Epoch 78 Batch 2300 Loss 2.6730 Accuracy 0.9967\n",
      "Epoch 78 Batch 2350 Loss 2.6721 Accuracy 0.9967\n",
      "Epoch 78 Batch 2400 Loss 2.6757 Accuracy 0.9967\n",
      "Epoch 78 Batch 2450 Loss 2.6772 Accuracy 0.9967\n",
      "Epoch 78 Batch 2500 Loss 2.6805 Accuracy 0.9967\n",
      "Epoch 78 Batch 2550 Loss 2.6801 Accuracy 0.9967\n",
      "Epoch 78 Batch 2600 Loss 2.6770 Accuracy 0.9967\n",
      "Epoch 78 Batch 2650 Loss 2.6745 Accuracy 0.9967\n",
      "Epoch 78 Loss 2.6761 Accuracy 0.9967\n",
      "Time taken for 1 epoch: 196.69345617294312 secs\n",
      "\n",
      "Epoch 79 Batch 0 Loss 1.9364 Accuracy 0.9978\n",
      "Epoch 79 Batch 50 Loss 2.7593 Accuracy 0.9966\n",
      "Epoch 79 Batch 100 Loss 2.7115 Accuracy 0.9966\n",
      "Epoch 79 Batch 150 Loss 2.7363 Accuracy 0.9966\n",
      "Epoch 79 Batch 200 Loss 2.6646 Accuracy 0.9967\n",
      "Epoch 79 Batch 250 Loss 2.6534 Accuracy 0.9967\n",
      "Epoch 79 Batch 300 Loss 2.6551 Accuracy 0.9967\n",
      "Epoch 79 Batch 350 Loss 2.6528 Accuracy 0.9967\n",
      "Epoch 79 Batch 400 Loss 2.6498 Accuracy 0.9967\n",
      "Epoch 79 Batch 450 Loss 2.6812 Accuracy 0.9967\n",
      "Epoch 79 Batch 500 Loss 2.6687 Accuracy 0.9967\n",
      "Epoch 79 Batch 550 Loss 2.6833 Accuracy 0.9967\n",
      "Epoch 79 Batch 600 Loss 2.6999 Accuracy 0.9966\n",
      "Epoch 79 Batch 650 Loss 2.6973 Accuracy 0.9967\n",
      "Epoch 79 Batch 700 Loss 2.6941 Accuracy 0.9967\n",
      "Epoch 79 Batch 750 Loss 2.6947 Accuracy 0.9967\n",
      "Epoch 79 Batch 800 Loss 2.6820 Accuracy 0.9967\n",
      "Epoch 79 Batch 850 Loss 2.6834 Accuracy 0.9967\n",
      "Epoch 79 Batch 900 Loss 2.6842 Accuracy 0.9967\n",
      "Epoch 79 Batch 950 Loss 2.6905 Accuracy 0.9967\n",
      "Epoch 79 Batch 1000 Loss 2.6875 Accuracy 0.9967\n",
      "Epoch 79 Batch 1050 Loss 2.6753 Accuracy 0.9967\n",
      "Epoch 79 Batch 1100 Loss 2.6736 Accuracy 0.9967\n",
      "Epoch 79 Batch 1150 Loss 2.6652 Accuracy 0.9967\n",
      "Epoch 79 Batch 1200 Loss 2.6747 Accuracy 0.9967\n",
      "Epoch 79 Batch 1250 Loss 2.6685 Accuracy 0.9967\n",
      "Epoch 79 Batch 1300 Loss 2.6723 Accuracy 0.9967\n",
      "Epoch 79 Batch 1350 Loss 2.6677 Accuracy 0.9967\n",
      "Epoch 79 Batch 1400 Loss 2.6686 Accuracy 0.9967\n",
      "Epoch 79 Batch 1450 Loss 2.6620 Accuracy 0.9967\n",
      "Epoch 79 Batch 1500 Loss 2.6602 Accuracy 0.9967\n",
      "Epoch 79 Batch 1550 Loss 2.6633 Accuracy 0.9967\n",
      "Epoch 79 Batch 1600 Loss 2.6635 Accuracy 0.9967\n",
      "Epoch 79 Batch 1650 Loss 2.6643 Accuracy 0.9967\n",
      "Epoch 79 Batch 1700 Loss 2.6678 Accuracy 0.9967\n",
      "Epoch 79 Batch 1750 Loss 2.6620 Accuracy 0.9967\n",
      "Epoch 79 Batch 1800 Loss 2.6642 Accuracy 0.9967\n",
      "Epoch 79 Batch 1850 Loss 2.6565 Accuracy 0.9967\n",
      "Epoch 79 Batch 1900 Loss 2.6517 Accuracy 0.9967\n",
      "Epoch 79 Batch 1950 Loss 2.6438 Accuracy 0.9967\n",
      "Epoch 79 Batch 2000 Loss 2.6491 Accuracy 0.9967\n",
      "Epoch 79 Batch 2050 Loss 2.6560 Accuracy 0.9967\n",
      "Epoch 79 Batch 2100 Loss 2.6528 Accuracy 0.9967\n",
      "Epoch 79 Batch 2150 Loss 2.6528 Accuracy 0.9967\n",
      "Epoch 79 Batch 2200 Loss 2.6572 Accuracy 0.9967\n",
      "Epoch 79 Batch 2250 Loss 2.6600 Accuracy 0.9967\n",
      "Epoch 79 Batch 2300 Loss 2.6575 Accuracy 0.9967\n",
      "Epoch 79 Batch 2350 Loss 2.6565 Accuracy 0.9967\n",
      "Epoch 79 Batch 2400 Loss 2.6578 Accuracy 0.9967\n",
      "Epoch 79 Batch 2450 Loss 2.6601 Accuracy 0.9967\n",
      "Epoch 79 Batch 2500 Loss 2.6614 Accuracy 0.9967\n",
      "Epoch 79 Batch 2550 Loss 2.6618 Accuracy 0.9967\n",
      "Epoch 79 Batch 2600 Loss 2.6591 Accuracy 0.9967\n",
      "Epoch 79 Batch 2650 Loss 2.6575 Accuracy 0.9967\n",
      "Epoch 79 Loss 2.6576 Accuracy 0.9967\n",
      "Time taken for 1 epoch: 195.66996932029724 secs\n",
      "\n",
      "Epoch 80 Batch 0 Loss 1.5663 Accuracy 0.9980\n",
      "Epoch 80 Batch 50 Loss 2.7056 Accuracy 0.9966\n",
      "Epoch 80 Batch 100 Loss 2.6991 Accuracy 0.9967\n",
      "Epoch 80 Batch 150 Loss 2.7292 Accuracy 0.9966\n",
      "Epoch 80 Batch 200 Loss 2.6458 Accuracy 0.9967\n",
      "Epoch 80 Batch 250 Loss 2.6352 Accuracy 0.9967\n",
      "Epoch 80 Batch 300 Loss 2.6324 Accuracy 0.9967\n",
      "Epoch 80 Batch 350 Loss 2.6379 Accuracy 0.9968\n",
      "Epoch 80 Batch 400 Loss 2.6367 Accuracy 0.9968\n",
      "Epoch 80 Batch 450 Loss 2.6651 Accuracy 0.9967\n",
      "Epoch 80 Batch 500 Loss 2.6542 Accuracy 0.9967\n",
      "Epoch 80 Batch 550 Loss 2.6691 Accuracy 0.9967\n",
      "Epoch 80 Batch 600 Loss 2.6802 Accuracy 0.9967\n",
      "Epoch 80 Batch 650 Loss 2.6801 Accuracy 0.9967\n",
      "Epoch 80 Batch 700 Loss 2.6800 Accuracy 0.9967\n",
      "Epoch 80 Batch 750 Loss 2.6801 Accuracy 0.9967\n",
      "Epoch 80 Batch 800 Loss 2.6675 Accuracy 0.9967\n",
      "Epoch 80 Batch 850 Loss 2.6699 Accuracy 0.9967\n",
      "Epoch 80 Batch 900 Loss 2.6681 Accuracy 0.9967\n",
      "Epoch 80 Batch 950 Loss 2.6709 Accuracy 0.9967\n",
      "Epoch 80 Batch 1000 Loss 2.6700 Accuracy 0.9967\n",
      "Epoch 80 Batch 1050 Loss 2.6603 Accuracy 0.9967\n",
      "Epoch 80 Batch 1100 Loss 2.6572 Accuracy 0.9967\n",
      "Epoch 80 Batch 1150 Loss 2.6485 Accuracy 0.9967\n",
      "Epoch 80 Batch 1200 Loss 2.6585 Accuracy 0.9967\n",
      "Epoch 80 Batch 1250 Loss 2.6524 Accuracy 0.9967\n",
      "Epoch 80 Batch 1300 Loss 2.6535 Accuracy 0.9967\n",
      "Epoch 80 Batch 1350 Loss 2.6487 Accuracy 0.9967\n",
      "Epoch 80 Batch 1400 Loss 2.6500 Accuracy 0.9967\n",
      "Epoch 80 Batch 1450 Loss 2.6445 Accuracy 0.9967\n",
      "Epoch 80 Batch 1500 Loss 2.6424 Accuracy 0.9967\n",
      "Epoch 80 Batch 1550 Loss 2.6448 Accuracy 0.9967\n",
      "Epoch 80 Batch 1600 Loss 2.6435 Accuracy 0.9967\n",
      "Epoch 80 Batch 1650 Loss 2.6437 Accuracy 0.9967\n",
      "Epoch 80 Batch 1700 Loss 2.6472 Accuracy 0.9967\n",
      "Epoch 80 Batch 1750 Loss 2.6421 Accuracy 0.9967\n",
      "Epoch 80 Batch 1800 Loss 2.6448 Accuracy 0.9967\n",
      "Epoch 80 Batch 1850 Loss 2.6394 Accuracy 0.9967\n",
      "Epoch 80 Batch 1900 Loss 2.6358 Accuracy 0.9968\n",
      "Epoch 80 Batch 1950 Loss 2.6279 Accuracy 0.9968\n",
      "Epoch 80 Batch 2000 Loss 2.6343 Accuracy 0.9968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Batch 2050 Loss 2.6399 Accuracy 0.9967\n",
      "Epoch 80 Batch 2100 Loss 2.6389 Accuracy 0.9967\n",
      "Epoch 80 Batch 2150 Loss 2.6411 Accuracy 0.9967\n",
      "Epoch 80 Batch 2200 Loss 2.6446 Accuracy 0.9967\n",
      "Epoch 80 Batch 2250 Loss 2.6465 Accuracy 0.9967\n",
      "Epoch 80 Batch 2300 Loss 2.6438 Accuracy 0.9967\n",
      "Epoch 80 Batch 2350 Loss 2.6443 Accuracy 0.9967\n",
      "Epoch 80 Batch 2400 Loss 2.6468 Accuracy 0.9967\n",
      "Epoch 80 Batch 2450 Loss 2.6490 Accuracy 0.9967\n",
      "Epoch 80 Batch 2500 Loss 2.6506 Accuracy 0.9967\n",
      "Epoch 80 Batch 2550 Loss 2.6495 Accuracy 0.9967\n",
      "Epoch 80 Batch 2600 Loss 2.6472 Accuracy 0.9967\n",
      "Epoch 80 Batch 2650 Loss 2.6448 Accuracy 0.9967\n",
      "Saving checkpoint for epoch 80 at ./checkpoints/train\\ckpt-17\n",
      "Epoch 80 Loss 2.6469 Accuracy 0.9967\n",
      "Time taken for 1 epoch: 195.35668635368347 secs\n",
      "\n",
      "Epoch 81 Batch 0 Loss 1.9546 Accuracy 0.9976\n",
      "Epoch 81 Batch 50 Loss 2.7237 Accuracy 0.9966\n",
      "Epoch 81 Batch 100 Loss 2.6932 Accuracy 0.9967\n",
      "Epoch 81 Batch 150 Loss 2.7126 Accuracy 0.9967\n",
      "Epoch 81 Batch 200 Loss 2.6446 Accuracy 0.9968\n",
      "Epoch 81 Batch 250 Loss 2.6294 Accuracy 0.9968\n",
      "Epoch 81 Batch 300 Loss 2.6227 Accuracy 0.9968\n",
      "Epoch 81 Batch 350 Loss 2.6222 Accuracy 0.9968\n",
      "Epoch 81 Batch 400 Loss 2.6187 Accuracy 0.9968\n",
      "Epoch 81 Batch 450 Loss 2.6466 Accuracy 0.9967\n",
      "Epoch 81 Batch 500 Loss 2.6383 Accuracy 0.9967\n",
      "Epoch 81 Batch 550 Loss 2.6526 Accuracy 0.9967\n",
      "Epoch 81 Batch 600 Loss 2.6691 Accuracy 0.9967\n",
      "Epoch 81 Batch 650 Loss 2.6685 Accuracy 0.9967\n",
      "Epoch 81 Batch 700 Loss 2.6652 Accuracy 0.9967\n",
      "Epoch 81 Batch 750 Loss 2.6653 Accuracy 0.9967\n",
      "Epoch 81 Batch 800 Loss 2.6527 Accuracy 0.9967\n",
      "Epoch 81 Batch 850 Loss 2.6576 Accuracy 0.9967\n",
      "Epoch 81 Batch 900 Loss 2.6607 Accuracy 0.9967\n",
      "Epoch 81 Batch 950 Loss 2.6663 Accuracy 0.9967\n",
      "Epoch 81 Batch 1000 Loss 2.6635 Accuracy 0.9967\n",
      "Epoch 81 Batch 1050 Loss 2.6540 Accuracy 0.9967\n",
      "Epoch 81 Batch 1100 Loss 2.6503 Accuracy 0.9967\n",
      "Epoch 81 Batch 1150 Loss 2.6436 Accuracy 0.9967\n",
      "Epoch 81 Batch 1200 Loss 2.6545 Accuracy 0.9967\n",
      "Epoch 81 Batch 1250 Loss 2.6503 Accuracy 0.9967\n",
      "Epoch 81 Batch 1300 Loss 2.6517 Accuracy 0.9967\n",
      "Epoch 81 Batch 1350 Loss 2.6467 Accuracy 0.9967\n",
      "Epoch 81 Batch 1400 Loss 2.6467 Accuracy 0.9967\n",
      "Epoch 81 Batch 1450 Loss 2.6416 Accuracy 0.9967\n",
      "Epoch 81 Batch 1500 Loss 2.6398 Accuracy 0.9967\n",
      "Epoch 81 Batch 1550 Loss 2.6409 Accuracy 0.9967\n",
      "Epoch 81 Batch 1600 Loss 2.6440 Accuracy 0.9967\n",
      "Epoch 81 Batch 1650 Loss 2.6450 Accuracy 0.9967\n",
      "Epoch 81 Batch 1700 Loss 2.6482 Accuracy 0.9967\n",
      "Epoch 81 Batch 1750 Loss 2.6435 Accuracy 0.9967\n",
      "Epoch 81 Batch 1800 Loss 2.6451 Accuracy 0.9967\n",
      "Epoch 81 Batch 1850 Loss 2.6382 Accuracy 0.9967\n",
      "Epoch 81 Batch 1900 Loss 2.6348 Accuracy 0.9968\n",
      "Epoch 81 Batch 1950 Loss 2.6268 Accuracy 0.9968\n",
      "Epoch 81 Batch 2000 Loss 2.6305 Accuracy 0.9968\n",
      "Epoch 81 Batch 2050 Loss 2.6366 Accuracy 0.9967\n",
      "Epoch 81 Batch 2100 Loss 2.6345 Accuracy 0.9968\n",
      "Epoch 81 Batch 2150 Loss 2.6355 Accuracy 0.9967\n",
      "Epoch 81 Batch 2200 Loss 2.6394 Accuracy 0.9967\n",
      "Epoch 81 Batch 2250 Loss 2.6422 Accuracy 0.9967\n",
      "Epoch 81 Batch 2300 Loss 2.6394 Accuracy 0.9967\n",
      "Epoch 81 Batch 2350 Loss 2.6386 Accuracy 0.9967\n",
      "Epoch 81 Batch 2400 Loss 2.6394 Accuracy 0.9967\n",
      "Epoch 81 Batch 2450 Loss 2.6422 Accuracy 0.9967\n",
      "Epoch 81 Batch 2500 Loss 2.6447 Accuracy 0.9967\n",
      "Epoch 81 Batch 2550 Loss 2.6430 Accuracy 0.9967\n",
      "Epoch 81 Batch 2600 Loss 2.6410 Accuracy 0.9967\n",
      "Epoch 81 Batch 2650 Loss 2.6381 Accuracy 0.9967\n",
      "Epoch 81 Loss 2.6388 Accuracy 0.9967\n",
      "Time taken for 1 epoch: 196.02639031410217 secs\n",
      "\n",
      "Epoch 82 Batch 0 Loss 1.7398 Accuracy 0.9979\n",
      "Epoch 82 Batch 50 Loss 2.6856 Accuracy 0.9967\n",
      "Epoch 82 Batch 100 Loss 2.6708 Accuracy 0.9967\n",
      "Epoch 82 Batch 150 Loss 2.6922 Accuracy 0.9967\n",
      "Epoch 82 Batch 200 Loss 2.6181 Accuracy 0.9968\n",
      "Epoch 82 Batch 250 Loss 2.6063 Accuracy 0.9968\n",
      "Epoch 82 Batch 300 Loss 2.6107 Accuracy 0.9968\n",
      "Epoch 82 Batch 350 Loss 2.6129 Accuracy 0.9968\n",
      "Epoch 82 Batch 400 Loss 2.6159 Accuracy 0.9968\n",
      "Epoch 82 Batch 450 Loss 2.6518 Accuracy 0.9967\n",
      "Epoch 82 Batch 500 Loss 2.6420 Accuracy 0.9967\n",
      "Epoch 82 Batch 550 Loss 2.6605 Accuracy 0.9967\n",
      "Epoch 82 Batch 600 Loss 2.6704 Accuracy 0.9967\n",
      "Epoch 82 Batch 650 Loss 2.6679 Accuracy 0.9967\n",
      "Epoch 82 Batch 700 Loss 2.6646 Accuracy 0.9967\n",
      "Epoch 82 Batch 750 Loss 2.6646 Accuracy 0.9967\n",
      "Epoch 82 Batch 800 Loss 2.6501 Accuracy 0.9967\n",
      "Epoch 82 Batch 850 Loss 2.6559 Accuracy 0.9967\n",
      "Epoch 82 Batch 900 Loss 2.6540 Accuracy 0.9967\n",
      "Epoch 82 Batch 950 Loss 2.6593 Accuracy 0.9967\n",
      "Epoch 82 Batch 1000 Loss 2.6594 Accuracy 0.9967\n",
      "Epoch 82 Batch 1050 Loss 2.6486 Accuracy 0.9967\n",
      "Epoch 82 Batch 1100 Loss 2.6451 Accuracy 0.9967\n",
      "Epoch 82 Batch 1150 Loss 2.6374 Accuracy 0.9967\n",
      "Epoch 82 Batch 1200 Loss 2.6490 Accuracy 0.9967\n",
      "Epoch 82 Batch 1250 Loss 2.6434 Accuracy 0.9967\n",
      "Epoch 82 Batch 1300 Loss 2.6432 Accuracy 0.9967\n",
      "Epoch 82 Batch 1350 Loss 2.6388 Accuracy 0.9967\n",
      "Epoch 82 Batch 1400 Loss 2.6413 Accuracy 0.9967\n",
      "Epoch 82 Batch 1450 Loss 2.6352 Accuracy 0.9967\n",
      "Epoch 82 Batch 1500 Loss 2.6347 Accuracy 0.9967\n",
      "Epoch 82 Batch 1550 Loss 2.6353 Accuracy 0.9967\n",
      "Epoch 82 Batch 1600 Loss 2.6354 Accuracy 0.9967\n",
      "Epoch 82 Batch 1650 Loss 2.6356 Accuracy 0.9967\n",
      "Epoch 82 Batch 1700 Loss 2.6386 Accuracy 0.9967\n",
      "Epoch 82 Batch 1750 Loss 2.6323 Accuracy 0.9968\n",
      "Epoch 82 Batch 1800 Loss 2.6338 Accuracy 0.9967\n",
      "Epoch 82 Batch 1850 Loss 2.6260 Accuracy 0.9968\n",
      "Epoch 82 Batch 1900 Loss 2.6230 Accuracy 0.9968\n",
      "Epoch 82 Batch 1950 Loss 2.6148 Accuracy 0.9968\n",
      "Epoch 82 Batch 2000 Loss 2.6185 Accuracy 0.9968\n",
      "Epoch 82 Batch 2050 Loss 2.6257 Accuracy 0.9968\n",
      "Epoch 82 Batch 2100 Loss 2.6245 Accuracy 0.9968\n",
      "Epoch 82 Batch 2150 Loss 2.6263 Accuracy 0.9968\n",
      "Epoch 82 Batch 2200 Loss 2.6313 Accuracy 0.9968\n",
      "Epoch 82 Batch 2250 Loss 2.6336 Accuracy 0.9968\n",
      "Epoch 82 Batch 2300 Loss 2.6300 Accuracy 0.9968\n",
      "Epoch 82 Batch 2350 Loss 2.6296 Accuracy 0.9968\n",
      "Epoch 82 Batch 2400 Loss 2.6308 Accuracy 0.9968\n",
      "Epoch 82 Batch 2450 Loss 2.6322 Accuracy 0.9968\n",
      "Epoch 82 Batch 2500 Loss 2.6333 Accuracy 0.9968\n",
      "Epoch 82 Batch 2550 Loss 2.6335 Accuracy 0.9968\n",
      "Epoch 82 Batch 2600 Loss 2.6303 Accuracy 0.9968\n",
      "Epoch 82 Batch 2650 Loss 2.6281 Accuracy 0.9968\n",
      "Epoch 82 Loss 2.6290 Accuracy 0.9968\n",
      "Time taken for 1 epoch: 195.6634464263916 secs\n",
      "\n",
      "Epoch 83 Batch 0 Loss 1.8618 Accuracy 0.9977\n",
      "Epoch 83 Batch 50 Loss 2.6422 Accuracy 0.9967\n",
      "Epoch 83 Batch 100 Loss 2.6260 Accuracy 0.9968\n",
      "Epoch 83 Batch 150 Loss 2.6575 Accuracy 0.9967\n",
      "Epoch 83 Batch 200 Loss 2.5981 Accuracy 0.9968\n",
      "Epoch 83 Batch 250 Loss 2.5898 Accuracy 0.9968\n",
      "Epoch 83 Batch 300 Loss 2.5863 Accuracy 0.9968\n",
      "Epoch 83 Batch 350 Loss 2.5864 Accuracy 0.9968\n",
      "Epoch 83 Batch 400 Loss 2.5885 Accuracy 0.9968\n",
      "Epoch 83 Batch 450 Loss 2.6269 Accuracy 0.9968\n",
      "Epoch 83 Batch 500 Loss 2.6139 Accuracy 0.9968\n",
      "Epoch 83 Batch 550 Loss 2.6280 Accuracy 0.9968\n",
      "Epoch 83 Batch 600 Loss 2.6427 Accuracy 0.9967\n",
      "Epoch 83 Batch 650 Loss 2.6408 Accuracy 0.9967\n",
      "Epoch 83 Batch 700 Loss 2.6365 Accuracy 0.9967\n",
      "Epoch 83 Batch 750 Loss 2.6411 Accuracy 0.9967\n",
      "Epoch 83 Batch 800 Loss 2.6310 Accuracy 0.9968\n",
      "Epoch 83 Batch 850 Loss 2.6321 Accuracy 0.9967\n",
      "Epoch 83 Batch 900 Loss 2.6309 Accuracy 0.9967\n",
      "Epoch 83 Batch 950 Loss 2.6340 Accuracy 0.9967\n",
      "Epoch 83 Batch 1000 Loss 2.6309 Accuracy 0.9968\n",
      "Epoch 83 Batch 1050 Loss 2.6238 Accuracy 0.9968\n",
      "Epoch 83 Batch 1100 Loss 2.6210 Accuracy 0.9968\n",
      "Epoch 83 Batch 1150 Loss 2.6109 Accuracy 0.9968\n",
      "Epoch 83 Batch 1200 Loss 2.6194 Accuracy 0.9968\n",
      "Epoch 83 Batch 1250 Loss 2.6121 Accuracy 0.9968\n",
      "Epoch 83 Batch 1300 Loss 2.6127 Accuracy 0.9968\n",
      "Epoch 83 Batch 1350 Loss 2.6093 Accuracy 0.9968\n",
      "Epoch 83 Batch 1400 Loss 2.6138 Accuracy 0.9968\n",
      "Epoch 83 Batch 1450 Loss 2.6078 Accuracy 0.9968\n",
      "Epoch 83 Batch 1500 Loss 2.6073 Accuracy 0.9968\n",
      "Epoch 83 Batch 1550 Loss 2.6092 Accuracy 0.9968\n",
      "Epoch 83 Batch 1600 Loss 2.6104 Accuracy 0.9968\n",
      "Epoch 83 Batch 1650 Loss 2.6102 Accuracy 0.9968\n",
      "Epoch 83 Batch 1700 Loss 2.6146 Accuracy 0.9968\n",
      "Epoch 83 Batch 1750 Loss 2.6097 Accuracy 0.9968\n",
      "Epoch 83 Batch 1800 Loss 2.6109 Accuracy 0.9968\n",
      "Epoch 83 Batch 1850 Loss 2.6041 Accuracy 0.9968\n",
      "Epoch 83 Batch 1900 Loss 2.5997 Accuracy 0.9968\n",
      "Epoch 83 Batch 1950 Loss 2.5915 Accuracy 0.9968\n",
      "Epoch 83 Batch 2000 Loss 2.5975 Accuracy 0.9968\n",
      "Epoch 83 Batch 2050 Loss 2.6046 Accuracy 0.9968\n",
      "Epoch 83 Batch 2100 Loss 2.6026 Accuracy 0.9968\n",
      "Epoch 83 Batch 2150 Loss 2.6046 Accuracy 0.9968\n",
      "Epoch 83 Batch 2200 Loss 2.6089 Accuracy 0.9968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 2250 Loss 2.6101 Accuracy 0.9968\n",
      "Epoch 83 Batch 2300 Loss 2.6079 Accuracy 0.9968\n",
      "Epoch 83 Batch 2350 Loss 2.6075 Accuracy 0.9968\n",
      "Epoch 83 Batch 2400 Loss 2.6081 Accuracy 0.9968\n",
      "Epoch 83 Batch 2450 Loss 2.6108 Accuracy 0.9968\n",
      "Epoch 83 Batch 2500 Loss 2.6138 Accuracy 0.9968\n",
      "Epoch 83 Batch 2550 Loss 2.6125 Accuracy 0.9968\n",
      "Epoch 83 Batch 2600 Loss 2.6102 Accuracy 0.9968\n",
      "Epoch 83 Batch 2650 Loss 2.6080 Accuracy 0.9968\n",
      "Epoch 83 Loss 2.6094 Accuracy 0.9968\n",
      "Time taken for 1 epoch: 195.66996693611145 secs\n",
      "\n",
      "Epoch 84 Batch 0 Loss 1.6042 Accuracy 0.9979\n",
      "Epoch 84 Batch 50 Loss 2.6405 Accuracy 0.9967\n",
      "Epoch 84 Batch 100 Loss 2.6339 Accuracy 0.9967\n",
      "Epoch 84 Batch 150 Loss 2.6538 Accuracy 0.9967\n",
      "Epoch 84 Batch 200 Loss 2.5869 Accuracy 0.9968\n",
      "Epoch 84 Batch 250 Loss 2.5790 Accuracy 0.9968\n",
      "Epoch 84 Batch 300 Loss 2.5849 Accuracy 0.9968\n",
      "Epoch 84 Batch 350 Loss 2.5865 Accuracy 0.9968\n",
      "Epoch 84 Batch 400 Loss 2.5890 Accuracy 0.9968\n",
      "Epoch 84 Batch 450 Loss 2.6232 Accuracy 0.9968\n",
      "Epoch 84 Batch 500 Loss 2.6088 Accuracy 0.9968\n",
      "Epoch 84 Batch 550 Loss 2.6217 Accuracy 0.9968\n",
      "Epoch 84 Batch 600 Loss 2.6317 Accuracy 0.9967\n",
      "Epoch 84 Batch 650 Loss 2.6296 Accuracy 0.9967\n",
      "Epoch 84 Batch 700 Loss 2.6298 Accuracy 0.9967\n",
      "Epoch 84 Batch 750 Loss 2.6293 Accuracy 0.9967\n",
      "Epoch 84 Batch 800 Loss 2.6144 Accuracy 0.9968\n",
      "Epoch 84 Batch 850 Loss 2.6210 Accuracy 0.9968\n",
      "Epoch 84 Batch 900 Loss 2.6193 Accuracy 0.9968\n",
      "Epoch 84 Batch 950 Loss 2.6240 Accuracy 0.9968\n",
      "Epoch 84 Batch 1000 Loss 2.6193 Accuracy 0.9968\n",
      "Epoch 84 Batch 1050 Loss 2.6084 Accuracy 0.9968\n",
      "Epoch 84 Batch 1100 Loss 2.6071 Accuracy 0.9968\n",
      "Epoch 84 Batch 1150 Loss 2.5975 Accuracy 0.9968\n",
      "Epoch 84 Batch 1200 Loss 2.6093 Accuracy 0.9968\n",
      "Epoch 84 Batch 1250 Loss 2.6042 Accuracy 0.9968\n",
      "Epoch 84 Batch 1300 Loss 2.6067 Accuracy 0.9968\n",
      "Epoch 84 Batch 1350 Loss 2.6009 Accuracy 0.9968\n",
      "Epoch 84 Batch 1400 Loss 2.6016 Accuracy 0.9968\n",
      "Epoch 84 Batch 1450 Loss 2.5962 Accuracy 0.9968\n",
      "Epoch 84 Batch 1500 Loss 2.5933 Accuracy 0.9968\n",
      "Epoch 84 Batch 1550 Loss 2.5955 Accuracy 0.9968\n",
      "Epoch 84 Batch 1600 Loss 2.5973 Accuracy 0.9968\n",
      "Epoch 84 Batch 1650 Loss 2.5970 Accuracy 0.9968\n",
      "Epoch 84 Batch 1700 Loss 2.5999 Accuracy 0.9968\n",
      "Epoch 84 Batch 1750 Loss 2.5960 Accuracy 0.9968\n",
      "Epoch 84 Batch 1800 Loss 2.5977 Accuracy 0.9968\n",
      "Epoch 84 Batch 1850 Loss 2.5907 Accuracy 0.9968\n",
      "Epoch 84 Batch 1900 Loss 2.5876 Accuracy 0.9968\n",
      "Epoch 84 Batch 1950 Loss 2.5824 Accuracy 0.9968\n",
      "Epoch 84 Batch 2000 Loss 2.5876 Accuracy 0.9968\n",
      "Epoch 84 Batch 2050 Loss 2.5955 Accuracy 0.9968\n",
      "Epoch 84 Batch 2100 Loss 2.5918 Accuracy 0.9968\n",
      "Epoch 84 Batch 2150 Loss 2.5948 Accuracy 0.9968\n",
      "Epoch 84 Batch 2200 Loss 2.5984 Accuracy 0.9968\n",
      "Epoch 84 Batch 2250 Loss 2.5994 Accuracy 0.9968\n",
      "Epoch 84 Batch 2300 Loss 2.5968 Accuracy 0.9968\n",
      "Epoch 84 Batch 2350 Loss 2.5961 Accuracy 0.9968\n",
      "Epoch 84 Batch 2400 Loss 2.5981 Accuracy 0.9968\n",
      "Epoch 84 Batch 2450 Loss 2.6007 Accuracy 0.9968\n",
      "Epoch 84 Batch 2500 Loss 2.6031 Accuracy 0.9968\n",
      "Epoch 84 Batch 2550 Loss 2.6024 Accuracy 0.9968\n",
      "Epoch 84 Batch 2600 Loss 2.5999 Accuracy 0.9968\n",
      "Epoch 84 Batch 2650 Loss 2.5976 Accuracy 0.9968\n",
      "Epoch 84 Loss 2.5994 Accuracy 0.9968\n",
      "Time taken for 1 epoch: 195.7534475326538 secs\n",
      "\n",
      "Epoch 85 Batch 0 Loss 1.8375 Accuracy 0.9979\n",
      "Epoch 85 Batch 50 Loss 2.6339 Accuracy 0.9967\n",
      "Epoch 85 Batch 100 Loss 2.6142 Accuracy 0.9968\n",
      "Epoch 85 Batch 150 Loss 2.6479 Accuracy 0.9967\n",
      "Epoch 85 Batch 200 Loss 2.5874 Accuracy 0.9968\n",
      "Epoch 85 Batch 250 Loss 2.5812 Accuracy 0.9968\n",
      "Epoch 85 Batch 300 Loss 2.5877 Accuracy 0.9968\n",
      "Epoch 85 Batch 350 Loss 2.5894 Accuracy 0.9968\n",
      "Epoch 85 Batch 400 Loss 2.5843 Accuracy 0.9968\n",
      "Epoch 85 Batch 450 Loss 2.6178 Accuracy 0.9968\n",
      "Epoch 85 Batch 500 Loss 2.6078 Accuracy 0.9968\n",
      "Epoch 85 Batch 550 Loss 2.6208 Accuracy 0.9968\n",
      "Epoch 85 Batch 600 Loss 2.6346 Accuracy 0.9967\n",
      "Epoch 85 Batch 650 Loss 2.6306 Accuracy 0.9968\n",
      "Epoch 85 Batch 700 Loss 2.6250 Accuracy 0.9968\n",
      "Epoch 85 Batch 750 Loss 2.6294 Accuracy 0.9968\n",
      "Epoch 85 Batch 800 Loss 2.6158 Accuracy 0.9968\n",
      "Epoch 85 Batch 850 Loss 2.6190 Accuracy 0.9968\n",
      "Epoch 85 Batch 900 Loss 2.6195 Accuracy 0.9968\n",
      "Epoch 85 Batch 950 Loss 2.6231 Accuracy 0.9968\n",
      "Epoch 85 Batch 1000 Loss 2.6211 Accuracy 0.9968\n",
      "Epoch 85 Batch 1050 Loss 2.6084 Accuracy 0.9968\n",
      "Epoch 85 Batch 1100 Loss 2.6086 Accuracy 0.9968\n",
      "Epoch 85 Batch 1150 Loss 2.5975 Accuracy 0.9968\n",
      "Epoch 85 Batch 1200 Loss 2.6095 Accuracy 0.9968\n",
      "Epoch 85 Batch 1250 Loss 2.6040 Accuracy 0.9968\n",
      "Epoch 85 Batch 1300 Loss 2.6037 Accuracy 0.9968\n",
      "Epoch 85 Batch 1350 Loss 2.5995 Accuracy 0.9968\n",
      "Epoch 85 Batch 1400 Loss 2.6013 Accuracy 0.9968\n",
      "Epoch 85 Batch 1450 Loss 2.5945 Accuracy 0.9968\n",
      "Epoch 85 Batch 1500 Loss 2.5922 Accuracy 0.9968\n",
      "Epoch 85 Batch 1550 Loss 2.5951 Accuracy 0.9968\n",
      "Epoch 85 Batch 1600 Loss 2.5952 Accuracy 0.9968\n",
      "Epoch 85 Batch 1650 Loss 2.5948 Accuracy 0.9968\n",
      "Epoch 85 Batch 1700 Loss 2.5970 Accuracy 0.9968\n",
      "Epoch 85 Batch 1750 Loss 2.5902 Accuracy 0.9968\n",
      "Epoch 85 Batch 1800 Loss 2.5916 Accuracy 0.9968\n",
      "Epoch 85 Batch 1850 Loss 2.5856 Accuracy 0.9968\n",
      "Epoch 85 Batch 1900 Loss 2.5831 Accuracy 0.9968\n",
      "Epoch 85 Batch 1950 Loss 2.5764 Accuracy 0.9968\n",
      "Epoch 85 Batch 2000 Loss 2.5814 Accuracy 0.9968\n",
      "Epoch 85 Batch 2050 Loss 2.5879 Accuracy 0.9968\n",
      "Epoch 85 Batch 2100 Loss 2.5867 Accuracy 0.9968\n",
      "Epoch 85 Batch 2150 Loss 2.5894 Accuracy 0.9968\n",
      "Epoch 85 Batch 2200 Loss 2.5945 Accuracy 0.9968\n",
      "Epoch 85 Batch 2250 Loss 2.5958 Accuracy 0.9968\n",
      "Epoch 85 Batch 2300 Loss 2.5930 Accuracy 0.9968\n",
      "Epoch 85 Batch 2350 Loss 2.5930 Accuracy 0.9968\n",
      "Epoch 85 Batch 2400 Loss 2.5941 Accuracy 0.9968\n",
      "Epoch 85 Batch 2450 Loss 2.5950 Accuracy 0.9968\n",
      "Epoch 85 Batch 2500 Loss 2.5968 Accuracy 0.9968\n",
      "Epoch 85 Batch 2550 Loss 2.5953 Accuracy 0.9968\n",
      "Epoch 85 Batch 2600 Loss 2.5929 Accuracy 0.9968\n",
      "Epoch 85 Batch 2650 Loss 2.5905 Accuracy 0.9968\n",
      "Saving checkpoint for epoch 85 at ./checkpoints/train\\ckpt-18\n",
      "Epoch 85 Loss 2.5918 Accuracy 0.9968\n",
      "Time taken for 1 epoch: 196.1732153892517 secs\n",
      "\n",
      "Epoch 86 Batch 0 Loss 1.9316 Accuracy 0.9978\n",
      "Epoch 86 Batch 50 Loss 2.6460 Accuracy 0.9967\n",
      "Epoch 86 Batch 100 Loss 2.6285 Accuracy 0.9967\n",
      "Epoch 86 Batch 150 Loss 2.6357 Accuracy 0.9967\n",
      "Epoch 86 Batch 200 Loss 2.5655 Accuracy 0.9968\n",
      "Epoch 86 Batch 250 Loss 2.5601 Accuracy 0.9968\n",
      "Epoch 86 Batch 300 Loss 2.5663 Accuracy 0.9968\n",
      "Epoch 86 Batch 350 Loss 2.5676 Accuracy 0.9968\n",
      "Epoch 86 Batch 400 Loss 2.5639 Accuracy 0.9968\n",
      "Epoch 86 Batch 450 Loss 2.5970 Accuracy 0.9968\n",
      "Epoch 86 Batch 500 Loss 2.5832 Accuracy 0.9968\n",
      "Epoch 86 Batch 550 Loss 2.5975 Accuracy 0.9968\n",
      "Epoch 86 Batch 600 Loss 2.6148 Accuracy 0.9968\n",
      "Epoch 86 Batch 650 Loss 2.6171 Accuracy 0.9968\n",
      "Epoch 86 Batch 700 Loss 2.6138 Accuracy 0.9968\n",
      "Epoch 86 Batch 750 Loss 2.6152 Accuracy 0.9968\n",
      "Epoch 86 Batch 800 Loss 2.6001 Accuracy 0.9968\n",
      "Epoch 86 Batch 850 Loss 2.6043 Accuracy 0.9968\n",
      "Epoch 86 Batch 900 Loss 2.6038 Accuracy 0.9968\n",
      "Epoch 86 Batch 950 Loss 2.6067 Accuracy 0.9968\n",
      "Epoch 86 Batch 1000 Loss 2.6023 Accuracy 0.9968\n",
      "Epoch 86 Batch 1050 Loss 2.5924 Accuracy 0.9968\n",
      "Epoch 86 Batch 1100 Loss 2.5916 Accuracy 0.9968\n",
      "Epoch 86 Batch 1150 Loss 2.5840 Accuracy 0.9968\n",
      "Epoch 86 Batch 1200 Loss 2.5972 Accuracy 0.9968\n",
      "Epoch 86 Batch 1250 Loss 2.5928 Accuracy 0.9968\n",
      "Epoch 86 Batch 1300 Loss 2.5942 Accuracy 0.9968\n",
      "Epoch 86 Batch 1350 Loss 2.5929 Accuracy 0.9968\n",
      "Epoch 86 Batch 1400 Loss 2.5974 Accuracy 0.9968\n",
      "Epoch 86 Batch 1450 Loss 2.5921 Accuracy 0.9968\n",
      "Epoch 86 Batch 1500 Loss 2.5906 Accuracy 0.9968\n",
      "Epoch 86 Batch 1550 Loss 2.5928 Accuracy 0.9968\n",
      "Epoch 86 Batch 1600 Loss 2.5933 Accuracy 0.9968\n",
      "Epoch 86 Batch 1650 Loss 2.5943 Accuracy 0.9968\n",
      "Epoch 86 Batch 1700 Loss 2.5981 Accuracy 0.9968\n",
      "Epoch 86 Batch 1750 Loss 2.5921 Accuracy 0.9968\n",
      "Epoch 86 Batch 1800 Loss 2.5939 Accuracy 0.9968\n",
      "Epoch 86 Batch 1850 Loss 2.5878 Accuracy 0.9968\n",
      "Epoch 86 Batch 1900 Loss 2.5854 Accuracy 0.9968\n",
      "Epoch 86 Batch 1950 Loss 2.5763 Accuracy 0.9968\n",
      "Epoch 86 Batch 2000 Loss 2.5811 Accuracy 0.9968\n",
      "Epoch 86 Batch 2050 Loss 2.5870 Accuracy 0.9968\n",
      "Epoch 86 Batch 2100 Loss 2.5849 Accuracy 0.9968\n",
      "Epoch 86 Batch 2150 Loss 2.5858 Accuracy 0.9968\n",
      "Epoch 86 Batch 2200 Loss 2.5902 Accuracy 0.9968\n",
      "Epoch 86 Batch 2250 Loss 2.5918 Accuracy 0.9968\n",
      "Epoch 86 Batch 2300 Loss 2.5876 Accuracy 0.9968\n",
      "Epoch 86 Batch 2350 Loss 2.5878 Accuracy 0.9968\n",
      "Epoch 86 Batch 2400 Loss 2.5893 Accuracy 0.9968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 2450 Loss 2.5909 Accuracy 0.9968\n",
      "Epoch 86 Batch 2500 Loss 2.5929 Accuracy 0.9968\n",
      "Epoch 86 Batch 2550 Loss 2.5926 Accuracy 0.9968\n",
      "Epoch 86 Batch 2600 Loss 2.5894 Accuracy 0.9968\n",
      "Epoch 86 Batch 2650 Loss 2.5862 Accuracy 0.9968\n",
      "Epoch 86 Loss 2.5867 Accuracy 0.9968\n",
      "Time taken for 1 epoch: 196.56694865226746 secs\n",
      "\n",
      "Epoch 87 Batch 0 Loss 1.9595 Accuracy 0.9978\n",
      "Epoch 87 Batch 50 Loss 2.6268 Accuracy 0.9968\n",
      "Epoch 87 Batch 100 Loss 2.6194 Accuracy 0.9968\n",
      "Epoch 87 Batch 150 Loss 2.6690 Accuracy 0.9967\n",
      "Epoch 87 Batch 200 Loss 2.5796 Accuracy 0.9968\n",
      "Epoch 87 Batch 250 Loss 2.5642 Accuracy 0.9968\n",
      "Epoch 87 Batch 300 Loss 2.5633 Accuracy 0.9968\n",
      "Epoch 87 Batch 350 Loss 2.5609 Accuracy 0.9968\n",
      "Epoch 87 Batch 400 Loss 2.5621 Accuracy 0.9968\n",
      "Epoch 87 Batch 450 Loss 2.6014 Accuracy 0.9968\n",
      "Epoch 87 Batch 500 Loss 2.5852 Accuracy 0.9968\n",
      "Epoch 87 Batch 550 Loss 2.5953 Accuracy 0.9968\n",
      "Epoch 87 Batch 600 Loss 2.6150 Accuracy 0.9968\n",
      "Epoch 87 Batch 650 Loss 2.6055 Accuracy 0.9968\n",
      "Epoch 87 Batch 700 Loss 2.5973 Accuracy 0.9968\n",
      "Epoch 87 Batch 750 Loss 2.5957 Accuracy 0.9968\n",
      "Epoch 87 Batch 800 Loss 2.5810 Accuracy 0.9968\n",
      "Epoch 87 Batch 850 Loss 2.5845 Accuracy 0.9968\n",
      "Epoch 87 Batch 900 Loss 2.5841 Accuracy 0.9968\n",
      "Epoch 87 Batch 950 Loss 2.5878 Accuracy 0.9968\n",
      "Epoch 87 Batch 1000 Loss 2.5849 Accuracy 0.9968\n",
      "Epoch 87 Batch 1050 Loss 2.5767 Accuracy 0.9968\n",
      "Epoch 87 Batch 1100 Loss 2.5739 Accuracy 0.9968\n",
      "Epoch 87 Batch 1150 Loss 2.5659 Accuracy 0.9968\n",
      "Epoch 87 Batch 1200 Loss 2.5746 Accuracy 0.9968\n",
      "Epoch 87 Batch 1250 Loss 2.5690 Accuracy 0.9968\n",
      "Epoch 87 Batch 1300 Loss 2.5735 Accuracy 0.9968\n",
      "Epoch 87 Batch 1350 Loss 2.5692 Accuracy 0.9968\n",
      "Epoch 87 Batch 1400 Loss 2.5723 Accuracy 0.9968\n",
      "Epoch 87 Batch 1450 Loss 2.5676 Accuracy 0.9968\n",
      "Epoch 87 Batch 1500 Loss 2.5663 Accuracy 0.9968\n",
      "Epoch 87 Batch 1550 Loss 2.5681 Accuracy 0.9968\n",
      "Epoch 87 Batch 1600 Loss 2.5698 Accuracy 0.9968\n",
      "Epoch 87 Batch 1650 Loss 2.5707 Accuracy 0.9968\n",
      "Epoch 87 Batch 1700 Loss 2.5743 Accuracy 0.9968\n",
      "Epoch 87 Batch 1750 Loss 2.5691 Accuracy 0.9968\n",
      "Epoch 87 Batch 1800 Loss 2.5698 Accuracy 0.9968\n",
      "Epoch 87 Batch 1850 Loss 2.5641 Accuracy 0.9968\n",
      "Epoch 87 Batch 1900 Loss 2.5618 Accuracy 0.9968\n",
      "Epoch 87 Batch 1950 Loss 2.5545 Accuracy 0.9969\n",
      "Epoch 87 Batch 2000 Loss 2.5604 Accuracy 0.9968\n",
      "Epoch 87 Batch 2050 Loss 2.5671 Accuracy 0.9968\n",
      "Epoch 87 Batch 2100 Loss 2.5651 Accuracy 0.9968\n",
      "Epoch 87 Batch 2150 Loss 2.5671 Accuracy 0.9968\n",
      "Epoch 87 Batch 2200 Loss 2.5728 Accuracy 0.9968\n",
      "Epoch 87 Batch 2250 Loss 2.5755 Accuracy 0.9968\n",
      "Epoch 87 Batch 2300 Loss 2.5727 Accuracy 0.9968\n",
      "Epoch 87 Batch 2350 Loss 2.5729 Accuracy 0.9968\n",
      "Epoch 87 Batch 2400 Loss 2.5753 Accuracy 0.9968\n",
      "Epoch 87 Batch 2450 Loss 2.5768 Accuracy 0.9968\n",
      "Epoch 87 Batch 2500 Loss 2.5781 Accuracy 0.9968\n",
      "Epoch 87 Batch 2550 Loss 2.5771 Accuracy 0.9968\n",
      "Epoch 87 Batch 2600 Loss 2.5752 Accuracy 0.9968\n",
      "Epoch 87 Batch 2650 Loss 2.5731 Accuracy 0.9968\n",
      "Epoch 87 Loss 2.5738 Accuracy 0.9968\n",
      "Time taken for 1 epoch: 196.50987935066223 secs\n",
      "\n",
      "Epoch 88 Batch 0 Loss 1.7227 Accuracy 0.9979\n",
      "Epoch 88 Batch 50 Loss 2.5617 Accuracy 0.9968\n",
      "Epoch 88 Batch 100 Loss 2.5764 Accuracy 0.9968\n",
      "Epoch 88 Batch 150 Loss 2.6089 Accuracy 0.9968\n",
      "Epoch 88 Batch 200 Loss 2.5556 Accuracy 0.9969\n",
      "Epoch 88 Batch 250 Loss 2.5405 Accuracy 0.9969\n",
      "Epoch 88 Batch 300 Loss 2.5402 Accuracy 0.9969\n",
      "Epoch 88 Batch 350 Loss 2.5506 Accuracy 0.9969\n",
      "Epoch 88 Batch 400 Loss 2.5525 Accuracy 0.9969\n",
      "Epoch 88 Batch 450 Loss 2.5824 Accuracy 0.9968\n",
      "Epoch 88 Batch 500 Loss 2.5744 Accuracy 0.9968\n",
      "Epoch 88 Batch 550 Loss 2.5867 Accuracy 0.9968\n",
      "Epoch 88 Batch 600 Loss 2.6060 Accuracy 0.9968\n",
      "Epoch 88 Batch 650 Loss 2.5982 Accuracy 0.9968\n",
      "Epoch 88 Batch 700 Loss 2.5935 Accuracy 0.9968\n",
      "Epoch 88 Batch 750 Loss 2.5930 Accuracy 0.9968\n",
      "Epoch 88 Batch 800 Loss 2.5780 Accuracy 0.9968\n",
      "Epoch 88 Batch 850 Loss 2.5821 Accuracy 0.9968\n",
      "Epoch 88 Batch 900 Loss 2.5839 Accuracy 0.9968\n",
      "Epoch 88 Batch 950 Loss 2.5899 Accuracy 0.9968\n",
      "Epoch 88 Batch 1000 Loss 2.5868 Accuracy 0.9968\n",
      "Epoch 88 Batch 1050 Loss 2.5754 Accuracy 0.9968\n",
      "Epoch 88 Batch 1100 Loss 2.5722 Accuracy 0.9968\n",
      "Epoch 88 Batch 1150 Loss 2.5630 Accuracy 0.9968\n",
      "Epoch 88 Batch 1200 Loss 2.5730 Accuracy 0.9968\n",
      "Epoch 88 Batch 1250 Loss 2.5671 Accuracy 0.9968\n",
      "Epoch 88 Batch 1300 Loss 2.5690 Accuracy 0.9968\n",
      "Epoch 88 Batch 1350 Loss 2.5655 Accuracy 0.9968\n",
      "Epoch 88 Batch 1400 Loss 2.5675 Accuracy 0.9968\n",
      "Epoch 88 Batch 1450 Loss 2.5600 Accuracy 0.9968\n",
      "Epoch 88 Batch 1500 Loss 2.5583 Accuracy 0.9968\n",
      "Epoch 88 Batch 1550 Loss 2.5608 Accuracy 0.9968\n",
      "Epoch 88 Batch 1600 Loss 2.5607 Accuracy 0.9968\n",
      "Epoch 88 Batch 1650 Loss 2.5595 Accuracy 0.9968\n",
      "Epoch 88 Batch 1700 Loss 2.5629 Accuracy 0.9968\n",
      "Epoch 88 Batch 1750 Loss 2.5575 Accuracy 0.9969\n",
      "Epoch 88 Batch 1800 Loss 2.5603 Accuracy 0.9969\n",
      "Epoch 88 Batch 1850 Loss 2.5543 Accuracy 0.9969\n",
      "Epoch 88 Batch 1900 Loss 2.5505 Accuracy 0.9969\n",
      "Epoch 88 Batch 1950 Loss 2.5438 Accuracy 0.9969\n",
      "Epoch 88 Batch 2000 Loss 2.5491 Accuracy 0.9969\n",
      "Epoch 88 Batch 2050 Loss 2.5551 Accuracy 0.9969\n",
      "Epoch 88 Batch 2100 Loss 2.5544 Accuracy 0.9969\n",
      "Epoch 88 Batch 2150 Loss 2.5576 Accuracy 0.9969\n",
      "Epoch 88 Batch 2200 Loss 2.5618 Accuracy 0.9968\n",
      "Epoch 88 Batch 2250 Loss 2.5644 Accuracy 0.9968\n",
      "Epoch 88 Batch 2300 Loss 2.5613 Accuracy 0.9968\n",
      "Epoch 88 Batch 2350 Loss 2.5613 Accuracy 0.9968\n",
      "Epoch 88 Batch 2400 Loss 2.5628 Accuracy 0.9968\n",
      "Epoch 88 Batch 2450 Loss 2.5632 Accuracy 0.9968\n",
      "Epoch 88 Batch 2500 Loss 2.5650 Accuracy 0.9968\n",
      "Epoch 88 Batch 2550 Loss 2.5643 Accuracy 0.9968\n",
      "Epoch 88 Batch 2600 Loss 2.5611 Accuracy 0.9968\n",
      "Epoch 88 Batch 2650 Loss 2.5594 Accuracy 0.9969\n",
      "Epoch 88 Loss 2.5601 Accuracy 0.9969\n",
      "Time taken for 1 epoch: 195.72981905937195 secs\n",
      "\n",
      "Epoch 89 Batch 0 Loss 1.5785 Accuracy 0.9979\n",
      "Epoch 89 Batch 50 Loss 2.5733 Accuracy 0.9968\n",
      "Epoch 89 Batch 100 Loss 2.5681 Accuracy 0.9968\n",
      "Epoch 89 Batch 150 Loss 2.5856 Accuracy 0.9968\n",
      "Epoch 89 Batch 200 Loss 2.5234 Accuracy 0.9969\n",
      "Epoch 89 Batch 250 Loss 2.5216 Accuracy 0.9969\n",
      "Epoch 89 Batch 300 Loss 2.5157 Accuracy 0.9969\n",
      "Epoch 89 Batch 350 Loss 2.5137 Accuracy 0.9969\n",
      "Epoch 89 Batch 400 Loss 2.5067 Accuracy 0.9969\n",
      "Epoch 89 Batch 450 Loss 2.5391 Accuracy 0.9969\n",
      "Epoch 89 Batch 500 Loss 2.5369 Accuracy 0.9969\n",
      "Epoch 89 Batch 550 Loss 2.5542 Accuracy 0.9968\n",
      "Epoch 89 Batch 600 Loss 2.5682 Accuracy 0.9968\n",
      "Epoch 89 Batch 650 Loss 2.5673 Accuracy 0.9968\n",
      "Epoch 89 Batch 700 Loss 2.5685 Accuracy 0.9968\n",
      "Epoch 89 Batch 750 Loss 2.5693 Accuracy 0.9968\n",
      "Epoch 89 Batch 800 Loss 2.5573 Accuracy 0.9968\n",
      "Epoch 89 Batch 850 Loss 2.5631 Accuracy 0.9968\n",
      "Epoch 89 Batch 900 Loss 2.5634 Accuracy 0.9968\n",
      "Epoch 89 Batch 950 Loss 2.5702 Accuracy 0.9968\n",
      "Epoch 89 Batch 1000 Loss 2.5669 Accuracy 0.9968\n",
      "Epoch 89 Batch 1050 Loss 2.5550 Accuracy 0.9969\n",
      "Epoch 89 Batch 1100 Loss 2.5552 Accuracy 0.9969\n",
      "Epoch 89 Batch 1150 Loss 2.5477 Accuracy 0.9969\n",
      "Epoch 89 Batch 1200 Loss 2.5586 Accuracy 0.9968\n",
      "Epoch 89 Batch 1250 Loss 2.5518 Accuracy 0.9969\n",
      "Epoch 89 Batch 1300 Loss 2.5534 Accuracy 0.9969\n",
      "Epoch 89 Batch 1350 Loss 2.5493 Accuracy 0.9969\n",
      "Epoch 89 Batch 1400 Loss 2.5531 Accuracy 0.9969\n",
      "Epoch 89 Batch 1450 Loss 2.5472 Accuracy 0.9969\n",
      "Epoch 89 Batch 1500 Loss 2.5450 Accuracy 0.9969\n",
      "Epoch 89 Batch 1550 Loss 2.5471 Accuracy 0.9969\n",
      "Epoch 89 Batch 1600 Loss 2.5481 Accuracy 0.9969\n",
      "Epoch 89 Batch 1650 Loss 2.5483 Accuracy 0.9969\n",
      "Epoch 89 Batch 1700 Loss 2.5508 Accuracy 0.9969\n",
      "Epoch 89 Batch 1750 Loss 2.5450 Accuracy 0.9969\n",
      "Epoch 89 Batch 1800 Loss 2.5467 Accuracy 0.9969\n",
      "Epoch 89 Batch 1850 Loss 2.5406 Accuracy 0.9969\n",
      "Epoch 89 Batch 1900 Loss 2.5383 Accuracy 0.9969\n",
      "Epoch 89 Batch 1950 Loss 2.5299 Accuracy 0.9969\n",
      "Epoch 89 Batch 2000 Loss 2.5362 Accuracy 0.9969\n",
      "Epoch 89 Batch 2050 Loss 2.5420 Accuracy 0.9969\n",
      "Epoch 89 Batch 2100 Loss 2.5401 Accuracy 0.9969\n",
      "Epoch 89 Batch 2150 Loss 2.5424 Accuracy 0.9969\n",
      "Epoch 89 Batch 2200 Loss 2.5464 Accuracy 0.9969\n",
      "Epoch 89 Batch 2250 Loss 2.5482 Accuracy 0.9969\n",
      "Epoch 89 Batch 2300 Loss 2.5456 Accuracy 0.9969\n",
      "Epoch 89 Batch 2350 Loss 2.5466 Accuracy 0.9969\n",
      "Epoch 89 Batch 2400 Loss 2.5485 Accuracy 0.9969\n",
      "Epoch 89 Batch 2450 Loss 2.5488 Accuracy 0.9969\n",
      "Epoch 89 Batch 2500 Loss 2.5504 Accuracy 0.9969\n",
      "Epoch 89 Batch 2550 Loss 2.5491 Accuracy 0.9969\n",
      "Epoch 89 Batch 2600 Loss 2.5460 Accuracy 0.9969\n",
      "Epoch 89 Batch 2650 Loss 2.5448 Accuracy 0.9969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Loss 2.5457 Accuracy 0.9969\n",
      "Time taken for 1 epoch: 195.12707114219666 secs\n",
      "\n",
      "Epoch 90 Batch 0 Loss 1.7546 Accuracy 0.9977\n",
      "Epoch 90 Batch 50 Loss 2.5983 Accuracy 0.9968\n",
      "Epoch 90 Batch 100 Loss 2.5974 Accuracy 0.9968\n",
      "Epoch 90 Batch 150 Loss 2.6205 Accuracy 0.9968\n",
      "Epoch 90 Batch 200 Loss 2.5534 Accuracy 0.9969\n",
      "Epoch 90 Batch 250 Loss 2.5457 Accuracy 0.9969\n",
      "Epoch 90 Batch 300 Loss 2.5396 Accuracy 0.9969\n",
      "Epoch 90 Batch 350 Loss 2.5437 Accuracy 0.9969\n",
      "Epoch 90 Batch 400 Loss 2.5349 Accuracy 0.9969\n",
      "Epoch 90 Batch 450 Loss 2.5677 Accuracy 0.9968\n",
      "Epoch 90 Batch 500 Loss 2.5587 Accuracy 0.9968\n",
      "Epoch 90 Batch 550 Loss 2.5708 Accuracy 0.9968\n",
      "Epoch 90 Batch 600 Loss 2.5862 Accuracy 0.9968\n",
      "Epoch 90 Batch 650 Loss 2.5819 Accuracy 0.9968\n",
      "Epoch 90 Batch 700 Loss 2.5798 Accuracy 0.9968\n",
      "Epoch 90 Batch 750 Loss 2.5812 Accuracy 0.9968\n",
      "Epoch 90 Batch 800 Loss 2.5679 Accuracy 0.9968\n",
      "Epoch 90 Batch 850 Loss 2.5718 Accuracy 0.9968\n",
      "Epoch 90 Batch 900 Loss 2.5687 Accuracy 0.9968\n",
      "Epoch 90 Batch 950 Loss 2.5734 Accuracy 0.9968\n",
      "Epoch 90 Batch 1000 Loss 2.5715 Accuracy 0.9968\n",
      "Epoch 90 Batch 1050 Loss 2.5640 Accuracy 0.9968\n",
      "Epoch 90 Batch 1100 Loss 2.5613 Accuracy 0.9968\n",
      "Epoch 90 Batch 1150 Loss 2.5505 Accuracy 0.9969\n",
      "Epoch 90 Batch 1200 Loss 2.5637 Accuracy 0.9968\n",
      "Epoch 90 Batch 1250 Loss 2.5569 Accuracy 0.9968\n",
      "Epoch 90 Batch 1300 Loss 2.5596 Accuracy 0.9968\n",
      "Epoch 90 Batch 1350 Loss 2.5541 Accuracy 0.9969\n",
      "Epoch 90 Batch 1400 Loss 2.5549 Accuracy 0.9969\n",
      "Epoch 90 Batch 1450 Loss 2.5482 Accuracy 0.9969\n",
      "Epoch 90 Batch 1500 Loss 2.5472 Accuracy 0.9969\n",
      "Epoch 90 Batch 1550 Loss 2.5507 Accuracy 0.9969\n",
      "Epoch 90 Batch 1600 Loss 2.5507 Accuracy 0.9969\n",
      "Epoch 90 Batch 1650 Loss 2.5524 Accuracy 0.9969\n",
      "Epoch 90 Batch 1700 Loss 2.5561 Accuracy 0.9969\n",
      "Epoch 90 Batch 1750 Loss 2.5506 Accuracy 0.9969\n",
      "Epoch 90 Batch 1800 Loss 2.5518 Accuracy 0.9969\n",
      "Epoch 90 Batch 1850 Loss 2.5456 Accuracy 0.9969\n",
      "Epoch 90 Batch 1900 Loss 2.5424 Accuracy 0.9969\n",
      "Epoch 90 Batch 1950 Loss 2.5345 Accuracy 0.9969\n",
      "Epoch 90 Batch 2000 Loss 2.5386 Accuracy 0.9969\n",
      "Epoch 90 Batch 2050 Loss 2.5449 Accuracy 0.9969\n",
      "Epoch 90 Batch 2100 Loss 2.5435 Accuracy 0.9969\n",
      "Epoch 90 Batch 2150 Loss 2.5442 Accuracy 0.9969\n",
      "Epoch 90 Batch 2200 Loss 2.5481 Accuracy 0.9969\n",
      "Epoch 90 Batch 2250 Loss 2.5501 Accuracy 0.9969\n",
      "Epoch 90 Batch 2300 Loss 2.5458 Accuracy 0.9969\n",
      "Epoch 90 Batch 2350 Loss 2.5450 Accuracy 0.9969\n",
      "Epoch 90 Batch 2400 Loss 2.5463 Accuracy 0.9969\n",
      "Epoch 90 Batch 2450 Loss 2.5487 Accuracy 0.9969\n",
      "Epoch 90 Batch 2500 Loss 2.5520 Accuracy 0.9969\n",
      "Epoch 90 Batch 2550 Loss 2.5508 Accuracy 0.9969\n",
      "Epoch 90 Batch 2600 Loss 2.5478 Accuracy 0.9969\n",
      "Epoch 90 Batch 2650 Loss 2.5459 Accuracy 0.9969\n",
      "Saving checkpoint for epoch 90 at ./checkpoints/train\\ckpt-19\n",
      "Epoch 90 Loss 2.5474 Accuracy 0.9969\n",
      "Time taken for 1 epoch: 195.58663296699524 secs\n",
      "\n",
      "Epoch 91 Batch 0 Loss 1.6893 Accuracy 0.9980\n",
      "Epoch 91 Batch 50 Loss 2.5996 Accuracy 0.9968\n",
      "Epoch 91 Batch 100 Loss 2.5864 Accuracy 0.9968\n",
      "Epoch 91 Batch 150 Loss 2.6216 Accuracy 0.9968\n",
      "Epoch 91 Batch 200 Loss 2.5566 Accuracy 0.9969\n",
      "Epoch 91 Batch 250 Loss 2.5469 Accuracy 0.9969\n",
      "Epoch 91 Batch 300 Loss 2.5531 Accuracy 0.9969\n",
      "Epoch 91 Batch 350 Loss 2.5490 Accuracy 0.9969\n",
      "Epoch 91 Batch 400 Loss 2.5404 Accuracy 0.9969\n",
      "Epoch 91 Batch 450 Loss 2.5675 Accuracy 0.9968\n",
      "Epoch 91 Batch 500 Loss 2.5523 Accuracy 0.9969\n",
      "Epoch 91 Batch 550 Loss 2.5685 Accuracy 0.9968\n",
      "Epoch 91 Batch 600 Loss 2.5762 Accuracy 0.9968\n",
      "Epoch 91 Batch 650 Loss 2.5721 Accuracy 0.9968\n",
      "Epoch 91 Batch 700 Loss 2.5677 Accuracy 0.9968\n",
      "Epoch 91 Batch 750 Loss 2.5708 Accuracy 0.9968\n",
      "Epoch 91 Batch 800 Loss 2.5603 Accuracy 0.9968\n",
      "Epoch 91 Batch 850 Loss 2.5631 Accuracy 0.9968\n",
      "Epoch 91 Batch 900 Loss 2.5643 Accuracy 0.9968\n",
      "Epoch 91 Batch 950 Loss 2.5695 Accuracy 0.9968\n",
      "Epoch 91 Batch 1000 Loss 2.5664 Accuracy 0.9968\n",
      "Epoch 91 Batch 1050 Loss 2.5545 Accuracy 0.9969\n",
      "Epoch 91 Batch 1100 Loss 2.5532 Accuracy 0.9969\n",
      "Epoch 91 Batch 1150 Loss 2.5462 Accuracy 0.9969\n",
      "Epoch 91 Batch 1200 Loss 2.5577 Accuracy 0.9969\n",
      "Epoch 91 Batch 1250 Loss 2.5524 Accuracy 0.9969\n",
      "Epoch 91 Batch 1300 Loss 2.5528 Accuracy 0.9969\n",
      "Epoch 91 Batch 1350 Loss 2.5495 Accuracy 0.9969\n",
      "Epoch 91 Batch 1400 Loss 2.5533 Accuracy 0.9969\n",
      "Epoch 91 Batch 1450 Loss 2.5467 Accuracy 0.9969\n",
      "Epoch 91 Batch 1500 Loss 2.5446 Accuracy 0.9969\n",
      "Epoch 91 Batch 1550 Loss 2.5445 Accuracy 0.9969\n",
      "Epoch 91 Batch 1600 Loss 2.5443 Accuracy 0.9969\n",
      "Epoch 91 Batch 1650 Loss 2.5439 Accuracy 0.9969\n",
      "Epoch 91 Batch 1700 Loss 2.5484 Accuracy 0.9969\n",
      "Epoch 91 Batch 1750 Loss 2.5417 Accuracy 0.9969\n",
      "Epoch 91 Batch 1800 Loss 2.5419 Accuracy 0.9969\n",
      "Epoch 91 Batch 1850 Loss 2.5343 Accuracy 0.9969\n",
      "Epoch 91 Batch 1900 Loss 2.5306 Accuracy 0.9969\n",
      "Epoch 91 Batch 1950 Loss 2.5227 Accuracy 0.9969\n",
      "Epoch 91 Batch 2000 Loss 2.5265 Accuracy 0.9969\n",
      "Epoch 91 Batch 2050 Loss 2.5336 Accuracy 0.9969\n",
      "Epoch 91 Batch 2100 Loss 2.5318 Accuracy 0.9969\n",
      "Epoch 91 Batch 2150 Loss 2.5340 Accuracy 0.9969\n",
      "Epoch 91 Batch 2200 Loss 2.5370 Accuracy 0.9969\n",
      "Epoch 91 Batch 2250 Loss 2.5391 Accuracy 0.9969\n",
      "Epoch 91 Batch 2300 Loss 2.5370 Accuracy 0.9969\n",
      "Epoch 91 Batch 2350 Loss 2.5362 Accuracy 0.9969\n",
      "Epoch 91 Batch 2400 Loss 2.5373 Accuracy 0.9969\n",
      "Epoch 91 Batch 2450 Loss 2.5376 Accuracy 0.9969\n",
      "Epoch 91 Batch 2500 Loss 2.5394 Accuracy 0.9969\n",
      "Epoch 91 Batch 2550 Loss 2.5389 Accuracy 0.9969\n",
      "Epoch 91 Batch 2600 Loss 2.5373 Accuracy 0.9969\n",
      "Epoch 91 Batch 2650 Loss 2.5354 Accuracy 0.9969\n",
      "Epoch 91 Loss 2.5363 Accuracy 0.9969\n",
      "Time taken for 1 epoch: 195.3432993888855 secs\n",
      "\n",
      "Epoch 92 Batch 0 Loss 1.7975 Accuracy 0.9979\n",
      "Epoch 92 Batch 50 Loss 2.5732 Accuracy 0.9968\n",
      "Epoch 92 Batch 100 Loss 2.5652 Accuracy 0.9968\n",
      "Epoch 92 Batch 150 Loss 2.5720 Accuracy 0.9968\n",
      "Epoch 92 Batch 200 Loss 2.5129 Accuracy 0.9969\n",
      "Epoch 92 Batch 250 Loss 2.5094 Accuracy 0.9969\n",
      "Epoch 92 Batch 300 Loss 2.5087 Accuracy 0.9969\n",
      "Epoch 92 Batch 350 Loss 2.5127 Accuracy 0.9969\n",
      "Epoch 92 Batch 400 Loss 2.5067 Accuracy 0.9969\n",
      "Epoch 92 Batch 450 Loss 2.5329 Accuracy 0.9969\n",
      "Epoch 92 Batch 500 Loss 2.5215 Accuracy 0.9969\n",
      "Epoch 92 Batch 550 Loss 2.5378 Accuracy 0.9969\n",
      "Epoch 92 Batch 600 Loss 2.5513 Accuracy 0.9969\n",
      "Epoch 92 Batch 650 Loss 2.5477 Accuracy 0.9969\n",
      "Epoch 92 Batch 700 Loss 2.5442 Accuracy 0.9969\n",
      "Epoch 92 Batch 750 Loss 2.5476 Accuracy 0.9969\n",
      "Epoch 92 Batch 800 Loss 2.5354 Accuracy 0.9969\n",
      "Epoch 92 Batch 850 Loss 2.5411 Accuracy 0.9969\n",
      "Epoch 92 Batch 900 Loss 2.5446 Accuracy 0.9969\n",
      "Epoch 92 Batch 950 Loss 2.5476 Accuracy 0.9969\n",
      "Epoch 92 Batch 1000 Loss 2.5432 Accuracy 0.9969\n",
      "Epoch 92 Batch 1050 Loss 2.5340 Accuracy 0.9969\n",
      "Epoch 92 Batch 1100 Loss 2.5338 Accuracy 0.9969\n",
      "Epoch 92 Batch 1150 Loss 2.5244 Accuracy 0.9969\n",
      "Epoch 92 Batch 1200 Loss 2.5362 Accuracy 0.9969\n",
      "Epoch 92 Batch 1250 Loss 2.5310 Accuracy 0.9969\n",
      "Epoch 92 Batch 1300 Loss 2.5299 Accuracy 0.9969\n",
      "Epoch 92 Batch 1350 Loss 2.5272 Accuracy 0.9969\n",
      "Epoch 92 Batch 1400 Loss 2.5297 Accuracy 0.9969\n",
      "Epoch 92 Batch 1450 Loss 2.5246 Accuracy 0.9969\n",
      "Epoch 92 Batch 1500 Loss 2.5232 Accuracy 0.9969\n",
      "Epoch 92 Batch 1550 Loss 2.5248 Accuracy 0.9969\n",
      "Epoch 92 Batch 1600 Loss 2.5255 Accuracy 0.9969\n",
      "Epoch 92 Batch 1650 Loss 2.5260 Accuracy 0.9969\n",
      "Epoch 92 Batch 1700 Loss 2.5276 Accuracy 0.9969\n",
      "Epoch 92 Batch 1750 Loss 2.5223 Accuracy 0.9969\n",
      "Epoch 92 Batch 1800 Loss 2.5237 Accuracy 0.9969\n",
      "Epoch 92 Batch 1850 Loss 2.5167 Accuracy 0.9969\n",
      "Epoch 92 Batch 1900 Loss 2.5120 Accuracy 0.9969\n",
      "Epoch 92 Batch 1950 Loss 2.5046 Accuracy 0.9969\n",
      "Epoch 92 Batch 2000 Loss 2.5103 Accuracy 0.9969\n",
      "Epoch 92 Batch 2050 Loss 2.5161 Accuracy 0.9969\n",
      "Epoch 92 Batch 2100 Loss 2.5147 Accuracy 0.9969\n",
      "Epoch 92 Batch 2150 Loss 2.5170 Accuracy 0.9969\n",
      "Epoch 92 Batch 2200 Loss 2.5206 Accuracy 0.9969\n",
      "Epoch 92 Batch 2250 Loss 2.5233 Accuracy 0.9969\n",
      "Epoch 92 Batch 2300 Loss 2.5217 Accuracy 0.9969\n",
      "Epoch 92 Batch 2350 Loss 2.5217 Accuracy 0.9969\n",
      "Epoch 92 Batch 2400 Loss 2.5245 Accuracy 0.9969\n",
      "Epoch 92 Batch 2450 Loss 2.5251 Accuracy 0.9969\n",
      "Epoch 92 Batch 2500 Loss 2.5267 Accuracy 0.9969\n",
      "Epoch 92 Batch 2550 Loss 2.5260 Accuracy 0.9969\n",
      "Epoch 92 Batch 2600 Loss 2.5235 Accuracy 0.9969\n",
      "Epoch 92 Batch 2650 Loss 2.5228 Accuracy 0.9969\n",
      "Epoch 92 Loss 2.5239 Accuracy 0.9969\n",
      "Time taken for 1 epoch: 195.52650785446167 secs\n",
      "\n",
      "Epoch 93 Batch 0 Loss 1.6107 Accuracy 0.9981\n",
      "Epoch 93 Batch 50 Loss 2.5410 Accuracy 0.9969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Batch 100 Loss 2.5495 Accuracy 0.9968\n",
      "Epoch 93 Batch 150 Loss 2.5746 Accuracy 0.9968\n",
      "Epoch 93 Batch 200 Loss 2.5001 Accuracy 0.9969\n",
      "Epoch 93 Batch 250 Loss 2.4978 Accuracy 0.9969\n",
      "Epoch 93 Batch 300 Loss 2.4908 Accuracy 0.9969\n",
      "Epoch 93 Batch 350 Loss 2.4929 Accuracy 0.9969\n",
      "Epoch 93 Batch 400 Loss 2.4847 Accuracy 0.9969\n",
      "Epoch 93 Batch 450 Loss 2.5184 Accuracy 0.9969\n",
      "Epoch 93 Batch 500 Loss 2.5105 Accuracy 0.9969\n",
      "Epoch 93 Batch 550 Loss 2.5253 Accuracy 0.9969\n",
      "Epoch 93 Batch 600 Loss 2.5441 Accuracy 0.9969\n",
      "Epoch 93 Batch 650 Loss 2.5474 Accuracy 0.9969\n",
      "Epoch 93 Batch 700 Loss 2.5431 Accuracy 0.9969\n",
      "Epoch 93 Batch 750 Loss 2.5461 Accuracy 0.9969\n",
      "Epoch 93 Batch 800 Loss 2.5292 Accuracy 0.9969\n",
      "Epoch 93 Batch 850 Loss 2.5342 Accuracy 0.9969\n",
      "Epoch 93 Batch 900 Loss 2.5363 Accuracy 0.9969\n",
      "Epoch 93 Batch 950 Loss 2.5385 Accuracy 0.9969\n",
      "Epoch 93 Batch 1000 Loss 2.5364 Accuracy 0.9969\n",
      "Epoch 93 Batch 1050 Loss 2.5278 Accuracy 0.9969\n",
      "Epoch 93 Batch 1100 Loss 2.5261 Accuracy 0.9969\n",
      "Epoch 93 Batch 1150 Loss 2.5134 Accuracy 0.9969\n",
      "Epoch 93 Batch 1200 Loss 2.5249 Accuracy 0.9969\n",
      "Epoch 93 Batch 1250 Loss 2.5172 Accuracy 0.9969\n",
      "Epoch 93 Batch 1300 Loss 2.5184 Accuracy 0.9969\n",
      "Epoch 93 Batch 1350 Loss 2.5150 Accuracy 0.9969\n",
      "Epoch 93 Batch 1400 Loss 2.5175 Accuracy 0.9969\n",
      "Epoch 93 Batch 1450 Loss 2.5117 Accuracy 0.9969\n",
      "Epoch 93 Batch 1500 Loss 2.5085 Accuracy 0.9969\n",
      "Epoch 93 Batch 1550 Loss 2.5098 Accuracy 0.9969\n",
      "Epoch 93 Batch 1600 Loss 2.5108 Accuracy 0.9969\n",
      "Epoch 93 Batch 1650 Loss 2.5127 Accuracy 0.9969\n",
      "Epoch 93 Batch 1700 Loss 2.5150 Accuracy 0.9969\n",
      "Epoch 93 Batch 1750 Loss 2.5112 Accuracy 0.9969\n",
      "Epoch 93 Batch 1800 Loss 2.5131 Accuracy 0.9969\n",
      "Epoch 93 Batch 1850 Loss 2.5064 Accuracy 0.9969\n",
      "Epoch 93 Batch 1900 Loss 2.5025 Accuracy 0.9969\n",
      "Epoch 93 Batch 1950 Loss 2.4943 Accuracy 0.9969\n",
      "Epoch 93 Batch 2000 Loss 2.4993 Accuracy 0.9969\n",
      "Epoch 93 Batch 2050 Loss 2.5041 Accuracy 0.9969\n",
      "Epoch 93 Batch 2100 Loss 2.5019 Accuracy 0.9969\n",
      "Epoch 93 Batch 2150 Loss 2.5035 Accuracy 0.9969\n",
      "Epoch 93 Batch 2200 Loss 2.5079 Accuracy 0.9969\n",
      "Epoch 93 Batch 2250 Loss 2.5115 Accuracy 0.9969\n",
      "Epoch 93 Batch 2300 Loss 2.5090 Accuracy 0.9969\n",
      "Epoch 93 Batch 2350 Loss 2.5094 Accuracy 0.9969\n",
      "Epoch 93 Batch 2400 Loss 2.5115 Accuracy 0.9969\n",
      "Epoch 93 Batch 2450 Loss 2.5127 Accuracy 0.9969\n",
      "Epoch 93 Batch 2500 Loss 2.5154 Accuracy 0.9969\n",
      "Epoch 93 Batch 2550 Loss 2.5155 Accuracy 0.9969\n",
      "Epoch 93 Batch 2600 Loss 2.5139 Accuracy 0.9969\n",
      "Epoch 93 Batch 2650 Loss 2.5120 Accuracy 0.9969\n",
      "Epoch 93 Loss 2.5134 Accuracy 0.9969\n",
      "Time taken for 1 epoch: 195.62654781341553 secs\n",
      "\n",
      "Epoch 94 Batch 0 Loss 2.1593 Accuracy 0.9972\n",
      "Epoch 94 Batch 50 Loss 2.5420 Accuracy 0.9969\n",
      "Epoch 94 Batch 100 Loss 2.5409 Accuracy 0.9968\n",
      "Epoch 94 Batch 150 Loss 2.5660 Accuracy 0.9968\n",
      "Epoch 94 Batch 200 Loss 2.5016 Accuracy 0.9969\n",
      "Epoch 94 Batch 250 Loss 2.4903 Accuracy 0.9969\n",
      "Epoch 94 Batch 300 Loss 2.4860 Accuracy 0.9969\n",
      "Epoch 94 Batch 350 Loss 2.4936 Accuracy 0.9969\n",
      "Epoch 94 Batch 400 Loss 2.4928 Accuracy 0.9969\n",
      "Epoch 94 Batch 450 Loss 2.5269 Accuracy 0.9969\n",
      "Epoch 94 Batch 500 Loss 2.5100 Accuracy 0.9969\n",
      "Epoch 94 Batch 550 Loss 2.5193 Accuracy 0.9969\n",
      "Epoch 94 Batch 600 Loss 2.5305 Accuracy 0.9969\n",
      "Epoch 94 Batch 650 Loss 2.5274 Accuracy 0.9969\n",
      "Epoch 94 Batch 700 Loss 2.5268 Accuracy 0.9969\n",
      "Epoch 94 Batch 750 Loss 2.5318 Accuracy 0.9969\n",
      "Epoch 94 Batch 800 Loss 2.5194 Accuracy 0.9969\n",
      "Epoch 94 Batch 850 Loss 2.5243 Accuracy 0.9969\n",
      "Epoch 94 Batch 900 Loss 2.5285 Accuracy 0.9969\n",
      "Epoch 94 Batch 950 Loss 2.5319 Accuracy 0.9969\n",
      "Epoch 94 Batch 1000 Loss 2.5281 Accuracy 0.9969\n",
      "Epoch 94 Batch 1050 Loss 2.5149 Accuracy 0.9969\n",
      "Epoch 94 Batch 1100 Loss 2.5125 Accuracy 0.9969\n",
      "Epoch 94 Batch 1150 Loss 2.5032 Accuracy 0.9969\n",
      "Epoch 94 Batch 1200 Loss 2.5173 Accuracy 0.9969\n",
      "Epoch 94 Batch 1250 Loss 2.5120 Accuracy 0.9969\n",
      "Epoch 94 Batch 1300 Loss 2.5142 Accuracy 0.9969\n",
      "Epoch 94 Batch 1350 Loss 2.5103 Accuracy 0.9969\n",
      "Epoch 94 Batch 1400 Loss 2.5141 Accuracy 0.9969\n",
      "Epoch 94 Batch 1450 Loss 2.5081 Accuracy 0.9969\n",
      "Epoch 94 Batch 1500 Loss 2.5058 Accuracy 0.9969\n",
      "Epoch 94 Batch 1550 Loss 2.5087 Accuracy 0.9969\n",
      "Epoch 94 Batch 1600 Loss 2.5095 Accuracy 0.9969\n",
      "Epoch 94 Batch 1650 Loss 2.5099 Accuracy 0.9969\n",
      "Epoch 94 Batch 1700 Loss 2.5122 Accuracy 0.9969\n",
      "Epoch 94 Batch 1750 Loss 2.5076 Accuracy 0.9969\n",
      "Epoch 94 Batch 1800 Loss 2.5110 Accuracy 0.9969\n",
      "Epoch 94 Batch 1850 Loss 2.5042 Accuracy 0.9969\n",
      "Epoch 94 Batch 1900 Loss 2.5014 Accuracy 0.9969\n",
      "Epoch 94 Batch 1950 Loss 2.4931 Accuracy 0.9969\n",
      "Epoch 94 Batch 2000 Loss 2.4981 Accuracy 0.9969\n",
      "Epoch 94 Batch 2050 Loss 2.5035 Accuracy 0.9969\n",
      "Epoch 94 Batch 2100 Loss 2.5019 Accuracy 0.9969\n",
      "Epoch 94 Batch 2150 Loss 2.5026 Accuracy 0.9969\n",
      "Epoch 94 Batch 2200 Loss 2.5074 Accuracy 0.9969\n",
      "Epoch 94 Batch 2250 Loss 2.5099 Accuracy 0.9969\n",
      "Epoch 94 Batch 2300 Loss 2.5074 Accuracy 0.9969\n",
      "Epoch 94 Batch 2350 Loss 2.5076 Accuracy 0.9969\n",
      "Epoch 94 Batch 2400 Loss 2.5090 Accuracy 0.9969\n",
      "Epoch 94 Batch 2450 Loss 2.5119 Accuracy 0.9969\n",
      "Epoch 94 Batch 2500 Loss 2.5149 Accuracy 0.9969\n",
      "Epoch 94 Batch 2550 Loss 2.5138 Accuracy 0.9969\n",
      "Epoch 94 Batch 2600 Loss 2.5118 Accuracy 0.9969\n",
      "Epoch 94 Batch 2650 Loss 2.5102 Accuracy 0.9969\n",
      "Epoch 94 Loss 2.5114 Accuracy 0.9969\n",
      "Time taken for 1 epoch: 195.35671997070312 secs\n",
      "\n",
      "Epoch 95 Batch 0 Loss 1.5256 Accuracy 0.9981\n",
      "Epoch 95 Batch 50 Loss 2.5884 Accuracy 0.9968\n",
      "Epoch 95 Batch 100 Loss 2.5598 Accuracy 0.9968\n",
      "Epoch 95 Batch 150 Loss 2.5627 Accuracy 0.9968\n",
      "Epoch 95 Batch 200 Loss 2.5000 Accuracy 0.9969\n",
      "Epoch 95 Batch 250 Loss 2.4886 Accuracy 0.9969\n",
      "Epoch 95 Batch 300 Loss 2.4818 Accuracy 0.9969\n",
      "Epoch 95 Batch 350 Loss 2.4805 Accuracy 0.9970\n",
      "Epoch 95 Batch 400 Loss 2.4787 Accuracy 0.9970\n",
      "Epoch 95 Batch 450 Loss 2.5102 Accuracy 0.9969\n",
      "Epoch 95 Batch 500 Loss 2.5001 Accuracy 0.9969\n",
      "Epoch 95 Batch 550 Loss 2.5112 Accuracy 0.9969\n",
      "Epoch 95 Batch 600 Loss 2.5274 Accuracy 0.9969\n",
      "Epoch 95 Batch 650 Loss 2.5249 Accuracy 0.9969\n",
      "Epoch 95 Batch 700 Loss 2.5210 Accuracy 0.9969\n",
      "Epoch 95 Batch 750 Loss 2.5230 Accuracy 0.9969\n",
      "Epoch 95 Batch 800 Loss 2.5127 Accuracy 0.9969\n",
      "Epoch 95 Batch 850 Loss 2.5119 Accuracy 0.9969\n",
      "Epoch 95 Batch 900 Loss 2.5116 Accuracy 0.9969\n",
      "Epoch 95 Batch 950 Loss 2.5180 Accuracy 0.9969\n",
      "Epoch 95 Batch 1000 Loss 2.5175 Accuracy 0.9969\n",
      "Epoch 95 Batch 1050 Loss 2.5098 Accuracy 0.9969\n",
      "Epoch 95 Batch 1100 Loss 2.5088 Accuracy 0.9969\n",
      "Epoch 95 Batch 1150 Loss 2.4982 Accuracy 0.9969\n",
      "Epoch 95 Batch 1200 Loss 2.5074 Accuracy 0.9969\n",
      "Epoch 95 Batch 1250 Loss 2.5032 Accuracy 0.9969\n",
      "Epoch 95 Batch 1300 Loss 2.5055 Accuracy 0.9969\n",
      "Epoch 95 Batch 1350 Loss 2.5002 Accuracy 0.9969\n",
      "Epoch 95 Batch 1400 Loss 2.5032 Accuracy 0.9969\n",
      "Epoch 95 Batch 1450 Loss 2.4981 Accuracy 0.9969\n",
      "Epoch 95 Batch 1500 Loss 2.4963 Accuracy 0.9969\n",
      "Epoch 95 Batch 1550 Loss 2.4973 Accuracy 0.9969\n",
      "Epoch 95 Batch 1600 Loss 2.4982 Accuracy 0.9969\n",
      "Epoch 95 Batch 1650 Loss 2.4998 Accuracy 0.9969\n",
      "Epoch 95 Batch 1700 Loss 2.5027 Accuracy 0.9969\n",
      "Epoch 95 Batch 1750 Loss 2.4975 Accuracy 0.9969\n",
      "Epoch 95 Batch 1800 Loss 2.4993 Accuracy 0.9969\n",
      "Epoch 95 Batch 1850 Loss 2.4921 Accuracy 0.9969\n",
      "Epoch 95 Batch 1900 Loss 2.4886 Accuracy 0.9969\n",
      "Epoch 95 Batch 1950 Loss 2.4825 Accuracy 0.9969\n",
      "Epoch 95 Batch 2000 Loss 2.4882 Accuracy 0.9969\n",
      "Epoch 95 Batch 2050 Loss 2.4957 Accuracy 0.9969\n",
      "Epoch 95 Batch 2100 Loss 2.4939 Accuracy 0.9969\n",
      "Epoch 95 Batch 2150 Loss 2.4957 Accuracy 0.9969\n",
      "Epoch 95 Batch 2200 Loss 2.5017 Accuracy 0.9969\n",
      "Epoch 95 Batch 2250 Loss 2.5026 Accuracy 0.9969\n",
      "Epoch 95 Batch 2300 Loss 2.4993 Accuracy 0.9969\n",
      "Epoch 95 Batch 2350 Loss 2.4978 Accuracy 0.9969\n",
      "Epoch 95 Batch 2400 Loss 2.4991 Accuracy 0.9969\n",
      "Epoch 95 Batch 2450 Loss 2.5003 Accuracy 0.9969\n",
      "Epoch 95 Batch 2500 Loss 2.5032 Accuracy 0.9969\n",
      "Epoch 95 Batch 2550 Loss 2.5020 Accuracy 0.9969\n",
      "Epoch 95 Batch 2600 Loss 2.4996 Accuracy 0.9969\n",
      "Epoch 95 Batch 2650 Loss 2.4977 Accuracy 0.9969\n",
      "Saving checkpoint for epoch 95 at ./checkpoints/train\\ckpt-20\n",
      "Epoch 95 Loss 2.4988 Accuracy 0.9969\n",
      "Time taken for 1 epoch: 196.23020720481873 secs\n",
      "\n",
      "Epoch 96 Batch 0 Loss 1.8065 Accuracy 0.9976\n",
      "Epoch 96 Batch 50 Loss 2.5780 Accuracy 0.9969\n",
      "Epoch 96 Batch 100 Loss 2.5163 Accuracy 0.9969\n",
      "Epoch 96 Batch 150 Loss 2.5396 Accuracy 0.9969\n",
      "Epoch 96 Batch 200 Loss 2.4756 Accuracy 0.9970\n",
      "Epoch 96 Batch 250 Loss 2.4633 Accuracy 0.9970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 300 Loss 2.4562 Accuracy 0.9970\n",
      "Epoch 96 Batch 350 Loss 2.4501 Accuracy 0.9970\n",
      "Epoch 96 Batch 400 Loss 2.4506 Accuracy 0.9970\n",
      "Epoch 96 Batch 450 Loss 2.4795 Accuracy 0.9970\n",
      "Epoch 96 Batch 500 Loss 2.4709 Accuracy 0.9970\n",
      "Epoch 96 Batch 550 Loss 2.4875 Accuracy 0.9969\n",
      "Epoch 96 Batch 600 Loss 2.5030 Accuracy 0.9969\n",
      "Epoch 96 Batch 650 Loss 2.5000 Accuracy 0.9969\n",
      "Epoch 96 Batch 700 Loss 2.4939 Accuracy 0.9969\n",
      "Epoch 96 Batch 750 Loss 2.4935 Accuracy 0.9969\n",
      "Epoch 96 Batch 800 Loss 2.4835 Accuracy 0.9970\n",
      "Epoch 96 Batch 850 Loss 2.4890 Accuracy 0.9969\n",
      "Epoch 96 Batch 900 Loss 2.4891 Accuracy 0.9969\n",
      "Epoch 96 Batch 950 Loss 2.4904 Accuracy 0.9969\n",
      "Epoch 96 Batch 1000 Loss 2.4872 Accuracy 0.9969\n",
      "Epoch 96 Batch 1050 Loss 2.4793 Accuracy 0.9970\n",
      "Epoch 96 Batch 1100 Loss 2.4809 Accuracy 0.9970\n",
      "Epoch 96 Batch 1150 Loss 2.4738 Accuracy 0.9970\n",
      "Epoch 96 Batch 1200 Loss 2.4871 Accuracy 0.9969\n",
      "Epoch 96 Batch 1250 Loss 2.4801 Accuracy 0.9970\n",
      "Epoch 96 Batch 1300 Loss 2.4809 Accuracy 0.9970\n",
      "Epoch 96 Batch 1350 Loss 2.4774 Accuracy 0.9970\n",
      "Epoch 96 Batch 1400 Loss 2.4815 Accuracy 0.9970\n",
      "Epoch 96 Batch 1450 Loss 2.4762 Accuracy 0.9970\n",
      "Epoch 96 Batch 1500 Loss 2.4762 Accuracy 0.9970\n",
      "Epoch 96 Batch 1550 Loss 2.4799 Accuracy 0.9970\n",
      "Epoch 96 Batch 1600 Loss 2.4801 Accuracy 0.9970\n",
      "Epoch 96 Batch 1650 Loss 2.4802 Accuracy 0.9970\n",
      "Epoch 96 Batch 1700 Loss 2.4850 Accuracy 0.9969\n",
      "Epoch 96 Batch 1750 Loss 2.4806 Accuracy 0.9970\n",
      "Epoch 96 Batch 1800 Loss 2.4831 Accuracy 0.9970\n",
      "Epoch 96 Batch 1850 Loss 2.4758 Accuracy 0.9970\n",
      "Epoch 96 Batch 1900 Loss 2.4729 Accuracy 0.9970\n",
      "Epoch 96 Batch 1950 Loss 2.4643 Accuracy 0.9970\n",
      "Epoch 96 Batch 2000 Loss 2.4681 Accuracy 0.9970\n",
      "Epoch 96 Batch 2050 Loss 2.4741 Accuracy 0.9970\n",
      "Epoch 96 Batch 2100 Loss 2.4728 Accuracy 0.9970\n",
      "Epoch 96 Batch 2150 Loss 2.4738 Accuracy 0.9970\n",
      "Epoch 96 Batch 2200 Loss 2.4779 Accuracy 0.9970\n",
      "Epoch 96 Batch 2250 Loss 2.4805 Accuracy 0.9970\n",
      "Epoch 96 Batch 2300 Loss 2.4777 Accuracy 0.9970\n",
      "Epoch 96 Batch 2350 Loss 2.4785 Accuracy 0.9970\n",
      "Epoch 96 Batch 2400 Loss 2.4799 Accuracy 0.9970\n",
      "Epoch 96 Batch 2450 Loss 2.4818 Accuracy 0.9970\n",
      "Epoch 96 Batch 2500 Loss 2.4834 Accuracy 0.9970\n",
      "Epoch 96 Batch 2550 Loss 2.4829 Accuracy 0.9970\n",
      "Epoch 96 Batch 2600 Loss 2.4804 Accuracy 0.9970\n",
      "Epoch 96 Batch 2650 Loss 2.4789 Accuracy 0.9970\n",
      "Epoch 96 Loss 2.4810 Accuracy 0.9970\n",
      "Time taken for 1 epoch: 195.3464584350586 secs\n",
      "\n",
      "Epoch 97 Batch 0 Loss 1.9393 Accuracy 0.9978\n",
      "Epoch 97 Batch 50 Loss 2.5560 Accuracy 0.9969\n",
      "Epoch 97 Batch 100 Loss 2.5223 Accuracy 0.9969\n",
      "Epoch 97 Batch 150 Loss 2.5455 Accuracy 0.9969\n",
      "Epoch 97 Batch 200 Loss 2.4763 Accuracy 0.9970\n",
      "Epoch 97 Batch 250 Loss 2.4659 Accuracy 0.9970\n",
      "Epoch 97 Batch 300 Loss 2.4758 Accuracy 0.9970\n",
      "Epoch 97 Batch 350 Loss 2.4718 Accuracy 0.9970\n",
      "Epoch 97 Batch 400 Loss 2.4715 Accuracy 0.9970\n",
      "Epoch 97 Batch 450 Loss 2.5078 Accuracy 0.9969\n",
      "Epoch 97 Batch 500 Loss 2.4903 Accuracy 0.9969\n",
      "Epoch 97 Batch 550 Loss 2.4999 Accuracy 0.9969\n",
      "Epoch 97 Batch 600 Loss 2.5137 Accuracy 0.9969\n",
      "Epoch 97 Batch 650 Loss 2.5085 Accuracy 0.9969\n",
      "Epoch 97 Batch 700 Loss 2.5111 Accuracy 0.9969\n",
      "Epoch 97 Batch 750 Loss 2.5136 Accuracy 0.9969\n",
      "Epoch 97 Batch 800 Loss 2.4997 Accuracy 0.9969\n",
      "Epoch 97 Batch 850 Loss 2.5048 Accuracy 0.9969\n",
      "Epoch 97 Batch 900 Loss 2.5047 Accuracy 0.9969\n",
      "Epoch 97 Batch 950 Loss 2.5096 Accuracy 0.9969\n",
      "Epoch 97 Batch 1000 Loss 2.5057 Accuracy 0.9969\n",
      "Epoch 97 Batch 1050 Loss 2.4938 Accuracy 0.9969\n",
      "Epoch 97 Batch 1100 Loss 2.4926 Accuracy 0.9969\n",
      "Epoch 97 Batch 1150 Loss 2.4844 Accuracy 0.9969\n",
      "Epoch 97 Batch 1200 Loss 2.4916 Accuracy 0.9969\n",
      "Epoch 97 Batch 1250 Loss 2.4865 Accuracy 0.9969\n",
      "Epoch 97 Batch 1300 Loss 2.4882 Accuracy 0.9969\n",
      "Epoch 97 Batch 1350 Loss 2.4834 Accuracy 0.9969\n",
      "Epoch 97 Batch 1400 Loss 2.4870 Accuracy 0.9969\n",
      "Epoch 97 Batch 1450 Loss 2.4809 Accuracy 0.9970\n",
      "Epoch 97 Batch 1500 Loss 2.4801 Accuracy 0.9970\n",
      "Epoch 97 Batch 1550 Loss 2.4806 Accuracy 0.9970\n",
      "Epoch 97 Batch 1600 Loss 2.4818 Accuracy 0.9970\n",
      "Epoch 97 Batch 1650 Loss 2.4809 Accuracy 0.9970\n",
      "Epoch 97 Batch 1700 Loss 2.4843 Accuracy 0.9970\n",
      "Epoch 97 Batch 1750 Loss 2.4792 Accuracy 0.9970\n",
      "Epoch 97 Batch 1800 Loss 2.4806 Accuracy 0.9970\n",
      "Epoch 97 Batch 1850 Loss 2.4750 Accuracy 0.9970\n",
      "Epoch 97 Batch 1900 Loss 2.4709 Accuracy 0.9970\n",
      "Epoch 97 Batch 1950 Loss 2.4632 Accuracy 0.9970\n",
      "Epoch 97 Batch 2000 Loss 2.4679 Accuracy 0.9970\n",
      "Epoch 97 Batch 2050 Loss 2.4756 Accuracy 0.9970\n",
      "Epoch 97 Batch 2100 Loss 2.4749 Accuracy 0.9970\n",
      "Epoch 97 Batch 2150 Loss 2.4769 Accuracy 0.9970\n",
      "Epoch 97 Batch 2200 Loss 2.4813 Accuracy 0.9970\n",
      "Epoch 97 Batch 2250 Loss 2.4833 Accuracy 0.9970\n",
      "Epoch 97 Batch 2300 Loss 2.4802 Accuracy 0.9970\n",
      "Epoch 97 Batch 2350 Loss 2.4798 Accuracy 0.9970\n",
      "Epoch 97 Batch 2400 Loss 2.4813 Accuracy 0.9970\n",
      "Epoch 97 Batch 2450 Loss 2.4832 Accuracy 0.9970\n",
      "Epoch 97 Batch 2500 Loss 2.4856 Accuracy 0.9969\n",
      "Epoch 97 Batch 2550 Loss 2.4836 Accuracy 0.9970\n",
      "Epoch 97 Batch 2600 Loss 2.4826 Accuracy 0.9970\n",
      "Epoch 97 Batch 2650 Loss 2.4804 Accuracy 0.9970\n",
      "Epoch 97 Loss 2.4815 Accuracy 0.9970\n",
      "Time taken for 1 epoch: 196.6099762916565 secs\n",
      "\n",
      "Epoch 98 Batch 0 Loss 1.7925 Accuracy 0.9981\n",
      "Epoch 98 Batch 50 Loss 2.5321 Accuracy 0.9969\n",
      "Epoch 98 Batch 100 Loss 2.4916 Accuracy 0.9969\n",
      "Epoch 98 Batch 150 Loss 2.5396 Accuracy 0.9969\n",
      "Epoch 98 Batch 200 Loss 2.4784 Accuracy 0.9970\n",
      "Epoch 98 Batch 250 Loss 2.4634 Accuracy 0.9970\n",
      "Epoch 98 Batch 300 Loss 2.4540 Accuracy 0.9970\n",
      "Epoch 98 Batch 350 Loss 2.4531 Accuracy 0.9970\n",
      "Epoch 98 Batch 400 Loss 2.4538 Accuracy 0.9970\n",
      "Epoch 98 Batch 450 Loss 2.4875 Accuracy 0.9969\n",
      "Epoch 98 Batch 500 Loss 2.4708 Accuracy 0.9970\n",
      "Epoch 98 Batch 550 Loss 2.4804 Accuracy 0.9970\n",
      "Epoch 98 Batch 600 Loss 2.4947 Accuracy 0.9969\n",
      "Epoch 98 Batch 650 Loss 2.4950 Accuracy 0.9969\n",
      "Epoch 98 Batch 700 Loss 2.4902 Accuracy 0.9969\n",
      "Epoch 98 Batch 750 Loss 2.4937 Accuracy 0.9969\n",
      "Epoch 98 Batch 800 Loss 2.4795 Accuracy 0.9970\n",
      "Epoch 98 Batch 850 Loss 2.4829 Accuracy 0.9970\n",
      "Epoch 98 Batch 900 Loss 2.4831 Accuracy 0.9969\n",
      "Epoch 98 Batch 950 Loss 2.4869 Accuracy 0.9969\n",
      "Epoch 98 Batch 1000 Loss 2.4863 Accuracy 0.9969\n",
      "Epoch 98 Batch 1050 Loss 2.4738 Accuracy 0.9970\n",
      "Epoch 98 Batch 1100 Loss 2.4743 Accuracy 0.9970\n",
      "Epoch 98 Batch 1150 Loss 2.4667 Accuracy 0.9970\n",
      "Epoch 98 Batch 1200 Loss 2.4785 Accuracy 0.9970\n",
      "Epoch 98 Batch 1250 Loss 2.4737 Accuracy 0.9970\n",
      "Epoch 98 Batch 1300 Loss 2.4735 Accuracy 0.9970\n",
      "Epoch 98 Batch 1350 Loss 2.4708 Accuracy 0.9970\n",
      "Epoch 98 Batch 1400 Loss 2.4728 Accuracy 0.9970\n",
      "Epoch 98 Batch 1450 Loss 2.4676 Accuracy 0.9970\n",
      "Epoch 98 Batch 1500 Loss 2.4675 Accuracy 0.9970\n",
      "Epoch 98 Batch 1550 Loss 2.4711 Accuracy 0.9970\n",
      "Epoch 98 Batch 1600 Loss 2.4720 Accuracy 0.9970\n",
      "Epoch 98 Batch 1650 Loss 2.4724 Accuracy 0.9970\n",
      "Epoch 98 Batch 1700 Loss 2.4745 Accuracy 0.9970\n",
      "Epoch 98 Batch 1750 Loss 2.4722 Accuracy 0.9970\n",
      "Epoch 98 Batch 1800 Loss 2.4749 Accuracy 0.9970\n",
      "Epoch 98 Batch 1850 Loss 2.4691 Accuracy 0.9970\n",
      "Epoch 98 Batch 1900 Loss 2.4650 Accuracy 0.9970\n",
      "Epoch 98 Batch 1950 Loss 2.4582 Accuracy 0.9970\n",
      "Epoch 98 Batch 2000 Loss 2.4634 Accuracy 0.9970\n",
      "Epoch 98 Batch 2050 Loss 2.4693 Accuracy 0.9970\n",
      "Epoch 98 Batch 2100 Loss 2.4693 Accuracy 0.9970\n",
      "Epoch 98 Batch 2150 Loss 2.4713 Accuracy 0.9970\n",
      "Epoch 98 Batch 2200 Loss 2.4751 Accuracy 0.9970\n",
      "Epoch 98 Batch 2250 Loss 2.4774 Accuracy 0.9970\n",
      "Epoch 98 Batch 2300 Loss 2.4744 Accuracy 0.9970\n",
      "Epoch 98 Batch 2350 Loss 2.4736 Accuracy 0.9970\n",
      "Epoch 98 Batch 2400 Loss 2.4766 Accuracy 0.9970\n",
      "Epoch 98 Batch 2450 Loss 2.4771 Accuracy 0.9970\n",
      "Epoch 98 Batch 2500 Loss 2.4786 Accuracy 0.9970\n",
      "Epoch 98 Batch 2550 Loss 2.4778 Accuracy 0.9970\n",
      "Epoch 98 Batch 2600 Loss 2.4754 Accuracy 0.9970\n",
      "Epoch 98 Batch 2650 Loss 2.4730 Accuracy 0.9970\n",
      "Epoch 98 Loss 2.4737 Accuracy 0.9970\n",
      "Time taken for 1 epoch: 195.07351756095886 secs\n",
      "\n",
      "Epoch 99 Batch 0 Loss 1.9972 Accuracy 0.9975\n",
      "Epoch 99 Batch 50 Loss 2.5040 Accuracy 0.9969\n",
      "Epoch 99 Batch 100 Loss 2.4798 Accuracy 0.9970\n",
      "Epoch 99 Batch 150 Loss 2.5175 Accuracy 0.9969\n",
      "Epoch 99 Batch 200 Loss 2.4601 Accuracy 0.9970\n",
      "Epoch 99 Batch 250 Loss 2.4557 Accuracy 0.9970\n",
      "Epoch 99 Batch 300 Loss 2.4569 Accuracy 0.9970\n",
      "Epoch 99 Batch 350 Loss 2.4496 Accuracy 0.9970\n",
      "Epoch 99 Batch 400 Loss 2.4498 Accuracy 0.9970\n",
      "Epoch 99 Batch 450 Loss 2.4823 Accuracy 0.9970\n",
      "Epoch 99 Batch 500 Loss 2.4695 Accuracy 0.9970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 550 Loss 2.4796 Accuracy 0.9970\n",
      "Epoch 99 Batch 600 Loss 2.4922 Accuracy 0.9969\n",
      "Epoch 99 Batch 650 Loss 2.4878 Accuracy 0.9969\n",
      "Epoch 99 Batch 700 Loss 2.4861 Accuracy 0.9970\n",
      "Epoch 99 Batch 750 Loss 2.4883 Accuracy 0.9969\n",
      "Epoch 99 Batch 800 Loss 2.4754 Accuracy 0.9970\n",
      "Epoch 99 Batch 850 Loss 2.4815 Accuracy 0.9970\n",
      "Epoch 99 Batch 900 Loss 2.4802 Accuracy 0.9970\n",
      "Epoch 99 Batch 950 Loss 2.4856 Accuracy 0.9970\n",
      "Epoch 99 Batch 1000 Loss 2.4796 Accuracy 0.9970\n",
      "Epoch 99 Batch 1050 Loss 2.4692 Accuracy 0.9970\n",
      "Epoch 99 Batch 1100 Loss 2.4692 Accuracy 0.9970\n",
      "Epoch 99 Batch 1150 Loss 2.4632 Accuracy 0.9970\n",
      "Epoch 99 Batch 1200 Loss 2.4743 Accuracy 0.9970\n",
      "Epoch 99 Batch 1250 Loss 2.4691 Accuracy 0.9970\n",
      "Epoch 99 Batch 1300 Loss 2.4730 Accuracy 0.9970\n",
      "Epoch 99 Batch 1350 Loss 2.4700 Accuracy 0.9970\n",
      "Epoch 99 Batch 1400 Loss 2.4708 Accuracy 0.9970\n",
      "Epoch 99 Batch 1450 Loss 2.4660 Accuracy 0.9970\n",
      "Epoch 99 Batch 1500 Loss 2.4649 Accuracy 0.9970\n",
      "Epoch 99 Batch 1550 Loss 2.4679 Accuracy 0.9970\n",
      "Epoch 99 Batch 1600 Loss 2.4703 Accuracy 0.9970\n",
      "Epoch 99 Batch 1650 Loss 2.4709 Accuracy 0.9970\n",
      "Epoch 99 Batch 1700 Loss 2.4730 Accuracy 0.9970\n",
      "Epoch 99 Batch 1750 Loss 2.4667 Accuracy 0.9970\n",
      "Epoch 99 Batch 1800 Loss 2.4686 Accuracy 0.9970\n",
      "Epoch 99 Batch 1850 Loss 2.4612 Accuracy 0.9970\n",
      "Epoch 99 Batch 1900 Loss 2.4574 Accuracy 0.9970\n",
      "Epoch 99 Batch 1950 Loss 2.4513 Accuracy 0.9970\n",
      "Epoch 99 Batch 2000 Loss 2.4549 Accuracy 0.9970\n",
      "Epoch 99 Batch 2050 Loss 2.4612 Accuracy 0.9970\n",
      "Epoch 99 Batch 2100 Loss 2.4583 Accuracy 0.9970\n",
      "Epoch 99 Batch 2150 Loss 2.4591 Accuracy 0.9970\n",
      "Epoch 99 Batch 2200 Loss 2.4637 Accuracy 0.9970\n",
      "Epoch 99 Batch 2250 Loss 2.4642 Accuracy 0.9970\n",
      "Epoch 99 Batch 2300 Loss 2.4622 Accuracy 0.9970\n",
      "Epoch 99 Batch 2350 Loss 2.4618 Accuracy 0.9970\n",
      "Epoch 99 Batch 2400 Loss 2.4626 Accuracy 0.9970\n",
      "Epoch 99 Batch 2450 Loss 2.4646 Accuracy 0.9970\n",
      "Epoch 99 Batch 2500 Loss 2.4663 Accuracy 0.9970\n",
      "Epoch 99 Batch 2550 Loss 2.4654 Accuracy 0.9970\n",
      "Epoch 99 Batch 2600 Loss 2.4622 Accuracy 0.9970\n",
      "Epoch 99 Batch 2650 Loss 2.4609 Accuracy 0.9970\n",
      "Epoch 99 Loss 2.4608 Accuracy 0.9970\n",
      "Time taken for 1 epoch: 194.96310806274414 secs\n",
      "\n",
      "Epoch 100 Batch 0 Loss 1.5262 Accuracy 0.9984\n",
      "Epoch 100 Batch 50 Loss 2.5277 Accuracy 0.9968\n",
      "Epoch 100 Batch 100 Loss 2.4979 Accuracy 0.9969\n",
      "Epoch 100 Batch 150 Loss 2.5071 Accuracy 0.9969\n",
      "Epoch 100 Batch 200 Loss 2.4405 Accuracy 0.9970\n",
      "Epoch 100 Batch 250 Loss 2.4344 Accuracy 0.9970\n",
      "Epoch 100 Batch 300 Loss 2.4380 Accuracy 0.9970\n",
      "Epoch 100 Batch 350 Loss 2.4462 Accuracy 0.9970\n",
      "Epoch 100 Batch 400 Loss 2.4446 Accuracy 0.9970\n",
      "Epoch 100 Batch 450 Loss 2.4783 Accuracy 0.9969\n",
      "Epoch 100 Batch 500 Loss 2.4647 Accuracy 0.9970\n",
      "Epoch 100 Batch 550 Loss 2.4822 Accuracy 0.9969\n",
      "Epoch 100 Batch 600 Loss 2.4931 Accuracy 0.9969\n",
      "Epoch 100 Batch 650 Loss 2.4929 Accuracy 0.9969\n",
      "Epoch 100 Batch 700 Loss 2.4918 Accuracy 0.9969\n",
      "Epoch 100 Batch 750 Loss 2.4921 Accuracy 0.9969\n",
      "Epoch 100 Batch 800 Loss 2.4771 Accuracy 0.9970\n",
      "Epoch 100 Batch 850 Loss 2.4806 Accuracy 0.9970\n",
      "Epoch 100 Batch 900 Loss 2.4803 Accuracy 0.9969\n",
      "Epoch 100 Batch 950 Loss 2.4823 Accuracy 0.9969\n",
      "Epoch 100 Batch 1000 Loss 2.4808 Accuracy 0.9969\n",
      "Epoch 100 Batch 1050 Loss 2.4693 Accuracy 0.9970\n",
      "Epoch 100 Batch 1100 Loss 2.4671 Accuracy 0.9970\n",
      "Epoch 100 Batch 1150 Loss 2.4559 Accuracy 0.9970\n",
      "Epoch 100 Batch 1200 Loss 2.4681 Accuracy 0.9970\n",
      "Epoch 100 Batch 1250 Loss 2.4633 Accuracy 0.9970\n",
      "Epoch 100 Batch 1300 Loss 2.4642 Accuracy 0.9970\n",
      "Epoch 100 Batch 1350 Loss 2.4610 Accuracy 0.9970\n",
      "Epoch 100 Batch 1400 Loss 2.4607 Accuracy 0.9970\n",
      "Epoch 100 Batch 1450 Loss 2.4556 Accuracy 0.9970\n",
      "Epoch 100 Batch 1500 Loss 2.4550 Accuracy 0.9970\n",
      "Epoch 100 Batch 1550 Loss 2.4559 Accuracy 0.9970\n",
      "Epoch 100 Batch 1600 Loss 2.4559 Accuracy 0.9970\n",
      "Epoch 100 Batch 1650 Loss 2.4565 Accuracy 0.9970\n",
      "Epoch 100 Batch 1700 Loss 2.4597 Accuracy 0.9970\n",
      "Epoch 100 Batch 1750 Loss 2.4537 Accuracy 0.9970\n",
      "Epoch 100 Batch 1800 Loss 2.4535 Accuracy 0.9970\n",
      "Epoch 100 Batch 1850 Loss 2.4488 Accuracy 0.9970\n",
      "Epoch 100 Batch 1900 Loss 2.4456 Accuracy 0.9970\n",
      "Epoch 100 Batch 1950 Loss 2.4375 Accuracy 0.9970\n",
      "Epoch 100 Batch 2000 Loss 2.4427 Accuracy 0.9970\n",
      "Epoch 100 Batch 2050 Loss 2.4473 Accuracy 0.9970\n",
      "Epoch 100 Batch 2100 Loss 2.4459 Accuracy 0.9970\n",
      "Epoch 100 Batch 2150 Loss 2.4486 Accuracy 0.9970\n",
      "Epoch 100 Batch 2200 Loss 2.4529 Accuracy 0.9970\n",
      "Epoch 100 Batch 2250 Loss 2.4536 Accuracy 0.9970\n",
      "Epoch 100 Batch 2300 Loss 2.4506 Accuracy 0.9970\n",
      "Epoch 100 Batch 2350 Loss 2.4510 Accuracy 0.9970\n",
      "Epoch 100 Batch 2400 Loss 2.4528 Accuracy 0.9970\n",
      "Epoch 100 Batch 2450 Loss 2.4547 Accuracy 0.9970\n",
      "Epoch 100 Batch 2500 Loss 2.4566 Accuracy 0.9970\n",
      "Epoch 100 Batch 2550 Loss 2.4554 Accuracy 0.9970\n",
      "Epoch 100 Batch 2600 Loss 2.4525 Accuracy 0.9970\n",
      "Epoch 100 Batch 2650 Loss 2.4515 Accuracy 0.9970\n",
      "Saving checkpoint for epoch 100 at ./checkpoints/train\\ckpt-21\n",
      "Epoch 100 Loss 2.4519 Accuracy 0.9970\n",
      "Time taken for 1 epoch: 195.02998399734497 secs\n",
      "\n",
      "Epoch 101 Batch 0 Loss 1.4937 Accuracy 0.9982\n",
      "Epoch 101 Batch 50 Loss 2.4388 Accuracy 0.9970\n",
      "Epoch 101 Batch 100 Loss 2.4317 Accuracy 0.9970\n",
      "Epoch 101 Batch 150 Loss 2.4675 Accuracy 0.9970\n",
      "Epoch 101 Batch 200 Loss 2.4061 Accuracy 0.9970\n",
      "Epoch 101 Batch 250 Loss 2.3973 Accuracy 0.9971\n",
      "Epoch 101 Batch 300 Loss 2.3995 Accuracy 0.9971\n",
      "Epoch 101 Batch 350 Loss 2.4032 Accuracy 0.9971\n",
      "Epoch 101 Batch 400 Loss 2.4063 Accuracy 0.9971\n",
      "Epoch 101 Batch 450 Loss 2.4351 Accuracy 0.9970\n",
      "Epoch 101 Batch 500 Loss 2.4252 Accuracy 0.9970\n",
      "Epoch 101 Batch 550 Loss 2.4399 Accuracy 0.9970\n",
      "Epoch 101 Batch 600 Loss 2.4576 Accuracy 0.9970\n",
      "Epoch 101 Batch 650 Loss 2.4631 Accuracy 0.9970\n",
      "Epoch 101 Batch 700 Loss 2.4596 Accuracy 0.9970\n",
      "Epoch 101 Batch 750 Loss 2.4648 Accuracy 0.9970\n",
      "Epoch 101 Batch 800 Loss 2.4534 Accuracy 0.9970\n",
      "Epoch 101 Batch 850 Loss 2.4591 Accuracy 0.9970\n",
      "Epoch 101 Batch 900 Loss 2.4595 Accuracy 0.9970\n",
      "Epoch 101 Batch 950 Loss 2.4637 Accuracy 0.9970\n",
      "Epoch 101 Batch 1000 Loss 2.4604 Accuracy 0.9970\n",
      "Epoch 101 Batch 1050 Loss 2.4493 Accuracy 0.9970\n",
      "Epoch 101 Batch 1100 Loss 2.4475 Accuracy 0.9970\n",
      "Epoch 101 Batch 1150 Loss 2.4413 Accuracy 0.9970\n",
      "Epoch 101 Batch 1200 Loss 2.4507 Accuracy 0.9970\n",
      "Epoch 101 Batch 1250 Loss 2.4463 Accuracy 0.9970\n",
      "Epoch 101 Batch 1300 Loss 2.4468 Accuracy 0.9970\n",
      "Epoch 101 Batch 1350 Loss 2.4424 Accuracy 0.9970\n",
      "Epoch 101 Batch 1400 Loss 2.4449 Accuracy 0.9970\n",
      "Epoch 101 Batch 1450 Loss 2.4401 Accuracy 0.9970\n",
      "Epoch 101 Batch 1500 Loss 2.4385 Accuracy 0.9970\n",
      "Epoch 101 Batch 1550 Loss 2.4400 Accuracy 0.9970\n",
      "Epoch 101 Batch 1600 Loss 2.4415 Accuracy 0.9970\n",
      "Epoch 101 Batch 1650 Loss 2.4419 Accuracy 0.9970\n",
      "Epoch 101 Batch 1700 Loss 2.4435 Accuracy 0.9970\n",
      "Epoch 101 Batch 1750 Loss 2.4397 Accuracy 0.9970\n",
      "Epoch 101 Batch 1800 Loss 2.4413 Accuracy 0.9970\n",
      "Epoch 101 Batch 1850 Loss 2.4354 Accuracy 0.9970\n",
      "Epoch 101 Batch 1900 Loss 2.4322 Accuracy 0.9970\n",
      "Epoch 101 Batch 1950 Loss 2.4258 Accuracy 0.9970\n",
      "Epoch 101 Batch 2000 Loss 2.4311 Accuracy 0.9970\n",
      "Epoch 101 Batch 2050 Loss 2.4384 Accuracy 0.9970\n",
      "Epoch 101 Batch 2100 Loss 2.4368 Accuracy 0.9970\n",
      "Epoch 101 Batch 2150 Loss 2.4388 Accuracy 0.9970\n",
      "Epoch 101 Batch 2200 Loss 2.4424 Accuracy 0.9970\n",
      "Epoch 101 Batch 2250 Loss 2.4436 Accuracy 0.9970\n",
      "Epoch 101 Batch 2300 Loss 2.4415 Accuracy 0.9970\n",
      "Epoch 101 Batch 2350 Loss 2.4417 Accuracy 0.9970\n",
      "Epoch 101 Batch 2400 Loss 2.4424 Accuracy 0.9970\n",
      "Epoch 101 Batch 2450 Loss 2.4452 Accuracy 0.9970\n",
      "Epoch 101 Batch 2500 Loss 2.4475 Accuracy 0.9970\n",
      "Epoch 101 Batch 2550 Loss 2.4472 Accuracy 0.9970\n",
      "Epoch 101 Batch 2600 Loss 2.4437 Accuracy 0.9970\n",
      "Epoch 101 Batch 2650 Loss 2.4416 Accuracy 0.9970\n",
      "Epoch 101 Loss 2.4435 Accuracy 0.9970\n",
      "Time taken for 1 epoch: 194.97017693519592 secs\n",
      "\n",
      "Epoch 102 Batch 0 Loss 1.9398 Accuracy 0.9977\n",
      "Epoch 102 Batch 50 Loss 2.4930 Accuracy 0.9969\n",
      "Epoch 102 Batch 100 Loss 2.4620 Accuracy 0.9970\n",
      "Epoch 102 Batch 150 Loss 2.4994 Accuracy 0.9969\n",
      "Epoch 102 Batch 200 Loss 2.4313 Accuracy 0.9970\n",
      "Epoch 102 Batch 250 Loss 2.4292 Accuracy 0.9970\n",
      "Epoch 102 Batch 300 Loss 2.4345 Accuracy 0.9970\n",
      "Epoch 102 Batch 350 Loss 2.4262 Accuracy 0.9970\n",
      "Epoch 102 Batch 400 Loss 2.4196 Accuracy 0.9970\n",
      "Epoch 102 Batch 450 Loss 2.4479 Accuracy 0.9970\n",
      "Epoch 102 Batch 500 Loss 2.4420 Accuracy 0.9970\n",
      "Epoch 102 Batch 550 Loss 2.4558 Accuracy 0.9970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 Batch 600 Loss 2.4710 Accuracy 0.9970\n",
      "Epoch 102 Batch 650 Loss 2.4690 Accuracy 0.9970\n",
      "Epoch 102 Batch 700 Loss 2.4683 Accuracy 0.9970\n",
      "Epoch 102 Batch 750 Loss 2.4657 Accuracy 0.9970\n",
      "Epoch 102 Batch 800 Loss 2.4541 Accuracy 0.9970\n",
      "Epoch 102 Batch 850 Loss 2.4572 Accuracy 0.9970\n",
      "Epoch 102 Batch 900 Loss 2.4598 Accuracy 0.9970\n",
      "Epoch 102 Batch 950 Loss 2.4636 Accuracy 0.9970\n",
      "Epoch 102 Batch 1000 Loss 2.4609 Accuracy 0.9970\n",
      "Epoch 102 Batch 1050 Loss 2.4510 Accuracy 0.9970\n",
      "Epoch 102 Batch 1100 Loss 2.4519 Accuracy 0.9970\n",
      "Epoch 102 Batch 1150 Loss 2.4445 Accuracy 0.9970\n",
      "Epoch 102 Batch 1200 Loss 2.4542 Accuracy 0.9970\n",
      "Epoch 102 Batch 1250 Loss 2.4492 Accuracy 0.9970\n",
      "Epoch 102 Batch 1300 Loss 2.4483 Accuracy 0.9970\n",
      "Epoch 102 Batch 1350 Loss 2.4443 Accuracy 0.9970\n",
      "Epoch 102 Batch 1400 Loss 2.4479 Accuracy 0.9970\n",
      "Epoch 102 Batch 1450 Loss 2.4423 Accuracy 0.9970\n",
      "Epoch 102 Batch 1500 Loss 2.4419 Accuracy 0.9970\n",
      "Epoch 102 Batch 1550 Loss 2.4436 Accuracy 0.9970\n",
      "Epoch 102 Batch 1600 Loss 2.4424 Accuracy 0.9970\n",
      "Epoch 102 Batch 1650 Loss 2.4414 Accuracy 0.9970\n",
      "Epoch 102 Batch 1700 Loss 2.4452 Accuracy 0.9970\n",
      "Epoch 102 Batch 1750 Loss 2.4405 Accuracy 0.9970\n",
      "Epoch 102 Batch 1800 Loss 2.4426 Accuracy 0.9970\n",
      "Epoch 102 Batch 1850 Loss 2.4357 Accuracy 0.9970\n",
      "Epoch 102 Batch 1900 Loss 2.4334 Accuracy 0.9970\n",
      "Epoch 102 Batch 1950 Loss 2.4251 Accuracy 0.9970\n",
      "Epoch 102 Batch 2000 Loss 2.4300 Accuracy 0.9970\n",
      "Epoch 102 Batch 2050 Loss 2.4352 Accuracy 0.9970\n",
      "Epoch 102 Batch 2100 Loss 2.4351 Accuracy 0.9970\n",
      "Epoch 102 Batch 2150 Loss 2.4372 Accuracy 0.9970\n",
      "Epoch 102 Batch 2200 Loss 2.4419 Accuracy 0.9970\n",
      "Epoch 102 Batch 2250 Loss 2.4431 Accuracy 0.9970\n",
      "Epoch 102 Batch 2300 Loss 2.4400 Accuracy 0.9970\n",
      "Epoch 102 Batch 2350 Loss 2.4405 Accuracy 0.9970\n",
      "Epoch 102 Batch 2400 Loss 2.4417 Accuracy 0.9970\n",
      "Epoch 102 Batch 2450 Loss 2.4431 Accuracy 0.9970\n",
      "Epoch 102 Batch 2500 Loss 2.4450 Accuracy 0.9970\n",
      "Epoch 102 Batch 2550 Loss 2.4428 Accuracy 0.9970\n",
      "Epoch 102 Batch 2600 Loss 2.4403 Accuracy 0.9970\n",
      "Epoch 102 Batch 2650 Loss 2.4382 Accuracy 0.9970\n",
      "Epoch 102 Loss 2.4398 Accuracy 0.9970\n",
      "Time taken for 1 epoch: 195.476637840271 secs\n",
      "\n",
      "Epoch 103 Batch 0 Loss 1.7485 Accuracy 0.9979\n",
      "Epoch 103 Batch 50 Loss 2.5150 Accuracy 0.9969\n",
      "Epoch 103 Batch 100 Loss 2.4766 Accuracy 0.9970\n",
      "Epoch 103 Batch 150 Loss 2.4958 Accuracy 0.9969\n",
      "Epoch 103 Batch 200 Loss 2.4210 Accuracy 0.9970\n",
      "Epoch 103 Batch 250 Loss 2.4132 Accuracy 0.9970\n",
      "Epoch 103 Batch 300 Loss 2.4068 Accuracy 0.9971\n",
      "Epoch 103 Batch 350 Loss 2.4070 Accuracy 0.9970\n",
      "Epoch 103 Batch 400 Loss 2.4014 Accuracy 0.9970\n",
      "Epoch 103 Batch 450 Loss 2.4336 Accuracy 0.9970\n",
      "Epoch 103 Batch 500 Loss 2.4263 Accuracy 0.9970\n",
      "Epoch 103 Batch 550 Loss 2.4374 Accuracy 0.9970\n",
      "Epoch 103 Batch 600 Loss 2.4556 Accuracy 0.9970\n",
      "Epoch 103 Batch 650 Loss 2.4551 Accuracy 0.9970\n",
      "Epoch 103 Batch 700 Loss 2.4544 Accuracy 0.9970\n",
      "Epoch 103 Batch 750 Loss 2.4560 Accuracy 0.9970\n",
      "Epoch 103 Batch 800 Loss 2.4476 Accuracy 0.9970\n",
      "Epoch 103 Batch 850 Loss 2.4528 Accuracy 0.9970\n",
      "Epoch 103 Batch 900 Loss 2.4543 Accuracy 0.9970\n",
      "Epoch 103 Batch 950 Loss 2.4544 Accuracy 0.9970\n",
      "Epoch 103 Batch 1000 Loss 2.4529 Accuracy 0.9970\n",
      "Epoch 103 Batch 1050 Loss 2.4440 Accuracy 0.9970\n",
      "Epoch 103 Batch 1100 Loss 2.4440 Accuracy 0.9970\n",
      "Epoch 103 Batch 1150 Loss 2.4355 Accuracy 0.9970\n",
      "Epoch 103 Batch 1200 Loss 2.4473 Accuracy 0.9970\n",
      "Epoch 103 Batch 1250 Loss 2.4410 Accuracy 0.9970\n",
      "Epoch 103 Batch 1300 Loss 2.4420 Accuracy 0.9970\n",
      "Epoch 103 Batch 1350 Loss 2.4375 Accuracy 0.9970\n",
      "Epoch 103 Batch 1400 Loss 2.4396 Accuracy 0.9970\n",
      "Epoch 103 Batch 1450 Loss 2.4339 Accuracy 0.9970\n",
      "Epoch 103 Batch 1500 Loss 2.4327 Accuracy 0.9970\n",
      "Epoch 103 Batch 1550 Loss 2.4334 Accuracy 0.9970\n",
      "Epoch 103 Batch 1600 Loss 2.4348 Accuracy 0.9970\n",
      "Epoch 103 Batch 1650 Loss 2.4335 Accuracy 0.9970\n",
      "Epoch 103 Batch 1700 Loss 2.4360 Accuracy 0.9970\n",
      "Epoch 103 Batch 1750 Loss 2.4326 Accuracy 0.9970\n",
      "Epoch 103 Batch 1800 Loss 2.4343 Accuracy 0.9970\n",
      "Epoch 103 Batch 1850 Loss 2.4286 Accuracy 0.9970\n",
      "Epoch 103 Batch 1900 Loss 2.4250 Accuracy 0.9970\n",
      "Epoch 103 Batch 1950 Loss 2.4173 Accuracy 0.9970\n",
      "Epoch 103 Batch 2000 Loss 2.4231 Accuracy 0.9970\n",
      "Epoch 103 Batch 2050 Loss 2.4282 Accuracy 0.9970\n",
      "Epoch 103 Batch 2100 Loss 2.4274 Accuracy 0.9970\n",
      "Epoch 103 Batch 2150 Loss 2.4283 Accuracy 0.9970\n",
      "Epoch 103 Batch 2200 Loss 2.4312 Accuracy 0.9970\n",
      "Epoch 103 Batch 2250 Loss 2.4325 Accuracy 0.9970\n",
      "Epoch 103 Batch 2300 Loss 2.4297 Accuracy 0.9970\n",
      "Epoch 103 Batch 2350 Loss 2.4313 Accuracy 0.9970\n",
      "Epoch 103 Batch 2400 Loss 2.4334 Accuracy 0.9970\n",
      "Epoch 103 Batch 2450 Loss 2.4352 Accuracy 0.9970\n",
      "Epoch 103 Batch 2500 Loss 2.4370 Accuracy 0.9970\n",
      "Epoch 103 Batch 2550 Loss 2.4355 Accuracy 0.9970\n",
      "Epoch 103 Batch 2600 Loss 2.4326 Accuracy 0.9970\n",
      "Epoch 103 Batch 2650 Loss 2.4298 Accuracy 0.9970\n",
      "Epoch 103 Loss 2.4324 Accuracy 0.9970\n",
      "Time taken for 1 epoch: 195.06002569198608 secs\n",
      "\n",
      "Epoch 104 Batch 0 Loss 2.1388 Accuracy 0.9974\n",
      "Epoch 104 Batch 50 Loss 2.4766 Accuracy 0.9970\n",
      "Epoch 104 Batch 100 Loss 2.4466 Accuracy 0.9970\n",
      "Epoch 104 Batch 150 Loss 2.4711 Accuracy 0.9970\n",
      "Epoch 104 Batch 200 Loss 2.4074 Accuracy 0.9970\n",
      "Epoch 104 Batch 250 Loss 2.3857 Accuracy 0.9971\n",
      "Epoch 104 Batch 300 Loss 2.3883 Accuracy 0.9971\n",
      "Epoch 104 Batch 350 Loss 2.3883 Accuracy 0.9971\n",
      "Epoch 104 Batch 400 Loss 2.3901 Accuracy 0.9971\n",
      "Epoch 104 Batch 450 Loss 2.4219 Accuracy 0.9970\n",
      "Epoch 104 Batch 500 Loss 2.4115 Accuracy 0.9970\n",
      "Epoch 104 Batch 550 Loss 2.4235 Accuracy 0.9970\n",
      "Epoch 104 Batch 600 Loss 2.4388 Accuracy 0.9970\n",
      "Epoch 104 Batch 650 Loss 2.4355 Accuracy 0.9970\n",
      "Epoch 104 Batch 700 Loss 2.4343 Accuracy 0.9970\n",
      "Epoch 104 Batch 750 Loss 2.4358 Accuracy 0.9970\n",
      "Epoch 104 Batch 800 Loss 2.4237 Accuracy 0.9970\n",
      "Epoch 104 Batch 850 Loss 2.4295 Accuracy 0.9970\n",
      "Epoch 104 Batch 900 Loss 2.4272 Accuracy 0.9970\n",
      "Epoch 104 Batch 950 Loss 2.4312 Accuracy 0.9970\n",
      "Epoch 104 Batch 1000 Loss 2.4290 Accuracy 0.9970\n",
      "Epoch 104 Batch 1050 Loss 2.4182 Accuracy 0.9970\n",
      "Epoch 104 Batch 1100 Loss 2.4168 Accuracy 0.9970\n",
      "Epoch 104 Batch 1150 Loss 2.4093 Accuracy 0.9970\n",
      "Epoch 104 Batch 1200 Loss 2.4194 Accuracy 0.9970\n",
      "Epoch 104 Batch 1250 Loss 2.4167 Accuracy 0.9970\n",
      "Epoch 104 Batch 1300 Loss 2.4170 Accuracy 0.9970\n",
      "Epoch 104 Batch 1350 Loss 2.4118 Accuracy 0.9970\n",
      "Epoch 104 Batch 1400 Loss 2.4150 Accuracy 0.9970\n",
      "Epoch 104 Batch 1450 Loss 2.4101 Accuracy 0.9970\n",
      "Epoch 104 Batch 1500 Loss 2.4074 Accuracy 0.9970\n",
      "Epoch 104 Batch 1550 Loss 2.4111 Accuracy 0.9970\n",
      "Epoch 104 Batch 1600 Loss 2.4135 Accuracy 0.9970\n",
      "Epoch 104 Batch 1650 Loss 2.4137 Accuracy 0.9970\n",
      "Epoch 104 Batch 1700 Loss 2.4157 Accuracy 0.9970\n",
      "Epoch 104 Batch 1750 Loss 2.4129 Accuracy 0.9970\n",
      "Epoch 104 Batch 1800 Loss 2.4155 Accuracy 0.9970\n",
      "Epoch 104 Batch 1850 Loss 2.4098 Accuracy 0.9970\n",
      "Epoch 104 Batch 1900 Loss 2.4057 Accuracy 0.9971\n",
      "Epoch 104 Batch 1950 Loss 2.3981 Accuracy 0.9971\n",
      "Epoch 104 Batch 2000 Loss 2.4017 Accuracy 0.9971\n",
      "Epoch 104 Batch 2050 Loss 2.4081 Accuracy 0.9970\n",
      "Epoch 104 Batch 2100 Loss 2.4060 Accuracy 0.9971\n",
      "Epoch 104 Batch 2150 Loss 2.4079 Accuracy 0.9970\n",
      "Epoch 104 Batch 2200 Loss 2.4118 Accuracy 0.9970\n",
      "Epoch 104 Batch 2250 Loss 2.4132 Accuracy 0.9970\n",
      "Epoch 104 Batch 2300 Loss 2.4102 Accuracy 0.9970\n",
      "Epoch 104 Batch 2350 Loss 2.4087 Accuracy 0.9970\n",
      "Epoch 104 Batch 2400 Loss 2.4110 Accuracy 0.9970\n",
      "Epoch 104 Batch 2450 Loss 2.4129 Accuracy 0.9970\n",
      "Epoch 104 Batch 2500 Loss 2.4156 Accuracy 0.9970\n",
      "Epoch 104 Batch 2550 Loss 2.4156 Accuracy 0.9970\n",
      "Epoch 104 Batch 2600 Loss 2.4141 Accuracy 0.9970\n",
      "Epoch 104 Batch 2650 Loss 2.4119 Accuracy 0.9970\n",
      "Epoch 104 Loss 2.4129 Accuracy 0.9970\n",
      "Time taken for 1 epoch: 197.48308062553406 secs\n",
      "\n",
      "Epoch 105 Batch 0 Loss 1.6978 Accuracy 0.9979\n",
      "Epoch 105 Batch 50 Loss 2.4246 Accuracy 0.9970\n",
      "Epoch 105 Batch 100 Loss 2.4526 Accuracy 0.9970\n",
      "Epoch 105 Batch 150 Loss 2.4642 Accuracy 0.9970\n",
      "Epoch 105 Batch 200 Loss 2.4103 Accuracy 0.9970\n",
      "Epoch 105 Batch 250 Loss 2.3967 Accuracy 0.9971\n",
      "Epoch 105 Batch 300 Loss 2.3908 Accuracy 0.9971\n",
      "Epoch 105 Batch 350 Loss 2.3909 Accuracy 0.9971\n",
      "Epoch 105 Batch 400 Loss 2.3878 Accuracy 0.9971\n",
      "Epoch 105 Batch 450 Loss 2.4257 Accuracy 0.9970\n",
      "Epoch 105 Batch 500 Loss 2.4150 Accuracy 0.9970\n",
      "Epoch 105 Batch 550 Loss 2.4256 Accuracy 0.9970\n",
      "Epoch 105 Batch 600 Loss 2.4412 Accuracy 0.9970\n",
      "Epoch 105 Batch 650 Loss 2.4360 Accuracy 0.9970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 Batch 700 Loss 2.4312 Accuracy 0.9970\n",
      "Epoch 105 Batch 750 Loss 2.4308 Accuracy 0.9970\n",
      "Epoch 105 Batch 800 Loss 2.4168 Accuracy 0.9970\n",
      "Epoch 105 Batch 850 Loss 2.4219 Accuracy 0.9970\n",
      "Epoch 105 Batch 900 Loss 2.4219 Accuracy 0.9970\n",
      "Epoch 105 Batch 950 Loss 2.4283 Accuracy 0.9970\n",
      "Epoch 105 Batch 1000 Loss 2.4250 Accuracy 0.9970\n",
      "Epoch 105 Batch 1050 Loss 2.4147 Accuracy 0.9970\n",
      "Epoch 105 Batch 1100 Loss 2.4148 Accuracy 0.9970\n",
      "Epoch 105 Batch 1150 Loss 2.4076 Accuracy 0.9971\n",
      "Epoch 105 Batch 1200 Loss 2.4188 Accuracy 0.9970\n",
      "Epoch 105 Batch 1250 Loss 2.4122 Accuracy 0.9970\n",
      "Epoch 105 Batch 1300 Loss 2.4147 Accuracy 0.9970\n",
      "Epoch 105 Batch 1350 Loss 2.4112 Accuracy 0.9970\n",
      "Epoch 105 Batch 1400 Loss 2.4150 Accuracy 0.9970\n",
      "Epoch 105 Batch 1450 Loss 2.4083 Accuracy 0.9971\n",
      "Epoch 105 Batch 1500 Loss 2.4062 Accuracy 0.9971\n",
      "Epoch 105 Batch 1550 Loss 2.4084 Accuracy 0.9970\n",
      "Epoch 105 Batch 1600 Loss 2.4100 Accuracy 0.9970\n",
      "Epoch 105 Batch 1650 Loss 2.4104 Accuracy 0.9970\n",
      "Epoch 105 Batch 1700 Loss 2.4116 Accuracy 0.9970\n",
      "Epoch 105 Batch 1750 Loss 2.4083 Accuracy 0.9971\n",
      "Epoch 105 Batch 1800 Loss 2.4090 Accuracy 0.9971\n",
      "Epoch 105 Batch 1850 Loss 2.4036 Accuracy 0.9971\n",
      "Epoch 105 Batch 1900 Loss 2.4013 Accuracy 0.9971\n",
      "Epoch 105 Batch 1950 Loss 2.3941 Accuracy 0.9971\n",
      "Epoch 105 Batch 2000 Loss 2.3979 Accuracy 0.9971\n",
      "Epoch 105 Batch 2050 Loss 2.4038 Accuracy 0.9971\n",
      "Epoch 105 Batch 2100 Loss 2.4035 Accuracy 0.9971\n",
      "Epoch 105 Batch 2150 Loss 2.4052 Accuracy 0.9971\n",
      "Epoch 105 Batch 2200 Loss 2.4091 Accuracy 0.9971\n",
      "Epoch 105 Batch 2250 Loss 2.4123 Accuracy 0.9970\n",
      "Epoch 105 Batch 2300 Loss 2.4103 Accuracy 0.9971\n",
      "Epoch 105 Batch 2350 Loss 2.4097 Accuracy 0.9971\n",
      "Epoch 105 Batch 2400 Loss 2.4120 Accuracy 0.9970\n",
      "Epoch 105 Batch 2450 Loss 2.4134 Accuracy 0.9970\n",
      "Epoch 105 Batch 2500 Loss 2.4144 Accuracy 0.9970\n",
      "Epoch 105 Batch 2550 Loss 2.4128 Accuracy 0.9970\n",
      "Epoch 105 Batch 2600 Loss 2.4102 Accuracy 0.9971\n",
      "Epoch 105 Batch 2650 Loss 2.4091 Accuracy 0.9971\n",
      "Saving checkpoint for epoch 105 at ./checkpoints/train\\ckpt-22\n",
      "Epoch 105 Loss 2.4106 Accuracy 0.9971\n",
      "Time taken for 1 epoch: 195.54038906097412 secs\n",
      "\n",
      "Epoch 106 Batch 0 Loss 1.7517 Accuracy 0.9978\n",
      "Epoch 106 Batch 50 Loss 2.4237 Accuracy 0.9970\n",
      "Epoch 106 Batch 100 Loss 2.4285 Accuracy 0.9970\n",
      "Epoch 106 Batch 150 Loss 2.4593 Accuracy 0.9970\n",
      "Epoch 106 Batch 200 Loss 2.3907 Accuracy 0.9971\n",
      "Epoch 106 Batch 250 Loss 2.3853 Accuracy 0.9971\n",
      "Epoch 106 Batch 300 Loss 2.3796 Accuracy 0.9971\n",
      "Epoch 106 Batch 350 Loss 2.3837 Accuracy 0.9971\n",
      "Epoch 106 Batch 400 Loss 2.3854 Accuracy 0.9971\n",
      "Epoch 106 Batch 450 Loss 2.4154 Accuracy 0.9970\n",
      "Epoch 106 Batch 500 Loss 2.4006 Accuracy 0.9970\n",
      "Epoch 106 Batch 550 Loss 2.4116 Accuracy 0.9970\n",
      "Epoch 106 Batch 600 Loss 2.4240 Accuracy 0.9970\n",
      "Epoch 106 Batch 650 Loss 2.4240 Accuracy 0.9970\n",
      "Epoch 106 Batch 700 Loss 2.4215 Accuracy 0.9970\n",
      "Epoch 106 Batch 750 Loss 2.4207 Accuracy 0.9970\n",
      "Epoch 106 Batch 800 Loss 2.4075 Accuracy 0.9970\n",
      "Epoch 106 Batch 850 Loss 2.4158 Accuracy 0.9970\n",
      "Epoch 106 Batch 900 Loss 2.4193 Accuracy 0.9970\n",
      "Epoch 106 Batch 950 Loss 2.4227 Accuracy 0.9970\n",
      "Epoch 106 Batch 1000 Loss 2.4183 Accuracy 0.9970\n",
      "Epoch 106 Batch 1050 Loss 2.4094 Accuracy 0.9970\n",
      "Epoch 106 Batch 1100 Loss 2.4076 Accuracy 0.9970\n",
      "Epoch 106 Batch 1150 Loss 2.4010 Accuracy 0.9970\n",
      "Epoch 106 Batch 1200 Loss 2.4082 Accuracy 0.9970\n",
      "Epoch 106 Batch 1250 Loss 2.4025 Accuracy 0.9970\n",
      "Epoch 106 Batch 1300 Loss 2.4031 Accuracy 0.9970\n",
      "Epoch 106 Batch 1350 Loss 2.4006 Accuracy 0.9970\n",
      "Epoch 106 Batch 1400 Loss 2.4025 Accuracy 0.9970\n",
      "Epoch 106 Batch 1450 Loss 2.3971 Accuracy 0.9971\n",
      "Epoch 106 Batch 1500 Loss 2.3955 Accuracy 0.9971\n",
      "Epoch 106 Batch 1550 Loss 2.3969 Accuracy 0.9971\n",
      "Epoch 106 Batch 1600 Loss 2.3981 Accuracy 0.9971\n",
      "Epoch 106 Batch 1650 Loss 2.3982 Accuracy 0.9971\n",
      "Epoch 106 Batch 1700 Loss 2.3994 Accuracy 0.9971\n",
      "Epoch 106 Batch 1750 Loss 2.3948 Accuracy 0.9971\n",
      "Epoch 106 Batch 1800 Loss 2.3958 Accuracy 0.9971\n",
      "Epoch 106 Batch 1850 Loss 2.3898 Accuracy 0.9971\n",
      "Epoch 106 Batch 1900 Loss 2.3867 Accuracy 0.9971\n",
      "Epoch 106 Batch 1950 Loss 2.3798 Accuracy 0.9971\n",
      "Epoch 106 Batch 2000 Loss 2.3841 Accuracy 0.9971\n",
      "Epoch 106 Batch 2050 Loss 2.3895 Accuracy 0.9971\n",
      "Epoch 106 Batch 2100 Loss 2.3885 Accuracy 0.9971\n",
      "Epoch 106 Batch 2150 Loss 2.3901 Accuracy 0.9971\n",
      "Epoch 106 Batch 2200 Loss 2.3938 Accuracy 0.9971\n",
      "Epoch 106 Batch 2250 Loss 2.3964 Accuracy 0.9971\n",
      "Epoch 106 Batch 2300 Loss 2.3928 Accuracy 0.9971\n",
      "Epoch 106 Batch 2350 Loss 2.3918 Accuracy 0.9971\n",
      "Epoch 106 Batch 2400 Loss 2.3933 Accuracy 0.9971\n",
      "Epoch 106 Batch 2450 Loss 2.3957 Accuracy 0.9971\n",
      "Epoch 106 Batch 2500 Loss 2.3968 Accuracy 0.9971\n",
      "Epoch 106 Batch 2550 Loss 2.3960 Accuracy 0.9971\n",
      "Epoch 106 Batch 2600 Loss 2.3936 Accuracy 0.9971\n",
      "Epoch 106 Batch 2650 Loss 2.3918 Accuracy 0.9971\n",
      "Epoch 106 Loss 2.3923 Accuracy 0.9971\n",
      "Time taken for 1 epoch: 196.15298986434937 secs\n",
      "\n",
      "Epoch 107 Batch 0 Loss 1.7504 Accuracy 0.9978\n",
      "Epoch 107 Batch 50 Loss 2.5064 Accuracy 0.9969\n",
      "Epoch 107 Batch 100 Loss 2.4662 Accuracy 0.9970\n",
      "Epoch 107 Batch 150 Loss 2.4831 Accuracy 0.9969\n",
      "Epoch 107 Batch 200 Loss 2.4123 Accuracy 0.9970\n",
      "Epoch 107 Batch 250 Loss 2.4002 Accuracy 0.9971\n",
      "Epoch 107 Batch 300 Loss 2.3978 Accuracy 0.9971\n",
      "Epoch 107 Batch 350 Loss 2.4021 Accuracy 0.9971\n",
      "Epoch 107 Batch 400 Loss 2.3984 Accuracy 0.9971\n",
      "Epoch 107 Batch 450 Loss 2.4261 Accuracy 0.9970\n",
      "Epoch 107 Batch 500 Loss 2.4150 Accuracy 0.9970\n",
      "Epoch 107 Batch 550 Loss 2.4245 Accuracy 0.9970\n",
      "Epoch 107 Batch 600 Loss 2.4327 Accuracy 0.9970\n",
      "Epoch 107 Batch 650 Loss 2.4291 Accuracy 0.9970\n",
      "Epoch 107 Batch 700 Loss 2.4256 Accuracy 0.9970\n",
      "Epoch 107 Batch 750 Loss 2.4277 Accuracy 0.9970\n",
      "Epoch 107 Batch 800 Loss 2.4162 Accuracy 0.9970\n",
      "Epoch 107 Batch 850 Loss 2.4184 Accuracy 0.9970\n",
      "Epoch 107 Batch 900 Loss 2.4176 Accuracy 0.9970\n",
      "Epoch 107 Batch 950 Loss 2.4184 Accuracy 0.9970\n",
      "Epoch 107 Batch 1000 Loss 2.4178 Accuracy 0.9970\n",
      "Epoch 107 Batch 1050 Loss 2.4104 Accuracy 0.9970\n",
      "Epoch 107 Batch 1100 Loss 2.4118 Accuracy 0.9970\n",
      "Epoch 107 Batch 1150 Loss 2.4068 Accuracy 0.9970\n",
      "Epoch 107 Batch 1200 Loss 2.4167 Accuracy 0.9970\n",
      "Epoch 107 Batch 1250 Loss 2.4127 Accuracy 0.9970\n",
      "Epoch 107 Batch 1300 Loss 2.4150 Accuracy 0.9970\n",
      "Epoch 107 Batch 1350 Loss 2.4111 Accuracy 0.9970\n",
      "Epoch 107 Batch 1400 Loss 2.4130 Accuracy 0.9970\n",
      "Epoch 107 Batch 1450 Loss 2.4076 Accuracy 0.9970\n",
      "Epoch 107 Batch 1500 Loss 2.4066 Accuracy 0.9970\n",
      "Epoch 107 Batch 1550 Loss 2.4089 Accuracy 0.9970\n",
      "Epoch 107 Batch 1600 Loss 2.4098 Accuracy 0.9970\n",
      "Epoch 107 Batch 1650 Loss 2.4109 Accuracy 0.9970\n",
      "Epoch 107 Batch 1700 Loss 2.4125 Accuracy 0.9970\n",
      "Epoch 107 Batch 1750 Loss 2.4072 Accuracy 0.9970\n",
      "Epoch 107 Batch 1800 Loss 2.4081 Accuracy 0.9970\n",
      "Epoch 107 Batch 1850 Loss 2.4014 Accuracy 0.9971\n",
      "Epoch 107 Batch 1900 Loss 2.3968 Accuracy 0.9971\n",
      "Epoch 107 Batch 1950 Loss 2.3903 Accuracy 0.9971\n",
      "Epoch 107 Batch 2000 Loss 2.3959 Accuracy 0.9971\n",
      "Epoch 107 Batch 2050 Loss 2.4006 Accuracy 0.9971\n",
      "Epoch 107 Batch 2100 Loss 2.3980 Accuracy 0.9971\n",
      "Epoch 107 Batch 2150 Loss 2.3975 Accuracy 0.9971\n",
      "Epoch 107 Batch 2200 Loss 2.4021 Accuracy 0.9971\n",
      "Epoch 107 Batch 2250 Loss 2.4031 Accuracy 0.9971\n",
      "Epoch 107 Batch 2300 Loss 2.4007 Accuracy 0.9971\n",
      "Epoch 107 Batch 2350 Loss 2.4001 Accuracy 0.9971\n",
      "Epoch 107 Batch 2400 Loss 2.4018 Accuracy 0.9971\n",
      "Epoch 107 Batch 2450 Loss 2.4044 Accuracy 0.9971\n",
      "Epoch 107 Batch 2500 Loss 2.4056 Accuracy 0.9971\n",
      "Epoch 107 Batch 2550 Loss 2.4040 Accuracy 0.9971\n",
      "Epoch 107 Batch 2600 Loss 2.4020 Accuracy 0.9971\n",
      "Epoch 107 Batch 2650 Loss 2.4004 Accuracy 0.9971\n",
      "Epoch 107 Loss 2.4006 Accuracy 0.9971\n",
      "Time taken for 1 epoch: 194.4199275970459 secs\n",
      "\n",
      "Epoch 108 Batch 0 Loss 1.5858 Accuracy 0.9980\n",
      "Epoch 108 Batch 50 Loss 2.3781 Accuracy 0.9971\n",
      "Epoch 108 Batch 100 Loss 2.3939 Accuracy 0.9971\n",
      "Epoch 108 Batch 150 Loss 2.4246 Accuracy 0.9970\n",
      "Epoch 108 Batch 200 Loss 2.3612 Accuracy 0.9971\n",
      "Epoch 108 Batch 250 Loss 2.3572 Accuracy 0.9971\n",
      "Epoch 108 Batch 300 Loss 2.3579 Accuracy 0.9971\n",
      "Epoch 108 Batch 350 Loss 2.3580 Accuracy 0.9971\n",
      "Epoch 108 Batch 400 Loss 2.3626 Accuracy 0.9971\n",
      "Epoch 108 Batch 450 Loss 2.3993 Accuracy 0.9971\n",
      "Epoch 108 Batch 500 Loss 2.3862 Accuracy 0.9971\n",
      "Epoch 108 Batch 550 Loss 2.3985 Accuracy 0.9971\n",
      "Epoch 108 Batch 600 Loss 2.4137 Accuracy 0.9970\n",
      "Epoch 108 Batch 650 Loss 2.4145 Accuracy 0.9970\n",
      "Epoch 108 Batch 700 Loss 2.4135 Accuracy 0.9970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108 Batch 750 Loss 2.4136 Accuracy 0.9970\n",
      "Epoch 108 Batch 800 Loss 2.4020 Accuracy 0.9970\n",
      "Epoch 108 Batch 850 Loss 2.4052 Accuracy 0.9970\n",
      "Epoch 108 Batch 900 Loss 2.4052 Accuracy 0.9970\n",
      "Epoch 108 Batch 950 Loss 2.4116 Accuracy 0.9970\n",
      "Epoch 108 Batch 1000 Loss 2.4099 Accuracy 0.9970\n",
      "Epoch 108 Batch 1050 Loss 2.3969 Accuracy 0.9971\n",
      "Epoch 108 Batch 1100 Loss 2.3935 Accuracy 0.9971\n",
      "Epoch 108 Batch 1150 Loss 2.3872 Accuracy 0.9971\n",
      "Epoch 108 Batch 1200 Loss 2.3990 Accuracy 0.9971\n",
      "Epoch 108 Batch 1250 Loss 2.3945 Accuracy 0.9971\n",
      "Epoch 108 Batch 1300 Loss 2.3970 Accuracy 0.9971\n",
      "Epoch 108 Batch 1350 Loss 2.3945 Accuracy 0.9971\n",
      "Epoch 108 Batch 1400 Loss 2.3961 Accuracy 0.9971\n",
      "Epoch 108 Batch 1450 Loss 2.3891 Accuracy 0.9971\n",
      "Epoch 108 Batch 1500 Loss 2.3868 Accuracy 0.9971\n",
      "Epoch 108 Batch 1550 Loss 2.3886 Accuracy 0.9971\n",
      "Epoch 108 Batch 1600 Loss 2.3890 Accuracy 0.9971\n",
      "Epoch 108 Batch 1650 Loss 2.3914 Accuracy 0.9971\n",
      "Epoch 108 Batch 1700 Loss 2.3945 Accuracy 0.9971\n",
      "Epoch 108 Batch 1750 Loss 2.3906 Accuracy 0.9971\n",
      "Epoch 108 Batch 1800 Loss 2.3913 Accuracy 0.9971\n",
      "Epoch 108 Batch 1850 Loss 2.3867 Accuracy 0.9971\n",
      "Epoch 108 Batch 1900 Loss 2.3823 Accuracy 0.9971\n",
      "Epoch 108 Batch 1950 Loss 2.3756 Accuracy 0.9971\n",
      "Epoch 108 Batch 2000 Loss 2.3820 Accuracy 0.9971\n",
      "Epoch 108 Batch 2050 Loss 2.3880 Accuracy 0.9971\n",
      "Epoch 108 Batch 2100 Loss 2.3857 Accuracy 0.9971\n",
      "Epoch 108 Batch 2150 Loss 2.3864 Accuracy 0.9971\n",
      "Epoch 108 Batch 2200 Loss 2.3900 Accuracy 0.9971\n",
      "Epoch 108 Batch 2250 Loss 2.3930 Accuracy 0.9971\n",
      "Epoch 108 Batch 2300 Loss 2.3904 Accuracy 0.9971\n",
      "Epoch 108 Batch 2350 Loss 2.3901 Accuracy 0.9971\n",
      "Epoch 108 Batch 2400 Loss 2.3916 Accuracy 0.9971\n",
      "Epoch 108 Batch 2450 Loss 2.3948 Accuracy 0.9971\n",
      "Epoch 108 Batch 2500 Loss 2.3966 Accuracy 0.9971\n",
      "Epoch 108 Batch 2550 Loss 2.3944 Accuracy 0.9971\n",
      "Epoch 108 Batch 2600 Loss 2.3920 Accuracy 0.9971\n",
      "Epoch 108 Batch 2650 Loss 2.3912 Accuracy 0.9971\n",
      "Epoch 108 Loss 2.3935 Accuracy 0.9971\n",
      "Time taken for 1 epoch: 198.02361631393433 secs\n",
      "\n",
      "Epoch 109 Batch 0 Loss 2.1781 Accuracy 0.9972\n",
      "Epoch 109 Batch 50 Loss 2.4294 Accuracy 0.9970\n",
      "Epoch 109 Batch 100 Loss 2.4090 Accuracy 0.9970\n",
      "Epoch 109 Batch 150 Loss 2.4223 Accuracy 0.9970\n",
      "Epoch 109 Batch 200 Loss 2.3545 Accuracy 0.9971\n",
      "Epoch 109 Batch 250 Loss 2.3589 Accuracy 0.9971\n",
      "Epoch 109 Batch 300 Loss 2.3561 Accuracy 0.9971\n",
      "Epoch 109 Batch 350 Loss 2.3599 Accuracy 0.9971\n",
      "Epoch 109 Batch 400 Loss 2.3522 Accuracy 0.9971\n",
      "Epoch 109 Batch 450 Loss 2.3891 Accuracy 0.9971\n",
      "Epoch 109 Batch 500 Loss 2.3754 Accuracy 0.9971\n",
      "Epoch 109 Batch 550 Loss 2.3904 Accuracy 0.9971\n",
      "Epoch 109 Batch 600 Loss 2.4017 Accuracy 0.9970\n",
      "Epoch 109 Batch 650 Loss 2.3964 Accuracy 0.9971\n",
      "Epoch 109 Batch 700 Loss 2.3965 Accuracy 0.9971\n",
      "Epoch 109 Batch 750 Loss 2.3975 Accuracy 0.9971\n",
      "Epoch 109 Batch 800 Loss 2.3831 Accuracy 0.9971\n",
      "Epoch 109 Batch 850 Loss 2.3926 Accuracy 0.9971\n",
      "Epoch 109 Batch 900 Loss 2.3935 Accuracy 0.9971\n",
      "Epoch 109 Batch 950 Loss 2.4004 Accuracy 0.9971\n",
      "Epoch 109 Batch 1000 Loss 2.3962 Accuracy 0.9971\n",
      "Epoch 109 Batch 1050 Loss 2.3891 Accuracy 0.9971\n",
      "Epoch 109 Batch 1100 Loss 2.3888 Accuracy 0.9971\n",
      "Epoch 109 Batch 1150 Loss 2.3799 Accuracy 0.9971\n",
      "Epoch 109 Batch 1200 Loss 2.3907 Accuracy 0.9971\n",
      "Epoch 109 Batch 1250 Loss 2.3858 Accuracy 0.9971\n",
      "Epoch 109 Batch 1300 Loss 2.3866 Accuracy 0.9971\n",
      "Epoch 109 Batch 1350 Loss 2.3830 Accuracy 0.9971\n",
      "Epoch 109 Batch 1400 Loss 2.3838 Accuracy 0.9971\n",
      "Epoch 109 Batch 1450 Loss 2.3773 Accuracy 0.9971\n",
      "Epoch 109 Batch 1500 Loss 2.3761 Accuracy 0.9971\n",
      "Epoch 109 Batch 1550 Loss 2.3782 Accuracy 0.9971\n",
      "Epoch 109 Batch 1600 Loss 2.3777 Accuracy 0.9971\n",
      "Epoch 109 Batch 1650 Loss 2.3808 Accuracy 0.9971\n",
      "Epoch 109 Batch 1700 Loss 2.3827 Accuracy 0.9971\n",
      "Epoch 109 Batch 1750 Loss 2.3780 Accuracy 0.9971\n",
      "Epoch 109 Batch 1800 Loss 2.3797 Accuracy 0.9971\n",
      "Epoch 109 Batch 1850 Loss 2.3742 Accuracy 0.9971\n",
      "Epoch 109 Batch 1900 Loss 2.3710 Accuracy 0.9971\n",
      "Epoch 109 Batch 1950 Loss 2.3637 Accuracy 0.9971\n",
      "Epoch 109 Batch 2000 Loss 2.3676 Accuracy 0.9971\n",
      "Epoch 109 Batch 2050 Loss 2.3733 Accuracy 0.9971\n",
      "Epoch 109 Batch 2100 Loss 2.3735 Accuracy 0.9971\n",
      "Epoch 109 Batch 2150 Loss 2.3759 Accuracy 0.9971\n",
      "Epoch 109 Batch 2200 Loss 2.3800 Accuracy 0.9971\n",
      "Epoch 109 Batch 2250 Loss 2.3827 Accuracy 0.9971\n",
      "Epoch 109 Batch 2300 Loss 2.3796 Accuracy 0.9971\n",
      "Epoch 109 Batch 2350 Loss 2.3797 Accuracy 0.9971\n",
      "Epoch 109 Batch 2400 Loss 2.3814 Accuracy 0.9971\n",
      "Epoch 109 Batch 2450 Loss 2.3834 Accuracy 0.9971\n",
      "Epoch 109 Batch 2500 Loss 2.3847 Accuracy 0.9971\n",
      "Epoch 109 Batch 2550 Loss 2.3843 Accuracy 0.9971\n",
      "Epoch 109 Batch 2600 Loss 2.3825 Accuracy 0.9971\n",
      "Epoch 109 Batch 2650 Loss 2.3807 Accuracy 0.9971\n",
      "Epoch 109 Loss 2.3815 Accuracy 0.9971\n",
      "Time taken for 1 epoch: 196.3832128047943 secs\n",
      "\n",
      "Epoch 110 Batch 0 Loss 1.6028 Accuracy 0.9981\n",
      "Epoch 110 Batch 50 Loss 2.4035 Accuracy 0.9970\n",
      "Epoch 110 Batch 100 Loss 2.4193 Accuracy 0.9970\n",
      "Epoch 110 Batch 150 Loss 2.4511 Accuracy 0.9970\n",
      "Epoch 110 Batch 200 Loss 2.3836 Accuracy 0.9971\n",
      "Epoch 110 Batch 250 Loss 2.3765 Accuracy 0.9971\n",
      "Epoch 110 Batch 300 Loss 2.3780 Accuracy 0.9971\n",
      "Epoch 110 Batch 350 Loss 2.3670 Accuracy 0.9971\n",
      "Epoch 110 Batch 400 Loss 2.3598 Accuracy 0.9971\n",
      "Epoch 110 Batch 450 Loss 2.3881 Accuracy 0.9971\n",
      "Epoch 110 Batch 500 Loss 2.3810 Accuracy 0.9971\n",
      "Epoch 110 Batch 550 Loss 2.3931 Accuracy 0.9971\n",
      "Epoch 110 Batch 600 Loss 2.4079 Accuracy 0.9970\n",
      "Epoch 110 Batch 650 Loss 2.4043 Accuracy 0.9970\n",
      "Epoch 110 Batch 700 Loss 2.4046 Accuracy 0.9970\n",
      "Epoch 110 Batch 750 Loss 2.4071 Accuracy 0.9970\n",
      "Epoch 110 Batch 800 Loss 2.3936 Accuracy 0.9971\n",
      "Epoch 110 Batch 850 Loss 2.3964 Accuracy 0.9971\n",
      "Epoch 110 Batch 900 Loss 2.3957 Accuracy 0.9971\n",
      "Epoch 110 Batch 950 Loss 2.3996 Accuracy 0.9971\n",
      "Epoch 110 Batch 1000 Loss 2.3963 Accuracy 0.9971\n",
      "Epoch 110 Batch 1050 Loss 2.3868 Accuracy 0.9971\n",
      "Epoch 110 Batch 1100 Loss 2.3862 Accuracy 0.9971\n",
      "Epoch 110 Batch 1150 Loss 2.3796 Accuracy 0.9971\n",
      "Epoch 110 Batch 1200 Loss 2.3897 Accuracy 0.9971\n",
      "Epoch 110 Batch 1250 Loss 2.3859 Accuracy 0.9971\n",
      "Epoch 110 Batch 1300 Loss 2.3869 Accuracy 0.9971\n",
      "Epoch 110 Batch 1350 Loss 2.3835 Accuracy 0.9971\n",
      "Epoch 110 Batch 1400 Loss 2.3854 Accuracy 0.9971\n",
      "Epoch 110 Batch 1450 Loss 2.3800 Accuracy 0.9971\n",
      "Epoch 110 Batch 1500 Loss 2.3787 Accuracy 0.9971\n",
      "Epoch 110 Batch 1550 Loss 2.3798 Accuracy 0.9971\n",
      "Epoch 110 Batch 1600 Loss 2.3795 Accuracy 0.9971\n",
      "Epoch 110 Batch 1650 Loss 2.3803 Accuracy 0.9971\n",
      "Epoch 110 Batch 1700 Loss 2.3824 Accuracy 0.9971\n",
      "Epoch 110 Batch 1750 Loss 2.3775 Accuracy 0.9971\n",
      "Epoch 110 Batch 1800 Loss 2.3790 Accuracy 0.9971\n",
      "Epoch 110 Batch 1850 Loss 2.3736 Accuracy 0.9971\n",
      "Epoch 110 Batch 1900 Loss 2.3711 Accuracy 0.9971\n",
      "Epoch 110 Batch 1950 Loss 2.3646 Accuracy 0.9971\n",
      "Epoch 110 Batch 2000 Loss 2.3688 Accuracy 0.9971\n",
      "Epoch 110 Batch 2050 Loss 2.3761 Accuracy 0.9971\n",
      "Epoch 110 Batch 2100 Loss 2.3742 Accuracy 0.9971\n",
      "Epoch 110 Batch 2150 Loss 2.3756 Accuracy 0.9971\n",
      "Epoch 110 Batch 2200 Loss 2.3792 Accuracy 0.9971\n",
      "Epoch 110 Batch 2250 Loss 2.3795 Accuracy 0.9971\n",
      "Epoch 110 Batch 2300 Loss 2.3769 Accuracy 0.9971\n",
      "Epoch 110 Batch 2350 Loss 2.3765 Accuracy 0.9971\n",
      "Epoch 110 Batch 2400 Loss 2.3773 Accuracy 0.9971\n",
      "Epoch 110 Batch 2450 Loss 2.3791 Accuracy 0.9971\n",
      "Epoch 110 Batch 2500 Loss 2.3816 Accuracy 0.9971\n",
      "Epoch 110 Batch 2550 Loss 2.3804 Accuracy 0.9971\n",
      "Epoch 110 Batch 2600 Loss 2.3779 Accuracy 0.9971\n",
      "Epoch 110 Batch 2650 Loss 2.3770 Accuracy 0.9971\n",
      "Saving checkpoint for epoch 110 at ./checkpoints/train\\ckpt-23\n",
      "Epoch 110 Loss 2.3782 Accuracy 0.9971\n",
      "Time taken for 1 epoch: 194.68340158462524 secs\n",
      "\n",
      "Epoch 111 Batch 0 Loss 1.7575 Accuracy 0.9978\n",
      "Epoch 111 Batch 50 Loss 2.4408 Accuracy 0.9970\n",
      "Epoch 111 Batch 100 Loss 2.4034 Accuracy 0.9970\n",
      "Epoch 111 Batch 150 Loss 2.4294 Accuracy 0.9970\n",
      "Epoch 111 Batch 200 Loss 2.3681 Accuracy 0.9971\n",
      "Epoch 111 Batch 250 Loss 2.3588 Accuracy 0.9971\n",
      "Epoch 111 Batch 300 Loss 2.3587 Accuracy 0.9971\n",
      "Epoch 111 Batch 350 Loss 2.3668 Accuracy 0.9971\n",
      "Epoch 111 Batch 400 Loss 2.3598 Accuracy 0.9971\n",
      "Epoch 111 Batch 450 Loss 2.3902 Accuracy 0.9971\n",
      "Epoch 111 Batch 500 Loss 2.3833 Accuracy 0.9971\n",
      "Epoch 111 Batch 550 Loss 2.3940 Accuracy 0.9971\n",
      "Epoch 111 Batch 600 Loss 2.4052 Accuracy 0.9970\n",
      "Epoch 111 Batch 650 Loss 2.4039 Accuracy 0.9970\n",
      "Epoch 111 Batch 700 Loss 2.4023 Accuracy 0.9971\n",
      "Epoch 111 Batch 750 Loss 2.4019 Accuracy 0.9971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111 Batch 800 Loss 2.3921 Accuracy 0.9971\n",
      "Epoch 111 Batch 850 Loss 2.3941 Accuracy 0.9971\n",
      "Epoch 111 Batch 900 Loss 2.3934 Accuracy 0.9971\n",
      "Epoch 111 Batch 950 Loss 2.3987 Accuracy 0.9971\n",
      "Epoch 111 Batch 1000 Loss 2.3934 Accuracy 0.9971\n",
      "Epoch 111 Batch 1050 Loss 2.3827 Accuracy 0.9971\n",
      "Epoch 111 Batch 1100 Loss 2.3819 Accuracy 0.9971\n",
      "Epoch 111 Batch 1150 Loss 2.3740 Accuracy 0.9971\n",
      "Epoch 111 Batch 1200 Loss 2.3829 Accuracy 0.9971\n",
      "Epoch 111 Batch 1250 Loss 2.3759 Accuracy 0.9971\n",
      "Epoch 111 Batch 1300 Loss 2.3770 Accuracy 0.9971\n",
      "Epoch 111 Batch 1350 Loss 2.3744 Accuracy 0.9971\n",
      "Epoch 111 Batch 1400 Loss 2.3766 Accuracy 0.9971\n",
      "Epoch 111 Batch 1450 Loss 2.3705 Accuracy 0.9971\n",
      "Epoch 111 Batch 1500 Loss 2.3690 Accuracy 0.9971\n",
      "Epoch 111 Batch 1550 Loss 2.3708 Accuracy 0.9971\n",
      "Epoch 111 Batch 1600 Loss 2.3728 Accuracy 0.9971\n",
      "Epoch 111 Batch 1650 Loss 2.3740 Accuracy 0.9971\n",
      "Epoch 111 Batch 1700 Loss 2.3748 Accuracy 0.9971\n",
      "Epoch 111 Batch 1750 Loss 2.3690 Accuracy 0.9971\n",
      "Epoch 111 Batch 1800 Loss 2.3699 Accuracy 0.9971\n",
      "Epoch 111 Batch 1850 Loss 2.3648 Accuracy 0.9971\n",
      "Epoch 111 Batch 1900 Loss 2.3605 Accuracy 0.9971\n",
      "Epoch 111 Batch 1950 Loss 2.3540 Accuracy 0.9971\n",
      "Epoch 111 Batch 2000 Loss 2.3602 Accuracy 0.9971\n",
      "Epoch 111 Batch 2050 Loss 2.3656 Accuracy 0.9971\n",
      "Epoch 111 Batch 2100 Loss 2.3640 Accuracy 0.9971\n",
      "Epoch 111 Batch 2150 Loss 2.3649 Accuracy 0.9971\n",
      "Epoch 111 Batch 2200 Loss 2.3693 Accuracy 0.9971\n",
      "Epoch 111 Batch 2250 Loss 2.3719 Accuracy 0.9971\n",
      "Epoch 111 Batch 2300 Loss 2.3698 Accuracy 0.9971\n",
      "Epoch 111 Batch 2350 Loss 2.3709 Accuracy 0.9971\n",
      "Epoch 111 Batch 2400 Loss 2.3723 Accuracy 0.9971\n",
      "Epoch 111 Batch 2450 Loss 2.3748 Accuracy 0.9971\n",
      "Epoch 111 Batch 2500 Loss 2.3770 Accuracy 0.9971\n",
      "Epoch 111 Batch 2550 Loss 2.3762 Accuracy 0.9971\n",
      "Epoch 111 Batch 2600 Loss 2.3739 Accuracy 0.9971\n",
      "Epoch 111 Batch 2650 Loss 2.3730 Accuracy 0.9971\n",
      "Epoch 111 Loss 2.3744 Accuracy 0.9971\n",
      "Time taken for 1 epoch: 195.51669454574585 secs\n",
      "\n",
      "Epoch 112 Batch 0 Loss 1.6994 Accuracy 0.9981\n",
      "Epoch 112 Batch 50 Loss 2.3963 Accuracy 0.9970\n",
      "Epoch 112 Batch 100 Loss 2.3899 Accuracy 0.9970\n",
      "Epoch 112 Batch 150 Loss 2.4164 Accuracy 0.9970\n",
      "Epoch 112 Batch 200 Loss 2.3714 Accuracy 0.9971\n",
      "Epoch 112 Batch 250 Loss 2.3641 Accuracy 0.9971\n",
      "Epoch 112 Batch 300 Loss 2.3637 Accuracy 0.9971\n",
      "Epoch 112 Batch 350 Loss 2.3691 Accuracy 0.9971\n",
      "Epoch 112 Batch 400 Loss 2.3698 Accuracy 0.9971\n",
      "Epoch 112 Batch 450 Loss 2.3950 Accuracy 0.9971\n",
      "Epoch 112 Batch 500 Loss 2.3771 Accuracy 0.9971\n",
      "Epoch 112 Batch 550 Loss 2.3881 Accuracy 0.9971\n",
      "Epoch 112 Batch 600 Loss 2.4001 Accuracy 0.9971\n",
      "Epoch 112 Batch 650 Loss 2.3942 Accuracy 0.9971\n",
      "Epoch 112 Batch 700 Loss 2.3911 Accuracy 0.9971\n",
      "Epoch 112 Batch 750 Loss 2.3941 Accuracy 0.9971\n",
      "Epoch 112 Batch 800 Loss 2.3813 Accuracy 0.9971\n",
      "Epoch 112 Batch 850 Loss 2.3880 Accuracy 0.9971\n",
      "Epoch 112 Batch 900 Loss 2.3887 Accuracy 0.9971\n",
      "Epoch 112 Batch 950 Loss 2.3933 Accuracy 0.9971\n",
      "Epoch 112 Batch 1000 Loss 2.3897 Accuracy 0.9971\n",
      "Epoch 112 Batch 1050 Loss 2.3791 Accuracy 0.9971\n",
      "Epoch 112 Batch 1100 Loss 2.3756 Accuracy 0.9971\n",
      "Epoch 112 Batch 1150 Loss 2.3694 Accuracy 0.9971\n",
      "Epoch 112 Batch 1200 Loss 2.3789 Accuracy 0.9971\n",
      "Epoch 112 Batch 1250 Loss 2.3745 Accuracy 0.9971\n",
      "Epoch 112 Batch 1300 Loss 2.3764 Accuracy 0.9971\n",
      "Epoch 112 Batch 1350 Loss 2.3737 Accuracy 0.9971\n",
      "Epoch 112 Batch 1400 Loss 2.3770 Accuracy 0.9971\n",
      "Epoch 112 Batch 1450 Loss 2.3721 Accuracy 0.9971\n",
      "Epoch 112 Batch 1500 Loss 2.3704 Accuracy 0.9971\n",
      "Epoch 112 Batch 1550 Loss 2.3729 Accuracy 0.9971\n",
      "Epoch 112 Batch 1600 Loss 2.3728 Accuracy 0.9971\n",
      "Epoch 112 Batch 1650 Loss 2.3731 Accuracy 0.9971\n",
      "Epoch 112 Batch 1700 Loss 2.3766 Accuracy 0.9971\n",
      "Epoch 112 Batch 1750 Loss 2.3720 Accuracy 0.9971\n",
      "Epoch 112 Batch 1800 Loss 2.3745 Accuracy 0.9971\n",
      "Epoch 112 Batch 1850 Loss 2.3680 Accuracy 0.9971\n",
      "Epoch 112 Batch 1900 Loss 2.3648 Accuracy 0.9971\n",
      "Epoch 112 Batch 1950 Loss 2.3567 Accuracy 0.9971\n",
      "Epoch 112 Batch 2000 Loss 2.3611 Accuracy 0.9971\n",
      "Epoch 112 Batch 2050 Loss 2.3660 Accuracy 0.9971\n",
      "Epoch 112 Batch 2100 Loss 2.3648 Accuracy 0.9971\n",
      "Epoch 112 Batch 2150 Loss 2.3681 Accuracy 0.9971\n",
      "Epoch 112 Batch 2200 Loss 2.3703 Accuracy 0.9971\n",
      "Epoch 112 Batch 2250 Loss 2.3707 Accuracy 0.9971\n",
      "Epoch 112 Batch 2300 Loss 2.3680 Accuracy 0.9971\n",
      "Epoch 112 Batch 2350 Loss 2.3677 Accuracy 0.9971\n",
      "Epoch 112 Batch 2400 Loss 2.3694 Accuracy 0.9971\n",
      "Epoch 112 Batch 2450 Loss 2.3697 Accuracy 0.9971\n",
      "Epoch 112 Batch 2500 Loss 2.3717 Accuracy 0.9971\n",
      "Epoch 112 Batch 2550 Loss 2.3707 Accuracy 0.9971\n",
      "Epoch 112 Batch 2600 Loss 2.3682 Accuracy 0.9971\n",
      "Epoch 112 Batch 2650 Loss 2.3667 Accuracy 0.9971\n",
      "Epoch 112 Loss 2.3670 Accuracy 0.9971\n",
      "Time taken for 1 epoch: 195.25988245010376 secs\n",
      "\n",
      "Epoch 113 Batch 0 Loss 1.9093 Accuracy 0.9977\n",
      "Epoch 113 Batch 50 Loss 2.3387 Accuracy 0.9971\n",
      "Epoch 113 Batch 100 Loss 2.3710 Accuracy 0.9971\n",
      "Epoch 113 Batch 150 Loss 2.4065 Accuracy 0.9970\n",
      "Epoch 113 Batch 200 Loss 2.3371 Accuracy 0.9971\n",
      "Epoch 113 Batch 250 Loss 2.3195 Accuracy 0.9972\n",
      "Epoch 113 Batch 300 Loss 2.3249 Accuracy 0.9971\n",
      "Epoch 113 Batch 350 Loss 2.3242 Accuracy 0.9971\n",
      "Epoch 113 Batch 400 Loss 2.3223 Accuracy 0.9971\n",
      "Epoch 113 Batch 450 Loss 2.3548 Accuracy 0.9971\n",
      "Epoch 113 Batch 500 Loss 2.3462 Accuracy 0.9971\n",
      "Epoch 113 Batch 550 Loss 2.3621 Accuracy 0.9971\n",
      "Epoch 113 Batch 600 Loss 2.3776 Accuracy 0.9971\n",
      "Epoch 113 Batch 650 Loss 2.3772 Accuracy 0.9971\n",
      "Epoch 113 Batch 700 Loss 2.3708 Accuracy 0.9971\n",
      "Epoch 113 Batch 750 Loss 2.3713 Accuracy 0.9971\n",
      "Epoch 113 Batch 800 Loss 2.3610 Accuracy 0.9971\n",
      "Epoch 113 Batch 850 Loss 2.3656 Accuracy 0.9971\n",
      "Epoch 113 Batch 900 Loss 2.3687 Accuracy 0.9971\n",
      "Epoch 113 Batch 950 Loss 2.3735 Accuracy 0.9971\n",
      "Epoch 113 Batch 1000 Loss 2.3712 Accuracy 0.9971\n",
      "Epoch 113 Batch 1050 Loss 2.3627 Accuracy 0.9971\n",
      "Epoch 113 Batch 1100 Loss 2.3601 Accuracy 0.9971\n",
      "Epoch 113 Batch 1150 Loss 2.3544 Accuracy 0.9971\n",
      "Epoch 113 Batch 1200 Loss 2.3638 Accuracy 0.9971\n",
      "Epoch 113 Batch 1250 Loss 2.3608 Accuracy 0.9971\n",
      "Epoch 113 Batch 1300 Loss 2.3637 Accuracy 0.9971\n",
      "Epoch 113 Batch 1350 Loss 2.3600 Accuracy 0.9971\n",
      "Epoch 113 Batch 1400 Loss 2.3617 Accuracy 0.9971\n",
      "Epoch 113 Batch 1450 Loss 2.3547 Accuracy 0.9971\n",
      "Epoch 113 Batch 1500 Loss 2.3516 Accuracy 0.9971\n",
      "Epoch 113 Batch 1550 Loss 2.3555 Accuracy 0.9971\n",
      "Epoch 113 Batch 1600 Loss 2.3553 Accuracy 0.9971\n",
      "Epoch 113 Batch 1650 Loss 2.3567 Accuracy 0.9971\n",
      "Epoch 113 Batch 1700 Loss 2.3592 Accuracy 0.9971\n",
      "Epoch 113 Batch 1750 Loss 2.3529 Accuracy 0.9971\n",
      "Epoch 113 Batch 1800 Loss 2.3549 Accuracy 0.9971\n",
      "Epoch 113 Batch 1850 Loss 2.3475 Accuracy 0.9971\n",
      "Epoch 113 Batch 1900 Loss 2.3429 Accuracy 0.9971\n",
      "Epoch 113 Batch 1950 Loss 2.3357 Accuracy 0.9971\n",
      "Epoch 113 Batch 2000 Loss 2.3401 Accuracy 0.9971\n",
      "Epoch 113 Batch 2050 Loss 2.3453 Accuracy 0.9971\n",
      "Epoch 113 Batch 2100 Loss 2.3444 Accuracy 0.9971\n",
      "Epoch 113 Batch 2150 Loss 2.3468 Accuracy 0.9971\n",
      "Epoch 113 Batch 2200 Loss 2.3509 Accuracy 0.9971\n",
      "Epoch 113 Batch 2250 Loss 2.3528 Accuracy 0.9971\n",
      "Epoch 113 Batch 2300 Loss 2.3497 Accuracy 0.9971\n",
      "Epoch 113 Batch 2350 Loss 2.3493 Accuracy 0.9971\n",
      "Epoch 113 Batch 2400 Loss 2.3513 Accuracy 0.9971\n",
      "Epoch 113 Batch 2450 Loss 2.3532 Accuracy 0.9971\n",
      "Epoch 113 Batch 2500 Loss 2.3552 Accuracy 0.9971\n",
      "Epoch 113 Batch 2550 Loss 2.3544 Accuracy 0.9971\n",
      "Epoch 113 Batch 2600 Loss 2.3533 Accuracy 0.9971\n",
      "Epoch 113 Batch 2650 Loss 2.3514 Accuracy 0.9971\n",
      "Epoch 113 Loss 2.3532 Accuracy 0.9971\n",
      "Time taken for 1 epoch: 195.690247297287 secs\n",
      "\n",
      "Epoch 114 Batch 0 Loss 1.5270 Accuracy 0.9984\n",
      "Epoch 114 Batch 50 Loss 2.3681 Accuracy 0.9971\n",
      "Epoch 114 Batch 100 Loss 2.3844 Accuracy 0.9971\n",
      "Epoch 114 Batch 150 Loss 2.4136 Accuracy 0.9970\n",
      "Epoch 114 Batch 200 Loss 2.3469 Accuracy 0.9971\n",
      "Epoch 114 Batch 250 Loss 2.3199 Accuracy 0.9972\n",
      "Epoch 114 Batch 300 Loss 2.3250 Accuracy 0.9972\n",
      "Epoch 114 Batch 350 Loss 2.3239 Accuracy 0.9972\n",
      "Epoch 114 Batch 400 Loss 2.3184 Accuracy 0.9972\n",
      "Epoch 114 Batch 450 Loss 2.3517 Accuracy 0.9971\n",
      "Epoch 114 Batch 500 Loss 2.3377 Accuracy 0.9971\n",
      "Epoch 114 Batch 550 Loss 2.3484 Accuracy 0.9971\n",
      "Epoch 114 Batch 600 Loss 2.3623 Accuracy 0.9971\n",
      "Epoch 114 Batch 650 Loss 2.3623 Accuracy 0.9971\n",
      "Epoch 114 Batch 700 Loss 2.3589 Accuracy 0.9971\n",
      "Epoch 114 Batch 750 Loss 2.3605 Accuracy 0.9971\n",
      "Epoch 114 Batch 800 Loss 2.3478 Accuracy 0.9971\n",
      "Epoch 114 Batch 850 Loss 2.3540 Accuracy 0.9971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114 Batch 900 Loss 2.3535 Accuracy 0.9971\n",
      "Epoch 114 Batch 950 Loss 2.3577 Accuracy 0.9971\n",
      "Epoch 114 Batch 1000 Loss 2.3535 Accuracy 0.9971\n",
      "Epoch 114 Batch 1050 Loss 2.3462 Accuracy 0.9971\n",
      "Epoch 114 Batch 1100 Loss 2.3467 Accuracy 0.9971\n",
      "Epoch 114 Batch 1150 Loss 2.3386 Accuracy 0.9971\n",
      "Epoch 114 Batch 1200 Loss 2.3474 Accuracy 0.9971\n",
      "Epoch 114 Batch 1250 Loss 2.3426 Accuracy 0.9971\n",
      "Epoch 114 Batch 1300 Loss 2.3422 Accuracy 0.9971\n",
      "Epoch 114 Batch 1350 Loss 2.3400 Accuracy 0.9971\n",
      "Epoch 114 Batch 1400 Loss 2.3426 Accuracy 0.9971\n",
      "Epoch 114 Batch 1450 Loss 2.3386 Accuracy 0.9971\n",
      "Epoch 114 Batch 1500 Loss 2.3358 Accuracy 0.9971\n",
      "Epoch 114 Batch 1550 Loss 2.3370 Accuracy 0.9971\n",
      "Epoch 114 Batch 1600 Loss 2.3371 Accuracy 0.9971\n",
      "Epoch 114 Batch 1650 Loss 2.3358 Accuracy 0.9971\n",
      "Epoch 114 Batch 1700 Loss 2.3400 Accuracy 0.9971\n",
      "Epoch 114 Batch 1750 Loss 2.3365 Accuracy 0.9971\n",
      "Epoch 114 Batch 1800 Loss 2.3390 Accuracy 0.9971\n",
      "Epoch 114 Batch 1850 Loss 2.3331 Accuracy 0.9971\n",
      "Epoch 114 Batch 1900 Loss 2.3297 Accuracy 0.9972\n",
      "Epoch 114 Batch 1950 Loss 2.3233 Accuracy 0.9972\n",
      "Epoch 114 Batch 2000 Loss 2.3284 Accuracy 0.9972\n",
      "Epoch 114 Batch 2050 Loss 2.3339 Accuracy 0.9971\n",
      "Epoch 114 Batch 2100 Loss 2.3332 Accuracy 0.9971\n",
      "Epoch 114 Batch 2150 Loss 2.3341 Accuracy 0.9971\n",
      "Epoch 114 Batch 2200 Loss 2.3379 Accuracy 0.9971\n",
      "Epoch 114 Batch 2250 Loss 2.3393 Accuracy 0.9971\n",
      "Epoch 114 Batch 2300 Loss 2.3373 Accuracy 0.9971\n",
      "Epoch 114 Batch 2350 Loss 2.3373 Accuracy 0.9971\n",
      "Epoch 114 Batch 2400 Loss 2.3409 Accuracy 0.9971\n",
      "Epoch 114 Batch 2450 Loss 2.3418 Accuracy 0.9971\n",
      "Epoch 114 Batch 2500 Loss 2.3440 Accuracy 0.9971\n",
      "Epoch 114 Batch 2550 Loss 2.3427 Accuracy 0.9971\n",
      "Epoch 114 Batch 2600 Loss 2.3398 Accuracy 0.9971\n",
      "Epoch 114 Batch 2650 Loss 2.3384 Accuracy 0.9971\n",
      "Epoch 114 Loss 2.3397 Accuracy 0.9971\n",
      "Time taken for 1 epoch: 195.38995099067688 secs\n",
      "\n",
      "Epoch 115 Batch 0 Loss 1.9163 Accuracy 0.9977\n",
      "Epoch 115 Batch 50 Loss 2.3638 Accuracy 0.9971\n",
      "Epoch 115 Batch 100 Loss 2.3502 Accuracy 0.9971\n",
      "Epoch 115 Batch 150 Loss 2.3774 Accuracy 0.9971\n",
      "Epoch 115 Batch 200 Loss 2.3264 Accuracy 0.9972\n",
      "Epoch 115 Batch 250 Loss 2.3174 Accuracy 0.9972\n",
      "Epoch 115 Batch 300 Loss 2.3191 Accuracy 0.9972\n",
      "Epoch 115 Batch 350 Loss 2.3168 Accuracy 0.9972\n",
      "Epoch 115 Batch 400 Loss 2.3249 Accuracy 0.9972\n",
      "Epoch 115 Batch 450 Loss 2.3539 Accuracy 0.9971\n",
      "Epoch 115 Batch 500 Loss 2.3433 Accuracy 0.9971\n",
      "Epoch 115 Batch 550 Loss 2.3533 Accuracy 0.9971\n",
      "Epoch 115 Batch 600 Loss 2.3672 Accuracy 0.9971\n",
      "Epoch 115 Batch 650 Loss 2.3651 Accuracy 0.9971\n",
      "Epoch 115 Batch 700 Loss 2.3625 Accuracy 0.9971\n",
      "Epoch 115 Batch 750 Loss 2.3622 Accuracy 0.9971\n",
      "Epoch 115 Batch 800 Loss 2.3500 Accuracy 0.9971\n",
      "Epoch 115 Batch 850 Loss 2.3581 Accuracy 0.9971\n",
      "Epoch 115 Batch 900 Loss 2.3573 Accuracy 0.9971\n",
      "Epoch 115 Batch 950 Loss 2.3628 Accuracy 0.9971\n",
      "Epoch 115 Batch 1000 Loss 2.3603 Accuracy 0.9971\n",
      "Epoch 115 Batch 1050 Loss 2.3518 Accuracy 0.9971\n",
      "Epoch 115 Batch 1100 Loss 2.3501 Accuracy 0.9971\n",
      "Epoch 115 Batch 1150 Loss 2.3402 Accuracy 0.9971\n",
      "Epoch 115 Batch 1200 Loss 2.3503 Accuracy 0.9971\n",
      "Epoch 115 Batch 1250 Loss 2.3453 Accuracy 0.9971\n",
      "Epoch 115 Batch 1300 Loss 2.3487 Accuracy 0.9971\n",
      "Epoch 115 Batch 1350 Loss 2.3456 Accuracy 0.9971\n",
      "Epoch 115 Batch 1400 Loss 2.3475 Accuracy 0.9971\n",
      "Epoch 115 Batch 1450 Loss 2.3420 Accuracy 0.9971\n",
      "Epoch 115 Batch 1500 Loss 2.3406 Accuracy 0.9971\n",
      "Epoch 115 Batch 1550 Loss 2.3425 Accuracy 0.9971\n",
      "Epoch 115 Batch 1600 Loss 2.3438 Accuracy 0.9971\n",
      "Epoch 115 Batch 1650 Loss 2.3444 Accuracy 0.9971\n",
      "Epoch 115 Batch 1700 Loss 2.3469 Accuracy 0.9971\n",
      "Epoch 115 Batch 1750 Loss 2.3428 Accuracy 0.9971\n",
      "Epoch 115 Batch 1800 Loss 2.3458 Accuracy 0.9971\n",
      "Epoch 115 Batch 1850 Loss 2.3411 Accuracy 0.9971\n",
      "Epoch 115 Batch 1900 Loss 2.3371 Accuracy 0.9971\n",
      "Epoch 115 Batch 1950 Loss 2.3300 Accuracy 0.9972\n",
      "Epoch 115 Batch 2000 Loss 2.3349 Accuracy 0.9971\n",
      "Epoch 115 Batch 2050 Loss 2.3397 Accuracy 0.9971\n",
      "Epoch 115 Batch 2100 Loss 2.3377 Accuracy 0.9971\n",
      "Epoch 115 Batch 2150 Loss 2.3394 Accuracy 0.9971\n",
      "Epoch 115 Batch 2200 Loss 2.3442 Accuracy 0.9971\n",
      "Epoch 115 Batch 2250 Loss 2.3476 Accuracy 0.9971\n",
      "Epoch 115 Batch 2300 Loss 2.3449 Accuracy 0.9971\n",
      "Epoch 115 Batch 2350 Loss 2.3450 Accuracy 0.9971\n",
      "Epoch 115 Batch 2400 Loss 2.3479 Accuracy 0.9971\n",
      "Epoch 115 Batch 2450 Loss 2.3498 Accuracy 0.9971\n",
      "Epoch 115 Batch 2500 Loss 2.3510 Accuracy 0.9971\n",
      "Epoch 115 Batch 2550 Loss 2.3510 Accuracy 0.9971\n",
      "Epoch 115 Batch 2600 Loss 2.3494 Accuracy 0.9971\n",
      "Epoch 115 Batch 2650 Loss 2.3470 Accuracy 0.9971\n",
      "Saving checkpoint for epoch 115 at ./checkpoints/train\\ckpt-24\n",
      "Epoch 115 Loss 2.3486 Accuracy 0.9971\n",
      "Time taken for 1 epoch: 196.37975215911865 secs\n",
      "\n",
      "Epoch 116 Batch 0 Loss 1.5398 Accuracy 0.9980\n",
      "Epoch 116 Batch 50 Loss 2.4055 Accuracy 0.9971\n",
      "Epoch 116 Batch 100 Loss 2.3793 Accuracy 0.9971\n",
      "Epoch 116 Batch 150 Loss 2.3939 Accuracy 0.9971\n",
      "Epoch 116 Batch 200 Loss 2.3224 Accuracy 0.9972\n",
      "Epoch 116 Batch 250 Loss 2.3237 Accuracy 0.9972\n",
      "Epoch 116 Batch 300 Loss 2.3242 Accuracy 0.9972\n",
      "Epoch 116 Batch 350 Loss 2.3179 Accuracy 0.9972\n",
      "Epoch 116 Batch 400 Loss 2.3178 Accuracy 0.9972\n",
      "Epoch 116 Batch 450 Loss 2.3460 Accuracy 0.9971\n",
      "Epoch 116 Batch 500 Loss 2.3429 Accuracy 0.9971\n",
      "Epoch 116 Batch 550 Loss 2.3520 Accuracy 0.9971\n",
      "Epoch 116 Batch 600 Loss 2.3646 Accuracy 0.9971\n",
      "Epoch 116 Batch 650 Loss 2.3646 Accuracy 0.9971\n",
      "Epoch 116 Batch 700 Loss 2.3585 Accuracy 0.9971\n",
      "Epoch 116 Batch 750 Loss 2.3582 Accuracy 0.9971\n",
      "Epoch 116 Batch 800 Loss 2.3438 Accuracy 0.9971\n",
      "Epoch 116 Batch 850 Loss 2.3467 Accuracy 0.9971\n",
      "Epoch 116 Batch 900 Loss 2.3489 Accuracy 0.9971\n",
      "Epoch 116 Batch 950 Loss 2.3536 Accuracy 0.9971\n",
      "Epoch 116 Batch 1000 Loss 2.3518 Accuracy 0.9971\n",
      "Epoch 116 Batch 1050 Loss 2.3413 Accuracy 0.9971\n",
      "Epoch 116 Batch 1100 Loss 2.3391 Accuracy 0.9971\n",
      "Epoch 116 Batch 1150 Loss 2.3303 Accuracy 0.9972\n",
      "Epoch 116 Batch 1200 Loss 2.3413 Accuracy 0.9971\n",
      "Epoch 116 Batch 1250 Loss 2.3359 Accuracy 0.9971\n",
      "Epoch 116 Batch 1300 Loss 2.3363 Accuracy 0.9971\n",
      "Epoch 116 Batch 1350 Loss 2.3319 Accuracy 0.9971\n",
      "Epoch 116 Batch 1400 Loss 2.3325 Accuracy 0.9971\n",
      "Epoch 116 Batch 1450 Loss 2.3274 Accuracy 0.9972\n",
      "Epoch 116 Batch 1500 Loss 2.3263 Accuracy 0.9972\n",
      "Epoch 116 Batch 1550 Loss 2.3293 Accuracy 0.9972\n",
      "Epoch 116 Batch 1600 Loss 2.3315 Accuracy 0.9971\n",
      "Epoch 116 Batch 1650 Loss 2.3314 Accuracy 0.9971\n",
      "Epoch 116 Batch 1700 Loss 2.3330 Accuracy 0.9971\n",
      "Epoch 116 Batch 1750 Loss 2.3277 Accuracy 0.9972\n",
      "Epoch 116 Batch 1800 Loss 2.3295 Accuracy 0.9972\n",
      "Epoch 116 Batch 1850 Loss 2.3233 Accuracy 0.9972\n",
      "Epoch 116 Batch 1900 Loss 2.3192 Accuracy 0.9972\n",
      "Epoch 116 Batch 1950 Loss 2.3136 Accuracy 0.9972\n",
      "Epoch 116 Batch 2000 Loss 2.3190 Accuracy 0.9972\n",
      "Epoch 116 Batch 2050 Loss 2.3253 Accuracy 0.9972\n",
      "Epoch 116 Batch 2100 Loss 2.3233 Accuracy 0.9972\n",
      "Epoch 116 Batch 2150 Loss 2.3258 Accuracy 0.9972\n",
      "Epoch 116 Batch 2200 Loss 2.3306 Accuracy 0.9972\n",
      "Epoch 116 Batch 2250 Loss 2.3328 Accuracy 0.9971\n",
      "Epoch 116 Batch 2300 Loss 2.3310 Accuracy 0.9972\n",
      "Epoch 116 Batch 2350 Loss 2.3307 Accuracy 0.9972\n",
      "Epoch 116 Batch 2400 Loss 2.3324 Accuracy 0.9971\n",
      "Epoch 116 Batch 2450 Loss 2.3343 Accuracy 0.9971\n",
      "Epoch 116 Batch 2500 Loss 2.3371 Accuracy 0.9971\n",
      "Epoch 116 Batch 2550 Loss 2.3367 Accuracy 0.9971\n",
      "Epoch 116 Batch 2600 Loss 2.3347 Accuracy 0.9971\n",
      "Epoch 116 Batch 2650 Loss 2.3324 Accuracy 0.9972\n",
      "Epoch 116 Loss 2.3332 Accuracy 0.9971\n",
      "Time taken for 1 epoch: 195.09660005569458 secs\n",
      "\n",
      "Epoch 117 Batch 0 Loss 1.7472 Accuracy 0.9980\n",
      "Epoch 117 Batch 50 Loss 2.3250 Accuracy 0.9972\n",
      "Epoch 117 Batch 100 Loss 2.3529 Accuracy 0.9971\n",
      "Epoch 117 Batch 150 Loss 2.3747 Accuracy 0.9971\n",
      "Epoch 117 Batch 200 Loss 2.3109 Accuracy 0.9972\n",
      "Epoch 117 Batch 250 Loss 2.2996 Accuracy 0.9972\n",
      "Epoch 117 Batch 300 Loss 2.2952 Accuracy 0.9972\n",
      "Epoch 117 Batch 350 Loss 2.2999 Accuracy 0.9972\n",
      "Epoch 117 Batch 400 Loss 2.2967 Accuracy 0.9972\n",
      "Epoch 117 Batch 450 Loss 2.3285 Accuracy 0.9972\n",
      "Epoch 117 Batch 500 Loss 2.3189 Accuracy 0.9972\n",
      "Epoch 117 Batch 550 Loss 2.3306 Accuracy 0.9971\n",
      "Epoch 117 Batch 600 Loss 2.3470 Accuracy 0.9971\n",
      "Epoch 117 Batch 650 Loss 2.3440 Accuracy 0.9971\n",
      "Epoch 117 Batch 700 Loss 2.3463 Accuracy 0.9971\n",
      "Epoch 117 Batch 750 Loss 2.3442 Accuracy 0.9971\n",
      "Epoch 117 Batch 800 Loss 2.3300 Accuracy 0.9972\n",
      "Epoch 117 Batch 850 Loss 2.3356 Accuracy 0.9971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117 Batch 900 Loss 2.3334 Accuracy 0.9971\n",
      "Epoch 117 Batch 950 Loss 2.3378 Accuracy 0.9971\n",
      "Epoch 117 Batch 1000 Loss 2.3347 Accuracy 0.9971\n",
      "Epoch 117 Batch 1050 Loss 2.3268 Accuracy 0.9972\n",
      "Epoch 117 Batch 1100 Loss 2.3242 Accuracy 0.9972\n",
      "Epoch 117 Batch 1150 Loss 2.3188 Accuracy 0.9972\n",
      "Epoch 117 Batch 1200 Loss 2.3288 Accuracy 0.9972\n",
      "Epoch 117 Batch 1250 Loss 2.3250 Accuracy 0.9972\n",
      "Epoch 117 Batch 1300 Loss 2.3246 Accuracy 0.9972\n",
      "Epoch 117 Batch 1350 Loss 2.3202 Accuracy 0.9972\n",
      "Epoch 117 Batch 1400 Loss 2.3217 Accuracy 0.9972\n",
      "Epoch 117 Batch 1450 Loss 2.3160 Accuracy 0.9972\n",
      "Epoch 117 Batch 1500 Loss 2.3144 Accuracy 0.9972\n",
      "Epoch 117 Batch 1550 Loss 2.3165 Accuracy 0.9972\n",
      "Epoch 117 Batch 1600 Loss 2.3175 Accuracy 0.9972\n",
      "Epoch 117 Batch 1650 Loss 2.3171 Accuracy 0.9972\n",
      "Epoch 117 Batch 1700 Loss 2.3195 Accuracy 0.9972\n",
      "Epoch 117 Batch 1750 Loss 2.3155 Accuracy 0.9972\n",
      "Epoch 117 Batch 1800 Loss 2.3168 Accuracy 0.9972\n",
      "Epoch 117 Batch 1850 Loss 2.3121 Accuracy 0.9972\n",
      "Epoch 117 Batch 1900 Loss 2.3086 Accuracy 0.9972\n",
      "Epoch 117 Batch 1950 Loss 2.3001 Accuracy 0.9972\n",
      "Epoch 117 Batch 2000 Loss 2.3049 Accuracy 0.9972\n",
      "Epoch 117 Batch 2050 Loss 2.3115 Accuracy 0.9972\n",
      "Epoch 117 Batch 2100 Loss 2.3102 Accuracy 0.9972\n",
      "Epoch 117 Batch 2150 Loss 2.3130 Accuracy 0.9972\n",
      "Epoch 117 Batch 2200 Loss 2.3176 Accuracy 0.9972\n",
      "Epoch 117 Batch 2250 Loss 2.3193 Accuracy 0.9972\n",
      "Epoch 117 Batch 2300 Loss 2.3174 Accuracy 0.9972\n",
      "Epoch 117 Batch 2350 Loss 2.3181 Accuracy 0.9972\n",
      "Epoch 117 Batch 2400 Loss 2.3202 Accuracy 0.9972\n",
      "Epoch 117 Batch 2450 Loss 2.3221 Accuracy 0.9972\n",
      "Epoch 117 Batch 2500 Loss 2.3244 Accuracy 0.9972\n",
      "Epoch 117 Batch 2550 Loss 2.3242 Accuracy 0.9972\n",
      "Epoch 117 Batch 2600 Loss 2.3212 Accuracy 0.9972\n",
      "Epoch 117 Batch 2650 Loss 2.3195 Accuracy 0.9972\n",
      "Epoch 117 Loss 2.3200 Accuracy 0.9972\n",
      "Time taken for 1 epoch: 194.8500018119812 secs\n",
      "\n",
      "Epoch 118 Batch 0 Loss 1.6192 Accuracy 0.9981\n",
      "Epoch 118 Batch 50 Loss 2.3385 Accuracy 0.9971\n",
      "Epoch 118 Batch 100 Loss 2.3476 Accuracy 0.9971\n",
      "Epoch 118 Batch 150 Loss 2.3700 Accuracy 0.9971\n",
      "Epoch 118 Batch 200 Loss 2.3143 Accuracy 0.9971\n",
      "Epoch 118 Batch 250 Loss 2.3004 Accuracy 0.9972\n",
      "Epoch 118 Batch 300 Loss 2.3002 Accuracy 0.9972\n",
      "Epoch 118 Batch 350 Loss 2.3035 Accuracy 0.9972\n",
      "Epoch 118 Batch 400 Loss 2.2979 Accuracy 0.9972\n",
      "Epoch 118 Batch 450 Loss 2.3220 Accuracy 0.9971\n",
      "Epoch 118 Batch 500 Loss 2.3125 Accuracy 0.9972\n",
      "Epoch 118 Batch 550 Loss 2.3272 Accuracy 0.9971\n",
      "Epoch 118 Batch 600 Loss 2.3435 Accuracy 0.9971\n",
      "Epoch 118 Batch 650 Loss 2.3409 Accuracy 0.9971\n",
      "Epoch 118 Batch 700 Loss 2.3391 Accuracy 0.9971\n",
      "Epoch 118 Batch 750 Loss 2.3365 Accuracy 0.9971\n",
      "Epoch 118 Batch 800 Loss 2.3240 Accuracy 0.9971\n",
      "Epoch 118 Batch 850 Loss 2.3298 Accuracy 0.9971\n",
      "Epoch 118 Batch 900 Loss 2.3308 Accuracy 0.9971\n",
      "Epoch 118 Batch 950 Loss 2.3357 Accuracy 0.9971\n",
      "Epoch 118 Batch 1000 Loss 2.3356 Accuracy 0.9971\n",
      "Epoch 118 Batch 1050 Loss 2.3271 Accuracy 0.9971\n",
      "Epoch 118 Batch 1100 Loss 2.3249 Accuracy 0.9972\n",
      "Epoch 118 Batch 1150 Loss 2.3183 Accuracy 0.9972\n",
      "Epoch 118 Batch 1200 Loss 2.3292 Accuracy 0.9971\n",
      "Epoch 118 Batch 1250 Loss 2.3237 Accuracy 0.9972\n",
      "Epoch 118 Batch 1300 Loss 2.3243 Accuracy 0.9972\n",
      "Epoch 118 Batch 1350 Loss 2.3201 Accuracy 0.9972\n",
      "Epoch 118 Batch 1400 Loss 2.3242 Accuracy 0.9972\n",
      "Epoch 118 Batch 1450 Loss 2.3191 Accuracy 0.9972\n",
      "Epoch 118 Batch 1500 Loss 2.3185 Accuracy 0.9972\n",
      "Epoch 118 Batch 1550 Loss 2.3205 Accuracy 0.9972\n",
      "Epoch 118 Batch 1600 Loss 2.3201 Accuracy 0.9972\n",
      "Epoch 118 Batch 1650 Loss 2.3215 Accuracy 0.9972\n",
      "Epoch 118 Batch 1700 Loss 2.3240 Accuracy 0.9972\n",
      "Epoch 118 Batch 1750 Loss 2.3202 Accuracy 0.9972\n",
      "Epoch 118 Batch 1800 Loss 2.3223 Accuracy 0.9972\n",
      "Epoch 118 Batch 1850 Loss 2.3161 Accuracy 0.9972\n",
      "Epoch 118 Batch 1900 Loss 2.3132 Accuracy 0.9972\n",
      "Epoch 118 Batch 1950 Loss 2.3080 Accuracy 0.9972\n",
      "Epoch 118 Batch 2000 Loss 2.3122 Accuracy 0.9972\n",
      "Epoch 118 Batch 2050 Loss 2.3181 Accuracy 0.9972\n",
      "Epoch 118 Batch 2100 Loss 2.3162 Accuracy 0.9972\n",
      "Epoch 118 Batch 2150 Loss 2.3195 Accuracy 0.9972\n",
      "Epoch 118 Batch 2200 Loss 2.3245 Accuracy 0.9972\n",
      "Epoch 118 Batch 2250 Loss 2.3261 Accuracy 0.9972\n",
      "Epoch 118 Batch 2300 Loss 2.3229 Accuracy 0.9972\n",
      "Epoch 118 Batch 2350 Loss 2.3216 Accuracy 0.9972\n",
      "Epoch 118 Batch 2400 Loss 2.3234 Accuracy 0.9972\n",
      "Epoch 118 Batch 2450 Loss 2.3252 Accuracy 0.9972\n",
      "Epoch 118 Batch 2500 Loss 2.3268 Accuracy 0.9972\n",
      "Epoch 118 Batch 2550 Loss 2.3260 Accuracy 0.9972\n",
      "Epoch 118 Batch 2600 Loss 2.3241 Accuracy 0.9972\n",
      "Epoch 118 Batch 2650 Loss 2.3220 Accuracy 0.9972\n",
      "Epoch 118 Loss 2.3217 Accuracy 0.9972\n",
      "Time taken for 1 epoch: 194.700186252594 secs\n",
      "\n",
      "Epoch 119 Batch 0 Loss 1.5913 Accuracy 0.9980\n",
      "Epoch 119 Batch 50 Loss 2.4421 Accuracy 0.9970\n",
      "Epoch 119 Batch 100 Loss 2.4050 Accuracy 0.9971\n",
      "Epoch 119 Batch 150 Loss 2.3961 Accuracy 0.9971\n",
      "Epoch 119 Batch 200 Loss 2.3415 Accuracy 0.9971\n",
      "Epoch 119 Batch 250 Loss 2.3176 Accuracy 0.9972\n",
      "Epoch 119 Batch 300 Loss 2.3193 Accuracy 0.9972\n",
      "Epoch 119 Batch 350 Loss 2.3190 Accuracy 0.9972\n",
      "Epoch 119 Batch 400 Loss 2.3150 Accuracy 0.9972\n",
      "Epoch 119 Batch 450 Loss 2.3429 Accuracy 0.9971\n",
      "Epoch 119 Batch 500 Loss 2.3319 Accuracy 0.9971\n",
      "Epoch 119 Batch 550 Loss 2.3450 Accuracy 0.9971\n",
      "Epoch 119 Batch 600 Loss 2.3571 Accuracy 0.9971\n",
      "Epoch 119 Batch 650 Loss 2.3511 Accuracy 0.9971\n",
      "Epoch 119 Batch 700 Loss 2.3473 Accuracy 0.9971\n",
      "Epoch 119 Batch 750 Loss 2.3511 Accuracy 0.9971\n",
      "Epoch 119 Batch 800 Loss 2.3387 Accuracy 0.9971\n",
      "Epoch 119 Batch 850 Loss 2.3436 Accuracy 0.9971\n",
      "Epoch 119 Batch 900 Loss 2.3443 Accuracy 0.9971\n",
      "Epoch 119 Batch 950 Loss 2.3482 Accuracy 0.9971\n",
      "Epoch 119 Batch 1000 Loss 2.3467 Accuracy 0.9971\n",
      "Epoch 119 Batch 1050 Loss 2.3397 Accuracy 0.9971\n",
      "Epoch 119 Batch 1100 Loss 2.3375 Accuracy 0.9971\n",
      "Epoch 119 Batch 1150 Loss 2.3282 Accuracy 0.9972\n",
      "Epoch 119 Batch 1200 Loss 2.3392 Accuracy 0.9971\n",
      "Epoch 119 Batch 1250 Loss 2.3337 Accuracy 0.9971\n",
      "Epoch 119 Batch 1300 Loss 2.3347 Accuracy 0.9971\n",
      "Epoch 119 Batch 1350 Loss 2.3299 Accuracy 0.9972\n",
      "Epoch 119 Batch 1400 Loss 2.3323 Accuracy 0.9972\n",
      "Epoch 119 Batch 1450 Loss 2.3262 Accuracy 0.9972\n",
      "Epoch 119 Batch 1500 Loss 2.3259 Accuracy 0.9972\n",
      "Epoch 119 Batch 1550 Loss 2.3265 Accuracy 0.9972\n",
      "Epoch 119 Batch 1600 Loss 2.3275 Accuracy 0.9972\n",
      "Epoch 119 Batch 1650 Loss 2.3271 Accuracy 0.9972\n",
      "Epoch 119 Batch 1700 Loss 2.3290 Accuracy 0.9972\n",
      "Epoch 119 Batch 1750 Loss 2.3252 Accuracy 0.9972\n",
      "Epoch 119 Batch 1800 Loss 2.3262 Accuracy 0.9972\n",
      "Epoch 119 Batch 1850 Loss 2.3210 Accuracy 0.9972\n",
      "Epoch 119 Batch 1900 Loss 2.3176 Accuracy 0.9972\n",
      "Epoch 119 Batch 1950 Loss 2.3093 Accuracy 0.9972\n",
      "Epoch 119 Batch 2000 Loss 2.3139 Accuracy 0.9972\n",
      "Epoch 119 Batch 2050 Loss 2.3198 Accuracy 0.9972\n",
      "Epoch 119 Batch 2100 Loss 2.3184 Accuracy 0.9972\n",
      "Epoch 119 Batch 2150 Loss 2.3202 Accuracy 0.9972\n",
      "Epoch 119 Batch 2200 Loss 2.3250 Accuracy 0.9972\n",
      "Epoch 119 Batch 2250 Loss 2.3266 Accuracy 0.9972\n",
      "Epoch 119 Batch 2300 Loss 2.3246 Accuracy 0.9972\n",
      "Epoch 119 Batch 2350 Loss 2.3246 Accuracy 0.9972\n",
      "Epoch 119 Batch 2400 Loss 2.3254 Accuracy 0.9972\n",
      "Epoch 119 Batch 2450 Loss 2.3275 Accuracy 0.9972\n",
      "Epoch 119 Batch 2500 Loss 2.3294 Accuracy 0.9972\n",
      "Epoch 119 Batch 2550 Loss 2.3286 Accuracy 0.9972\n",
      "Epoch 119 Batch 2600 Loss 2.3258 Accuracy 0.9972\n",
      "Epoch 119 Batch 2650 Loss 2.3238 Accuracy 0.9972\n",
      "Epoch 119 Loss 2.3248 Accuracy 0.9972\n",
      "Time taken for 1 epoch: 194.99980902671814 secs\n",
      "\n",
      "Epoch 120 Batch 0 Loss 1.6123 Accuracy 0.9979\n",
      "Epoch 120 Batch 50 Loss 2.3264 Accuracy 0.9971\n",
      "Epoch 120 Batch 100 Loss 2.3414 Accuracy 0.9971\n",
      "Epoch 120 Batch 150 Loss 2.3466 Accuracy 0.9971\n",
      "Epoch 120 Batch 200 Loss 2.2885 Accuracy 0.9972\n",
      "Epoch 120 Batch 250 Loss 2.2917 Accuracy 0.9972\n",
      "Epoch 120 Batch 300 Loss 2.2836 Accuracy 0.9972\n",
      "Epoch 120 Batch 350 Loss 2.2757 Accuracy 0.9972\n",
      "Epoch 120 Batch 400 Loss 2.2774 Accuracy 0.9972\n",
      "Epoch 120 Batch 450 Loss 2.3060 Accuracy 0.9972\n",
      "Epoch 120 Batch 500 Loss 2.3006 Accuracy 0.9972\n",
      "Epoch 120 Batch 550 Loss 2.3119 Accuracy 0.9972\n",
      "Epoch 120 Batch 600 Loss 2.3230 Accuracy 0.9972\n",
      "Epoch 120 Batch 650 Loss 2.3213 Accuracy 0.9972\n",
      "Epoch 120 Batch 700 Loss 2.3192 Accuracy 0.9972\n",
      "Epoch 120 Batch 750 Loss 2.3229 Accuracy 0.9972\n",
      "Epoch 120 Batch 800 Loss 2.3131 Accuracy 0.9972\n",
      "Epoch 120 Batch 850 Loss 2.3217 Accuracy 0.9972\n",
      "Epoch 120 Batch 900 Loss 2.3215 Accuracy 0.9972\n",
      "Epoch 120 Batch 950 Loss 2.3266 Accuracy 0.9972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120 Batch 1000 Loss 2.3245 Accuracy 0.9972\n",
      "Epoch 120 Batch 1050 Loss 2.3161 Accuracy 0.9972\n",
      "Epoch 120 Batch 1100 Loss 2.3144 Accuracy 0.9972\n",
      "Epoch 120 Batch 1150 Loss 2.3050 Accuracy 0.9972\n",
      "Epoch 120 Batch 1200 Loss 2.3168 Accuracy 0.9972\n",
      "Epoch 120 Batch 1250 Loss 2.3122 Accuracy 0.9972\n",
      "Epoch 120 Batch 1300 Loss 2.3119 Accuracy 0.9972\n",
      "Epoch 120 Batch 1350 Loss 2.3085 Accuracy 0.9972\n",
      "Epoch 120 Batch 1400 Loss 2.3125 Accuracy 0.9972\n",
      "Epoch 120 Batch 1450 Loss 2.3079 Accuracy 0.9972\n",
      "Epoch 120 Batch 1500 Loss 2.3082 Accuracy 0.9972\n",
      "Epoch 120 Batch 1550 Loss 2.3123 Accuracy 0.9972\n",
      "Epoch 120 Batch 1600 Loss 2.3136 Accuracy 0.9972\n",
      "Epoch 120 Batch 1650 Loss 2.3139 Accuracy 0.9972\n",
      "Epoch 120 Batch 1700 Loss 2.3143 Accuracy 0.9972\n",
      "Epoch 120 Batch 1750 Loss 2.3103 Accuracy 0.9972\n",
      "Epoch 120 Batch 1800 Loss 2.3132 Accuracy 0.9972\n",
      "Epoch 120 Batch 1850 Loss 2.3079 Accuracy 0.9972\n",
      "Epoch 120 Batch 1900 Loss 2.3055 Accuracy 0.9972\n",
      "Epoch 120 Batch 1950 Loss 2.2986 Accuracy 0.9972\n",
      "Epoch 120 Batch 2000 Loss 2.3034 Accuracy 0.9972\n",
      "Epoch 120 Batch 2050 Loss 2.3096 Accuracy 0.9972\n",
      "Epoch 120 Batch 2100 Loss 2.3075 Accuracy 0.9972\n",
      "Epoch 120 Batch 2150 Loss 2.3078 Accuracy 0.9972\n",
      "Epoch 120 Batch 2200 Loss 2.3108 Accuracy 0.9972\n",
      "Epoch 120 Batch 2250 Loss 2.3113 Accuracy 0.9972\n",
      "Epoch 120 Batch 2300 Loss 2.3095 Accuracy 0.9972\n",
      "Epoch 120 Batch 2350 Loss 2.3085 Accuracy 0.9972\n",
      "Epoch 120 Batch 2400 Loss 2.3116 Accuracy 0.9972\n",
      "Epoch 120 Batch 2450 Loss 2.3140 Accuracy 0.9972\n",
      "Epoch 120 Batch 2500 Loss 2.3161 Accuracy 0.9972\n",
      "Epoch 120 Batch 2550 Loss 2.3172 Accuracy 0.9972\n",
      "Epoch 120 Batch 2600 Loss 2.3149 Accuracy 0.9972\n",
      "Epoch 120 Batch 2650 Loss 2.3135 Accuracy 0.9972\n",
      "Saving checkpoint for epoch 120 at ./checkpoints/train\\ckpt-25\n",
      "Epoch 120 Loss 2.3149 Accuracy 0.9972\n",
      "Time taken for 1 epoch: 195.35710787773132 secs\n",
      "\n",
      "Epoch 121 Batch 0 Loss 1.9736 Accuracy 0.9978\n",
      "Epoch 121 Batch 50 Loss 2.3630 Accuracy 0.9971\n",
      "Epoch 121 Batch 100 Loss 2.3695 Accuracy 0.9971\n",
      "Epoch 121 Batch 150 Loss 2.3873 Accuracy 0.9971\n",
      "Epoch 121 Batch 200 Loss 2.3142 Accuracy 0.9972\n",
      "Epoch 121 Batch 250 Loss 2.3022 Accuracy 0.9972\n",
      "Epoch 121 Batch 300 Loss 2.3007 Accuracy 0.9972\n",
      "Epoch 121 Batch 350 Loss 2.2937 Accuracy 0.9972\n",
      "Epoch 121 Batch 400 Loss 2.2900 Accuracy 0.9972\n",
      "Epoch 121 Batch 450 Loss 2.3201 Accuracy 0.9972\n",
      "Epoch 121 Batch 500 Loss 2.3040 Accuracy 0.9972\n",
      "Epoch 121 Batch 550 Loss 2.3144 Accuracy 0.9972\n",
      "Epoch 121 Batch 600 Loss 2.3248 Accuracy 0.9971\n",
      "Epoch 121 Batch 650 Loss 2.3192 Accuracy 0.9972\n",
      "Epoch 121 Batch 700 Loss 2.3178 Accuracy 0.9972\n",
      "Epoch 121 Batch 750 Loss 2.3211 Accuracy 0.9972\n",
      "Epoch 121 Batch 800 Loss 2.3105 Accuracy 0.9972\n",
      "Epoch 121 Batch 850 Loss 2.3149 Accuracy 0.9972\n",
      "Epoch 121 Batch 900 Loss 2.3150 Accuracy 0.9972\n",
      "Epoch 121 Batch 950 Loss 2.3165 Accuracy 0.9972\n",
      "Epoch 121 Batch 1000 Loss 2.3148 Accuracy 0.9972\n",
      "Epoch 121 Batch 1050 Loss 2.3071 Accuracy 0.9972\n",
      "Epoch 121 Batch 1100 Loss 2.3049 Accuracy 0.9972\n",
      "Epoch 121 Batch 1150 Loss 2.2974 Accuracy 0.9972\n",
      "Epoch 121 Batch 1200 Loss 2.3092 Accuracy 0.9972\n",
      "Epoch 121 Batch 1250 Loss 2.3043 Accuracy 0.9972\n",
      "Epoch 121 Batch 1300 Loss 2.3058 Accuracy 0.9972\n",
      "Epoch 121 Batch 1350 Loss 2.3025 Accuracy 0.9972\n",
      "Epoch 121 Batch 1400 Loss 2.3038 Accuracy 0.9972\n",
      "Epoch 121 Batch 1450 Loss 2.2978 Accuracy 0.9972\n",
      "Epoch 121 Batch 1500 Loss 2.2972 Accuracy 0.9972\n",
      "Epoch 121 Batch 1550 Loss 2.2981 Accuracy 0.9972\n",
      "Epoch 121 Batch 1600 Loss 2.2968 Accuracy 0.9972\n",
      "Epoch 121 Batch 1650 Loss 2.2979 Accuracy 0.9972\n",
      "Epoch 121 Batch 1700 Loss 2.3016 Accuracy 0.9972\n",
      "Epoch 121 Batch 1750 Loss 2.2979 Accuracy 0.9972\n",
      "Epoch 121 Batch 1800 Loss 2.3008 Accuracy 0.9972\n",
      "Epoch 121 Batch 1850 Loss 2.2963 Accuracy 0.9972\n",
      "Epoch 121 Batch 1900 Loss 2.2924 Accuracy 0.9972\n",
      "Epoch 121 Batch 1950 Loss 2.2853 Accuracy 0.9972\n",
      "Epoch 121 Batch 2000 Loss 2.2883 Accuracy 0.9972\n",
      "Epoch 121 Batch 2050 Loss 2.2936 Accuracy 0.9972\n",
      "Epoch 121 Batch 2100 Loss 2.2934 Accuracy 0.9972\n",
      "Epoch 121 Batch 2150 Loss 2.2954 Accuracy 0.9972\n",
      "Epoch 121 Batch 2200 Loss 2.2982 Accuracy 0.9972\n",
      "Epoch 121 Batch 2250 Loss 2.2983 Accuracy 0.9972\n",
      "Epoch 121 Batch 2300 Loss 2.2951 Accuracy 0.9972\n",
      "Epoch 121 Batch 2350 Loss 2.2954 Accuracy 0.9972\n",
      "Epoch 121 Batch 2400 Loss 2.2975 Accuracy 0.9972\n",
      "Epoch 121 Batch 2450 Loss 2.3009 Accuracy 0.9972\n",
      "Epoch 121 Batch 2500 Loss 2.3025 Accuracy 0.9972\n",
      "Epoch 121 Batch 2550 Loss 2.3017 Accuracy 0.9972\n",
      "Epoch 121 Batch 2600 Loss 2.2990 Accuracy 0.9972\n",
      "Epoch 121 Batch 2650 Loss 2.2976 Accuracy 0.9972\n",
      "Epoch 121 Loss 2.2985 Accuracy 0.9972\n",
      "Time taken for 1 epoch: 194.64954829216003 secs\n",
      "\n",
      "Epoch 122 Batch 0 Loss 1.6789 Accuracy 0.9978\n",
      "Epoch 122 Batch 50 Loss 2.3019 Accuracy 0.9972\n",
      "Epoch 122 Batch 100 Loss 2.3032 Accuracy 0.9972\n",
      "Epoch 122 Batch 150 Loss 2.3343 Accuracy 0.9971\n",
      "Epoch 122 Batch 200 Loss 2.2764 Accuracy 0.9972\n",
      "Epoch 122 Batch 250 Loss 2.2604 Accuracy 0.9972\n",
      "Epoch 122 Batch 300 Loss 2.2630 Accuracy 0.9972\n",
      "Epoch 122 Batch 350 Loss 2.2654 Accuracy 0.9972\n",
      "Epoch 122 Batch 400 Loss 2.2668 Accuracy 0.9972\n",
      "Epoch 122 Batch 450 Loss 2.2946 Accuracy 0.9972\n",
      "Epoch 122 Batch 500 Loss 2.2876 Accuracy 0.9972\n",
      "Epoch 122 Batch 550 Loss 2.2976 Accuracy 0.9972\n",
      "Epoch 122 Batch 600 Loss 2.3146 Accuracy 0.9972\n",
      "Epoch 122 Batch 650 Loss 2.3077 Accuracy 0.9972\n",
      "Epoch 122 Batch 700 Loss 2.3069 Accuracy 0.9972\n",
      "Epoch 122 Batch 750 Loss 2.3070 Accuracy 0.9972\n",
      "Epoch 122 Batch 800 Loss 2.2979 Accuracy 0.9972\n",
      "Epoch 122 Batch 850 Loss 2.3018 Accuracy 0.9972\n",
      "Epoch 122 Batch 900 Loss 2.3032 Accuracy 0.9972\n",
      "Epoch 122 Batch 950 Loss 2.3080 Accuracy 0.9972\n",
      "Epoch 122 Batch 1000 Loss 2.3066 Accuracy 0.9972\n",
      "Epoch 122 Batch 1050 Loss 2.2972 Accuracy 0.9972\n",
      "Epoch 122 Batch 1100 Loss 2.2956 Accuracy 0.9972\n",
      "Epoch 122 Batch 1150 Loss 2.2878 Accuracy 0.9972\n",
      "Epoch 122 Batch 1200 Loss 2.2986 Accuracy 0.9972\n",
      "Epoch 122 Batch 1250 Loss 2.2933 Accuracy 0.9972\n",
      "Epoch 122 Batch 1300 Loss 2.2952 Accuracy 0.9972\n",
      "Epoch 122 Batch 1350 Loss 2.2915 Accuracy 0.9972\n",
      "Epoch 122 Batch 1400 Loss 2.2935 Accuracy 0.9972\n",
      "Epoch 122 Batch 1450 Loss 2.2895 Accuracy 0.9972\n",
      "Epoch 122 Batch 1500 Loss 2.2892 Accuracy 0.9972\n",
      "Epoch 122 Batch 1550 Loss 2.2903 Accuracy 0.9972\n",
      "Epoch 122 Batch 1600 Loss 2.2911 Accuracy 0.9972\n",
      "Epoch 122 Batch 1650 Loss 2.2931 Accuracy 0.9972\n",
      "Epoch 122 Batch 1700 Loss 2.2954 Accuracy 0.9972\n",
      "Epoch 122 Batch 1750 Loss 2.2909 Accuracy 0.9972\n",
      "Epoch 122 Batch 1800 Loss 2.2911 Accuracy 0.9972\n",
      "Epoch 122 Batch 1850 Loss 2.2862 Accuracy 0.9972\n",
      "Epoch 122 Batch 1900 Loss 2.2822 Accuracy 0.9972\n",
      "Epoch 122 Batch 1950 Loss 2.2754 Accuracy 0.9972\n",
      "Epoch 122 Batch 2000 Loss 2.2807 Accuracy 0.9972\n",
      "Epoch 122 Batch 2050 Loss 2.2870 Accuracy 0.9972\n",
      "Epoch 122 Batch 2100 Loss 2.2858 Accuracy 0.9972\n",
      "Epoch 122 Batch 2150 Loss 2.2891 Accuracy 0.9972\n",
      "Epoch 122 Batch 2200 Loss 2.2912 Accuracy 0.9972\n",
      "Epoch 122 Batch 2250 Loss 2.2940 Accuracy 0.9972\n",
      "Epoch 122 Batch 2300 Loss 2.2915 Accuracy 0.9972\n",
      "Epoch 122 Batch 2350 Loss 2.2913 Accuracy 0.9972\n",
      "Epoch 122 Batch 2400 Loss 2.2926 Accuracy 0.9972\n",
      "Epoch 122 Batch 2450 Loss 2.2937 Accuracy 0.9972\n",
      "Epoch 122 Batch 2500 Loss 2.2959 Accuracy 0.9972\n",
      "Epoch 122 Batch 2550 Loss 2.2951 Accuracy 0.9972\n",
      "Epoch 122 Batch 2600 Loss 2.2931 Accuracy 0.9972\n",
      "Epoch 122 Batch 2650 Loss 2.2915 Accuracy 0.9972\n",
      "Epoch 122 Loss 2.2929 Accuracy 0.9972\n",
      "Time taken for 1 epoch: 194.72103834152222 secs\n",
      "\n",
      "Epoch 123 Batch 0 Loss 1.4942 Accuracy 0.9980\n",
      "Epoch 123 Batch 50 Loss 2.3611 Accuracy 0.9971\n",
      "Epoch 123 Batch 100 Loss 2.3576 Accuracy 0.9971\n",
      "Epoch 123 Batch 150 Loss 2.3497 Accuracy 0.9971\n",
      "Epoch 123 Batch 200 Loss 2.2824 Accuracy 0.9972\n",
      "Epoch 123 Batch 250 Loss 2.2681 Accuracy 0.9972\n",
      "Epoch 123 Batch 300 Loss 2.2628 Accuracy 0.9972\n",
      "Epoch 123 Batch 350 Loss 2.2655 Accuracy 0.9972\n",
      "Epoch 123 Batch 400 Loss 2.2628 Accuracy 0.9972\n",
      "Epoch 123 Batch 450 Loss 2.2874 Accuracy 0.9972\n",
      "Epoch 123 Batch 500 Loss 2.2745 Accuracy 0.9972\n",
      "Epoch 123 Batch 550 Loss 2.2900 Accuracy 0.9972\n",
      "Epoch 123 Batch 600 Loss 2.3027 Accuracy 0.9972\n",
      "Epoch 123 Batch 650 Loss 2.3019 Accuracy 0.9972\n",
      "Epoch 123 Batch 700 Loss 2.2998 Accuracy 0.9972\n",
      "Epoch 123 Batch 750 Loss 2.3037 Accuracy 0.9972\n",
      "Epoch 123 Batch 800 Loss 2.2918 Accuracy 0.9972\n",
      "Epoch 123 Batch 850 Loss 2.2945 Accuracy 0.9972\n",
      "Epoch 123 Batch 900 Loss 2.2942 Accuracy 0.9972\n",
      "Epoch 123 Batch 950 Loss 2.3001 Accuracy 0.9972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123 Batch 1000 Loss 2.2973 Accuracy 0.9972\n",
      "Epoch 123 Batch 1050 Loss 2.2894 Accuracy 0.9972\n",
      "Epoch 123 Batch 1100 Loss 2.2886 Accuracy 0.9972\n",
      "Epoch 123 Batch 1150 Loss 2.2816 Accuracy 0.9972\n",
      "Epoch 123 Batch 1200 Loss 2.2907 Accuracy 0.9972\n",
      "Epoch 123 Batch 1250 Loss 2.2880 Accuracy 0.9972\n",
      "Epoch 123 Batch 1300 Loss 2.2878 Accuracy 0.9972\n",
      "Epoch 123 Batch 1350 Loss 2.2842 Accuracy 0.9972\n",
      "Epoch 123 Batch 1400 Loss 2.2856 Accuracy 0.9972\n",
      "Epoch 123 Batch 1450 Loss 2.2811 Accuracy 0.9972\n",
      "Epoch 123 Batch 1500 Loss 2.2797 Accuracy 0.9972\n",
      "Epoch 123 Batch 1550 Loss 2.2813 Accuracy 0.9972\n",
      "Epoch 123 Batch 1600 Loss 2.2830 Accuracy 0.9972\n",
      "Epoch 123 Batch 1650 Loss 2.2863 Accuracy 0.9972\n",
      "Epoch 123 Batch 1700 Loss 2.2884 Accuracy 0.9972\n",
      "Epoch 123 Batch 1750 Loss 2.2855 Accuracy 0.9972\n",
      "Epoch 123 Batch 1800 Loss 2.2880 Accuracy 0.9972\n",
      "Epoch 123 Batch 1850 Loss 2.2839 Accuracy 0.9972\n",
      "Epoch 123 Batch 1900 Loss 2.2807 Accuracy 0.9972\n",
      "Epoch 123 Batch 1950 Loss 2.2728 Accuracy 0.9972\n",
      "Epoch 123 Batch 2000 Loss 2.2778 Accuracy 0.9972\n",
      "Epoch 123 Batch 2050 Loss 2.2819 Accuracy 0.9972\n",
      "Epoch 123 Batch 2100 Loss 2.2797 Accuracy 0.9972\n",
      "Epoch 123 Batch 2150 Loss 2.2808 Accuracy 0.9972\n",
      "Epoch 123 Batch 2200 Loss 2.2849 Accuracy 0.9972\n",
      "Epoch 123 Batch 2250 Loss 2.2872 Accuracy 0.9972\n",
      "Epoch 123 Batch 2300 Loss 2.2837 Accuracy 0.9972\n",
      "Epoch 123 Batch 2350 Loss 2.2840 Accuracy 0.9972\n",
      "Epoch 123 Batch 2400 Loss 2.2864 Accuracy 0.9972\n",
      "Epoch 123 Batch 2450 Loss 2.2881 Accuracy 0.9972\n",
      "Epoch 123 Batch 2500 Loss 2.2901 Accuracy 0.9972\n",
      "Epoch 123 Batch 2550 Loss 2.2889 Accuracy 0.9972\n",
      "Epoch 123 Batch 2600 Loss 2.2872 Accuracy 0.9972\n",
      "Epoch 123 Batch 2650 Loss 2.2854 Accuracy 0.9972\n",
      "Epoch 123 Loss 2.2859 Accuracy 0.9972\n",
      "Time taken for 1 epoch: 194.92230653762817 secs\n",
      "\n",
      "Epoch 124 Batch 0 Loss 1.9618 Accuracy 0.9976\n",
      "Epoch 124 Batch 50 Loss 2.2858 Accuracy 0.9972\n",
      "Epoch 124 Batch 100 Loss 2.2843 Accuracy 0.9972\n",
      "Epoch 124 Batch 150 Loss 2.3245 Accuracy 0.9972\n",
      "Epoch 124 Batch 200 Loss 2.2664 Accuracy 0.9973\n",
      "Epoch 124 Batch 250 Loss 2.2494 Accuracy 0.9973\n",
      "Epoch 124 Batch 300 Loss 2.2519 Accuracy 0.9973\n",
      "Epoch 124 Batch 350 Loss 2.2551 Accuracy 0.9972\n",
      "Epoch 124 Batch 400 Loss 2.2570 Accuracy 0.9972\n",
      "Epoch 124 Batch 450 Loss 2.2857 Accuracy 0.9972\n",
      "Epoch 124 Batch 500 Loss 2.2823 Accuracy 0.9972\n",
      "Epoch 124 Batch 550 Loss 2.2948 Accuracy 0.9972\n",
      "Epoch 124 Batch 600 Loss 2.3044 Accuracy 0.9972\n",
      "Epoch 124 Batch 650 Loss 2.3021 Accuracy 0.9972\n",
      "Epoch 124 Batch 700 Loss 2.3013 Accuracy 0.9972\n",
      "Epoch 124 Batch 750 Loss 2.3023 Accuracy 0.9972\n",
      "Epoch 124 Batch 800 Loss 2.2890 Accuracy 0.9972\n",
      "Epoch 124 Batch 850 Loss 2.2928 Accuracy 0.9972\n",
      "Epoch 124 Batch 900 Loss 2.2937 Accuracy 0.9972\n",
      "Epoch 124 Batch 950 Loss 2.2986 Accuracy 0.9972\n",
      "Epoch 124 Batch 1000 Loss 2.2918 Accuracy 0.9972\n",
      "Epoch 124 Batch 1050 Loss 2.2829 Accuracy 0.9972\n",
      "Epoch 124 Batch 1100 Loss 2.2814 Accuracy 0.9972\n",
      "Epoch 124 Batch 1150 Loss 2.2754 Accuracy 0.9972\n",
      "Epoch 124 Batch 1200 Loss 2.2846 Accuracy 0.9972\n",
      "Epoch 124 Batch 1250 Loss 2.2817 Accuracy 0.9972\n",
      "Epoch 124 Batch 1300 Loss 2.2827 Accuracy 0.9972\n",
      "Epoch 124 Batch 1350 Loss 2.2818 Accuracy 0.9972\n",
      "Epoch 124 Batch 1400 Loss 2.2852 Accuracy 0.9972\n",
      "Epoch 124 Batch 1450 Loss 2.2801 Accuracy 0.9972\n",
      "Epoch 124 Batch 1500 Loss 2.2781 Accuracy 0.9972\n",
      "Epoch 124 Batch 1550 Loss 2.2793 Accuracy 0.9972\n",
      "Epoch 124 Batch 1600 Loss 2.2806 Accuracy 0.9972\n",
      "Epoch 124 Batch 1650 Loss 2.2813 Accuracy 0.9972\n",
      "Epoch 124 Batch 1700 Loss 2.2838 Accuracy 0.9972\n",
      "Epoch 124 Batch 1750 Loss 2.2790 Accuracy 0.9972\n",
      "Epoch 124 Batch 1800 Loss 2.2814 Accuracy 0.9972\n",
      "Epoch 124 Batch 1850 Loss 2.2766 Accuracy 0.9972\n",
      "Epoch 124 Batch 1900 Loss 2.2740 Accuracy 0.9972\n",
      "Epoch 124 Batch 1950 Loss 2.2666 Accuracy 0.9972\n",
      "Epoch 124 Batch 2000 Loss 2.2720 Accuracy 0.9972\n",
      "Epoch 124 Batch 2050 Loss 2.2777 Accuracy 0.9972\n",
      "Epoch 124 Batch 2100 Loss 2.2771 Accuracy 0.9972\n",
      "Epoch 124 Batch 2150 Loss 2.2794 Accuracy 0.9972\n",
      "Epoch 124 Batch 2200 Loss 2.2832 Accuracy 0.9972\n",
      "Epoch 124 Batch 2250 Loss 2.2844 Accuracy 0.9972\n",
      "Epoch 124 Batch 2300 Loss 2.2806 Accuracy 0.9972\n",
      "Epoch 124 Batch 2350 Loss 2.2807 Accuracy 0.9972\n",
      "Epoch 124 Batch 2400 Loss 2.2817 Accuracy 0.9972\n",
      "Epoch 124 Batch 2450 Loss 2.2830 Accuracy 0.9972\n",
      "Epoch 124 Batch 2500 Loss 2.2845 Accuracy 0.9972\n",
      "Epoch 124 Batch 2550 Loss 2.2830 Accuracy 0.9972\n",
      "Epoch 124 Batch 2600 Loss 2.2807 Accuracy 0.9972\n",
      "Epoch 124 Batch 2650 Loss 2.2791 Accuracy 0.9972\n",
      "Epoch 124 Loss 2.2807 Accuracy 0.9972\n",
      "Time taken for 1 epoch: 195.97332978248596 secs\n",
      "\n",
      "Epoch 125 Batch 0 Loss 1.5751 Accuracy 0.9984\n",
      "Epoch 125 Batch 50 Loss 2.3084 Accuracy 0.9972\n",
      "Epoch 125 Batch 100 Loss 2.3148 Accuracy 0.9972\n",
      "Epoch 125 Batch 150 Loss 2.3295 Accuracy 0.9972\n",
      "Epoch 125 Batch 200 Loss 2.2725 Accuracy 0.9972\n",
      "Epoch 125 Batch 250 Loss 2.2646 Accuracy 0.9972\n",
      "Epoch 125 Batch 300 Loss 2.2627 Accuracy 0.9972\n",
      "Epoch 125 Batch 350 Loss 2.2658 Accuracy 0.9972\n",
      "Epoch 125 Batch 400 Loss 2.2761 Accuracy 0.9972\n",
      "Epoch 125 Batch 450 Loss 2.2975 Accuracy 0.9972\n",
      "Epoch 125 Batch 500 Loss 2.2912 Accuracy 0.9972\n",
      "Epoch 125 Batch 550 Loss 2.2990 Accuracy 0.9972\n",
      "Epoch 125 Batch 600 Loss 2.3118 Accuracy 0.9972\n",
      "Epoch 125 Batch 650 Loss 2.3103 Accuracy 0.9972\n",
      "Epoch 125 Batch 700 Loss 2.3070 Accuracy 0.9972\n",
      "Epoch 125 Batch 750 Loss 2.3099 Accuracy 0.9972\n",
      "Epoch 125 Batch 800 Loss 2.2963 Accuracy 0.9972\n",
      "Epoch 125 Batch 850 Loss 2.3024 Accuracy 0.9972\n",
      "Epoch 125 Batch 900 Loss 2.3038 Accuracy 0.9972\n",
      "Epoch 125 Batch 950 Loss 2.3057 Accuracy 0.9972\n",
      "Epoch 125 Batch 1000 Loss 2.3022 Accuracy 0.9972\n",
      "Epoch 125 Batch 1050 Loss 2.2949 Accuracy 0.9972\n",
      "Epoch 125 Batch 1100 Loss 2.2929 Accuracy 0.9972\n",
      "Epoch 125 Batch 1150 Loss 2.2845 Accuracy 0.9972\n",
      "Epoch 125 Batch 1200 Loss 2.2959 Accuracy 0.9972\n",
      "Epoch 125 Batch 1250 Loss 2.2922 Accuracy 0.9972\n",
      "Epoch 125 Batch 1300 Loss 2.2925 Accuracy 0.9972\n",
      "Epoch 125 Batch 1350 Loss 2.2892 Accuracy 0.9972\n",
      "Epoch 125 Batch 1400 Loss 2.2907 Accuracy 0.9972\n",
      "Epoch 125 Batch 1450 Loss 2.2851 Accuracy 0.9972\n",
      "Epoch 125 Batch 1500 Loss 2.2826 Accuracy 0.9972\n",
      "Epoch 125 Batch 1550 Loss 2.2852 Accuracy 0.9972\n",
      "Epoch 125 Batch 1600 Loss 2.2859 Accuracy 0.9972\n",
      "Epoch 125 Batch 1650 Loss 2.2864 Accuracy 0.9972\n",
      "Epoch 125 Batch 1700 Loss 2.2873 Accuracy 0.9972\n",
      "Epoch 125 Batch 1750 Loss 2.2842 Accuracy 0.9972\n",
      "Epoch 125 Batch 1800 Loss 2.2860 Accuracy 0.9972\n",
      "Epoch 125 Batch 1850 Loss 2.2802 Accuracy 0.9972\n",
      "Epoch 125 Batch 1900 Loss 2.2771 Accuracy 0.9972\n",
      "Epoch 125 Batch 1950 Loss 2.2694 Accuracy 0.9972\n",
      "Epoch 125 Batch 2000 Loss 2.2731 Accuracy 0.9972\n",
      "Epoch 125 Batch 2050 Loss 2.2785 Accuracy 0.9972\n",
      "Epoch 125 Batch 2100 Loss 2.2783 Accuracy 0.9972\n",
      "Epoch 125 Batch 2150 Loss 2.2803 Accuracy 0.9972\n",
      "Epoch 125 Batch 2200 Loss 2.2825 Accuracy 0.9972\n",
      "Epoch 125 Batch 2250 Loss 2.2838 Accuracy 0.9972\n",
      "Epoch 125 Batch 2300 Loss 2.2814 Accuracy 0.9972\n",
      "Epoch 125 Batch 2350 Loss 2.2811 Accuracy 0.9972\n",
      "Epoch 125 Batch 2400 Loss 2.2835 Accuracy 0.9972\n",
      "Epoch 125 Batch 2450 Loss 2.2855 Accuracy 0.9972\n",
      "Epoch 125 Batch 2500 Loss 2.2869 Accuracy 0.9972\n",
      "Epoch 125 Batch 2550 Loss 2.2858 Accuracy 0.9972\n",
      "Epoch 125 Batch 2600 Loss 2.2844 Accuracy 0.9972\n",
      "Epoch 125 Batch 2650 Loss 2.2828 Accuracy 0.9972\n",
      "Saving checkpoint for epoch 125 at ./checkpoints/train\\ckpt-26\n",
      "Epoch 125 Loss 2.2842 Accuracy 0.9972\n",
      "Time taken for 1 epoch: 194.76048231124878 secs\n",
      "\n",
      "Epoch 126 Batch 0 Loss 1.8473 Accuracy 0.9978\n",
      "Epoch 126 Batch 50 Loss 2.3375 Accuracy 0.9971\n",
      "Epoch 126 Batch 100 Loss 2.2952 Accuracy 0.9972\n",
      "Epoch 126 Batch 150 Loss 2.3140 Accuracy 0.9972\n",
      "Epoch 126 Batch 200 Loss 2.2491 Accuracy 0.9973\n",
      "Epoch 126 Batch 250 Loss 2.2370 Accuracy 0.9973\n",
      "Epoch 126 Batch 300 Loss 2.2348 Accuracy 0.9973\n",
      "Epoch 126 Batch 350 Loss 2.2439 Accuracy 0.9973\n",
      "Epoch 126 Batch 400 Loss 2.2412 Accuracy 0.9973\n",
      "Epoch 126 Batch 450 Loss 2.2679 Accuracy 0.9972\n",
      "Epoch 126 Batch 500 Loss 2.2602 Accuracy 0.9972\n",
      "Epoch 126 Batch 550 Loss 2.2712 Accuracy 0.9972\n",
      "Epoch 126 Batch 600 Loss 2.2817 Accuracy 0.9972\n",
      "Epoch 126 Batch 650 Loss 2.2822 Accuracy 0.9972\n",
      "Epoch 126 Batch 700 Loss 2.2809 Accuracy 0.9972\n",
      "Epoch 126 Batch 750 Loss 2.2842 Accuracy 0.9972\n",
      "Epoch 126 Batch 800 Loss 2.2736 Accuracy 0.9972\n",
      "Epoch 126 Batch 850 Loss 2.2793 Accuracy 0.9972\n",
      "Epoch 126 Batch 900 Loss 2.2776 Accuracy 0.9972\n",
      "Epoch 126 Batch 950 Loss 2.2826 Accuracy 0.9972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126 Batch 1000 Loss 2.2819 Accuracy 0.9972\n",
      "Epoch 126 Batch 1050 Loss 2.2725 Accuracy 0.9972\n",
      "Epoch 126 Batch 1100 Loss 2.2727 Accuracy 0.9972\n",
      "Epoch 126 Batch 1150 Loss 2.2654 Accuracy 0.9972\n",
      "Epoch 126 Batch 1200 Loss 2.2745 Accuracy 0.9972\n",
      "Epoch 126 Batch 1250 Loss 2.2709 Accuracy 0.9972\n",
      "Epoch 126 Batch 1300 Loss 2.2726 Accuracy 0.9972\n",
      "Epoch 126 Batch 1350 Loss 2.2694 Accuracy 0.9972\n",
      "Epoch 126 Batch 1400 Loss 2.2696 Accuracy 0.9972\n",
      "Epoch 126 Batch 1450 Loss 2.2646 Accuracy 0.9972\n",
      "Epoch 126 Batch 1500 Loss 2.2632 Accuracy 0.9972\n",
      "Epoch 126 Batch 1550 Loss 2.2643 Accuracy 0.9972\n",
      "Epoch 126 Batch 1600 Loss 2.2650 Accuracy 0.9972\n",
      "Epoch 126 Batch 1650 Loss 2.2671 Accuracy 0.9972\n",
      "Epoch 126 Batch 1700 Loss 2.2716 Accuracy 0.9972\n",
      "Epoch 126 Batch 1750 Loss 2.2666 Accuracy 0.9972\n",
      "Epoch 126 Batch 1800 Loss 2.2685 Accuracy 0.9972\n",
      "Epoch 126 Batch 1850 Loss 2.2625 Accuracy 0.9972\n",
      "Epoch 126 Batch 1900 Loss 2.2598 Accuracy 0.9973\n",
      "Epoch 126 Batch 1950 Loss 2.2543 Accuracy 0.9973\n",
      "Epoch 126 Batch 2000 Loss 2.2590 Accuracy 0.9973\n",
      "Epoch 126 Batch 2050 Loss 2.2639 Accuracy 0.9972\n",
      "Epoch 126 Batch 2100 Loss 2.2621 Accuracy 0.9972\n",
      "Epoch 126 Batch 2150 Loss 2.2640 Accuracy 0.9972\n",
      "Epoch 126 Batch 2200 Loss 2.2674 Accuracy 0.9972\n",
      "Epoch 126 Batch 2250 Loss 2.2682 Accuracy 0.9972\n",
      "Epoch 126 Batch 2300 Loss 2.2656 Accuracy 0.9972\n",
      "Epoch 126 Batch 2350 Loss 2.2663 Accuracy 0.9972\n",
      "Epoch 126 Batch 2400 Loss 2.2685 Accuracy 0.9972\n",
      "Epoch 126 Batch 2450 Loss 2.2698 Accuracy 0.9972\n",
      "Epoch 126 Batch 2500 Loss 2.2726 Accuracy 0.9972\n",
      "Epoch 126 Batch 2550 Loss 2.2714 Accuracy 0.9972\n",
      "Epoch 126 Batch 2600 Loss 2.2689 Accuracy 0.9972\n",
      "Epoch 126 Batch 2650 Loss 2.2674 Accuracy 0.9972\n",
      "Epoch 126 Loss 2.2686 Accuracy 0.9972\n",
      "Time taken for 1 epoch: 194.63993883132935 secs\n",
      "\n",
      "Epoch 127 Batch 0 Loss 1.3414 Accuracy 0.9983\n",
      "Epoch 127 Batch 50 Loss 2.3431 Accuracy 0.9971\n",
      "Epoch 127 Batch 100 Loss 2.3324 Accuracy 0.9971\n",
      "Epoch 127 Batch 150 Loss 2.3404 Accuracy 0.9971\n",
      "Epoch 127 Batch 200 Loss 2.2735 Accuracy 0.9972\n",
      "Epoch 127 Batch 250 Loss 2.2631 Accuracy 0.9972\n",
      "Epoch 127 Batch 300 Loss 2.2697 Accuracy 0.9972\n",
      "Epoch 127 Batch 350 Loss 2.2670 Accuracy 0.9972\n",
      "Epoch 127 Batch 400 Loss 2.2639 Accuracy 0.9972\n",
      "Epoch 127 Batch 450 Loss 2.2886 Accuracy 0.9972\n",
      "Epoch 127 Batch 500 Loss 2.2807 Accuracy 0.9972\n",
      "Epoch 127 Batch 550 Loss 2.2913 Accuracy 0.9972\n",
      "Epoch 127 Batch 600 Loss 2.2991 Accuracy 0.9972\n",
      "Epoch 127 Batch 650 Loss 2.2977 Accuracy 0.9972\n",
      "Epoch 127 Batch 700 Loss 2.2936 Accuracy 0.9972\n",
      "Epoch 127 Batch 750 Loss 2.2934 Accuracy 0.9972\n",
      "Epoch 127 Batch 800 Loss 2.2839 Accuracy 0.9972\n",
      "Epoch 127 Batch 850 Loss 2.2842 Accuracy 0.9972\n",
      "Epoch 127 Batch 900 Loss 2.2853 Accuracy 0.9972\n",
      "Epoch 127 Batch 950 Loss 2.2889 Accuracy 0.9972\n",
      "Epoch 127 Batch 1000 Loss 2.2867 Accuracy 0.9972\n",
      "Epoch 127 Batch 1050 Loss 2.2774 Accuracy 0.9972\n",
      "Epoch 127 Batch 1100 Loss 2.2764 Accuracy 0.9972\n",
      "Epoch 127 Batch 1150 Loss 2.2696 Accuracy 0.9972\n",
      "Epoch 127 Batch 1200 Loss 2.2781 Accuracy 0.9972\n",
      "Epoch 127 Batch 1250 Loss 2.2727 Accuracy 0.9972\n",
      "Epoch 127 Batch 1300 Loss 2.2733 Accuracy 0.9972\n",
      "Epoch 127 Batch 1350 Loss 2.2726 Accuracy 0.9972\n",
      "Epoch 127 Batch 1400 Loss 2.2745 Accuracy 0.9972\n",
      "Epoch 127 Batch 1450 Loss 2.2684 Accuracy 0.9972\n",
      "Epoch 127 Batch 1500 Loss 2.2657 Accuracy 0.9972\n",
      "Epoch 127 Batch 1550 Loss 2.2684 Accuracy 0.9972\n",
      "Epoch 127 Batch 1600 Loss 2.2690 Accuracy 0.9972\n",
      "Epoch 127 Batch 1650 Loss 2.2683 Accuracy 0.9972\n",
      "Epoch 127 Batch 1700 Loss 2.2710 Accuracy 0.9972\n",
      "Epoch 127 Batch 1750 Loss 2.2658 Accuracy 0.9972\n",
      "Epoch 127 Batch 1800 Loss 2.2676 Accuracy 0.9972\n",
      "Epoch 127 Batch 1850 Loss 2.2621 Accuracy 0.9972\n",
      "Epoch 127 Batch 1900 Loss 2.2591 Accuracy 0.9972\n",
      "Epoch 127 Batch 1950 Loss 2.2524 Accuracy 0.9972\n",
      "Epoch 127 Batch 2000 Loss 2.2578 Accuracy 0.9972\n",
      "Epoch 127 Batch 2050 Loss 2.2639 Accuracy 0.9972\n",
      "Epoch 127 Batch 2100 Loss 2.2637 Accuracy 0.9972\n",
      "Epoch 127 Batch 2150 Loss 2.2664 Accuracy 0.9972\n",
      "Epoch 127 Batch 2200 Loss 2.2704 Accuracy 0.9972\n",
      "Epoch 127 Batch 2250 Loss 2.2724 Accuracy 0.9972\n",
      "Epoch 127 Batch 2300 Loss 2.2699 Accuracy 0.9972\n",
      "Epoch 127 Batch 2350 Loss 2.2702 Accuracy 0.9972\n",
      "Epoch 127 Batch 2400 Loss 2.2718 Accuracy 0.9972\n",
      "Epoch 127 Batch 2450 Loss 2.2728 Accuracy 0.9972\n",
      "Epoch 127 Batch 2500 Loss 2.2740 Accuracy 0.9972\n",
      "Epoch 127 Batch 2550 Loss 2.2736 Accuracy 0.9972\n",
      "Epoch 127 Batch 2600 Loss 2.2719 Accuracy 0.9972\n",
      "Epoch 127 Batch 2650 Loss 2.2698 Accuracy 0.9972\n",
      "Epoch 127 Loss 2.2707 Accuracy 0.9972\n",
      "Time taken for 1 epoch: 195.0431308746338 secs\n",
      "\n",
      "Epoch 128 Batch 0 Loss 1.4224 Accuracy 0.9984\n",
      "Epoch 128 Batch 50 Loss 2.3372 Accuracy 0.9971\n",
      "Epoch 128 Batch 100 Loss 2.3136 Accuracy 0.9972\n",
      "Epoch 128 Batch 150 Loss 2.3114 Accuracy 0.9972\n",
      "Epoch 128 Batch 200 Loss 2.2449 Accuracy 0.9973\n",
      "Epoch 128 Batch 250 Loss 2.2347 Accuracy 0.9973\n",
      "Epoch 128 Batch 300 Loss 2.2300 Accuracy 0.9973\n",
      "Epoch 128 Batch 350 Loss 2.2291 Accuracy 0.9973\n",
      "Epoch 128 Batch 400 Loss 2.2306 Accuracy 0.9973\n",
      "Epoch 128 Batch 450 Loss 2.2638 Accuracy 0.9972\n",
      "Epoch 128 Batch 500 Loss 2.2552 Accuracy 0.9972\n",
      "Epoch 128 Batch 550 Loss 2.2645 Accuracy 0.9972\n",
      "Epoch 128 Batch 600 Loss 2.2770 Accuracy 0.9972\n",
      "Epoch 128 Batch 650 Loss 2.2770 Accuracy 0.9972\n",
      "Epoch 128 Batch 700 Loss 2.2733 Accuracy 0.9972\n",
      "Epoch 128 Batch 750 Loss 2.2744 Accuracy 0.9972\n",
      "Epoch 128 Batch 800 Loss 2.2647 Accuracy 0.9972\n",
      "Epoch 128 Batch 850 Loss 2.2678 Accuracy 0.9972\n",
      "Epoch 128 Batch 900 Loss 2.2657 Accuracy 0.9972\n",
      "Epoch 128 Batch 950 Loss 2.2710 Accuracy 0.9972\n",
      "Epoch 128 Batch 1000 Loss 2.2705 Accuracy 0.9972\n",
      "Epoch 128 Batch 1050 Loss 2.2619 Accuracy 0.9972\n",
      "Epoch 128 Batch 1100 Loss 2.2589 Accuracy 0.9972\n",
      "Epoch 128 Batch 1150 Loss 2.2519 Accuracy 0.9973\n",
      "Epoch 128 Batch 1200 Loss 2.2617 Accuracy 0.9972\n",
      "Epoch 128 Batch 1250 Loss 2.2570 Accuracy 0.9972\n",
      "Epoch 128 Batch 1300 Loss 2.2608 Accuracy 0.9972\n",
      "Epoch 128 Batch 1350 Loss 2.2576 Accuracy 0.9972\n",
      "Epoch 128 Batch 1400 Loss 2.2609 Accuracy 0.9972\n",
      "Epoch 128 Batch 1450 Loss 2.2580 Accuracy 0.9972\n",
      "Epoch 128 Batch 1500 Loss 2.2574 Accuracy 0.9972\n",
      "Epoch 128 Batch 1550 Loss 2.2577 Accuracy 0.9972\n",
      "Epoch 128 Batch 1600 Loss 2.2577 Accuracy 0.9972\n",
      "Epoch 128 Batch 1650 Loss 2.2581 Accuracy 0.9972\n",
      "Epoch 128 Batch 1700 Loss 2.2595 Accuracy 0.9972\n",
      "Epoch 128 Batch 1750 Loss 2.2550 Accuracy 0.9973\n",
      "Epoch 128 Batch 1800 Loss 2.2571 Accuracy 0.9972\n",
      "Epoch 128 Batch 1850 Loss 2.2519 Accuracy 0.9973\n",
      "Epoch 128 Batch 1900 Loss 2.2483 Accuracy 0.9973\n",
      "Epoch 128 Batch 1950 Loss 2.2412 Accuracy 0.9973\n",
      "Epoch 128 Batch 2000 Loss 2.2473 Accuracy 0.9973\n",
      "Epoch 128 Batch 2050 Loss 2.2536 Accuracy 0.9973\n",
      "Epoch 128 Batch 2100 Loss 2.2526 Accuracy 0.9973\n",
      "Epoch 128 Batch 2150 Loss 2.2543 Accuracy 0.9973\n",
      "Epoch 128 Batch 2200 Loss 2.2582 Accuracy 0.9972\n",
      "Epoch 128 Batch 2250 Loss 2.2587 Accuracy 0.9972\n",
      "Epoch 128 Batch 2300 Loss 2.2553 Accuracy 0.9973\n",
      "Epoch 128 Batch 2350 Loss 2.2553 Accuracy 0.9973\n",
      "Epoch 128 Batch 2400 Loss 2.2573 Accuracy 0.9972\n",
      "Epoch 128 Batch 2450 Loss 2.2589 Accuracy 0.9972\n",
      "Epoch 128 Batch 2500 Loss 2.2613 Accuracy 0.9972\n",
      "Epoch 128 Batch 2550 Loss 2.2607 Accuracy 0.9972\n",
      "Epoch 128 Batch 2600 Loss 2.2586 Accuracy 0.9972\n",
      "Epoch 128 Batch 2650 Loss 2.2572 Accuracy 0.9973\n",
      "Epoch 128 Loss 2.2580 Accuracy 0.9972\n",
      "Time taken for 1 epoch: 194.35318303108215 secs\n",
      "\n",
      "Epoch 129 Batch 0 Loss 1.5976 Accuracy 0.9979\n",
      "Epoch 129 Batch 50 Loss 2.2567 Accuracy 0.9972\n",
      "Epoch 129 Batch 100 Loss 2.2544 Accuracy 0.9972\n",
      "Epoch 129 Batch 150 Loss 2.2881 Accuracy 0.9972\n",
      "Epoch 129 Batch 200 Loss 2.2356 Accuracy 0.9973\n",
      "Epoch 129 Batch 250 Loss 2.2282 Accuracy 0.9973\n",
      "Epoch 129 Batch 300 Loss 2.2342 Accuracy 0.9973\n",
      "Epoch 129 Batch 350 Loss 2.2381 Accuracy 0.9973\n",
      "Epoch 129 Batch 400 Loss 2.2314 Accuracy 0.9973\n",
      "Epoch 129 Batch 450 Loss 2.2620 Accuracy 0.9972\n",
      "Epoch 129 Batch 500 Loss 2.2524 Accuracy 0.9972\n",
      "Epoch 129 Batch 550 Loss 2.2661 Accuracy 0.9972\n",
      "Epoch 129 Batch 600 Loss 2.2765 Accuracy 0.9972\n",
      "Epoch 129 Batch 650 Loss 2.2706 Accuracy 0.9972\n",
      "Epoch 129 Batch 700 Loss 2.2693 Accuracy 0.9972\n",
      "Epoch 129 Batch 750 Loss 2.2699 Accuracy 0.9972\n",
      "Epoch 129 Batch 800 Loss 2.2570 Accuracy 0.9972\n",
      "Epoch 129 Batch 850 Loss 2.2605 Accuracy 0.9972\n",
      "Epoch 129 Batch 900 Loss 2.2606 Accuracy 0.9972\n",
      "Epoch 129 Batch 950 Loss 2.2649 Accuracy 0.9972\n",
      "Epoch 129 Batch 1000 Loss 2.2606 Accuracy 0.9972\n",
      "Epoch 129 Batch 1050 Loss 2.2529 Accuracy 0.9972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129 Batch 1100 Loss 2.2519 Accuracy 0.9972\n",
      "Epoch 129 Batch 1150 Loss 2.2443 Accuracy 0.9973\n",
      "Epoch 129 Batch 1200 Loss 2.2540 Accuracy 0.9972\n",
      "Epoch 129 Batch 1250 Loss 2.2489 Accuracy 0.9973\n",
      "Epoch 129 Batch 1300 Loss 2.2506 Accuracy 0.9972\n",
      "Epoch 129 Batch 1350 Loss 2.2472 Accuracy 0.9973\n",
      "Epoch 129 Batch 1400 Loss 2.2477 Accuracy 0.9973\n",
      "Epoch 129 Batch 1450 Loss 2.2428 Accuracy 0.9973\n",
      "Epoch 129 Batch 1500 Loss 2.2436 Accuracy 0.9973\n",
      "Epoch 129 Batch 1550 Loss 2.2458 Accuracy 0.9973\n",
      "Epoch 129 Batch 1600 Loss 2.2466 Accuracy 0.9973\n",
      "Epoch 129 Batch 1650 Loss 2.2481 Accuracy 0.9973\n",
      "Epoch 129 Batch 1700 Loss 2.2501 Accuracy 0.9973\n",
      "Epoch 129 Batch 1750 Loss 2.2464 Accuracy 0.9973\n",
      "Epoch 129 Batch 1800 Loss 2.2488 Accuracy 0.9973\n",
      "Epoch 129 Batch 1850 Loss 2.2436 Accuracy 0.9973\n",
      "Epoch 129 Batch 1900 Loss 2.2406 Accuracy 0.9973\n",
      "Epoch 129 Batch 1950 Loss 2.2329 Accuracy 0.9973\n",
      "Epoch 129 Batch 2000 Loss 2.2377 Accuracy 0.9973\n",
      "Epoch 129 Batch 2050 Loss 2.2429 Accuracy 0.9973\n",
      "Epoch 129 Batch 2100 Loss 2.2416 Accuracy 0.9973\n",
      "Epoch 129 Batch 2150 Loss 2.2444 Accuracy 0.9973\n",
      "Epoch 129 Batch 2200 Loss 2.2484 Accuracy 0.9973\n",
      "Epoch 129 Batch 2250 Loss 2.2512 Accuracy 0.9973\n",
      "Epoch 129 Batch 2300 Loss 2.2487 Accuracy 0.9973\n",
      "Epoch 129 Batch 2350 Loss 2.2481 Accuracy 0.9973\n",
      "Epoch 129 Batch 2400 Loss 2.2499 Accuracy 0.9973\n",
      "Epoch 129 Batch 2450 Loss 2.2507 Accuracy 0.9973\n",
      "Epoch 129 Batch 2500 Loss 2.2527 Accuracy 0.9973\n",
      "Epoch 129 Batch 2550 Loss 2.2522 Accuracy 0.9973\n",
      "Epoch 129 Batch 2600 Loss 2.2501 Accuracy 0.9973\n",
      "Epoch 129 Batch 2650 Loss 2.2488 Accuracy 0.9973\n",
      "Epoch 129 Loss 2.2500 Accuracy 0.9973\n",
      "Time taken for 1 epoch: 194.94008374214172 secs\n",
      "\n",
      "Epoch 130 Batch 0 Loss 1.6067 Accuracy 0.9980\n",
      "Epoch 130 Batch 50 Loss 2.3168 Accuracy 0.9971\n",
      "Epoch 130 Batch 100 Loss 2.3037 Accuracy 0.9972\n",
      "Epoch 130 Batch 150 Loss 2.3167 Accuracy 0.9972\n",
      "Epoch 130 Batch 200 Loss 2.2511 Accuracy 0.9973\n",
      "Epoch 130 Batch 250 Loss 2.2369 Accuracy 0.9973\n",
      "Epoch 130 Batch 300 Loss 2.2307 Accuracy 0.9973\n",
      "Epoch 130 Batch 350 Loss 2.2250 Accuracy 0.9973\n",
      "Epoch 130 Batch 400 Loss 2.2233 Accuracy 0.9973\n",
      "Epoch 130 Batch 450 Loss 2.2583 Accuracy 0.9972\n",
      "Epoch 130 Batch 500 Loss 2.2452 Accuracy 0.9972\n",
      "Epoch 130 Batch 550 Loss 2.2553 Accuracy 0.9972\n",
      "Epoch 130 Batch 600 Loss 2.2722 Accuracy 0.9972\n",
      "Epoch 130 Batch 650 Loss 2.2682 Accuracy 0.9972\n",
      "Epoch 130 Batch 700 Loss 2.2659 Accuracy 0.9972\n",
      "Epoch 130 Batch 750 Loss 2.2681 Accuracy 0.9972\n",
      "Epoch 130 Batch 800 Loss 2.2560 Accuracy 0.9972\n",
      "Epoch 130 Batch 850 Loss 2.2596 Accuracy 0.9972\n",
      "Epoch 130 Batch 900 Loss 2.2583 Accuracy 0.9972\n",
      "Epoch 130 Batch 950 Loss 2.2652 Accuracy 0.9972\n",
      "Epoch 130 Batch 1000 Loss 2.2637 Accuracy 0.9972\n",
      "Epoch 130 Batch 1050 Loss 2.2578 Accuracy 0.9972\n",
      "Epoch 130 Batch 1100 Loss 2.2536 Accuracy 0.9973\n",
      "Epoch 130 Batch 1150 Loss 2.2464 Accuracy 0.9973\n",
      "Epoch 130 Batch 1200 Loss 2.2584 Accuracy 0.9972\n",
      "Epoch 130 Batch 1250 Loss 2.2548 Accuracy 0.9973\n",
      "Epoch 130 Batch 1300 Loss 2.2569 Accuracy 0.9972\n",
      "Epoch 130 Batch 1350 Loss 2.2555 Accuracy 0.9972\n",
      "Epoch 130 Batch 1400 Loss 2.2556 Accuracy 0.9973\n",
      "Epoch 130 Batch 1450 Loss 2.2508 Accuracy 0.9973\n",
      "Epoch 130 Batch 1500 Loss 2.2492 Accuracy 0.9973\n",
      "Epoch 130 Batch 1550 Loss 2.2501 Accuracy 0.9973\n",
      "Epoch 130 Batch 1600 Loss 2.2513 Accuracy 0.9973\n",
      "Epoch 130 Batch 1650 Loss 2.2523 Accuracy 0.9973\n",
      "Epoch 130 Batch 1700 Loss 2.2564 Accuracy 0.9973\n",
      "Epoch 130 Batch 1750 Loss 2.2518 Accuracy 0.9973\n",
      "Epoch 130 Batch 1800 Loss 2.2520 Accuracy 0.9973\n",
      "Epoch 130 Batch 1850 Loss 2.2452 Accuracy 0.9973\n",
      "Epoch 130 Batch 1900 Loss 2.2423 Accuracy 0.9973\n",
      "Epoch 130 Batch 1950 Loss 2.2357 Accuracy 0.9973\n",
      "Epoch 130 Batch 2000 Loss 2.2401 Accuracy 0.9973\n",
      "Epoch 130 Batch 2050 Loss 2.2450 Accuracy 0.9973\n",
      "Epoch 130 Batch 2100 Loss 2.2432 Accuracy 0.9973\n",
      "Epoch 130 Batch 2150 Loss 2.2455 Accuracy 0.9973\n",
      "Epoch 130 Batch 2200 Loss 2.2490 Accuracy 0.9973\n",
      "Epoch 130 Batch 2250 Loss 2.2500 Accuracy 0.9973\n",
      "Epoch 130 Batch 2300 Loss 2.2478 Accuracy 0.9973\n",
      "Epoch 130 Batch 2350 Loss 2.2482 Accuracy 0.9973\n",
      "Epoch 130 Batch 2400 Loss 2.2489 Accuracy 0.9973\n",
      "Epoch 130 Batch 2450 Loss 2.2504 Accuracy 0.9973\n",
      "Epoch 130 Batch 2500 Loss 2.2522 Accuracy 0.9973\n",
      "Epoch 130 Batch 2550 Loss 2.2516 Accuracy 0.9973\n",
      "Epoch 130 Batch 2600 Loss 2.2489 Accuracy 0.9973\n",
      "Epoch 130 Batch 2650 Loss 2.2475 Accuracy 0.9973\n",
      "Saving checkpoint for epoch 130 at ./checkpoints/train\\ckpt-27\n",
      "Epoch 130 Loss 2.2491 Accuracy 0.9973\n",
      "Time taken for 1 epoch: 195.2801694869995 secs\n",
      "\n",
      "Epoch 131 Batch 0 Loss 1.6765 Accuracy 0.9979\n",
      "Epoch 131 Batch 50 Loss 2.3414 Accuracy 0.9972\n",
      "Epoch 131 Batch 100 Loss 2.2888 Accuracy 0.9972\n",
      "Epoch 131 Batch 150 Loss 2.2937 Accuracy 0.9972\n",
      "Epoch 131 Batch 200 Loss 2.2273 Accuracy 0.9973\n",
      "Epoch 131 Batch 250 Loss 2.2182 Accuracy 0.9973\n",
      "Epoch 131 Batch 300 Loss 2.2190 Accuracy 0.9973\n",
      "Epoch 131 Batch 350 Loss 2.2155 Accuracy 0.9973\n",
      "Epoch 131 Batch 400 Loss 2.2176 Accuracy 0.9973\n",
      "Epoch 131 Batch 450 Loss 2.2432 Accuracy 0.9973\n",
      "Epoch 131 Batch 500 Loss 2.2324 Accuracy 0.9973\n",
      "Epoch 131 Batch 550 Loss 2.2400 Accuracy 0.9973\n",
      "Epoch 131 Batch 600 Loss 2.2536 Accuracy 0.9973\n",
      "Epoch 131 Batch 650 Loss 2.2497 Accuracy 0.9973\n",
      "Epoch 131 Batch 700 Loss 2.2483 Accuracy 0.9973\n",
      "Epoch 131 Batch 750 Loss 2.2465 Accuracy 0.9973\n",
      "Epoch 131 Batch 800 Loss 2.2364 Accuracy 0.9973\n",
      "Epoch 131 Batch 850 Loss 2.2397 Accuracy 0.9973\n",
      "Epoch 131 Batch 900 Loss 2.2408 Accuracy 0.9973\n",
      "Epoch 131 Batch 950 Loss 2.2464 Accuracy 0.9973\n",
      "Epoch 131 Batch 1000 Loss 2.2430 Accuracy 0.9973\n",
      "Epoch 131 Batch 1050 Loss 2.2332 Accuracy 0.9973\n",
      "Epoch 131 Batch 1100 Loss 2.2301 Accuracy 0.9973\n",
      "Epoch 131 Batch 1150 Loss 2.2234 Accuracy 0.9973\n",
      "Epoch 131 Batch 1200 Loss 2.2353 Accuracy 0.9973\n",
      "Epoch 131 Batch 1250 Loss 2.2318 Accuracy 0.9973\n",
      "Epoch 131 Batch 1300 Loss 2.2334 Accuracy 0.9973\n",
      "Epoch 131 Batch 1350 Loss 2.2299 Accuracy 0.9973\n",
      "Epoch 131 Batch 1400 Loss 2.2329 Accuracy 0.9973\n",
      "Epoch 131 Batch 1450 Loss 2.2282 Accuracy 0.9973\n",
      "Epoch 131 Batch 1500 Loss 2.2278 Accuracy 0.9973\n",
      "Epoch 131 Batch 1550 Loss 2.2309 Accuracy 0.9973\n",
      "Epoch 131 Batch 1600 Loss 2.2336 Accuracy 0.9973\n",
      "Epoch 131 Batch 1650 Loss 2.2355 Accuracy 0.9973\n",
      "Epoch 131 Batch 1700 Loss 2.2379 Accuracy 0.9973\n",
      "Epoch 131 Batch 1750 Loss 2.2338 Accuracy 0.9973\n",
      "Epoch 131 Batch 1800 Loss 2.2365 Accuracy 0.9973\n",
      "Epoch 131 Batch 1850 Loss 2.2320 Accuracy 0.9973\n",
      "Epoch 131 Batch 1900 Loss 2.2285 Accuracy 0.9973\n",
      "Epoch 131 Batch 1950 Loss 2.2233 Accuracy 0.9973\n",
      "Epoch 131 Batch 2000 Loss 2.2278 Accuracy 0.9973\n",
      "Epoch 131 Batch 2050 Loss 2.2325 Accuracy 0.9973\n",
      "Epoch 131 Batch 2100 Loss 2.2309 Accuracy 0.9973\n",
      "Epoch 131 Batch 2150 Loss 2.2320 Accuracy 0.9973\n",
      "Epoch 131 Batch 2200 Loss 2.2360 Accuracy 0.9973\n",
      "Epoch 131 Batch 2250 Loss 2.2385 Accuracy 0.9973\n",
      "Epoch 131 Batch 2300 Loss 2.2356 Accuracy 0.9973\n",
      "Epoch 131 Batch 2350 Loss 2.2355 Accuracy 0.9973\n",
      "Epoch 131 Batch 2400 Loss 2.2364 Accuracy 0.9973\n",
      "Epoch 131 Batch 2450 Loss 2.2402 Accuracy 0.9973\n",
      "Epoch 131 Batch 2500 Loss 2.2421 Accuracy 0.9973\n",
      "Epoch 131 Batch 2550 Loss 2.2411 Accuracy 0.9973\n",
      "Epoch 131 Batch 2600 Loss 2.2400 Accuracy 0.9973\n",
      "Epoch 131 Batch 2650 Loss 2.2372 Accuracy 0.9973\n",
      "Epoch 131 Loss 2.2388 Accuracy 0.9973\n",
      "Time taken for 1 epoch: 194.5630087852478 secs\n",
      "\n",
      "Epoch 132 Batch 0 Loss 1.6126 Accuracy 0.9979\n",
      "Epoch 132 Batch 50 Loss 2.2749 Accuracy 0.9972\n",
      "Epoch 132 Batch 100 Loss 2.2438 Accuracy 0.9973\n",
      "Epoch 132 Batch 150 Loss 2.2739 Accuracy 0.9972\n",
      "Epoch 132 Batch 200 Loss 2.2274 Accuracy 0.9973\n",
      "Epoch 132 Batch 250 Loss 2.2156 Accuracy 0.9973\n",
      "Epoch 132 Batch 300 Loss 2.2141 Accuracy 0.9973\n",
      "Epoch 132 Batch 350 Loss 2.2190 Accuracy 0.9973\n",
      "Epoch 132 Batch 400 Loss 2.2148 Accuracy 0.9973\n",
      "Epoch 132 Batch 450 Loss 2.2324 Accuracy 0.9973\n",
      "Epoch 132 Batch 500 Loss 2.2310 Accuracy 0.9973\n",
      "Epoch 132 Batch 550 Loss 2.2352 Accuracy 0.9973\n",
      "Epoch 132 Batch 600 Loss 2.2507 Accuracy 0.9973\n",
      "Epoch 132 Batch 650 Loss 2.2538 Accuracy 0.9973\n",
      "Epoch 132 Batch 700 Loss 2.2503 Accuracy 0.9973\n",
      "Epoch 132 Batch 750 Loss 2.2548 Accuracy 0.9973\n",
      "Epoch 132 Batch 800 Loss 2.2417 Accuracy 0.9973\n",
      "Epoch 132 Batch 850 Loss 2.2478 Accuracy 0.9973\n",
      "Epoch 132 Batch 900 Loss 2.2497 Accuracy 0.9973\n",
      "Epoch 132 Batch 950 Loss 2.2534 Accuracy 0.9973\n",
      "Epoch 132 Batch 1000 Loss 2.2489 Accuracy 0.9973\n",
      "Epoch 132 Batch 1050 Loss 2.2410 Accuracy 0.9973\n",
      "Epoch 132 Batch 1100 Loss 2.2409 Accuracy 0.9973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 Batch 1150 Loss 2.2327 Accuracy 0.9973\n",
      "Epoch 132 Batch 1200 Loss 2.2416 Accuracy 0.9973\n",
      "Epoch 132 Batch 1250 Loss 2.2375 Accuracy 0.9973\n",
      "Epoch 132 Batch 1300 Loss 2.2385 Accuracy 0.9973\n",
      "Epoch 132 Batch 1350 Loss 2.2344 Accuracy 0.9973\n",
      "Epoch 132 Batch 1400 Loss 2.2348 Accuracy 0.9973\n",
      "Epoch 132 Batch 1450 Loss 2.2300 Accuracy 0.9973\n",
      "Epoch 132 Batch 1500 Loss 2.2271 Accuracy 0.9973\n",
      "Epoch 132 Batch 1550 Loss 2.2294 Accuracy 0.9973\n",
      "Epoch 132 Batch 1600 Loss 2.2310 Accuracy 0.9973\n",
      "Epoch 132 Batch 1650 Loss 2.2317 Accuracy 0.9973\n",
      "Epoch 132 Batch 1700 Loss 2.2333 Accuracy 0.9973\n",
      "Epoch 132 Batch 1750 Loss 2.2298 Accuracy 0.9973\n",
      "Epoch 132 Batch 1800 Loss 2.2320 Accuracy 0.9973\n",
      "Epoch 132 Batch 1850 Loss 2.2263 Accuracy 0.9973\n",
      "Epoch 132 Batch 1900 Loss 2.2217 Accuracy 0.9973\n",
      "Epoch 132 Batch 1950 Loss 2.2147 Accuracy 0.9973\n",
      "Epoch 132 Batch 2000 Loss 2.2188 Accuracy 0.9973\n",
      "Epoch 132 Batch 2050 Loss 2.2241 Accuracy 0.9973\n",
      "Epoch 132 Batch 2100 Loss 2.2233 Accuracy 0.9973\n",
      "Epoch 132 Batch 2150 Loss 2.2252 Accuracy 0.9973\n",
      "Epoch 132 Batch 2200 Loss 2.2281 Accuracy 0.9973\n",
      "Epoch 132 Batch 2250 Loss 2.2296 Accuracy 0.9973\n",
      "Epoch 132 Batch 2300 Loss 2.2271 Accuracy 0.9973\n",
      "Epoch 132 Batch 2350 Loss 2.2281 Accuracy 0.9973\n",
      "Epoch 132 Batch 2400 Loss 2.2293 Accuracy 0.9973\n",
      "Epoch 132 Batch 2450 Loss 2.2320 Accuracy 0.9973\n",
      "Epoch 132 Batch 2500 Loss 2.2332 Accuracy 0.9973\n",
      "Epoch 132 Batch 2550 Loss 2.2329 Accuracy 0.9973\n",
      "Epoch 132 Batch 2600 Loss 2.2303 Accuracy 0.9973\n",
      "Epoch 132 Batch 2650 Loss 2.2291 Accuracy 0.9973\n",
      "Epoch 132 Loss 2.2301 Accuracy 0.9973\n",
      "Time taken for 1 epoch: 195.3470401763916 secs\n",
      "\n",
      "Epoch 133 Batch 0 Loss 1.6616 Accuracy 0.9980\n",
      "Epoch 133 Batch 50 Loss 2.2146 Accuracy 0.9973\n",
      "Epoch 133 Batch 100 Loss 2.2232 Accuracy 0.9973\n",
      "Epoch 133 Batch 150 Loss 2.2505 Accuracy 0.9972\n",
      "Epoch 133 Batch 200 Loss 2.1999 Accuracy 0.9973\n",
      "Epoch 133 Batch 250 Loss 2.2082 Accuracy 0.9973\n",
      "Epoch 133 Batch 300 Loss 2.2128 Accuracy 0.9973\n",
      "Epoch 133 Batch 350 Loss 2.2180 Accuracy 0.9973\n",
      "Epoch 133 Batch 400 Loss 2.2180 Accuracy 0.9973\n",
      "Epoch 133 Batch 450 Loss 2.2424 Accuracy 0.9973\n",
      "Epoch 133 Batch 500 Loss 2.2339 Accuracy 0.9973\n",
      "Epoch 133 Batch 550 Loss 2.2439 Accuracy 0.9973\n",
      "Epoch 133 Batch 600 Loss 2.2550 Accuracy 0.9972\n",
      "Epoch 133 Batch 650 Loss 2.2554 Accuracy 0.9972\n",
      "Epoch 133 Batch 700 Loss 2.2550 Accuracy 0.9972\n",
      "Epoch 133 Batch 750 Loss 2.2576 Accuracy 0.9972\n",
      "Epoch 133 Batch 800 Loss 2.2478 Accuracy 0.9973\n",
      "Epoch 133 Batch 850 Loss 2.2529 Accuracy 0.9973\n",
      "Epoch 133 Batch 900 Loss 2.2530 Accuracy 0.9973\n",
      "Epoch 133 Batch 950 Loss 2.2559 Accuracy 0.9972\n",
      "Epoch 133 Batch 1000 Loss 2.2543 Accuracy 0.9973\n",
      "Epoch 133 Batch 1050 Loss 2.2443 Accuracy 0.9973\n",
      "Epoch 133 Batch 1100 Loss 2.2412 Accuracy 0.9973\n",
      "Epoch 133 Batch 1150 Loss 2.2332 Accuracy 0.9973\n",
      "Epoch 133 Batch 1200 Loss 2.2416 Accuracy 0.9973\n",
      "Epoch 133 Batch 1250 Loss 2.2380 Accuracy 0.9973\n",
      "Epoch 133 Batch 1300 Loss 2.2395 Accuracy 0.9973\n",
      "Epoch 133 Batch 1350 Loss 2.2365 Accuracy 0.9973\n",
      "Epoch 133 Batch 1400 Loss 2.2409 Accuracy 0.9973\n",
      "Epoch 133 Batch 1450 Loss 2.2365 Accuracy 0.9973\n",
      "Epoch 133 Batch 1500 Loss 2.2348 Accuracy 0.9973\n",
      "Epoch 133 Batch 1550 Loss 2.2375 Accuracy 0.9973\n",
      "Epoch 133 Batch 1600 Loss 2.2376 Accuracy 0.9973\n",
      "Epoch 133 Batch 1650 Loss 2.2380 Accuracy 0.9973\n",
      "Epoch 133 Batch 1700 Loss 2.2398 Accuracy 0.9973\n",
      "Epoch 133 Batch 1750 Loss 2.2346 Accuracy 0.9973\n",
      "Epoch 133 Batch 1800 Loss 2.2364 Accuracy 0.9973\n",
      "Epoch 133 Batch 1850 Loss 2.2316 Accuracy 0.9973\n",
      "Epoch 133 Batch 1900 Loss 2.2291 Accuracy 0.9973\n",
      "Epoch 133 Batch 1950 Loss 2.2224 Accuracy 0.9973\n",
      "Epoch 133 Batch 2000 Loss 2.2268 Accuracy 0.9973\n",
      "Epoch 133 Batch 2050 Loss 2.2315 Accuracy 0.9973\n",
      "Epoch 133 Batch 2100 Loss 2.2309 Accuracy 0.9973\n",
      "Epoch 133 Batch 2150 Loss 2.2326 Accuracy 0.9973\n",
      "Epoch 133 Batch 2200 Loss 2.2353 Accuracy 0.9973\n",
      "Epoch 133 Batch 2250 Loss 2.2361 Accuracy 0.9973\n",
      "Epoch 133 Batch 2300 Loss 2.2343 Accuracy 0.9973\n",
      "Epoch 133 Batch 2350 Loss 2.2334 Accuracy 0.9973\n",
      "Epoch 133 Batch 2400 Loss 2.2365 Accuracy 0.9973\n",
      "Epoch 133 Batch 2450 Loss 2.2390 Accuracy 0.9973\n",
      "Epoch 133 Batch 2500 Loss 2.2403 Accuracy 0.9973\n",
      "Epoch 133 Batch 2550 Loss 2.2386 Accuracy 0.9973\n",
      "Epoch 133 Batch 2600 Loss 2.2367 Accuracy 0.9973\n",
      "Epoch 133 Batch 2650 Loss 2.2347 Accuracy 0.9973\n",
      "Epoch 133 Loss 2.2348 Accuracy 0.9973\n",
      "Time taken for 1 epoch: 194.8231644630432 secs\n",
      "\n",
      "Epoch 134 Batch 0 Loss 1.6165 Accuracy 0.9980\n",
      "Epoch 134 Batch 50 Loss 2.2157 Accuracy 0.9973\n",
      "Epoch 134 Batch 100 Loss 2.2390 Accuracy 0.9973\n",
      "Epoch 134 Batch 150 Loss 2.2651 Accuracy 0.9972\n",
      "Epoch 134 Batch 200 Loss 2.2159 Accuracy 0.9973\n",
      "Epoch 134 Batch 250 Loss 2.2109 Accuracy 0.9973\n",
      "Epoch 134 Batch 300 Loss 2.2085 Accuracy 0.9973\n",
      "Epoch 134 Batch 350 Loss 2.2029 Accuracy 0.9973\n",
      "Epoch 134 Batch 400 Loss 2.2005 Accuracy 0.9973\n",
      "Epoch 134 Batch 450 Loss 2.2255 Accuracy 0.9973\n",
      "Epoch 134 Batch 500 Loss 2.2105 Accuracy 0.9973\n",
      "Epoch 134 Batch 550 Loss 2.2267 Accuracy 0.9973\n",
      "Epoch 134 Batch 600 Loss 2.2376 Accuracy 0.9973\n",
      "Epoch 134 Batch 650 Loss 2.2355 Accuracy 0.9973\n",
      "Epoch 134 Batch 700 Loss 2.2373 Accuracy 0.9973\n",
      "Epoch 134 Batch 750 Loss 2.2397 Accuracy 0.9973\n",
      "Epoch 134 Batch 800 Loss 2.2277 Accuracy 0.9973\n",
      "Epoch 134 Batch 850 Loss 2.2334 Accuracy 0.9973\n",
      "Epoch 134 Batch 900 Loss 2.2359 Accuracy 0.9973\n",
      "Epoch 134 Batch 950 Loss 2.2396 Accuracy 0.9973\n",
      "Epoch 134 Batch 1000 Loss 2.2391 Accuracy 0.9973\n",
      "Epoch 134 Batch 1050 Loss 2.2280 Accuracy 0.9973\n",
      "Epoch 134 Batch 1100 Loss 2.2270 Accuracy 0.9973\n",
      "Epoch 134 Batch 1150 Loss 2.2196 Accuracy 0.9973\n",
      "Epoch 134 Batch 1200 Loss 2.2281 Accuracy 0.9973\n",
      "Epoch 134 Batch 1250 Loss 2.2247 Accuracy 0.9973\n",
      "Epoch 134 Batch 1300 Loss 2.2270 Accuracy 0.9973\n",
      "Epoch 134 Batch 1350 Loss 2.2230 Accuracy 0.9973\n",
      "Epoch 134 Batch 1400 Loss 2.2253 Accuracy 0.9973\n",
      "Epoch 134 Batch 1450 Loss 2.2203 Accuracy 0.9973\n",
      "Epoch 134 Batch 1500 Loss 2.2205 Accuracy 0.9973\n",
      "Epoch 134 Batch 1550 Loss 2.2219 Accuracy 0.9973\n",
      "Epoch 134 Batch 1600 Loss 2.2219 Accuracy 0.9973\n",
      "Epoch 134 Batch 1650 Loss 2.2241 Accuracy 0.9973\n",
      "Epoch 134 Batch 1700 Loss 2.2270 Accuracy 0.9973\n",
      "Epoch 134 Batch 1750 Loss 2.2229 Accuracy 0.9973\n",
      "Epoch 134 Batch 1800 Loss 2.2249 Accuracy 0.9973\n",
      "Epoch 134 Batch 1850 Loss 2.2194 Accuracy 0.9973\n",
      "Epoch 134 Batch 1900 Loss 2.2159 Accuracy 0.9973\n",
      "Epoch 134 Batch 1950 Loss 2.2089 Accuracy 0.9973\n",
      "Epoch 134 Batch 2000 Loss 2.2148 Accuracy 0.9973\n",
      "Epoch 134 Batch 2050 Loss 2.2186 Accuracy 0.9973\n",
      "Epoch 134 Batch 2100 Loss 2.2173 Accuracy 0.9973\n",
      "Epoch 134 Batch 2150 Loss 2.2194 Accuracy 0.9973\n",
      "Epoch 134 Batch 2200 Loss 2.2225 Accuracy 0.9973\n",
      "Epoch 134 Batch 2250 Loss 2.2246 Accuracy 0.9973\n",
      "Epoch 134 Batch 2300 Loss 2.2237 Accuracy 0.9973\n",
      "Epoch 134 Batch 2350 Loss 2.2233 Accuracy 0.9973\n",
      "Epoch 134 Batch 2400 Loss 2.2237 Accuracy 0.9973\n",
      "Epoch 134 Batch 2450 Loss 2.2254 Accuracy 0.9973\n",
      "Epoch 134 Batch 2500 Loss 2.2279 Accuracy 0.9973\n",
      "Epoch 134 Batch 2550 Loss 2.2266 Accuracy 0.9973\n",
      "Epoch 134 Batch 2600 Loss 2.2245 Accuracy 0.9973\n",
      "Epoch 134 Batch 2650 Loss 2.2227 Accuracy 0.9973\n",
      "Epoch 134 Loss 2.2238 Accuracy 0.9973\n",
      "Time taken for 1 epoch: 195.74322152137756 secs\n",
      "\n",
      "Epoch 135 Batch 0 Loss 1.6140 Accuracy 0.9981\n",
      "Epoch 135 Batch 50 Loss 2.2394 Accuracy 0.9973\n",
      "Epoch 135 Batch 100 Loss 2.2416 Accuracy 0.9973\n",
      "Epoch 135 Batch 150 Loss 2.2718 Accuracy 0.9972\n",
      "Epoch 135 Batch 200 Loss 2.2086 Accuracy 0.9973\n",
      "Epoch 135 Batch 250 Loss 2.1978 Accuracy 0.9973\n",
      "Epoch 135 Batch 300 Loss 2.2012 Accuracy 0.9973\n",
      "Epoch 135 Batch 350 Loss 2.2015 Accuracy 0.9973\n",
      "Epoch 135 Batch 400 Loss 2.2007 Accuracy 0.9973\n",
      "Epoch 135 Batch 450 Loss 2.2224 Accuracy 0.9973\n",
      "Epoch 135 Batch 500 Loss 2.2120 Accuracy 0.9973\n",
      "Epoch 135 Batch 550 Loss 2.2223 Accuracy 0.9973\n",
      "Epoch 135 Batch 600 Loss 2.2405 Accuracy 0.9973\n",
      "Epoch 135 Batch 650 Loss 2.2415 Accuracy 0.9973\n",
      "Epoch 135 Batch 700 Loss 2.2427 Accuracy 0.9973\n",
      "Epoch 135 Batch 750 Loss 2.2470 Accuracy 0.9973\n",
      "Epoch 135 Batch 800 Loss 2.2380 Accuracy 0.9973\n",
      "Epoch 135 Batch 850 Loss 2.2415 Accuracy 0.9973\n",
      "Epoch 135 Batch 900 Loss 2.2403 Accuracy 0.9973\n",
      "Epoch 135 Batch 950 Loss 2.2445 Accuracy 0.9973\n",
      "Epoch 135 Batch 1000 Loss 2.2432 Accuracy 0.9973\n",
      "Epoch 135 Batch 1050 Loss 2.2344 Accuracy 0.9973\n",
      "Epoch 135 Batch 1100 Loss 2.2329 Accuracy 0.9973\n",
      "Epoch 135 Batch 1150 Loss 2.2262 Accuracy 0.9973\n",
      "Epoch 135 Batch 1200 Loss 2.2355 Accuracy 0.9973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135 Batch 1250 Loss 2.2301 Accuracy 0.9973\n",
      "Epoch 135 Batch 1300 Loss 2.2301 Accuracy 0.9973\n",
      "Epoch 135 Batch 1350 Loss 2.2285 Accuracy 0.9973\n",
      "Epoch 135 Batch 1400 Loss 2.2312 Accuracy 0.9973\n",
      "Epoch 135 Batch 1450 Loss 2.2250 Accuracy 0.9973\n",
      "Epoch 135 Batch 1500 Loss 2.2228 Accuracy 0.9973\n",
      "Epoch 135 Batch 1550 Loss 2.2251 Accuracy 0.9973\n",
      "Epoch 135 Batch 1600 Loss 2.2256 Accuracy 0.9973\n",
      "Epoch 135 Batch 1650 Loss 2.2267 Accuracy 0.9973\n",
      "Epoch 135 Batch 1700 Loss 2.2294 Accuracy 0.9973\n",
      "Epoch 135 Batch 1750 Loss 2.2249 Accuracy 0.9973\n",
      "Epoch 135 Batch 1800 Loss 2.2258 Accuracy 0.9973\n",
      "Epoch 135 Batch 1850 Loss 2.2206 Accuracy 0.9973\n",
      "Epoch 135 Batch 1900 Loss 2.2185 Accuracy 0.9973\n",
      "Epoch 135 Batch 1950 Loss 2.2126 Accuracy 0.9973\n",
      "Epoch 135 Batch 2000 Loss 2.2174 Accuracy 0.9973\n",
      "Epoch 135 Batch 2050 Loss 2.2234 Accuracy 0.9973\n",
      "Epoch 135 Batch 2100 Loss 2.2216 Accuracy 0.9973\n",
      "Epoch 135 Batch 2150 Loss 2.2249 Accuracy 0.9973\n",
      "Epoch 135 Batch 2200 Loss 2.2283 Accuracy 0.9973\n",
      "Epoch 135 Batch 2250 Loss 2.2297 Accuracy 0.9973\n",
      "Epoch 135 Batch 2300 Loss 2.2273 Accuracy 0.9973\n",
      "Epoch 135 Batch 2350 Loss 2.2264 Accuracy 0.9973\n",
      "Epoch 135 Batch 2400 Loss 2.2290 Accuracy 0.9973\n",
      "Epoch 135 Batch 2450 Loss 2.2304 Accuracy 0.9973\n",
      "Epoch 135 Batch 2500 Loss 2.2325 Accuracy 0.9973\n",
      "Epoch 135 Batch 2550 Loss 2.2317 Accuracy 0.9973\n",
      "Epoch 135 Batch 2600 Loss 2.2300 Accuracy 0.9973\n",
      "Epoch 135 Batch 2650 Loss 2.2293 Accuracy 0.9973\n",
      "Saving checkpoint for epoch 135 at ./checkpoints/train\\ckpt-28\n",
      "Epoch 135 Loss 2.2309 Accuracy 0.9973\n",
      "Time taken for 1 epoch: 194.93996572494507 secs\n",
      "\n",
      "Epoch 136 Batch 0 Loss 1.6893 Accuracy 0.9981\n",
      "Epoch 136 Batch 50 Loss 2.2835 Accuracy 0.9972\n",
      "Epoch 136 Batch 100 Loss 2.2359 Accuracy 0.9973\n",
      "Epoch 136 Batch 150 Loss 2.2631 Accuracy 0.9972\n",
      "Epoch 136 Batch 200 Loss 2.2029 Accuracy 0.9973\n",
      "Epoch 136 Batch 250 Loss 2.1904 Accuracy 0.9973\n",
      "Epoch 136 Batch 300 Loss 2.1939 Accuracy 0.9973\n",
      "Epoch 136 Batch 350 Loss 2.1952 Accuracy 0.9973\n",
      "Epoch 136 Batch 400 Loss 2.1904 Accuracy 0.9973\n",
      "Epoch 136 Batch 450 Loss 2.2257 Accuracy 0.9973\n",
      "Epoch 136 Batch 500 Loss 2.2184 Accuracy 0.9973\n",
      "Epoch 136 Batch 550 Loss 2.2312 Accuracy 0.9973\n",
      "Epoch 136 Batch 600 Loss 2.2416 Accuracy 0.9973\n",
      "Epoch 136 Batch 650 Loss 2.2361 Accuracy 0.9973\n",
      "Epoch 136 Batch 700 Loss 2.2318 Accuracy 0.9973\n",
      "Epoch 136 Batch 750 Loss 2.2346 Accuracy 0.9973\n",
      "Epoch 136 Batch 800 Loss 2.2280 Accuracy 0.9973\n",
      "Epoch 136 Batch 850 Loss 2.2303 Accuracy 0.9973\n",
      "Epoch 136 Batch 900 Loss 2.2289 Accuracy 0.9973\n",
      "Epoch 136 Batch 950 Loss 2.2314 Accuracy 0.9973\n",
      "Epoch 136 Batch 1000 Loss 2.2274 Accuracy 0.9973\n",
      "Epoch 136 Batch 1050 Loss 2.2207 Accuracy 0.9973\n",
      "Epoch 136 Batch 1100 Loss 2.2203 Accuracy 0.9973\n",
      "Epoch 136 Batch 1150 Loss 2.2144 Accuracy 0.9973\n",
      "Epoch 136 Batch 1200 Loss 2.2255 Accuracy 0.9973\n",
      "Epoch 136 Batch 1250 Loss 2.2215 Accuracy 0.9973\n",
      "Epoch 136 Batch 1300 Loss 2.2219 Accuracy 0.9973\n",
      "Epoch 136 Batch 1350 Loss 2.2179 Accuracy 0.9973\n",
      "Epoch 136 Batch 1400 Loss 2.2216 Accuracy 0.9973\n",
      "Epoch 136 Batch 1450 Loss 2.2153 Accuracy 0.9973\n",
      "Epoch 136 Batch 1500 Loss 2.2146 Accuracy 0.9973\n",
      "Epoch 136 Batch 1550 Loss 2.2178 Accuracy 0.9973\n",
      "Epoch 136 Batch 1600 Loss 2.2188 Accuracy 0.9973\n",
      "Epoch 136 Batch 1650 Loss 2.2190 Accuracy 0.9973\n",
      "Epoch 136 Batch 1700 Loss 2.2198 Accuracy 0.9973\n",
      "Epoch 136 Batch 1750 Loss 2.2157 Accuracy 0.9973\n",
      "Epoch 136 Batch 1800 Loss 2.2179 Accuracy 0.9973\n",
      "Epoch 136 Batch 1850 Loss 2.2122 Accuracy 0.9973\n",
      "Epoch 136 Batch 1900 Loss 2.2071 Accuracy 0.9973\n",
      "Epoch 136 Batch 1950 Loss 2.2003 Accuracy 0.9973\n",
      "Epoch 136 Batch 2000 Loss 2.2044 Accuracy 0.9973\n",
      "Epoch 136 Batch 2050 Loss 2.2091 Accuracy 0.9973\n",
      "Epoch 136 Batch 2100 Loss 2.2075 Accuracy 0.9973\n",
      "Epoch 136 Batch 2150 Loss 2.2109 Accuracy 0.9973\n",
      "Epoch 136 Batch 2200 Loss 2.2143 Accuracy 0.9973\n",
      "Epoch 136 Batch 2250 Loss 2.2151 Accuracy 0.9973\n",
      "Epoch 136 Batch 2300 Loss 2.2129 Accuracy 0.9973\n",
      "Epoch 136 Batch 2350 Loss 2.2129 Accuracy 0.9973\n",
      "Epoch 136 Batch 2400 Loss 2.2142 Accuracy 0.9973\n",
      "Epoch 136 Batch 2450 Loss 2.2172 Accuracy 0.9973\n",
      "Epoch 136 Batch 2500 Loss 2.2188 Accuracy 0.9973\n",
      "Epoch 136 Batch 2550 Loss 2.2180 Accuracy 0.9973\n",
      "Epoch 136 Batch 2600 Loss 2.2144 Accuracy 0.9973\n",
      "Epoch 136 Batch 2650 Loss 2.2122 Accuracy 0.9973\n",
      "Epoch 136 Loss 2.2135 Accuracy 0.9973\n",
      "Time taken for 1 epoch: 194.33695578575134 secs\n",
      "\n",
      "Epoch 137 Batch 0 Loss 1.4287 Accuracy 0.9982\n",
      "Epoch 137 Batch 50 Loss 2.2395 Accuracy 0.9973\n",
      "Epoch 137 Batch 100 Loss 2.2239 Accuracy 0.9973\n",
      "Epoch 137 Batch 150 Loss 2.2436 Accuracy 0.9973\n",
      "Epoch 137 Batch 200 Loss 2.1888 Accuracy 0.9973\n",
      "Epoch 137 Batch 250 Loss 2.1855 Accuracy 0.9973\n",
      "Epoch 137 Batch 300 Loss 2.1877 Accuracy 0.9973\n",
      "Epoch 137 Batch 350 Loss 2.1893 Accuracy 0.9973\n",
      "Epoch 137 Batch 400 Loss 2.1908 Accuracy 0.9973\n",
      "Epoch 137 Batch 450 Loss 2.2192 Accuracy 0.9973\n",
      "Epoch 137 Batch 500 Loss 2.2143 Accuracy 0.9973\n",
      "Epoch 137 Batch 550 Loss 2.2278 Accuracy 0.9973\n",
      "Epoch 137 Batch 600 Loss 2.2370 Accuracy 0.9973\n",
      "Epoch 137 Batch 650 Loss 2.2374 Accuracy 0.9973\n",
      "Epoch 137 Batch 700 Loss 2.2337 Accuracy 0.9973\n",
      "Epoch 137 Batch 750 Loss 2.2308 Accuracy 0.9973\n",
      "Epoch 137 Batch 800 Loss 2.2203 Accuracy 0.9973\n",
      "Epoch 137 Batch 850 Loss 2.2230 Accuracy 0.9973\n",
      "Epoch 137 Batch 900 Loss 2.2227 Accuracy 0.9973\n",
      "Epoch 137 Batch 950 Loss 2.2261 Accuracy 0.9973\n",
      "Epoch 137 Batch 1000 Loss 2.2235 Accuracy 0.9973\n",
      "Epoch 137 Batch 1050 Loss 2.2160 Accuracy 0.9973\n",
      "Epoch 137 Batch 1100 Loss 2.2138 Accuracy 0.9973\n",
      "Epoch 137 Batch 1150 Loss 2.2050 Accuracy 0.9973\n",
      "Epoch 137 Batch 1200 Loss 2.2146 Accuracy 0.9973\n",
      "Epoch 137 Batch 1250 Loss 2.2088 Accuracy 0.9973\n",
      "Epoch 137 Batch 1300 Loss 2.2104 Accuracy 0.9973\n",
      "Epoch 137 Batch 1350 Loss 2.2067 Accuracy 0.9973\n",
      "Epoch 137 Batch 1400 Loss 2.2085 Accuracy 0.9973\n",
      "Epoch 137 Batch 1450 Loss 2.2044 Accuracy 0.9973\n",
      "Epoch 137 Batch 1500 Loss 2.2057 Accuracy 0.9973\n",
      "Epoch 137 Batch 1550 Loss 2.2085 Accuracy 0.9973\n",
      "Epoch 137 Batch 1600 Loss 2.2089 Accuracy 0.9973\n",
      "Epoch 137 Batch 1650 Loss 2.2082 Accuracy 0.9973\n",
      "Epoch 137 Batch 1700 Loss 2.2118 Accuracy 0.9973\n",
      "Epoch 137 Batch 1750 Loss 2.2084 Accuracy 0.9973\n",
      "Epoch 137 Batch 1800 Loss 2.2092 Accuracy 0.9973\n",
      "Epoch 137 Batch 1850 Loss 2.2045 Accuracy 0.9973\n",
      "Epoch 137 Batch 1900 Loss 2.2008 Accuracy 0.9973\n",
      "Epoch 137 Batch 1950 Loss 2.1946 Accuracy 0.9973\n",
      "Epoch 137 Batch 2000 Loss 2.2011 Accuracy 0.9973\n",
      "Epoch 137 Batch 2050 Loss 2.2062 Accuracy 0.9973\n",
      "Epoch 137 Batch 2100 Loss 2.2048 Accuracy 0.9973\n",
      "Epoch 137 Batch 2150 Loss 2.2071 Accuracy 0.9973\n",
      "Epoch 137 Batch 2200 Loss 2.2103 Accuracy 0.9973\n",
      "Epoch 137 Batch 2250 Loss 2.2102 Accuracy 0.9973\n",
      "Epoch 137 Batch 2300 Loss 2.2084 Accuracy 0.9973\n",
      "Epoch 137 Batch 2350 Loss 2.2083 Accuracy 0.9973\n",
      "Epoch 137 Batch 2400 Loss 2.2106 Accuracy 0.9973\n",
      "Epoch 137 Batch 2450 Loss 2.2133 Accuracy 0.9973\n",
      "Epoch 137 Batch 2500 Loss 2.2144 Accuracy 0.9973\n",
      "Epoch 137 Batch 2550 Loss 2.2136 Accuracy 0.9973\n",
      "Epoch 137 Batch 2600 Loss 2.2111 Accuracy 0.9973\n",
      "Epoch 137 Batch 2650 Loss 2.2091 Accuracy 0.9973\n",
      "Epoch 137 Loss 2.2092 Accuracy 0.9973\n",
      "Time taken for 1 epoch: 194.02302956581116 secs\n",
      "\n",
      "Epoch 138 Batch 0 Loss 1.5888 Accuracy 0.9981\n",
      "Epoch 138 Batch 50 Loss 2.2476 Accuracy 0.9973\n",
      "Epoch 138 Batch 100 Loss 2.2180 Accuracy 0.9973\n",
      "Epoch 138 Batch 150 Loss 2.2493 Accuracy 0.9973\n",
      "Epoch 138 Batch 200 Loss 2.1873 Accuracy 0.9973\n",
      "Epoch 138 Batch 250 Loss 2.1715 Accuracy 0.9974\n",
      "Epoch 138 Batch 300 Loss 2.1654 Accuracy 0.9974\n",
      "Epoch 138 Batch 350 Loss 2.1729 Accuracy 0.9974\n",
      "Epoch 138 Batch 400 Loss 2.1749 Accuracy 0.9973\n",
      "Epoch 138 Batch 450 Loss 2.2089 Accuracy 0.9973\n",
      "Epoch 138 Batch 500 Loss 2.1982 Accuracy 0.9973\n",
      "Epoch 138 Batch 550 Loss 2.2067 Accuracy 0.9973\n",
      "Epoch 138 Batch 600 Loss 2.2167 Accuracy 0.9973\n",
      "Epoch 138 Batch 650 Loss 2.2147 Accuracy 0.9973\n",
      "Epoch 138 Batch 700 Loss 2.2100 Accuracy 0.9973\n",
      "Epoch 138 Batch 750 Loss 2.2120 Accuracy 0.9973\n",
      "Epoch 138 Batch 800 Loss 2.2032 Accuracy 0.9973\n",
      "Epoch 138 Batch 850 Loss 2.2084 Accuracy 0.9973\n",
      "Epoch 138 Batch 900 Loss 2.2125 Accuracy 0.9973\n",
      "Epoch 138 Batch 950 Loss 2.2194 Accuracy 0.9973\n",
      "Epoch 138 Batch 1000 Loss 2.2178 Accuracy 0.9973\n",
      "Epoch 138 Batch 1050 Loss 2.2071 Accuracy 0.9973\n",
      "Epoch 138 Batch 1100 Loss 2.2052 Accuracy 0.9973\n",
      "Epoch 138 Batch 1150 Loss 2.1990 Accuracy 0.9973\n",
      "Epoch 138 Batch 1200 Loss 2.2085 Accuracy 0.9973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138 Batch 1250 Loss 2.2054 Accuracy 0.9973\n",
      "Epoch 138 Batch 1300 Loss 2.2068 Accuracy 0.9973\n",
      "Epoch 138 Batch 1350 Loss 2.2020 Accuracy 0.9973\n",
      "Epoch 138 Batch 1400 Loss 2.2039 Accuracy 0.9973\n",
      "Epoch 138 Batch 1450 Loss 2.2005 Accuracy 0.9973\n",
      "Epoch 138 Batch 1500 Loss 2.1995 Accuracy 0.9973\n",
      "Epoch 138 Batch 1550 Loss 2.2026 Accuracy 0.9973\n",
      "Epoch 138 Batch 1600 Loss 2.2028 Accuracy 0.9973\n",
      "Epoch 138 Batch 1650 Loss 2.2044 Accuracy 0.9973\n",
      "Epoch 138 Batch 1700 Loss 2.2073 Accuracy 0.9973\n",
      "Epoch 138 Batch 1750 Loss 2.2019 Accuracy 0.9973\n",
      "Epoch 138 Batch 1800 Loss 2.2043 Accuracy 0.9973\n",
      "Epoch 138 Batch 1850 Loss 2.1981 Accuracy 0.9973\n",
      "Epoch 138 Batch 1900 Loss 2.1962 Accuracy 0.9973\n",
      "Epoch 138 Batch 1950 Loss 2.1888 Accuracy 0.9973\n",
      "Epoch 138 Batch 2000 Loss 2.1922 Accuracy 0.9973\n",
      "Epoch 138 Batch 2050 Loss 2.1966 Accuracy 0.9973\n",
      "Epoch 138 Batch 2100 Loss 2.1962 Accuracy 0.9973\n",
      "Epoch 138 Batch 2150 Loss 2.1968 Accuracy 0.9973\n",
      "Epoch 138 Batch 2200 Loss 2.2000 Accuracy 0.9973\n",
      "Epoch 138 Batch 2250 Loss 2.2012 Accuracy 0.9973\n",
      "Epoch 138 Batch 2300 Loss 2.1984 Accuracy 0.9973\n",
      "Epoch 138 Batch 2350 Loss 2.1984 Accuracy 0.9973\n",
      "Epoch 138 Batch 2400 Loss 2.1996 Accuracy 0.9973\n",
      "Epoch 138 Batch 2450 Loss 2.2017 Accuracy 0.9973\n",
      "Epoch 138 Batch 2500 Loss 2.2025 Accuracy 0.9973\n",
      "Epoch 138 Batch 2550 Loss 2.2021 Accuracy 0.9973\n",
      "Epoch 138 Batch 2600 Loss 2.2008 Accuracy 0.9973\n",
      "Epoch 138 Batch 2650 Loss 2.1987 Accuracy 0.9973\n",
      "Epoch 138 Loss 2.1998 Accuracy 0.9973\n",
      "Time taken for 1 epoch: 194.1700463294983 secs\n",
      "\n",
      "Epoch 139 Batch 0 Loss 1.3837 Accuracy 0.9984\n",
      "Epoch 139 Batch 50 Loss 2.2090 Accuracy 0.9973\n",
      "Epoch 139 Batch 100 Loss 2.2219 Accuracy 0.9973\n",
      "Epoch 139 Batch 150 Loss 2.2212 Accuracy 0.9973\n",
      "Epoch 139 Batch 200 Loss 2.1681 Accuracy 0.9974\n",
      "Epoch 139 Batch 250 Loss 2.1670 Accuracy 0.9974\n",
      "Epoch 139 Batch 300 Loss 2.1786 Accuracy 0.9973\n",
      "Epoch 139 Batch 350 Loss 2.1788 Accuracy 0.9973\n",
      "Epoch 139 Batch 400 Loss 2.1768 Accuracy 0.9973\n",
      "Epoch 139 Batch 450 Loss 2.2046 Accuracy 0.9973\n",
      "Epoch 139 Batch 500 Loss 2.1990 Accuracy 0.9973\n",
      "Epoch 139 Batch 550 Loss 2.2140 Accuracy 0.9973\n",
      "Epoch 139 Batch 600 Loss 2.2234 Accuracy 0.9973\n",
      "Epoch 139 Batch 650 Loss 2.2224 Accuracy 0.9973\n",
      "Epoch 139 Batch 700 Loss 2.2203 Accuracy 0.9973\n",
      "Epoch 139 Batch 750 Loss 2.2234 Accuracy 0.9973\n",
      "Epoch 139 Batch 800 Loss 2.2106 Accuracy 0.9973\n",
      "Epoch 139 Batch 850 Loss 2.2145 Accuracy 0.9973\n",
      "Epoch 139 Batch 900 Loss 2.2158 Accuracy 0.9973\n",
      "Epoch 139 Batch 950 Loss 2.2214 Accuracy 0.9973\n",
      "Epoch 139 Batch 1000 Loss 2.2155 Accuracy 0.9973\n",
      "Epoch 139 Batch 1050 Loss 2.2074 Accuracy 0.9973\n",
      "Epoch 139 Batch 1100 Loss 2.2051 Accuracy 0.9973\n",
      "Epoch 139 Batch 1150 Loss 2.1989 Accuracy 0.9973\n",
      "Epoch 139 Batch 1200 Loss 2.2065 Accuracy 0.9973\n",
      "Epoch 139 Batch 1250 Loss 2.2034 Accuracy 0.9973\n",
      "Epoch 139 Batch 1300 Loss 2.2041 Accuracy 0.9973\n",
      "Epoch 139 Batch 1350 Loss 2.2007 Accuracy 0.9973\n",
      "Epoch 139 Batch 1400 Loss 2.2033 Accuracy 0.9973\n",
      "Epoch 139 Batch 1450 Loss 2.1983 Accuracy 0.9973\n",
      "Epoch 139 Batch 1500 Loss 2.1985 Accuracy 0.9973\n",
      "Epoch 139 Batch 1550 Loss 2.1991 Accuracy 0.9973\n",
      "Epoch 139 Batch 1600 Loss 2.2006 Accuracy 0.9973\n",
      "Epoch 139 Batch 1650 Loss 2.2035 Accuracy 0.9973\n",
      "Epoch 139 Batch 1700 Loss 2.2046 Accuracy 0.9973\n",
      "Epoch 139 Batch 1750 Loss 2.1995 Accuracy 0.9973\n",
      "Epoch 139 Batch 1800 Loss 2.2007 Accuracy 0.9973\n",
      "Epoch 139 Batch 1850 Loss 2.1957 Accuracy 0.9973\n",
      "Epoch 139 Batch 1900 Loss 2.1925 Accuracy 0.9973\n",
      "Epoch 139 Batch 1950 Loss 2.1862 Accuracy 0.9973\n",
      "Epoch 139 Batch 2000 Loss 2.1903 Accuracy 0.9973\n",
      "Epoch 139 Batch 2050 Loss 2.1952 Accuracy 0.9973\n",
      "Epoch 139 Batch 2100 Loss 2.1931 Accuracy 0.9973\n",
      "Epoch 139 Batch 2150 Loss 2.1943 Accuracy 0.9973\n",
      "Epoch 139 Batch 2200 Loss 2.1971 Accuracy 0.9973\n",
      "Epoch 139 Batch 2250 Loss 2.1989 Accuracy 0.9973\n",
      "Epoch 139 Batch 2300 Loss 2.1975 Accuracy 0.9973\n",
      "Epoch 139 Batch 2350 Loss 2.1962 Accuracy 0.9973\n",
      "Epoch 139 Batch 2400 Loss 2.1982 Accuracy 0.9973\n",
      "Epoch 139 Batch 2450 Loss 2.1999 Accuracy 0.9973\n",
      "Epoch 139 Batch 2500 Loss 2.2018 Accuracy 0.9973\n",
      "Epoch 139 Batch 2550 Loss 2.2002 Accuracy 0.9973\n",
      "Epoch 139 Batch 2600 Loss 2.1976 Accuracy 0.9973\n",
      "Epoch 139 Batch 2650 Loss 2.1962 Accuracy 0.9973\n",
      "Epoch 139 Loss 2.1974 Accuracy 0.9973\n",
      "Time taken for 1 epoch: 194.67035746574402 secs\n",
      "\n",
      "Epoch 140 Batch 0 Loss 1.4983 Accuracy 0.9982\n",
      "Epoch 140 Batch 50 Loss 2.2264 Accuracy 0.9973\n",
      "Epoch 140 Batch 100 Loss 2.2058 Accuracy 0.9973\n",
      "Epoch 140 Batch 150 Loss 2.2288 Accuracy 0.9973\n",
      "Epoch 140 Batch 200 Loss 2.1754 Accuracy 0.9974\n",
      "Epoch 140 Batch 250 Loss 2.1661 Accuracy 0.9974\n",
      "Epoch 140 Batch 300 Loss 2.1680 Accuracy 0.9974\n",
      "Epoch 140 Batch 350 Loss 2.1753 Accuracy 0.9973\n",
      "Epoch 140 Batch 400 Loss 2.1730 Accuracy 0.9973\n",
      "Epoch 140 Batch 450 Loss 2.1984 Accuracy 0.9973\n",
      "Epoch 140 Batch 500 Loss 2.1874 Accuracy 0.9973\n",
      "Epoch 140 Batch 550 Loss 2.2024 Accuracy 0.9973\n",
      "Epoch 140 Batch 600 Loss 2.2163 Accuracy 0.9973\n",
      "Epoch 140 Batch 650 Loss 2.2159 Accuracy 0.9973\n",
      "Epoch 140 Batch 700 Loss 2.2119 Accuracy 0.9973\n",
      "Epoch 140 Batch 750 Loss 2.2090 Accuracy 0.9973\n",
      "Epoch 140 Batch 800 Loss 2.1998 Accuracy 0.9973\n",
      "Epoch 140 Batch 850 Loss 2.2054 Accuracy 0.9973\n",
      "Epoch 140 Batch 900 Loss 2.2052 Accuracy 0.9973\n",
      "Epoch 140 Batch 950 Loss 2.2081 Accuracy 0.9973\n",
      "Epoch 140 Batch 1000 Loss 2.2038 Accuracy 0.9973\n",
      "Epoch 140 Batch 1050 Loss 2.1979 Accuracy 0.9973\n",
      "Epoch 140 Batch 1100 Loss 2.1988 Accuracy 0.9973\n",
      "Epoch 140 Batch 1150 Loss 2.1945 Accuracy 0.9973\n",
      "Epoch 140 Batch 1200 Loss 2.2022 Accuracy 0.9973\n",
      "Epoch 140 Batch 1250 Loss 2.1971 Accuracy 0.9973\n",
      "Epoch 140 Batch 1300 Loss 2.1990 Accuracy 0.9973\n",
      "Epoch 140 Batch 1350 Loss 2.1954 Accuracy 0.9973\n",
      "Epoch 140 Batch 1400 Loss 2.1967 Accuracy 0.9973\n",
      "Epoch 140 Batch 1450 Loss 2.1912 Accuracy 0.9973\n",
      "Epoch 140 Batch 1500 Loss 2.1922 Accuracy 0.9973\n",
      "Epoch 140 Batch 1550 Loss 2.1936 Accuracy 0.9973\n",
      "Epoch 140 Batch 1600 Loss 2.1944 Accuracy 0.9973\n",
      "Epoch 140 Batch 1650 Loss 2.1948 Accuracy 0.9973\n",
      "Epoch 140 Batch 1700 Loss 2.1980 Accuracy 0.9973\n",
      "Epoch 140 Batch 1750 Loss 2.1936 Accuracy 0.9973\n",
      "Epoch 140 Batch 1800 Loss 2.1959 Accuracy 0.9973\n",
      "Epoch 140 Batch 1850 Loss 2.1894 Accuracy 0.9973\n",
      "Epoch 140 Batch 1900 Loss 2.1845 Accuracy 0.9973\n",
      "Epoch 140 Batch 1950 Loss 2.1780 Accuracy 0.9974\n",
      "Epoch 140 Batch 2000 Loss 2.1826 Accuracy 0.9973\n",
      "Epoch 140 Batch 2050 Loss 2.1869 Accuracy 0.9973\n",
      "Epoch 140 Batch 2100 Loss 2.1851 Accuracy 0.9973\n",
      "Epoch 140 Batch 2150 Loss 2.1861 Accuracy 0.9973\n",
      "Epoch 140 Batch 2200 Loss 2.1901 Accuracy 0.9973\n",
      "Epoch 140 Batch 2250 Loss 2.1920 Accuracy 0.9973\n",
      "Epoch 140 Batch 2300 Loss 2.1895 Accuracy 0.9973\n",
      "Epoch 140 Batch 2350 Loss 2.1891 Accuracy 0.9973\n",
      "Epoch 140 Batch 2400 Loss 2.1902 Accuracy 0.9973\n",
      "Epoch 140 Batch 2450 Loss 2.1920 Accuracy 0.9973\n",
      "Epoch 140 Batch 2500 Loss 2.1933 Accuracy 0.9973\n",
      "Epoch 140 Batch 2550 Loss 2.1929 Accuracy 0.9973\n",
      "Epoch 140 Batch 2600 Loss 2.1909 Accuracy 0.9973\n",
      "Epoch 140 Batch 2650 Loss 2.1902 Accuracy 0.9973\n",
      "Saving checkpoint for epoch 140 at ./checkpoints/train\\ckpt-29\n",
      "Epoch 140 Loss 2.1917 Accuracy 0.9973\n",
      "Time taken for 1 epoch: 194.79830074310303 secs\n",
      "\n",
      "Epoch 141 Batch 0 Loss 1.4189 Accuracy 0.9984\n",
      "Epoch 141 Batch 50 Loss 2.2130 Accuracy 0.9973\n",
      "Epoch 141 Batch 100 Loss 2.2075 Accuracy 0.9973\n",
      "Epoch 141 Batch 150 Loss 2.2372 Accuracy 0.9973\n",
      "Epoch 141 Batch 200 Loss 2.1757 Accuracy 0.9973\n",
      "Epoch 141 Batch 250 Loss 2.1724 Accuracy 0.9974\n",
      "Epoch 141 Batch 300 Loss 2.1745 Accuracy 0.9973\n",
      "Epoch 141 Batch 350 Loss 2.1709 Accuracy 0.9973\n",
      "Epoch 141 Batch 400 Loss 2.1729 Accuracy 0.9973\n",
      "Epoch 141 Batch 450 Loss 2.2021 Accuracy 0.9973\n",
      "Epoch 141 Batch 500 Loss 2.1928 Accuracy 0.9973\n",
      "Epoch 141 Batch 550 Loss 2.2062 Accuracy 0.9973\n",
      "Epoch 141 Batch 600 Loss 2.2162 Accuracy 0.9973\n",
      "Epoch 141 Batch 650 Loss 2.2153 Accuracy 0.9973\n",
      "Epoch 141 Batch 700 Loss 2.2091 Accuracy 0.9973\n",
      "Epoch 141 Batch 750 Loss 2.2092 Accuracy 0.9973\n",
      "Epoch 141 Batch 800 Loss 2.1990 Accuracy 0.9973\n",
      "Epoch 141 Batch 850 Loss 2.2005 Accuracy 0.9973\n",
      "Epoch 141 Batch 900 Loss 2.2006 Accuracy 0.9973\n",
      "Epoch 141 Batch 950 Loss 2.2055 Accuracy 0.9973\n",
      "Epoch 141 Batch 1000 Loss 2.2031 Accuracy 0.9973\n",
      "Epoch 141 Batch 1050 Loss 2.1956 Accuracy 0.9973\n",
      "Epoch 141 Batch 1100 Loss 2.1937 Accuracy 0.9973\n",
      "Epoch 141 Batch 1150 Loss 2.1885 Accuracy 0.9973\n",
      "Epoch 141 Batch 1200 Loss 2.1980 Accuracy 0.9973\n",
      "Epoch 141 Batch 1250 Loss 2.1936 Accuracy 0.9973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141 Batch 1300 Loss 2.1953 Accuracy 0.9973\n",
      "Epoch 141 Batch 1350 Loss 2.1914 Accuracy 0.9973\n",
      "Epoch 141 Batch 1400 Loss 2.1929 Accuracy 0.9973\n",
      "Epoch 141 Batch 1450 Loss 2.1874 Accuracy 0.9973\n",
      "Epoch 141 Batch 1500 Loss 2.1850 Accuracy 0.9973\n",
      "Epoch 141 Batch 1550 Loss 2.1879 Accuracy 0.9973\n",
      "Epoch 141 Batch 1600 Loss 2.1889 Accuracy 0.9973\n",
      "Epoch 141 Batch 1650 Loss 2.1905 Accuracy 0.9973\n",
      "Epoch 141 Batch 1700 Loss 2.1913 Accuracy 0.9973\n",
      "Epoch 141 Batch 1750 Loss 2.1890 Accuracy 0.9973\n",
      "Epoch 141 Batch 1800 Loss 2.1896 Accuracy 0.9973\n",
      "Epoch 141 Batch 1850 Loss 2.1853 Accuracy 0.9973\n",
      "Epoch 141 Batch 1900 Loss 2.1821 Accuracy 0.9973\n",
      "Epoch 141 Batch 1950 Loss 2.1760 Accuracy 0.9973\n",
      "Epoch 141 Batch 2000 Loss 2.1800 Accuracy 0.9973\n",
      "Epoch 141 Batch 2050 Loss 2.1853 Accuracy 0.9973\n",
      "Epoch 141 Batch 2100 Loss 2.1846 Accuracy 0.9973\n",
      "Epoch 141 Batch 2150 Loss 2.1878 Accuracy 0.9973\n",
      "Epoch 141 Batch 2200 Loss 2.1919 Accuracy 0.9973\n",
      "Epoch 141 Batch 2250 Loss 2.1934 Accuracy 0.9973\n",
      "Epoch 141 Batch 2300 Loss 2.1916 Accuracy 0.9973\n",
      "Epoch 141 Batch 2350 Loss 2.1918 Accuracy 0.9973\n",
      "Epoch 141 Batch 2400 Loss 2.1937 Accuracy 0.9973\n",
      "Epoch 141 Batch 2450 Loss 2.1963 Accuracy 0.9973\n",
      "Epoch 141 Batch 2500 Loss 2.1977 Accuracy 0.9973\n",
      "Epoch 141 Batch 2550 Loss 2.1973 Accuracy 0.9973\n",
      "Epoch 141 Batch 2600 Loss 2.1950 Accuracy 0.9973\n",
      "Epoch 141 Batch 2650 Loss 2.1932 Accuracy 0.9973\n",
      "Epoch 141 Loss 2.1950 Accuracy 0.9973\n",
      "Time taken for 1 epoch: 196.0713083744049 secs\n",
      "\n",
      "Epoch 142 Batch 0 Loss 1.5680 Accuracy 0.9982\n",
      "Epoch 142 Batch 50 Loss 2.1806 Accuracy 0.9974\n",
      "Epoch 142 Batch 100 Loss 2.1881 Accuracy 0.9974\n",
      "Epoch 142 Batch 150 Loss 2.2036 Accuracy 0.9973\n",
      "Epoch 142 Batch 200 Loss 2.1460 Accuracy 0.9974\n",
      "Epoch 142 Batch 250 Loss 2.1385 Accuracy 0.9974\n",
      "Epoch 142 Batch 300 Loss 2.1473 Accuracy 0.9974\n",
      "Epoch 142 Batch 350 Loss 2.1468 Accuracy 0.9974\n",
      "Epoch 142 Batch 400 Loss 2.1580 Accuracy 0.9974\n",
      "Epoch 142 Batch 450 Loss 2.1864 Accuracy 0.9974\n",
      "Epoch 142 Batch 500 Loss 2.1761 Accuracy 0.9974\n",
      "Epoch 142 Batch 550 Loss 2.1925 Accuracy 0.9974\n",
      "Epoch 142 Batch 600 Loss 2.2054 Accuracy 0.9973\n",
      "Epoch 142 Batch 650 Loss 2.2053 Accuracy 0.9973\n",
      "Epoch 142 Batch 700 Loss 2.2030 Accuracy 0.9973\n",
      "Epoch 142 Batch 750 Loss 2.2049 Accuracy 0.9973\n",
      "Epoch 142 Batch 800 Loss 2.1928 Accuracy 0.9973\n",
      "Epoch 142 Batch 850 Loss 2.1977 Accuracy 0.9973\n",
      "Epoch 142 Batch 900 Loss 2.2003 Accuracy 0.9973\n",
      "Epoch 142 Batch 950 Loss 2.2038 Accuracy 0.9973\n",
      "Epoch 142 Batch 1000 Loss 2.2011 Accuracy 0.9973\n",
      "Epoch 142 Batch 1050 Loss 2.1911 Accuracy 0.9973\n",
      "Epoch 142 Batch 1100 Loss 2.1898 Accuracy 0.9973\n",
      "Epoch 142 Batch 1150 Loss 2.1833 Accuracy 0.9974\n",
      "Epoch 142 Batch 1200 Loss 2.1959 Accuracy 0.9973\n",
      "Epoch 142 Batch 1250 Loss 2.1897 Accuracy 0.9973\n",
      "Epoch 142 Batch 1300 Loss 2.1920 Accuracy 0.9973\n",
      "Epoch 142 Batch 1350 Loss 2.1899 Accuracy 0.9973\n",
      "Epoch 142 Batch 1400 Loss 2.1905 Accuracy 0.9973\n",
      "Epoch 142 Batch 1450 Loss 2.1856 Accuracy 0.9973\n",
      "Epoch 142 Batch 1500 Loss 2.1839 Accuracy 0.9974\n",
      "Epoch 142 Batch 1550 Loss 2.1856 Accuracy 0.9973\n",
      "Epoch 142 Batch 1600 Loss 2.1868 Accuracy 0.9973\n",
      "Epoch 142 Batch 1650 Loss 2.1872 Accuracy 0.9973\n",
      "Epoch 142 Batch 1700 Loss 2.1900 Accuracy 0.9973\n",
      "Epoch 142 Batch 1750 Loss 2.1854 Accuracy 0.9973\n",
      "Epoch 142 Batch 1800 Loss 2.1868 Accuracy 0.9973\n",
      "Epoch 142 Batch 1850 Loss 2.1819 Accuracy 0.9974\n",
      "Epoch 142 Batch 1900 Loss 2.1800 Accuracy 0.9974\n",
      "Epoch 142 Batch 1950 Loss 2.1734 Accuracy 0.9974\n",
      "Epoch 142 Batch 2000 Loss 2.1768 Accuracy 0.9974\n",
      "Epoch 142 Batch 2050 Loss 2.1816 Accuracy 0.9974\n",
      "Epoch 142 Batch 2100 Loss 2.1809 Accuracy 0.9974\n",
      "Epoch 142 Batch 2150 Loss 2.1829 Accuracy 0.9974\n",
      "Epoch 142 Batch 2200 Loss 2.1866 Accuracy 0.9973\n",
      "Epoch 142 Batch 2250 Loss 2.1869 Accuracy 0.9973\n",
      "Epoch 142 Batch 2300 Loss 2.1834 Accuracy 0.9974\n",
      "Epoch 142 Batch 2350 Loss 2.1830 Accuracy 0.9974\n",
      "Epoch 142 Batch 2400 Loss 2.1842 Accuracy 0.9973\n",
      "Epoch 142 Batch 2450 Loss 2.1859 Accuracy 0.9973\n",
      "Epoch 142 Batch 2500 Loss 2.1877 Accuracy 0.9973\n",
      "Epoch 142 Batch 2550 Loss 2.1873 Accuracy 0.9973\n",
      "Epoch 142 Batch 2600 Loss 2.1857 Accuracy 0.9973\n",
      "Epoch 142 Batch 2650 Loss 2.1835 Accuracy 0.9974\n",
      "Epoch 142 Loss 2.1846 Accuracy 0.9973\n",
      "Time taken for 1 epoch: 194.75681471824646 secs\n",
      "\n",
      "Epoch 143 Batch 0 Loss 1.6143 Accuracy 0.9979\n",
      "Epoch 143 Batch 50 Loss 2.1798 Accuracy 0.9974\n",
      "Epoch 143 Batch 100 Loss 2.2067 Accuracy 0.9973\n",
      "Epoch 143 Batch 150 Loss 2.2158 Accuracy 0.9973\n",
      "Epoch 143 Batch 200 Loss 2.1607 Accuracy 0.9974\n",
      "Epoch 143 Batch 250 Loss 2.1621 Accuracy 0.9974\n",
      "Epoch 143 Batch 300 Loss 2.1614 Accuracy 0.9974\n",
      "Epoch 143 Batch 350 Loss 2.1652 Accuracy 0.9974\n",
      "Epoch 143 Batch 400 Loss 2.1675 Accuracy 0.9974\n",
      "Epoch 143 Batch 450 Loss 2.2004 Accuracy 0.9973\n",
      "Epoch 143 Batch 500 Loss 2.1909 Accuracy 0.9973\n",
      "Epoch 143 Batch 550 Loss 2.1975 Accuracy 0.9973\n",
      "Epoch 143 Batch 600 Loss 2.2053 Accuracy 0.9973\n",
      "Epoch 143 Batch 650 Loss 2.2001 Accuracy 0.9973\n",
      "Epoch 143 Batch 700 Loss 2.1955 Accuracy 0.9973\n",
      "Epoch 143 Batch 750 Loss 2.1964 Accuracy 0.9973\n",
      "Epoch 143 Batch 800 Loss 2.1881 Accuracy 0.9973\n",
      "Epoch 143 Batch 850 Loss 2.1921 Accuracy 0.9973\n",
      "Epoch 143 Batch 900 Loss 2.1909 Accuracy 0.9973\n",
      "Epoch 143 Batch 950 Loss 2.1954 Accuracy 0.9973\n",
      "Epoch 143 Batch 1000 Loss 2.1942 Accuracy 0.9973\n",
      "Epoch 143 Batch 1050 Loss 2.1876 Accuracy 0.9973\n",
      "Epoch 143 Batch 1100 Loss 2.1859 Accuracy 0.9973\n",
      "Epoch 143 Batch 1150 Loss 2.1780 Accuracy 0.9973\n",
      "Epoch 143 Batch 1200 Loss 2.1865 Accuracy 0.9973\n",
      "Epoch 143 Batch 1250 Loss 2.1820 Accuracy 0.9973\n",
      "Epoch 143 Batch 1300 Loss 2.1817 Accuracy 0.9973\n",
      "Epoch 143 Batch 1350 Loss 2.1796 Accuracy 0.9973\n",
      "Epoch 143 Batch 1400 Loss 2.1821 Accuracy 0.9973\n",
      "Epoch 143 Batch 1450 Loss 2.1774 Accuracy 0.9973\n",
      "Epoch 143 Batch 1500 Loss 2.1753 Accuracy 0.9974\n",
      "Epoch 143 Batch 1550 Loss 2.1767 Accuracy 0.9974\n",
      "Epoch 143 Batch 1600 Loss 2.1776 Accuracy 0.9974\n",
      "Epoch 143 Batch 1650 Loss 2.1764 Accuracy 0.9974\n",
      "Epoch 143 Batch 1700 Loss 2.1800 Accuracy 0.9973\n",
      "Epoch 143 Batch 1750 Loss 2.1755 Accuracy 0.9974\n",
      "Epoch 143 Batch 1800 Loss 2.1768 Accuracy 0.9974\n",
      "Epoch 143 Batch 1850 Loss 2.1726 Accuracy 0.9974\n",
      "Epoch 143 Batch 1900 Loss 2.1688 Accuracy 0.9974\n",
      "Epoch 143 Batch 1950 Loss 2.1612 Accuracy 0.9974\n",
      "Epoch 143 Batch 2000 Loss 2.1658 Accuracy 0.9974\n",
      "Epoch 143 Batch 2050 Loss 2.1717 Accuracy 0.9974\n",
      "Epoch 143 Batch 2100 Loss 2.1708 Accuracy 0.9974\n",
      "Epoch 143 Batch 2150 Loss 2.1718 Accuracy 0.9974\n",
      "Epoch 143 Batch 2200 Loss 2.1740 Accuracy 0.9974\n",
      "Epoch 143 Batch 2250 Loss 2.1738 Accuracy 0.9974\n",
      "Epoch 143 Batch 2300 Loss 2.1723 Accuracy 0.9974\n",
      "Epoch 143 Batch 2350 Loss 2.1726 Accuracy 0.9974\n",
      "Epoch 143 Batch 2400 Loss 2.1744 Accuracy 0.9974\n",
      "Epoch 143 Batch 2450 Loss 2.1768 Accuracy 0.9974\n",
      "Epoch 143 Batch 2500 Loss 2.1785 Accuracy 0.9974\n",
      "Epoch 143 Batch 2550 Loss 2.1788 Accuracy 0.9974\n",
      "Epoch 143 Batch 2600 Loss 2.1765 Accuracy 0.9974\n",
      "Epoch 143 Batch 2650 Loss 2.1749 Accuracy 0.9974\n",
      "Epoch 143 Loss 2.1762 Accuracy 0.9974\n",
      "Time taken for 1 epoch: 196.73648977279663 secs\n",
      "\n",
      "Epoch 144 Batch 0 Loss 1.4071 Accuracy 0.9983\n",
      "Epoch 144 Batch 50 Loss 2.1965 Accuracy 0.9973\n",
      "Epoch 144 Batch 100 Loss 2.1835 Accuracy 0.9973\n",
      "Epoch 144 Batch 150 Loss 2.2153 Accuracy 0.9973\n",
      "Epoch 144 Batch 200 Loss 2.1631 Accuracy 0.9974\n",
      "Epoch 144 Batch 250 Loss 2.1499 Accuracy 0.9974\n",
      "Epoch 144 Batch 300 Loss 2.1502 Accuracy 0.9974\n",
      "Epoch 144 Batch 350 Loss 2.1555 Accuracy 0.9974\n",
      "Epoch 144 Batch 400 Loss 2.1586 Accuracy 0.9974\n",
      "Epoch 144 Batch 450 Loss 2.1849 Accuracy 0.9973\n",
      "Epoch 144 Batch 500 Loss 2.1748 Accuracy 0.9973\n",
      "Epoch 144 Batch 550 Loss 2.1833 Accuracy 0.9973\n",
      "Epoch 144 Batch 600 Loss 2.1936 Accuracy 0.9973\n",
      "Epoch 144 Batch 650 Loss 2.1910 Accuracy 0.9973\n",
      "Epoch 144 Batch 700 Loss 2.1874 Accuracy 0.9973\n",
      "Epoch 144 Batch 750 Loss 2.1896 Accuracy 0.9973\n",
      "Epoch 144 Batch 800 Loss 2.1814 Accuracy 0.9973\n",
      "Epoch 144 Batch 850 Loss 2.1838 Accuracy 0.9973\n",
      "Epoch 144 Batch 900 Loss 2.1828 Accuracy 0.9973\n",
      "Epoch 144 Batch 950 Loss 2.1870 Accuracy 0.9973\n",
      "Epoch 144 Batch 1000 Loss 2.1841 Accuracy 0.9973\n",
      "Epoch 144 Batch 1050 Loss 2.1751 Accuracy 0.9974\n",
      "Epoch 144 Batch 1100 Loss 2.1717 Accuracy 0.9974\n",
      "Epoch 144 Batch 1150 Loss 2.1668 Accuracy 0.9974\n",
      "Epoch 144 Batch 1200 Loss 2.1764 Accuracy 0.9974\n",
      "Epoch 144 Batch 1250 Loss 2.1732 Accuracy 0.9974\n",
      "Epoch 144 Batch 1300 Loss 2.1750 Accuracy 0.9974\n",
      "Epoch 144 Batch 1350 Loss 2.1706 Accuracy 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144 Batch 1400 Loss 2.1722 Accuracy 0.9974\n",
      "Epoch 144 Batch 1450 Loss 2.1676 Accuracy 0.9974\n",
      "Epoch 144 Batch 1500 Loss 2.1674 Accuracy 0.9974\n",
      "Epoch 144 Batch 1550 Loss 2.1692 Accuracy 0.9974\n",
      "Epoch 144 Batch 1600 Loss 2.1693 Accuracy 0.9974\n",
      "Epoch 144 Batch 1650 Loss 2.1708 Accuracy 0.9974\n",
      "Epoch 144 Batch 1700 Loss 2.1728 Accuracy 0.9974\n",
      "Epoch 144 Batch 1750 Loss 2.1698 Accuracy 0.9974\n",
      "Epoch 144 Batch 1800 Loss 2.1712 Accuracy 0.9974\n",
      "Epoch 144 Batch 1850 Loss 2.1646 Accuracy 0.9974\n",
      "Epoch 144 Batch 1900 Loss 2.1611 Accuracy 0.9974\n",
      "Epoch 144 Batch 1950 Loss 2.1559 Accuracy 0.9974\n",
      "Epoch 144 Batch 2000 Loss 2.1609 Accuracy 0.9974\n",
      "Epoch 144 Batch 2050 Loss 2.1668 Accuracy 0.9974\n",
      "Epoch 144 Batch 2100 Loss 2.1658 Accuracy 0.9974\n",
      "Epoch 144 Batch 2150 Loss 2.1683 Accuracy 0.9974\n",
      "Epoch 144 Batch 2200 Loss 2.1715 Accuracy 0.9974\n",
      "Epoch 144 Batch 2250 Loss 2.1722 Accuracy 0.9974\n",
      "Epoch 144 Batch 2300 Loss 2.1697 Accuracy 0.9974\n",
      "Epoch 144 Batch 2350 Loss 2.1698 Accuracy 0.9974\n",
      "Epoch 144 Batch 2400 Loss 2.1714 Accuracy 0.9974\n",
      "Epoch 144 Batch 2450 Loss 2.1726 Accuracy 0.9974\n",
      "Epoch 144 Batch 2500 Loss 2.1738 Accuracy 0.9974\n",
      "Epoch 144 Batch 2550 Loss 2.1721 Accuracy 0.9974\n",
      "Epoch 144 Batch 2600 Loss 2.1696 Accuracy 0.9974\n",
      "Epoch 144 Batch 2650 Loss 2.1682 Accuracy 0.9974\n",
      "Epoch 144 Loss 2.1703 Accuracy 0.9974\n",
      "Time taken for 1 epoch: 195.25667119026184 secs\n",
      "\n",
      "Epoch 145 Batch 0 Loss 1.4766 Accuracy 0.9980\n",
      "Epoch 145 Batch 50 Loss 2.2081 Accuracy 0.9973\n",
      "Epoch 145 Batch 100 Loss 2.1916 Accuracy 0.9973\n",
      "Epoch 145 Batch 150 Loss 2.2186 Accuracy 0.9973\n",
      "Epoch 145 Batch 200 Loss 2.1609 Accuracy 0.9974\n",
      "Epoch 145 Batch 250 Loss 2.1490 Accuracy 0.9974\n",
      "Epoch 145 Batch 300 Loss 2.1421 Accuracy 0.9974\n",
      "Epoch 145 Batch 350 Loss 2.1395 Accuracy 0.9974\n",
      "Epoch 145 Batch 400 Loss 2.1433 Accuracy 0.9974\n",
      "Epoch 145 Batch 450 Loss 2.1730 Accuracy 0.9973\n",
      "Epoch 145 Batch 500 Loss 2.1624 Accuracy 0.9974\n",
      "Epoch 145 Batch 550 Loss 2.1721 Accuracy 0.9974\n",
      "Epoch 145 Batch 600 Loss 2.1862 Accuracy 0.9973\n",
      "Epoch 145 Batch 650 Loss 2.1847 Accuracy 0.9973\n",
      "Epoch 145 Batch 700 Loss 2.1863 Accuracy 0.9973\n",
      "Epoch 145 Batch 750 Loss 2.1859 Accuracy 0.9973\n",
      "Epoch 145 Batch 800 Loss 2.1736 Accuracy 0.9974\n",
      "Epoch 145 Batch 850 Loss 2.1760 Accuracy 0.9974\n",
      "Epoch 145 Batch 900 Loss 2.1772 Accuracy 0.9974\n",
      "Epoch 145 Batch 950 Loss 2.1806 Accuracy 0.9974\n",
      "Epoch 145 Batch 1000 Loss 2.1773 Accuracy 0.9974\n",
      "Epoch 145 Batch 1050 Loss 2.1673 Accuracy 0.9974\n",
      "Epoch 145 Batch 1100 Loss 2.1672 Accuracy 0.9974\n",
      "Epoch 145 Batch 1150 Loss 2.1598 Accuracy 0.9974\n",
      "Epoch 145 Batch 1200 Loss 2.1700 Accuracy 0.9974\n",
      "Epoch 145 Batch 1250 Loss 2.1649 Accuracy 0.9974\n",
      "Epoch 145 Batch 1300 Loss 2.1639 Accuracy 0.9974\n",
      "Epoch 145 Batch 1350 Loss 2.1622 Accuracy 0.9974\n",
      "Epoch 145 Batch 1400 Loss 2.1651 Accuracy 0.9974\n",
      "Epoch 145 Batch 1450 Loss 2.1599 Accuracy 0.9974\n",
      "Epoch 145 Batch 1500 Loss 2.1576 Accuracy 0.9974\n",
      "Epoch 145 Batch 1550 Loss 2.1577 Accuracy 0.9974\n",
      "Epoch 145 Batch 1600 Loss 2.1574 Accuracy 0.9974\n",
      "Epoch 145 Batch 1650 Loss 2.1592 Accuracy 0.9974\n",
      "Epoch 145 Batch 1700 Loss 2.1605 Accuracy 0.9974\n",
      "Epoch 145 Batch 1750 Loss 2.1554 Accuracy 0.9974\n",
      "Epoch 145 Batch 1800 Loss 2.1582 Accuracy 0.9974\n",
      "Epoch 145 Batch 1850 Loss 2.1526 Accuracy 0.9974\n",
      "Epoch 145 Batch 1900 Loss 2.1486 Accuracy 0.9974\n",
      "Epoch 145 Batch 1950 Loss 2.1426 Accuracy 0.9974\n",
      "Epoch 145 Batch 2000 Loss 2.1477 Accuracy 0.9974\n",
      "Epoch 145 Batch 2050 Loss 2.1521 Accuracy 0.9974\n",
      "Epoch 145 Batch 2100 Loss 2.1515 Accuracy 0.9974\n",
      "Epoch 145 Batch 2150 Loss 2.1535 Accuracy 0.9974\n",
      "Epoch 145 Batch 2200 Loss 2.1573 Accuracy 0.9974\n",
      "Epoch 145 Batch 2250 Loss 2.1596 Accuracy 0.9974\n",
      "Epoch 145 Batch 2300 Loss 2.1575 Accuracy 0.9974\n",
      "Epoch 145 Batch 2350 Loss 2.1586 Accuracy 0.9974\n",
      "Epoch 145 Batch 2400 Loss 2.1601 Accuracy 0.9974\n",
      "Epoch 145 Batch 2450 Loss 2.1613 Accuracy 0.9974\n",
      "Epoch 145 Batch 2500 Loss 2.1621 Accuracy 0.9974\n",
      "Epoch 145 Batch 2550 Loss 2.1605 Accuracy 0.9974\n",
      "Epoch 145 Batch 2600 Loss 2.1601 Accuracy 0.9974\n",
      "Epoch 145 Batch 2650 Loss 2.1585 Accuracy 0.9974\n",
      "Saving checkpoint for epoch 145 at ./checkpoints/train\\ckpt-30\n",
      "Epoch 145 Loss 2.1598 Accuracy 0.9974\n",
      "Time taken for 1 epoch: 197.4868929386139 secs\n",
      "\n",
      "Epoch 146 Batch 0 Loss 1.5723 Accuracy 0.9983\n",
      "Epoch 146 Batch 50 Loss 2.2147 Accuracy 0.9973\n",
      "Epoch 146 Batch 100 Loss 2.1901 Accuracy 0.9973\n",
      "Epoch 146 Batch 150 Loss 2.2163 Accuracy 0.9973\n",
      "Epoch 146 Batch 200 Loss 2.1546 Accuracy 0.9974\n",
      "Epoch 146 Batch 250 Loss 2.1332 Accuracy 0.9974\n",
      "Epoch 146 Batch 300 Loss 2.1508 Accuracy 0.9974\n",
      "Epoch 146 Batch 350 Loss 2.1540 Accuracy 0.9974\n",
      "Epoch 146 Batch 400 Loss 2.1501 Accuracy 0.9974\n",
      "Epoch 146 Batch 450 Loss 2.1805 Accuracy 0.9973\n",
      "Epoch 146 Batch 500 Loss 2.1734 Accuracy 0.9974\n",
      "Epoch 146 Batch 550 Loss 2.1847 Accuracy 0.9973\n",
      "Epoch 146 Batch 600 Loss 2.1955 Accuracy 0.9973\n",
      "Epoch 146 Batch 650 Loss 2.1907 Accuracy 0.9973\n",
      "Epoch 146 Batch 700 Loss 2.1861 Accuracy 0.9973\n",
      "Epoch 146 Batch 750 Loss 2.1871 Accuracy 0.9973\n",
      "Epoch 146 Batch 800 Loss 2.1781 Accuracy 0.9973\n",
      "Epoch 146 Batch 850 Loss 2.1814 Accuracy 0.9973\n",
      "Epoch 146 Batch 900 Loss 2.1813 Accuracy 0.9973\n",
      "Epoch 146 Batch 950 Loss 2.1849 Accuracy 0.9973\n",
      "Epoch 146 Batch 1000 Loss 2.1831 Accuracy 0.9973\n",
      "Epoch 146 Batch 1050 Loss 2.1751 Accuracy 0.9974\n",
      "Epoch 146 Batch 1100 Loss 2.1729 Accuracy 0.9974\n",
      "Epoch 146 Batch 1150 Loss 2.1666 Accuracy 0.9974\n",
      "Epoch 146 Batch 1200 Loss 2.1761 Accuracy 0.9973\n",
      "Epoch 146 Batch 1250 Loss 2.1717 Accuracy 0.9974\n",
      "Epoch 146 Batch 1300 Loss 2.1732 Accuracy 0.9974\n",
      "Epoch 146 Batch 1350 Loss 2.1694 Accuracy 0.9974\n",
      "Epoch 146 Batch 1400 Loss 2.1705 Accuracy 0.9974\n",
      "Epoch 146 Batch 1450 Loss 2.1669 Accuracy 0.9974\n",
      "Epoch 146 Batch 1500 Loss 2.1632 Accuracy 0.9974\n",
      "Epoch 146 Batch 1550 Loss 2.1646 Accuracy 0.9974\n",
      "Epoch 146 Batch 1600 Loss 2.1654 Accuracy 0.9974\n",
      "Epoch 146 Batch 1650 Loss 2.1659 Accuracy 0.9974\n",
      "Epoch 146 Batch 1700 Loss 2.1670 Accuracy 0.9974\n",
      "Epoch 146 Batch 1750 Loss 2.1634 Accuracy 0.9974\n",
      "Epoch 146 Batch 1800 Loss 2.1661 Accuracy 0.9974\n",
      "Epoch 146 Batch 1850 Loss 2.1611 Accuracy 0.9974\n",
      "Epoch 146 Batch 1900 Loss 2.1582 Accuracy 0.9974\n",
      "Epoch 146 Batch 1950 Loss 2.1515 Accuracy 0.9974\n",
      "Epoch 146 Batch 2000 Loss 2.1553 Accuracy 0.9974\n",
      "Epoch 146 Batch 2050 Loss 2.1598 Accuracy 0.9974\n",
      "Epoch 146 Batch 2100 Loss 2.1598 Accuracy 0.9974\n",
      "Epoch 146 Batch 2150 Loss 2.1624 Accuracy 0.9974\n",
      "Epoch 146 Batch 2200 Loss 2.1668 Accuracy 0.9974\n",
      "Epoch 146 Batch 2250 Loss 2.1680 Accuracy 0.9974\n",
      "Epoch 146 Batch 2300 Loss 2.1643 Accuracy 0.9974\n",
      "Epoch 146 Batch 2350 Loss 2.1639 Accuracy 0.9974\n",
      "Epoch 146 Batch 2400 Loss 2.1647 Accuracy 0.9974\n",
      "Epoch 146 Batch 2450 Loss 2.1669 Accuracy 0.9974\n",
      "Epoch 146 Batch 2500 Loss 2.1679 Accuracy 0.9974\n",
      "Epoch 146 Batch 2550 Loss 2.1669 Accuracy 0.9974\n",
      "Epoch 146 Batch 2600 Loss 2.1644 Accuracy 0.9974\n",
      "Epoch 146 Batch 2650 Loss 2.1625 Accuracy 0.9974\n",
      "Epoch 146 Loss 2.1635 Accuracy 0.9974\n",
      "Time taken for 1 epoch: 194.71330666542053 secs\n",
      "\n",
      "Epoch 147 Batch 0 Loss 1.3393 Accuracy 0.9984\n",
      "Epoch 147 Batch 50 Loss 2.1655 Accuracy 0.9974\n",
      "Epoch 147 Batch 100 Loss 2.1681 Accuracy 0.9973\n",
      "Epoch 147 Batch 150 Loss 2.1824 Accuracy 0.9973\n",
      "Epoch 147 Batch 200 Loss 2.1444 Accuracy 0.9974\n",
      "Epoch 147 Batch 250 Loss 2.1408 Accuracy 0.9974\n",
      "Epoch 147 Batch 300 Loss 2.1455 Accuracy 0.9974\n",
      "Epoch 147 Batch 350 Loss 2.1351 Accuracy 0.9974\n",
      "Epoch 147 Batch 400 Loss 2.1231 Accuracy 0.9974\n",
      "Epoch 147 Batch 450 Loss 2.1496 Accuracy 0.9974\n",
      "Epoch 147 Batch 500 Loss 2.1423 Accuracy 0.9974\n",
      "Epoch 147 Batch 550 Loss 2.1558 Accuracy 0.9974\n",
      "Epoch 147 Batch 600 Loss 2.1629 Accuracy 0.9974\n",
      "Epoch 147 Batch 650 Loss 2.1631 Accuracy 0.9974\n",
      "Epoch 147 Batch 700 Loss 2.1603 Accuracy 0.9974\n",
      "Epoch 147 Batch 750 Loss 2.1648 Accuracy 0.9974\n",
      "Epoch 147 Batch 800 Loss 2.1559 Accuracy 0.9974\n",
      "Epoch 147 Batch 850 Loss 2.1586 Accuracy 0.9974\n",
      "Epoch 147 Batch 900 Loss 2.1590 Accuracy 0.9974\n",
      "Epoch 147 Batch 950 Loss 2.1624 Accuracy 0.9974\n",
      "Epoch 147 Batch 1000 Loss 2.1625 Accuracy 0.9974\n",
      "Epoch 147 Batch 1050 Loss 2.1535 Accuracy 0.9974\n",
      "Epoch 147 Batch 1100 Loss 2.1519 Accuracy 0.9974\n",
      "Epoch 147 Batch 1150 Loss 2.1460 Accuracy 0.9974\n",
      "Epoch 147 Batch 1200 Loss 2.1550 Accuracy 0.9974\n",
      "Epoch 147 Batch 1250 Loss 2.1503 Accuracy 0.9974\n",
      "Epoch 147 Batch 1300 Loss 2.1530 Accuracy 0.9974\n",
      "Epoch 147 Batch 1350 Loss 2.1498 Accuracy 0.9974\n",
      "Epoch 147 Batch 1400 Loss 2.1537 Accuracy 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147 Batch 1450 Loss 2.1500 Accuracy 0.9974\n",
      "Epoch 147 Batch 1500 Loss 2.1492 Accuracy 0.9974\n",
      "Epoch 147 Batch 1550 Loss 2.1513 Accuracy 0.9974\n",
      "Epoch 147 Batch 1600 Loss 2.1534 Accuracy 0.9974\n",
      "Epoch 147 Batch 1650 Loss 2.1539 Accuracy 0.9974\n",
      "Epoch 147 Batch 1700 Loss 2.1569 Accuracy 0.9974\n",
      "Epoch 147 Batch 1750 Loss 2.1537 Accuracy 0.9974\n",
      "Epoch 147 Batch 1800 Loss 2.1550 Accuracy 0.9974\n",
      "Epoch 147 Batch 1850 Loss 2.1491 Accuracy 0.9974\n",
      "Epoch 147 Batch 1900 Loss 2.1467 Accuracy 0.9974\n",
      "Epoch 147 Batch 1950 Loss 2.1394 Accuracy 0.9974\n",
      "Epoch 147 Batch 2000 Loss 2.1423 Accuracy 0.9974\n",
      "Epoch 147 Batch 2050 Loss 2.1476 Accuracy 0.9974\n",
      "Epoch 147 Batch 2100 Loss 2.1463 Accuracy 0.9974\n",
      "Epoch 147 Batch 2150 Loss 2.1477 Accuracy 0.9974\n",
      "Epoch 147 Batch 2200 Loss 2.1499 Accuracy 0.9974\n",
      "Epoch 147 Batch 2250 Loss 2.1527 Accuracy 0.9974\n",
      "Epoch 147 Batch 2300 Loss 2.1502 Accuracy 0.9974\n",
      "Epoch 147 Batch 2350 Loss 2.1515 Accuracy 0.9974\n",
      "Epoch 147 Batch 2400 Loss 2.1521 Accuracy 0.9974\n",
      "Epoch 147 Batch 2450 Loss 2.1546 Accuracy 0.9974\n",
      "Epoch 147 Batch 2500 Loss 2.1569 Accuracy 0.9974\n",
      "Epoch 147 Batch 2550 Loss 2.1564 Accuracy 0.9974\n",
      "Epoch 147 Batch 2600 Loss 2.1543 Accuracy 0.9974\n",
      "Epoch 147 Batch 2650 Loss 2.1523 Accuracy 0.9974\n",
      "Epoch 147 Loss 2.1537 Accuracy 0.9974\n",
      "Time taken for 1 epoch: 194.66993641853333 secs\n",
      "\n",
      "Epoch 148 Batch 0 Loss 1.7475 Accuracy 0.9980\n",
      "Epoch 148 Batch 50 Loss 2.2186 Accuracy 0.9973\n",
      "Epoch 148 Batch 100 Loss 2.1874 Accuracy 0.9973\n",
      "Epoch 148 Batch 150 Loss 2.2080 Accuracy 0.9973\n",
      "Epoch 148 Batch 200 Loss 2.1563 Accuracy 0.9974\n",
      "Epoch 148 Batch 250 Loss 2.1277 Accuracy 0.9974\n",
      "Epoch 148 Batch 300 Loss 2.1235 Accuracy 0.9974\n",
      "Epoch 148 Batch 350 Loss 2.1202 Accuracy 0.9974\n",
      "Epoch 148 Batch 400 Loss 2.1206 Accuracy 0.9974\n",
      "Epoch 148 Batch 450 Loss 2.1485 Accuracy 0.9974\n",
      "Epoch 148 Batch 500 Loss 2.1349 Accuracy 0.9974\n",
      "Epoch 148 Batch 550 Loss 2.1494 Accuracy 0.9974\n",
      "Epoch 148 Batch 600 Loss 2.1645 Accuracy 0.9974\n",
      "Epoch 148 Batch 650 Loss 2.1605 Accuracy 0.9974\n",
      "Epoch 148 Batch 700 Loss 2.1598 Accuracy 0.9974\n",
      "Epoch 148 Batch 750 Loss 2.1605 Accuracy 0.9974\n",
      "Epoch 148 Batch 800 Loss 2.1460 Accuracy 0.9974\n",
      "Epoch 148 Batch 850 Loss 2.1502 Accuracy 0.9974\n",
      "Epoch 148 Batch 900 Loss 2.1507 Accuracy 0.9974\n",
      "Epoch 148 Batch 950 Loss 2.1565 Accuracy 0.9974\n",
      "Epoch 148 Batch 1000 Loss 2.1537 Accuracy 0.9974\n",
      "Epoch 148 Batch 1050 Loss 2.1468 Accuracy 0.9974\n",
      "Epoch 148 Batch 1100 Loss 2.1468 Accuracy 0.9974\n",
      "Epoch 148 Batch 1150 Loss 2.1407 Accuracy 0.9974\n",
      "Epoch 148 Batch 1200 Loss 2.1473 Accuracy 0.9974\n",
      "Epoch 148 Batch 1250 Loss 2.1433 Accuracy 0.9974\n",
      "Epoch 148 Batch 1300 Loss 2.1444 Accuracy 0.9974\n",
      "Epoch 148 Batch 1350 Loss 2.1411 Accuracy 0.9974\n",
      "Epoch 148 Batch 1400 Loss 2.1420 Accuracy 0.9974\n",
      "Epoch 148 Batch 1450 Loss 2.1376 Accuracy 0.9974\n",
      "Epoch 148 Batch 1500 Loss 2.1366 Accuracy 0.9974\n",
      "Epoch 148 Batch 1550 Loss 2.1380 Accuracy 0.9974\n",
      "Epoch 148 Batch 1600 Loss 2.1388 Accuracy 0.9974\n",
      "Epoch 148 Batch 1650 Loss 2.1394 Accuracy 0.9974\n",
      "Epoch 148 Batch 1700 Loss 2.1413 Accuracy 0.9974\n",
      "Epoch 148 Batch 1750 Loss 2.1380 Accuracy 0.9974\n",
      "Epoch 148 Batch 1800 Loss 2.1410 Accuracy 0.9974\n",
      "Epoch 148 Batch 1850 Loss 2.1364 Accuracy 0.9974\n",
      "Epoch 148 Batch 1900 Loss 2.1328 Accuracy 0.9974\n",
      "Epoch 148 Batch 1950 Loss 2.1273 Accuracy 0.9974\n",
      "Epoch 148 Batch 2000 Loss 2.1307 Accuracy 0.9974\n",
      "Epoch 148 Batch 2050 Loss 2.1358 Accuracy 0.9974\n",
      "Epoch 148 Batch 2100 Loss 2.1350 Accuracy 0.9974\n",
      "Epoch 148 Batch 2150 Loss 2.1379 Accuracy 0.9974\n",
      "Epoch 148 Batch 2200 Loss 2.1419 Accuracy 0.9974\n",
      "Epoch 148 Batch 2250 Loss 2.1454 Accuracy 0.9974\n",
      "Epoch 148 Batch 2300 Loss 2.1431 Accuracy 0.9974\n",
      "Epoch 148 Batch 2350 Loss 2.1438 Accuracy 0.9974\n",
      "Epoch 148 Batch 2400 Loss 2.1465 Accuracy 0.9974\n",
      "Epoch 148 Batch 2450 Loss 2.1477 Accuracy 0.9974\n",
      "Epoch 148 Batch 2500 Loss 2.1489 Accuracy 0.9974\n",
      "Epoch 148 Batch 2550 Loss 2.1491 Accuracy 0.9974\n",
      "Epoch 148 Batch 2600 Loss 2.1464 Accuracy 0.9974\n",
      "Epoch 148 Batch 2650 Loss 2.1454 Accuracy 0.9974\n",
      "Epoch 148 Loss 2.1459 Accuracy 0.9974\n",
      "Time taken for 1 epoch: 195.11675572395325 secs\n",
      "\n",
      "Epoch 149 Batch 0 Loss 1.5100 Accuracy 0.9983\n",
      "Epoch 149 Batch 50 Loss 2.1843 Accuracy 0.9974\n",
      "Epoch 149 Batch 100 Loss 2.1792 Accuracy 0.9974\n",
      "Epoch 149 Batch 150 Loss 2.1917 Accuracy 0.9973\n",
      "Epoch 149 Batch 200 Loss 2.1396 Accuracy 0.9974\n",
      "Epoch 149 Batch 250 Loss 2.1324 Accuracy 0.9974\n",
      "Epoch 149 Batch 300 Loss 2.1351 Accuracy 0.9974\n",
      "Epoch 149 Batch 350 Loss 2.1358 Accuracy 0.9974\n",
      "Epoch 149 Batch 400 Loss 2.1359 Accuracy 0.9974\n",
      "Epoch 149 Batch 450 Loss 2.1564 Accuracy 0.9974\n",
      "Epoch 149 Batch 500 Loss 2.1468 Accuracy 0.9974\n",
      "Epoch 149 Batch 550 Loss 2.1639 Accuracy 0.9974\n",
      "Epoch 149 Batch 600 Loss 2.1770 Accuracy 0.9974\n",
      "Epoch 149 Batch 650 Loss 2.1733 Accuracy 0.9974\n",
      "Epoch 149 Batch 700 Loss 2.1713 Accuracy 0.9974\n",
      "Epoch 149 Batch 750 Loss 2.1712 Accuracy 0.9974\n",
      "Epoch 149 Batch 800 Loss 2.1613 Accuracy 0.9974\n",
      "Epoch 149 Batch 850 Loss 2.1675 Accuracy 0.9974\n",
      "Epoch 149 Batch 900 Loss 2.1652 Accuracy 0.9974\n",
      "Epoch 149 Batch 950 Loss 2.1713 Accuracy 0.9974\n",
      "Epoch 149 Batch 1000 Loss 2.1676 Accuracy 0.9974\n",
      "Epoch 149 Batch 1050 Loss 2.1605 Accuracy 0.9974\n",
      "Epoch 149 Batch 1100 Loss 2.1615 Accuracy 0.9974\n",
      "Epoch 149 Batch 1150 Loss 2.1538 Accuracy 0.9974\n",
      "Epoch 149 Batch 1200 Loss 2.1611 Accuracy 0.9974\n",
      "Epoch 149 Batch 1250 Loss 2.1553 Accuracy 0.9974\n",
      "Epoch 149 Batch 1300 Loss 2.1558 Accuracy 0.9974\n",
      "Epoch 149 Batch 1350 Loss 2.1521 Accuracy 0.9974\n",
      "Epoch 149 Batch 1400 Loss 2.1527 Accuracy 0.9974\n",
      "Epoch 149 Batch 1450 Loss 2.1476 Accuracy 0.9974\n",
      "Epoch 149 Batch 1500 Loss 2.1474 Accuracy 0.9974\n",
      "Epoch 149 Batch 1550 Loss 2.1497 Accuracy 0.9974\n",
      "Epoch 149 Batch 1600 Loss 2.1505 Accuracy 0.9974\n",
      "Epoch 149 Batch 1650 Loss 2.1507 Accuracy 0.9974\n",
      "Epoch 149 Batch 1700 Loss 2.1524 Accuracy 0.9974\n",
      "Epoch 149 Batch 1750 Loss 2.1478 Accuracy 0.9974\n",
      "Epoch 149 Batch 1800 Loss 2.1492 Accuracy 0.9974\n",
      "Epoch 149 Batch 1850 Loss 2.1438 Accuracy 0.9974\n",
      "Epoch 149 Batch 1900 Loss 2.1404 Accuracy 0.9974\n",
      "Epoch 149 Batch 1950 Loss 2.1340 Accuracy 0.9974\n",
      "Epoch 149 Batch 2000 Loss 2.1380 Accuracy 0.9974\n",
      "Epoch 149 Batch 2050 Loss 2.1426 Accuracy 0.9974\n",
      "Epoch 149 Batch 2100 Loss 2.1407 Accuracy 0.9974\n",
      "Epoch 149 Batch 2150 Loss 2.1425 Accuracy 0.9974\n",
      "Epoch 149 Batch 2200 Loss 2.1459 Accuracy 0.9974\n",
      "Epoch 149 Batch 2250 Loss 2.1478 Accuracy 0.9974\n",
      "Epoch 149 Batch 2300 Loss 2.1449 Accuracy 0.9974\n",
      "Epoch 149 Batch 2350 Loss 2.1449 Accuracy 0.9974\n",
      "Epoch 149 Batch 2400 Loss 2.1462 Accuracy 0.9974\n",
      "Epoch 149 Batch 2450 Loss 2.1480 Accuracy 0.9974\n",
      "Epoch 149 Batch 2500 Loss 2.1491 Accuracy 0.9974\n",
      "Epoch 149 Batch 2550 Loss 2.1487 Accuracy 0.9974\n",
      "Epoch 149 Batch 2600 Loss 2.1469 Accuracy 0.9974\n",
      "Epoch 149 Batch 2650 Loss 2.1463 Accuracy 0.9974\n",
      "Epoch 149 Loss 2.1463 Accuracy 0.9974\n",
      "Time taken for 1 epoch: 194.53331327438354 secs\n",
      "\n",
      "Epoch 150 Batch 0 Loss 1.6563 Accuracy 0.9980\n",
      "Epoch 150 Batch 50 Loss 2.1994 Accuracy 0.9973\n",
      "Epoch 150 Batch 100 Loss 2.1997 Accuracy 0.9973\n",
      "Epoch 150 Batch 150 Loss 2.2229 Accuracy 0.9973\n",
      "Epoch 150 Batch 200 Loss 2.1551 Accuracy 0.9974\n",
      "Epoch 150 Batch 250 Loss 2.1398 Accuracy 0.9974\n",
      "Epoch 150 Batch 300 Loss 2.1395 Accuracy 0.9974\n",
      "Epoch 150 Batch 350 Loss 2.1322 Accuracy 0.9974\n",
      "Epoch 150 Batch 400 Loss 2.1265 Accuracy 0.9974\n",
      "Epoch 150 Batch 450 Loss 2.1509 Accuracy 0.9974\n",
      "Epoch 150 Batch 500 Loss 2.1382 Accuracy 0.9974\n",
      "Epoch 150 Batch 550 Loss 2.1486 Accuracy 0.9974\n",
      "Epoch 150 Batch 600 Loss 2.1600 Accuracy 0.9974\n",
      "Epoch 150 Batch 650 Loss 2.1607 Accuracy 0.9974\n",
      "Epoch 150 Batch 700 Loss 2.1603 Accuracy 0.9974\n",
      "Epoch 150 Batch 750 Loss 2.1589 Accuracy 0.9974\n",
      "Epoch 150 Batch 800 Loss 2.1475 Accuracy 0.9974\n",
      "Epoch 150 Batch 850 Loss 2.1508 Accuracy 0.9974\n",
      "Epoch 150 Batch 900 Loss 2.1514 Accuracy 0.9974\n",
      "Epoch 150 Batch 950 Loss 2.1592 Accuracy 0.9974\n",
      "Epoch 150 Batch 1000 Loss 2.1582 Accuracy 0.9974\n",
      "Epoch 150 Batch 1050 Loss 2.1490 Accuracy 0.9974\n",
      "Epoch 150 Batch 1100 Loss 2.1468 Accuracy 0.9974\n",
      "Epoch 150 Batch 1150 Loss 2.1382 Accuracy 0.9974\n",
      "Epoch 150 Batch 1200 Loss 2.1451 Accuracy 0.9974\n",
      "Epoch 150 Batch 1250 Loss 2.1402 Accuracy 0.9974\n",
      "Epoch 150 Batch 1300 Loss 2.1423 Accuracy 0.9974\n",
      "Epoch 150 Batch 1350 Loss 2.1386 Accuracy 0.9974\n",
      "Epoch 150 Batch 1400 Loss 2.1417 Accuracy 0.9974\n",
      "Epoch 150 Batch 1450 Loss 2.1360 Accuracy 0.9974\n",
      "Epoch 150 Batch 1500 Loss 2.1359 Accuracy 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150 Batch 1550 Loss 2.1360 Accuracy 0.9974\n",
      "Epoch 150 Batch 1600 Loss 2.1374 Accuracy 0.9974\n",
      "Epoch 150 Batch 1650 Loss 2.1393 Accuracy 0.9974\n",
      "Epoch 150 Batch 1700 Loss 2.1408 Accuracy 0.9974\n",
      "Epoch 150 Batch 1750 Loss 2.1373 Accuracy 0.9974\n",
      "Epoch 150 Batch 1800 Loss 2.1385 Accuracy 0.9974\n",
      "Epoch 150 Batch 1850 Loss 2.1345 Accuracy 0.9974\n",
      "Epoch 150 Batch 1900 Loss 2.1319 Accuracy 0.9974\n",
      "Epoch 150 Batch 1950 Loss 2.1254 Accuracy 0.9974\n",
      "Epoch 150 Batch 2000 Loss 2.1301 Accuracy 0.9974\n",
      "Epoch 150 Batch 2050 Loss 2.1347 Accuracy 0.9974\n",
      "Epoch 150 Batch 2100 Loss 2.1329 Accuracy 0.9974\n",
      "Epoch 150 Batch 2150 Loss 2.1370 Accuracy 0.9974\n",
      "Epoch 150 Batch 2200 Loss 2.1398 Accuracy 0.9974\n",
      "Epoch 150 Batch 2250 Loss 2.1410 Accuracy 0.9974\n",
      "Epoch 150 Batch 2300 Loss 2.1377 Accuracy 0.9974\n",
      "Epoch 150 Batch 2350 Loss 2.1364 Accuracy 0.9974\n",
      "Epoch 150 Batch 2400 Loss 2.1380 Accuracy 0.9974\n",
      "Epoch 150 Batch 2450 Loss 2.1397 Accuracy 0.9974\n",
      "Epoch 150 Batch 2500 Loss 2.1417 Accuracy 0.9974\n",
      "Epoch 150 Batch 2550 Loss 2.1421 Accuracy 0.9974\n",
      "Epoch 150 Batch 2600 Loss 2.1417 Accuracy 0.9974\n",
      "Epoch 150 Batch 2650 Loss 2.1393 Accuracy 0.9974\n",
      "Saving checkpoint for epoch 150 at ./checkpoints/train\\ckpt-31\n",
      "Epoch 150 Loss 2.1404 Accuracy 0.9974\n",
      "Time taken for 1 epoch: 195.45975637435913 secs\n",
      "\n",
      "Epoch 151 Batch 0 Loss 1.3973 Accuracy 0.9983\n",
      "Epoch 151 Batch 50 Loss 2.1734 Accuracy 0.9973\n",
      "Epoch 151 Batch 100 Loss 2.2007 Accuracy 0.9973\n",
      "Epoch 151 Batch 150 Loss 2.2151 Accuracy 0.9973\n",
      "Epoch 151 Batch 200 Loss 2.1503 Accuracy 0.9974\n",
      "Epoch 151 Batch 250 Loss 2.1376 Accuracy 0.9974\n",
      "Epoch 151 Batch 300 Loss 2.1413 Accuracy 0.9974\n",
      "Epoch 151 Batch 350 Loss 2.1340 Accuracy 0.9974\n",
      "Epoch 151 Batch 400 Loss 2.1296 Accuracy 0.9974\n",
      "Epoch 151 Batch 450 Loss 2.1561 Accuracy 0.9974\n",
      "Epoch 151 Batch 500 Loss 2.1414 Accuracy 0.9974\n",
      "Epoch 151 Batch 550 Loss 2.1495 Accuracy 0.9974\n",
      "Epoch 151 Batch 600 Loss 2.1635 Accuracy 0.9974\n",
      "Epoch 151 Batch 650 Loss 2.1605 Accuracy 0.9974\n",
      "Epoch 151 Batch 700 Loss 2.1593 Accuracy 0.9974\n",
      "Epoch 151 Batch 750 Loss 2.1606 Accuracy 0.9974\n",
      "Epoch 151 Batch 800 Loss 2.1517 Accuracy 0.9974\n",
      "Epoch 151 Batch 850 Loss 2.1541 Accuracy 0.9974\n",
      "Epoch 151 Batch 900 Loss 2.1535 Accuracy 0.9974\n",
      "Epoch 151 Batch 950 Loss 2.1567 Accuracy 0.9974\n",
      "Epoch 151 Batch 1000 Loss 2.1540 Accuracy 0.9974\n",
      "Epoch 151 Batch 1050 Loss 2.1454 Accuracy 0.9974\n",
      "Epoch 151 Batch 1100 Loss 2.1429 Accuracy 0.9974\n",
      "Epoch 151 Batch 1150 Loss 2.1357 Accuracy 0.9974\n",
      "Epoch 151 Batch 1200 Loss 2.1464 Accuracy 0.9974\n",
      "Epoch 151 Batch 1250 Loss 2.1427 Accuracy 0.9974\n",
      "Epoch 151 Batch 1300 Loss 2.1441 Accuracy 0.9974\n",
      "Epoch 151 Batch 1350 Loss 2.1399 Accuracy 0.9974\n",
      "Epoch 151 Batch 1400 Loss 2.1435 Accuracy 0.9974\n",
      "Epoch 151 Batch 1450 Loss 2.1396 Accuracy 0.9974\n",
      "Epoch 151 Batch 1500 Loss 2.1383 Accuracy 0.9974\n",
      "Epoch 151 Batch 1550 Loss 2.1403 Accuracy 0.9974\n",
      "Epoch 151 Batch 1600 Loss 2.1414 Accuracy 0.9974\n",
      "Epoch 151 Batch 1650 Loss 2.1434 Accuracy 0.9974\n",
      "Epoch 151 Batch 1700 Loss 2.1463 Accuracy 0.9974\n",
      "Epoch 151 Batch 1750 Loss 2.1435 Accuracy 0.9974\n",
      "Epoch 151 Batch 1800 Loss 2.1445 Accuracy 0.9974\n",
      "Epoch 151 Batch 1850 Loss 2.1410 Accuracy 0.9974\n",
      "Epoch 151 Batch 1900 Loss 2.1373 Accuracy 0.9974\n",
      "Epoch 151 Batch 1950 Loss 2.1316 Accuracy 0.9974\n",
      "Epoch 151 Batch 2000 Loss 2.1359 Accuracy 0.9974\n",
      "Epoch 151 Batch 2050 Loss 2.1421 Accuracy 0.9974\n",
      "Epoch 151 Batch 2100 Loss 2.1405 Accuracy 0.9974\n",
      "Epoch 151 Batch 2150 Loss 2.1416 Accuracy 0.9974\n",
      "Epoch 151 Batch 2200 Loss 2.1443 Accuracy 0.9974\n",
      "Epoch 151 Batch 2250 Loss 2.1457 Accuracy 0.9974\n",
      "Epoch 151 Batch 2300 Loss 2.1422 Accuracy 0.9974\n",
      "Epoch 151 Batch 2350 Loss 2.1425 Accuracy 0.9974\n",
      "Epoch 151 Batch 2400 Loss 2.1446 Accuracy 0.9974\n",
      "Epoch 151 Batch 2450 Loss 2.1461 Accuracy 0.9974\n",
      "Epoch 151 Batch 2500 Loss 2.1460 Accuracy 0.9974\n",
      "Epoch 151 Batch 2550 Loss 2.1452 Accuracy 0.9974\n",
      "Epoch 151 Batch 2600 Loss 2.1430 Accuracy 0.9974\n",
      "Epoch 151 Batch 2650 Loss 2.1415 Accuracy 0.9974\n",
      "Epoch 151 Loss 2.1419 Accuracy 0.9974\n",
      "Time taken for 1 epoch: 194.9737730026245 secs\n",
      "\n",
      "Epoch 152 Batch 0 Loss 1.5660 Accuracy 0.9982\n",
      "Epoch 152 Batch 50 Loss 2.1580 Accuracy 0.9974\n",
      "Epoch 152 Batch 100 Loss 2.1408 Accuracy 0.9974\n",
      "Epoch 152 Batch 150 Loss 2.1693 Accuracy 0.9974\n",
      "Epoch 152 Batch 200 Loss 2.1075 Accuracy 0.9974\n",
      "Epoch 152 Batch 250 Loss 2.1027 Accuracy 0.9974\n",
      "Epoch 152 Batch 300 Loss 2.1119 Accuracy 0.9974\n",
      "Epoch 152 Batch 350 Loss 2.1103 Accuracy 0.9974\n",
      "Epoch 152 Batch 400 Loss 2.1076 Accuracy 0.9974\n",
      "Epoch 152 Batch 450 Loss 2.1353 Accuracy 0.9974\n",
      "Epoch 152 Batch 500 Loss 2.1266 Accuracy 0.9974\n",
      "Epoch 152 Batch 550 Loss 2.1347 Accuracy 0.9974\n",
      "Epoch 152 Batch 600 Loss 2.1459 Accuracy 0.9974\n",
      "Epoch 152 Batch 650 Loss 2.1412 Accuracy 0.9974\n",
      "Epoch 152 Batch 700 Loss 2.1422 Accuracy 0.9974\n",
      "Epoch 152 Batch 750 Loss 2.1435 Accuracy 0.9974\n",
      "Epoch 152 Batch 800 Loss 2.1341 Accuracy 0.9974\n",
      "Epoch 152 Batch 850 Loss 2.1389 Accuracy 0.9974\n",
      "Epoch 152 Batch 900 Loss 2.1384 Accuracy 0.9974\n",
      "Epoch 152 Batch 950 Loss 2.1426 Accuracy 0.9974\n",
      "Epoch 152 Batch 1000 Loss 2.1397 Accuracy 0.9974\n",
      "Epoch 152 Batch 1050 Loss 2.1329 Accuracy 0.9974\n",
      "Epoch 152 Batch 1100 Loss 2.1305 Accuracy 0.9974\n",
      "Epoch 152 Batch 1150 Loss 2.1249 Accuracy 0.9974\n",
      "Epoch 152 Batch 1200 Loss 2.1349 Accuracy 0.9974\n",
      "Epoch 152 Batch 1250 Loss 2.1310 Accuracy 0.9974\n",
      "Epoch 152 Batch 1300 Loss 2.1323 Accuracy 0.9974\n",
      "Epoch 152 Batch 1350 Loss 2.1295 Accuracy 0.9974\n",
      "Epoch 152 Batch 1400 Loss 2.1309 Accuracy 0.9974\n",
      "Epoch 152 Batch 1450 Loss 2.1254 Accuracy 0.9974\n",
      "Epoch 152 Batch 1500 Loss 2.1234 Accuracy 0.9974\n",
      "Epoch 152 Batch 1550 Loss 2.1239 Accuracy 0.9974\n",
      "Epoch 152 Batch 1600 Loss 2.1237 Accuracy 0.9974\n",
      "Epoch 152 Batch 1650 Loss 2.1243 Accuracy 0.9974\n",
      "Epoch 152 Batch 1700 Loss 2.1261 Accuracy 0.9974\n",
      "Epoch 152 Batch 1750 Loss 2.1210 Accuracy 0.9974\n",
      "Epoch 152 Batch 1800 Loss 2.1243 Accuracy 0.9974\n",
      "Epoch 152 Batch 1850 Loss 2.1203 Accuracy 0.9974\n",
      "Epoch 152 Batch 1900 Loss 2.1169 Accuracy 0.9974\n",
      "Epoch 152 Batch 1950 Loss 2.1105 Accuracy 0.9974\n",
      "Epoch 152 Batch 2000 Loss 2.1161 Accuracy 0.9974\n",
      "Epoch 152 Batch 2050 Loss 2.1213 Accuracy 0.9974\n",
      "Epoch 152 Batch 2100 Loss 2.1207 Accuracy 0.9974\n",
      "Epoch 152 Batch 2150 Loss 2.1219 Accuracy 0.9974\n",
      "Epoch 152 Batch 2200 Loss 2.1254 Accuracy 0.9974\n",
      "Epoch 152 Batch 2250 Loss 2.1281 Accuracy 0.9974\n",
      "Epoch 152 Batch 2300 Loss 2.1264 Accuracy 0.9974\n",
      "Epoch 152 Batch 2350 Loss 2.1267 Accuracy 0.9974\n",
      "Epoch 152 Batch 2400 Loss 2.1287 Accuracy 0.9974\n",
      "Epoch 152 Batch 2450 Loss 2.1307 Accuracy 0.9974\n",
      "Epoch 152 Batch 2500 Loss 2.1321 Accuracy 0.9974\n",
      "Epoch 152 Batch 2550 Loss 2.1317 Accuracy 0.9974\n",
      "Epoch 152 Batch 2600 Loss 2.1304 Accuracy 0.9974\n",
      "Epoch 152 Batch 2650 Loss 2.1296 Accuracy 0.9974\n",
      "Epoch 152 Loss 2.1305 Accuracy 0.9974\n",
      "Time taken for 1 epoch: 195.67318654060364 secs\n",
      "\n",
      "Epoch 153 Batch 0 Loss 1.6485 Accuracy 0.9982\n",
      "Epoch 153 Batch 50 Loss 2.2134 Accuracy 0.9973\n",
      "Epoch 153 Batch 100 Loss 2.1897 Accuracy 0.9973\n",
      "Epoch 153 Batch 150 Loss 2.2053 Accuracy 0.9973\n",
      "Epoch 153 Batch 200 Loss 2.1452 Accuracy 0.9974\n",
      "Epoch 153 Batch 250 Loss 2.1361 Accuracy 0.9974\n",
      "Epoch 153 Batch 300 Loss 2.1314 Accuracy 0.9974\n",
      "Epoch 153 Batch 350 Loss 2.1344 Accuracy 0.9974\n",
      "Epoch 153 Batch 400 Loss 2.1342 Accuracy 0.9974\n",
      "Epoch 153 Batch 450 Loss 2.1583 Accuracy 0.9974\n",
      "Epoch 153 Batch 500 Loss 2.1458 Accuracy 0.9974\n",
      "Epoch 153 Batch 550 Loss 2.1473 Accuracy 0.9974\n",
      "Epoch 153 Batch 600 Loss 2.1592 Accuracy 0.9974\n",
      "Epoch 153 Batch 650 Loss 2.1584 Accuracy 0.9974\n",
      "Epoch 153 Batch 700 Loss 2.1561 Accuracy 0.9974\n",
      "Epoch 153 Batch 750 Loss 2.1647 Accuracy 0.9974\n",
      "Epoch 153 Batch 800 Loss 2.1534 Accuracy 0.9974\n",
      "Epoch 153 Batch 850 Loss 2.1552 Accuracy 0.9974\n",
      "Epoch 153 Batch 900 Loss 2.1552 Accuracy 0.9974\n",
      "Epoch 153 Batch 950 Loss 2.1587 Accuracy 0.9974\n",
      "Epoch 153 Batch 1000 Loss 2.1557 Accuracy 0.9974\n",
      "Epoch 153 Batch 1050 Loss 2.1463 Accuracy 0.9974\n",
      "Epoch 153 Batch 1100 Loss 2.1424 Accuracy 0.9974\n",
      "Epoch 153 Batch 1150 Loss 2.1338 Accuracy 0.9974\n",
      "Epoch 153 Batch 1200 Loss 2.1438 Accuracy 0.9974\n",
      "Epoch 153 Batch 1250 Loss 2.1400 Accuracy 0.9974\n",
      "Epoch 153 Batch 1300 Loss 2.1410 Accuracy 0.9974\n",
      "Epoch 153 Batch 1350 Loss 2.1369 Accuracy 0.9974\n",
      "Epoch 153 Batch 1400 Loss 2.1375 Accuracy 0.9974\n",
      "Epoch 153 Batch 1450 Loss 2.1326 Accuracy 0.9974\n",
      "Epoch 153 Batch 1500 Loss 2.1310 Accuracy 0.9974\n",
      "Epoch 153 Batch 1550 Loss 2.1331 Accuracy 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153 Batch 1600 Loss 2.1347 Accuracy 0.9974\n",
      "Epoch 153 Batch 1650 Loss 2.1352 Accuracy 0.9974\n",
      "Epoch 153 Batch 1700 Loss 2.1362 Accuracy 0.9974\n",
      "Epoch 153 Batch 1750 Loss 2.1318 Accuracy 0.9974\n",
      "Epoch 153 Batch 1800 Loss 2.1327 Accuracy 0.9974\n",
      "Epoch 153 Batch 1850 Loss 2.1279 Accuracy 0.9974\n",
      "Epoch 153 Batch 1900 Loss 2.1251 Accuracy 0.9974\n",
      "Epoch 153 Batch 1950 Loss 2.1200 Accuracy 0.9974\n",
      "Epoch 153 Batch 2000 Loss 2.1242 Accuracy 0.9974\n",
      "Epoch 153 Batch 2050 Loss 2.1299 Accuracy 0.9974\n",
      "Epoch 153 Batch 2100 Loss 2.1286 Accuracy 0.9974\n",
      "Epoch 153 Batch 2150 Loss 2.1306 Accuracy 0.9974\n",
      "Epoch 153 Batch 2200 Loss 2.1331 Accuracy 0.9974\n",
      "Epoch 153 Batch 2250 Loss 2.1344 Accuracy 0.9974\n",
      "Epoch 153 Batch 2300 Loss 2.1323 Accuracy 0.9974\n",
      "Epoch 153 Batch 2350 Loss 2.1317 Accuracy 0.9974\n",
      "Epoch 153 Batch 2400 Loss 2.1332 Accuracy 0.9974\n",
      "Epoch 153 Batch 2450 Loss 2.1342 Accuracy 0.9974\n",
      "Epoch 153 Batch 2500 Loss 2.1356 Accuracy 0.9974\n",
      "Epoch 153 Batch 2550 Loss 2.1343 Accuracy 0.9974\n",
      "Epoch 153 Batch 2600 Loss 2.1323 Accuracy 0.9974\n",
      "Epoch 153 Batch 2650 Loss 2.1309 Accuracy 0.9974\n",
      "Epoch 153 Loss 2.1322 Accuracy 0.9974\n",
      "Time taken for 1 epoch: 194.57310676574707 secs\n",
      "\n",
      "Epoch 154 Batch 0 Loss 1.7240 Accuracy 0.9978\n",
      "Epoch 154 Batch 50 Loss 2.1439 Accuracy 0.9974\n",
      "Epoch 154 Batch 100 Loss 2.1451 Accuracy 0.9974\n",
      "Epoch 154 Batch 150 Loss 2.1711 Accuracy 0.9973\n",
      "Epoch 154 Batch 200 Loss 2.1006 Accuracy 0.9974\n",
      "Epoch 154 Batch 250 Loss 2.0923 Accuracy 0.9975\n",
      "Epoch 154 Batch 300 Loss 2.1006 Accuracy 0.9974\n",
      "Epoch 154 Batch 350 Loss 2.1117 Accuracy 0.9974\n",
      "Epoch 154 Batch 400 Loss 2.1121 Accuracy 0.9974\n",
      "Epoch 154 Batch 450 Loss 2.1372 Accuracy 0.9974\n",
      "Epoch 154 Batch 500 Loss 2.1296 Accuracy 0.9974\n",
      "Epoch 154 Batch 550 Loss 2.1391 Accuracy 0.9974\n",
      "Epoch 154 Batch 600 Loss 2.1487 Accuracy 0.9974\n",
      "Epoch 154 Batch 650 Loss 2.1484 Accuracy 0.9974\n",
      "Epoch 154 Batch 700 Loss 2.1476 Accuracy 0.9974\n",
      "Epoch 154 Batch 750 Loss 2.1494 Accuracy 0.9974\n",
      "Epoch 154 Batch 800 Loss 2.1390 Accuracy 0.9974\n",
      "Epoch 154 Batch 850 Loss 2.1448 Accuracy 0.9974\n",
      "Epoch 154 Batch 900 Loss 2.1469 Accuracy 0.9974\n",
      "Epoch 154 Batch 950 Loss 2.1470 Accuracy 0.9974\n",
      "Epoch 154 Batch 1000 Loss 2.1454 Accuracy 0.9974\n",
      "Epoch 154 Batch 1050 Loss 2.1368 Accuracy 0.9974\n",
      "Epoch 154 Batch 1100 Loss 2.1349 Accuracy 0.9974\n",
      "Epoch 154 Batch 1150 Loss 2.1286 Accuracy 0.9974\n",
      "Epoch 154 Batch 1200 Loss 2.1348 Accuracy 0.9974\n",
      "Epoch 154 Batch 1250 Loss 2.1300 Accuracy 0.9974\n",
      "Epoch 154 Batch 1300 Loss 2.1310 Accuracy 0.9974\n",
      "Epoch 154 Batch 1350 Loss 2.1276 Accuracy 0.9974\n",
      "Epoch 154 Batch 1400 Loss 2.1314 Accuracy 0.9974\n",
      "Epoch 154 Batch 1450 Loss 2.1273 Accuracy 0.9974\n",
      "Epoch 154 Batch 1500 Loss 2.1265 Accuracy 0.9974\n",
      "Epoch 154 Batch 1550 Loss 2.1288 Accuracy 0.9974\n",
      "Epoch 154 Batch 1600 Loss 2.1298 Accuracy 0.9974\n",
      "Epoch 154 Batch 1650 Loss 2.1317 Accuracy 0.9974\n",
      "Epoch 154 Batch 1700 Loss 2.1330 Accuracy 0.9974\n",
      "Epoch 154 Batch 1750 Loss 2.1304 Accuracy 0.9974\n",
      "Epoch 154 Batch 1800 Loss 2.1314 Accuracy 0.9974\n",
      "Epoch 154 Batch 1850 Loss 2.1264 Accuracy 0.9974\n",
      "Epoch 154 Batch 1900 Loss 2.1216 Accuracy 0.9974\n",
      "Epoch 154 Batch 1950 Loss 2.1147 Accuracy 0.9974\n",
      "Epoch 154 Batch 2000 Loss 2.1210 Accuracy 0.9974\n",
      "Epoch 154 Batch 2050 Loss 2.1245 Accuracy 0.9974\n",
      "Epoch 154 Batch 2100 Loss 2.1238 Accuracy 0.9974\n",
      "Epoch 154 Batch 2150 Loss 2.1261 Accuracy 0.9974\n",
      "Epoch 154 Batch 2200 Loss 2.1282 Accuracy 0.9974\n",
      "Epoch 154 Batch 2250 Loss 2.1294 Accuracy 0.9974\n",
      "Epoch 154 Batch 2300 Loss 2.1260 Accuracy 0.9974\n",
      "Epoch 154 Batch 2350 Loss 2.1267 Accuracy 0.9974\n",
      "Epoch 154 Batch 2400 Loss 2.1279 Accuracy 0.9974\n",
      "Epoch 154 Batch 2450 Loss 2.1289 Accuracy 0.9974\n",
      "Epoch 154 Batch 2500 Loss 2.1317 Accuracy 0.9974\n",
      "Epoch 154 Batch 2550 Loss 2.1304 Accuracy 0.9974\n",
      "Epoch 154 Batch 2600 Loss 2.1276 Accuracy 0.9974\n",
      "Epoch 154 Batch 2650 Loss 2.1260 Accuracy 0.9974\n",
      "Epoch 154 Loss 2.1274 Accuracy 0.9974\n",
      "Time taken for 1 epoch: 194.84025835990906 secs\n",
      "\n",
      "Epoch 155 Batch 0 Loss 1.3649 Accuracy 0.9984\n",
      "Epoch 155 Batch 50 Loss 2.1937 Accuracy 0.9973\n",
      "Epoch 155 Batch 100 Loss 2.1639 Accuracy 0.9974\n",
      "Epoch 155 Batch 150 Loss 2.1653 Accuracy 0.9974\n",
      "Epoch 155 Batch 200 Loss 2.1140 Accuracy 0.9974\n",
      "Epoch 155 Batch 250 Loss 2.1024 Accuracy 0.9974\n",
      "Epoch 155 Batch 300 Loss 2.1099 Accuracy 0.9974\n",
      "Epoch 155 Batch 350 Loss 2.1135 Accuracy 0.9974\n",
      "Epoch 155 Batch 400 Loss 2.1069 Accuracy 0.9974\n",
      "Epoch 155 Batch 450 Loss 2.1330 Accuracy 0.9974\n",
      "Epoch 155 Batch 500 Loss 2.1224 Accuracy 0.9974\n",
      "Epoch 155 Batch 550 Loss 2.1306 Accuracy 0.9974\n",
      "Epoch 155 Batch 600 Loss 2.1445 Accuracy 0.9974\n",
      "Epoch 155 Batch 650 Loss 2.1449 Accuracy 0.9974\n",
      "Epoch 155 Batch 700 Loss 2.1422 Accuracy 0.9974\n",
      "Epoch 155 Batch 750 Loss 2.1405 Accuracy 0.9974\n",
      "Epoch 155 Batch 800 Loss 2.1287 Accuracy 0.9974\n",
      "Epoch 155 Batch 850 Loss 2.1339 Accuracy 0.9974\n",
      "Epoch 155 Batch 900 Loss 2.1354 Accuracy 0.9974\n",
      "Epoch 155 Batch 950 Loss 2.1384 Accuracy 0.9974\n",
      "Epoch 155 Batch 1000 Loss 2.1379 Accuracy 0.9974\n",
      "Epoch 155 Batch 1050 Loss 2.1276 Accuracy 0.9974\n",
      "Epoch 155 Batch 1100 Loss 2.1253 Accuracy 0.9974\n",
      "Epoch 155 Batch 1150 Loss 2.1182 Accuracy 0.9974\n",
      "Epoch 155 Batch 1200 Loss 2.1276 Accuracy 0.9974\n",
      "Epoch 155 Batch 1250 Loss 2.1229 Accuracy 0.9974\n",
      "Epoch 155 Batch 1300 Loss 2.1244 Accuracy 0.9974\n",
      "Epoch 155 Batch 1350 Loss 2.1207 Accuracy 0.9974\n",
      "Epoch 155 Batch 1400 Loss 2.1222 Accuracy 0.9974\n",
      "Epoch 155 Batch 1450 Loss 2.1182 Accuracy 0.9974\n",
      "Epoch 155 Batch 1500 Loss 2.1189 Accuracy 0.9974\n",
      "Epoch 155 Batch 1550 Loss 2.1219 Accuracy 0.9974\n",
      "Epoch 155 Batch 1600 Loss 2.1230 Accuracy 0.9974\n",
      "Epoch 155 Batch 1650 Loss 2.1229 Accuracy 0.9974\n",
      "Epoch 155 Batch 1700 Loss 2.1252 Accuracy 0.9974\n",
      "Epoch 155 Batch 1750 Loss 2.1218 Accuracy 0.9974\n",
      "Epoch 155 Batch 1800 Loss 2.1226 Accuracy 0.9974\n",
      "Epoch 155 Batch 1850 Loss 2.1176 Accuracy 0.9974\n",
      "Epoch 155 Batch 1900 Loss 2.1159 Accuracy 0.9974\n",
      "Epoch 155 Batch 1950 Loss 2.1098 Accuracy 0.9974\n",
      "Epoch 155 Batch 2000 Loss 2.1135 Accuracy 0.9974\n",
      "Epoch 155 Batch 2050 Loss 2.1183 Accuracy 0.9974\n",
      "Epoch 155 Batch 2100 Loss 2.1173 Accuracy 0.9974\n",
      "Epoch 155 Batch 2150 Loss 2.1189 Accuracy 0.9974\n",
      "Epoch 155 Batch 2200 Loss 2.1218 Accuracy 0.9974\n",
      "Epoch 155 Batch 2250 Loss 2.1227 Accuracy 0.9974\n",
      "Epoch 155 Batch 2300 Loss 2.1200 Accuracy 0.9974\n",
      "Epoch 155 Batch 2350 Loss 2.1190 Accuracy 0.9974\n",
      "Epoch 155 Batch 2400 Loss 2.1215 Accuracy 0.9974\n",
      "Epoch 155 Batch 2450 Loss 2.1221 Accuracy 0.9974\n",
      "Epoch 155 Batch 2500 Loss 2.1233 Accuracy 0.9974\n",
      "Epoch 155 Batch 2550 Loss 2.1221 Accuracy 0.9974\n",
      "Epoch 155 Batch 2600 Loss 2.1204 Accuracy 0.9974\n",
      "Epoch 155 Batch 2650 Loss 2.1196 Accuracy 0.9974\n",
      "Saving checkpoint for epoch 155 at ./checkpoints/train\\ckpt-32\n",
      "Epoch 155 Loss 2.1215 Accuracy 0.9974\n",
      "Time taken for 1 epoch: 194.9597225189209 secs\n",
      "\n",
      "Epoch 156 Batch 0 Loss 1.4087 Accuracy 0.9982\n",
      "Epoch 156 Batch 50 Loss 2.1209 Accuracy 0.9974\n",
      "Epoch 156 Batch 100 Loss 2.1450 Accuracy 0.9974\n",
      "Epoch 156 Batch 150 Loss 2.1693 Accuracy 0.9973\n",
      "Epoch 156 Batch 200 Loss 2.1105 Accuracy 0.9974\n",
      "Epoch 156 Batch 250 Loss 2.0977 Accuracy 0.9974\n",
      "Epoch 156 Batch 300 Loss 2.0966 Accuracy 0.9974\n",
      "Epoch 156 Batch 350 Loss 2.0987 Accuracy 0.9974\n",
      "Epoch 156 Batch 400 Loss 2.0952 Accuracy 0.9974\n",
      "Epoch 156 Batch 450 Loss 2.1258 Accuracy 0.9974\n",
      "Epoch 156 Batch 500 Loss 2.1159 Accuracy 0.9974\n",
      "Epoch 156 Batch 550 Loss 2.1229 Accuracy 0.9974\n",
      "Epoch 156 Batch 600 Loss 2.1356 Accuracy 0.9974\n",
      "Epoch 156 Batch 650 Loss 2.1382 Accuracy 0.9974\n",
      "Epoch 156 Batch 700 Loss 2.1363 Accuracy 0.9974\n",
      "Epoch 156 Batch 750 Loss 2.1342 Accuracy 0.9974\n",
      "Epoch 156 Batch 800 Loss 2.1259 Accuracy 0.9974\n",
      "Epoch 156 Batch 850 Loss 2.1286 Accuracy 0.9974\n",
      "Epoch 156 Batch 900 Loss 2.1260 Accuracy 0.9974\n",
      "Epoch 156 Batch 950 Loss 2.1277 Accuracy 0.9974\n",
      "Epoch 156 Batch 1000 Loss 2.1226 Accuracy 0.9974\n",
      "Epoch 156 Batch 1050 Loss 2.1140 Accuracy 0.9974\n",
      "Epoch 156 Batch 1100 Loss 2.1143 Accuracy 0.9974\n",
      "Epoch 156 Batch 1150 Loss 2.1079 Accuracy 0.9974\n",
      "Epoch 156 Batch 1200 Loss 2.1170 Accuracy 0.9974\n",
      "Epoch 156 Batch 1250 Loss 2.1138 Accuracy 0.9974\n",
      "Epoch 156 Batch 1300 Loss 2.1147 Accuracy 0.9974\n",
      "Epoch 156 Batch 1350 Loss 2.1112 Accuracy 0.9974\n",
      "Epoch 156 Batch 1400 Loss 2.1136 Accuracy 0.9974\n",
      "Epoch 156 Batch 1450 Loss 2.1105 Accuracy 0.9974\n",
      "Epoch 156 Batch 1500 Loss 2.1080 Accuracy 0.9974\n",
      "Epoch 156 Batch 1550 Loss 2.1097 Accuracy 0.9974\n",
      "Epoch 156 Batch 1600 Loss 2.1106 Accuracy 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156 Batch 1650 Loss 2.1112 Accuracy 0.9974\n",
      "Epoch 156 Batch 1700 Loss 2.1141 Accuracy 0.9974\n",
      "Epoch 156 Batch 1750 Loss 2.1113 Accuracy 0.9974\n",
      "Epoch 156 Batch 1800 Loss 2.1124 Accuracy 0.9974\n",
      "Epoch 156 Batch 1850 Loss 2.1077 Accuracy 0.9974\n",
      "Epoch 156 Batch 1900 Loss 2.1045 Accuracy 0.9974\n",
      "Epoch 156 Batch 1950 Loss 2.1001 Accuracy 0.9974\n",
      "Epoch 156 Batch 2000 Loss 2.1027 Accuracy 0.9974\n",
      "Epoch 156 Batch 2050 Loss 2.1071 Accuracy 0.9974\n",
      "Epoch 156 Batch 2100 Loss 2.1074 Accuracy 0.9974\n",
      "Epoch 156 Batch 2150 Loss 2.1100 Accuracy 0.9974\n",
      "Epoch 156 Batch 2200 Loss 2.1146 Accuracy 0.9974\n",
      "Epoch 156 Batch 2250 Loss 2.1165 Accuracy 0.9974\n",
      "Epoch 156 Batch 2300 Loss 2.1151 Accuracy 0.9974\n",
      "Epoch 156 Batch 2350 Loss 2.1147 Accuracy 0.9974\n",
      "Epoch 156 Batch 2400 Loss 2.1158 Accuracy 0.9974\n",
      "Epoch 156 Batch 2450 Loss 2.1174 Accuracy 0.9974\n",
      "Epoch 156 Batch 2500 Loss 2.1191 Accuracy 0.9974\n",
      "Epoch 156 Batch 2550 Loss 2.1176 Accuracy 0.9974\n",
      "Epoch 156 Batch 2600 Loss 2.1155 Accuracy 0.9974\n",
      "Epoch 156 Batch 2650 Loss 2.1149 Accuracy 0.9974\n",
      "Epoch 156 Loss 2.1156 Accuracy 0.9974\n",
      "Time taken for 1 epoch: 195.21666431427002 secs\n",
      "\n",
      "Epoch 157 Batch 0 Loss 1.5152 Accuracy 0.9979\n",
      "Epoch 157 Batch 50 Loss 2.1141 Accuracy 0.9974\n",
      "Epoch 157 Batch 100 Loss 2.1408 Accuracy 0.9974\n",
      "Epoch 157 Batch 150 Loss 2.1727 Accuracy 0.9973\n",
      "Epoch 157 Batch 200 Loss 2.1211 Accuracy 0.9974\n",
      "Epoch 157 Batch 250 Loss 2.1108 Accuracy 0.9974\n",
      "Epoch 157 Batch 300 Loss 2.1167 Accuracy 0.9974\n",
      "Epoch 157 Batch 350 Loss 2.1089 Accuracy 0.9975\n",
      "Epoch 157 Batch 400 Loss 2.1082 Accuracy 0.9975\n",
      "Epoch 157 Batch 450 Loss 2.1329 Accuracy 0.9974\n",
      "Epoch 157 Batch 500 Loss 2.1280 Accuracy 0.9974\n",
      "Epoch 157 Batch 550 Loss 2.1366 Accuracy 0.9974\n",
      "Epoch 157 Batch 600 Loss 2.1429 Accuracy 0.9974\n",
      "Epoch 157 Batch 650 Loss 2.1375 Accuracy 0.9974\n",
      "Epoch 157 Batch 700 Loss 2.1355 Accuracy 0.9974\n",
      "Epoch 157 Batch 750 Loss 2.1356 Accuracy 0.9974\n",
      "Epoch 157 Batch 800 Loss 2.1247 Accuracy 0.9974\n",
      "Epoch 157 Batch 850 Loss 2.1247 Accuracy 0.9974\n",
      "Epoch 157 Batch 900 Loss 2.1243 Accuracy 0.9974\n",
      "Epoch 157 Batch 950 Loss 2.1251 Accuracy 0.9974\n",
      "Epoch 157 Batch 1000 Loss 2.1223 Accuracy 0.9974\n",
      "Epoch 157 Batch 1050 Loss 2.1153 Accuracy 0.9974\n",
      "Epoch 157 Batch 1100 Loss 2.1142 Accuracy 0.9974\n",
      "Epoch 157 Batch 1150 Loss 2.1079 Accuracy 0.9974\n",
      "Epoch 157 Batch 1200 Loss 2.1169 Accuracy 0.9974\n",
      "Epoch 157 Batch 1250 Loss 2.1119 Accuracy 0.9974\n",
      "Epoch 157 Batch 1300 Loss 2.1097 Accuracy 0.9974\n",
      "Epoch 157 Batch 1350 Loss 2.1069 Accuracy 0.9974\n",
      "Epoch 157 Batch 1400 Loss 2.1072 Accuracy 0.9974\n",
      "Epoch 157 Batch 1450 Loss 2.1028 Accuracy 0.9975\n",
      "Epoch 157 Batch 1500 Loss 2.1026 Accuracy 0.9975\n",
      "Epoch 157 Batch 1550 Loss 2.1064 Accuracy 0.9975\n",
      "Epoch 157 Batch 1600 Loss 2.1075 Accuracy 0.9974\n",
      "Epoch 157 Batch 1650 Loss 2.1081 Accuracy 0.9974\n",
      "Epoch 157 Batch 1700 Loss 2.1082 Accuracy 0.9974\n",
      "Epoch 157 Batch 1750 Loss 2.1046 Accuracy 0.9975\n",
      "Epoch 157 Batch 1800 Loss 2.1057 Accuracy 0.9975\n",
      "Epoch 157 Batch 1850 Loss 2.1000 Accuracy 0.9975\n",
      "Epoch 157 Batch 1900 Loss 2.0966 Accuracy 0.9975\n",
      "Epoch 157 Batch 1950 Loss 2.0912 Accuracy 0.9975\n",
      "Epoch 157 Batch 2000 Loss 2.0959 Accuracy 0.9975\n",
      "Epoch 157 Batch 2050 Loss 2.1005 Accuracy 0.9975\n",
      "Epoch 157 Batch 2100 Loss 2.0991 Accuracy 0.9975\n",
      "Epoch 157 Batch 2150 Loss 2.1025 Accuracy 0.9975\n",
      "Epoch 157 Batch 2200 Loss 2.1050 Accuracy 0.9975\n",
      "Epoch 157 Batch 2250 Loss 2.1067 Accuracy 0.9975\n",
      "Epoch 157 Batch 2300 Loss 2.1045 Accuracy 0.9975\n",
      "Epoch 157 Batch 2350 Loss 2.1031 Accuracy 0.9975\n",
      "Epoch 157 Batch 2400 Loss 2.1052 Accuracy 0.9975\n",
      "Epoch 157 Batch 2450 Loss 2.1075 Accuracy 0.9974\n",
      "Epoch 157 Batch 2500 Loss 2.1094 Accuracy 0.9974\n",
      "Epoch 157 Batch 2550 Loss 2.1099 Accuracy 0.9974\n",
      "Epoch 157 Batch 2600 Loss 2.1087 Accuracy 0.9974\n",
      "Epoch 157 Batch 2650 Loss 2.1064 Accuracy 0.9974\n",
      "Epoch 157 Loss 2.1085 Accuracy 0.9974\n",
      "Time taken for 1 epoch: 195.4735026359558 secs\n",
      "\n",
      "Epoch 158 Batch 0 Loss 1.4613 Accuracy 0.9983\n",
      "Epoch 158 Batch 50 Loss 2.1478 Accuracy 0.9973\n",
      "Epoch 158 Batch 100 Loss 2.1469 Accuracy 0.9974\n",
      "Epoch 158 Batch 150 Loss 2.1648 Accuracy 0.9974\n",
      "Epoch 158 Batch 200 Loss 2.1119 Accuracy 0.9974\n",
      "Epoch 158 Batch 250 Loss 2.0916 Accuracy 0.9975\n",
      "Epoch 158 Batch 300 Loss 2.0886 Accuracy 0.9975\n",
      "Epoch 158 Batch 350 Loss 2.0831 Accuracy 0.9975\n",
      "Epoch 158 Batch 400 Loss 2.0844 Accuracy 0.9975\n",
      "Epoch 158 Batch 450 Loss 2.1135 Accuracy 0.9974\n",
      "Epoch 158 Batch 500 Loss 2.1050 Accuracy 0.9974\n",
      "Epoch 158 Batch 550 Loss 2.1161 Accuracy 0.9974\n",
      "Epoch 158 Batch 600 Loss 2.1283 Accuracy 0.9974\n",
      "Epoch 158 Batch 650 Loss 2.1232 Accuracy 0.9974\n",
      "Epoch 158 Batch 700 Loss 2.1220 Accuracy 0.9974\n",
      "Epoch 158 Batch 750 Loss 2.1248 Accuracy 0.9974\n",
      "Epoch 158 Batch 800 Loss 2.1128 Accuracy 0.9974\n",
      "Epoch 158 Batch 850 Loss 2.1181 Accuracy 0.9974\n",
      "Epoch 158 Batch 900 Loss 2.1199 Accuracy 0.9974\n",
      "Epoch 158 Batch 950 Loss 2.1217 Accuracy 0.9974\n",
      "Epoch 158 Batch 1000 Loss 2.1170 Accuracy 0.9974\n",
      "Epoch 158 Batch 1050 Loss 2.1082 Accuracy 0.9974\n",
      "Epoch 158 Batch 1100 Loss 2.1077 Accuracy 0.9974\n",
      "Epoch 158 Batch 1150 Loss 2.1021 Accuracy 0.9974\n",
      "Epoch 158 Batch 1200 Loss 2.1120 Accuracy 0.9974\n",
      "Epoch 158 Batch 1250 Loss 2.1090 Accuracy 0.9974\n",
      "Epoch 158 Batch 1300 Loss 2.1087 Accuracy 0.9974\n",
      "Epoch 158 Batch 1350 Loss 2.1056 Accuracy 0.9974\n",
      "Epoch 158 Batch 1400 Loss 2.1089 Accuracy 0.9974\n",
      "Epoch 158 Batch 1450 Loss 2.1047 Accuracy 0.9974\n",
      "Epoch 158 Batch 1500 Loss 2.1037 Accuracy 0.9974\n",
      "Epoch 158 Batch 1550 Loss 2.1058 Accuracy 0.9974\n",
      "Epoch 158 Batch 1600 Loss 2.1071 Accuracy 0.9974\n",
      "Epoch 158 Batch 1650 Loss 2.1080 Accuracy 0.9974\n",
      "Epoch 158 Batch 1700 Loss 2.1112 Accuracy 0.9974\n",
      "Epoch 158 Batch 1750 Loss 2.1076 Accuracy 0.9974\n",
      "Epoch 158 Batch 1800 Loss 2.1108 Accuracy 0.9974\n",
      "Epoch 158 Batch 1850 Loss 2.1052 Accuracy 0.9974\n",
      "Epoch 158 Batch 1900 Loss 2.1014 Accuracy 0.9974\n",
      "Epoch 158 Batch 1950 Loss 2.0948 Accuracy 0.9975\n",
      "Epoch 158 Batch 2000 Loss 2.0990 Accuracy 0.9975\n",
      "Epoch 158 Batch 2050 Loss 2.1044 Accuracy 0.9974\n",
      "Epoch 158 Batch 2100 Loss 2.1024 Accuracy 0.9974\n",
      "Epoch 158 Batch 2150 Loss 2.1037 Accuracy 0.9974\n",
      "Epoch 158 Batch 2200 Loss 2.1071 Accuracy 0.9974\n",
      "Epoch 158 Batch 2250 Loss 2.1086 Accuracy 0.9974\n",
      "Epoch 158 Batch 2300 Loss 2.1058 Accuracy 0.9974\n",
      "Epoch 158 Batch 2350 Loss 2.1051 Accuracy 0.9974\n",
      "Epoch 158 Batch 2400 Loss 2.1060 Accuracy 0.9974\n",
      "Epoch 158 Batch 2450 Loss 2.1083 Accuracy 0.9974\n",
      "Epoch 158 Batch 2500 Loss 2.1095 Accuracy 0.9974\n",
      "Epoch 158 Batch 2550 Loss 2.1076 Accuracy 0.9974\n",
      "Epoch 158 Batch 2600 Loss 2.1061 Accuracy 0.9974\n",
      "Epoch 158 Batch 2650 Loss 2.1044 Accuracy 0.9974\n",
      "Epoch 158 Loss 2.1067 Accuracy 0.9974\n",
      "Time taken for 1 epoch: 195.2235722541809 secs\n",
      "\n",
      "Epoch 159 Batch 0 Loss 1.5702 Accuracy 0.9980\n",
      "Epoch 159 Batch 50 Loss 2.1732 Accuracy 0.9974\n",
      "Epoch 159 Batch 100 Loss 2.1514 Accuracy 0.9974\n",
      "Epoch 159 Batch 150 Loss 2.1627 Accuracy 0.9974\n",
      "Epoch 159 Batch 200 Loss 2.1065 Accuracy 0.9975\n",
      "Epoch 159 Batch 250 Loss 2.1044 Accuracy 0.9975\n",
      "Epoch 159 Batch 300 Loss 2.1033 Accuracy 0.9975\n",
      "Epoch 159 Batch 350 Loss 2.1010 Accuracy 0.9975\n",
      "Epoch 159 Batch 400 Loss 2.1000 Accuracy 0.9975\n",
      "Epoch 159 Batch 450 Loss 2.1189 Accuracy 0.9974\n",
      "Epoch 159 Batch 500 Loss 2.1103 Accuracy 0.9974\n",
      "Epoch 159 Batch 550 Loss 2.1238 Accuracy 0.9974\n",
      "Epoch 159 Batch 600 Loss 2.1336 Accuracy 0.9974\n",
      "Epoch 159 Batch 650 Loss 2.1323 Accuracy 0.9974\n",
      "Epoch 159 Batch 700 Loss 2.1293 Accuracy 0.9974\n",
      "Epoch 159 Batch 750 Loss 2.1273 Accuracy 0.9974\n",
      "Epoch 159 Batch 800 Loss 2.1176 Accuracy 0.9974\n",
      "Epoch 159 Batch 850 Loss 2.1220 Accuracy 0.9974\n",
      "Epoch 159 Batch 900 Loss 2.1214 Accuracy 0.9974\n",
      "Epoch 159 Batch 950 Loss 2.1245 Accuracy 0.9974\n",
      "Epoch 159 Batch 1000 Loss 2.1223 Accuracy 0.9974\n",
      "Epoch 159 Batch 1050 Loss 2.1122 Accuracy 0.9974\n",
      "Epoch 159 Batch 1100 Loss 2.1111 Accuracy 0.9974\n",
      "Epoch 159 Batch 1150 Loss 2.1006 Accuracy 0.9975\n",
      "Epoch 159 Batch 1200 Loss 2.1076 Accuracy 0.9974\n",
      "Epoch 159 Batch 1250 Loss 2.1012 Accuracy 0.9975\n",
      "Epoch 159 Batch 1300 Loss 2.1021 Accuracy 0.9975\n",
      "Epoch 159 Batch 1350 Loss 2.1010 Accuracy 0.9975\n",
      "Epoch 159 Batch 1400 Loss 2.1033 Accuracy 0.9974\n",
      "Epoch 159 Batch 1450 Loss 2.0996 Accuracy 0.9975\n",
      "Epoch 159 Batch 1500 Loss 2.0981 Accuracy 0.9975\n",
      "Epoch 159 Batch 1550 Loss 2.0990 Accuracy 0.9975\n",
      "Epoch 159 Batch 1600 Loss 2.0999 Accuracy 0.9975\n",
      "Epoch 159 Batch 1650 Loss 2.1006 Accuracy 0.9975\n",
      "Epoch 159 Batch 1700 Loss 2.1030 Accuracy 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159 Batch 1750 Loss 2.0986 Accuracy 0.9975\n",
      "Epoch 159 Batch 1800 Loss 2.1007 Accuracy 0.9975\n",
      "Epoch 159 Batch 1850 Loss 2.0958 Accuracy 0.9975\n",
      "Epoch 159 Batch 1900 Loss 2.0933 Accuracy 0.9975\n",
      "Epoch 159 Batch 1950 Loss 2.0878 Accuracy 0.9975\n",
      "Epoch 159 Batch 2000 Loss 2.0922 Accuracy 0.9975\n",
      "Epoch 159 Batch 2050 Loss 2.0968 Accuracy 0.9975\n",
      "Epoch 159 Batch 2100 Loss 2.0950 Accuracy 0.9975\n",
      "Epoch 159 Batch 2150 Loss 2.0959 Accuracy 0.9975\n",
      "Epoch 159 Batch 2200 Loss 2.1001 Accuracy 0.9975\n",
      "Epoch 159 Batch 2250 Loss 2.1026 Accuracy 0.9974\n",
      "Epoch 159 Batch 2300 Loss 2.1000 Accuracy 0.9975\n",
      "Epoch 159 Batch 2350 Loss 2.1000 Accuracy 0.9975\n",
      "Epoch 159 Batch 2400 Loss 2.1009 Accuracy 0.9975\n",
      "Epoch 159 Batch 2450 Loss 2.1018 Accuracy 0.9975\n",
      "Epoch 159 Batch 2500 Loss 2.1041 Accuracy 0.9974\n",
      "Epoch 159 Batch 2550 Loss 2.1031 Accuracy 0.9974\n",
      "Epoch 159 Batch 2600 Loss 2.1015 Accuracy 0.9975\n",
      "Epoch 159 Batch 2650 Loss 2.0999 Accuracy 0.9975\n",
      "Epoch 159 Loss 2.1011 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 195.70988869667053 secs\n",
      "\n",
      "Epoch 160 Batch 0 Loss 1.4040 Accuracy 0.9984\n",
      "Epoch 160 Batch 50 Loss 2.1629 Accuracy 0.9974\n",
      "Epoch 160 Batch 100 Loss 2.1599 Accuracy 0.9974\n",
      "Epoch 160 Batch 150 Loss 2.1711 Accuracy 0.9974\n",
      "Epoch 160 Batch 200 Loss 2.1148 Accuracy 0.9974\n",
      "Epoch 160 Batch 250 Loss 2.0978 Accuracy 0.9975\n",
      "Epoch 160 Batch 300 Loss 2.0991 Accuracy 0.9974\n",
      "Epoch 160 Batch 350 Loss 2.0923 Accuracy 0.9974\n",
      "Epoch 160 Batch 400 Loss 2.0906 Accuracy 0.9975\n",
      "Epoch 160 Batch 450 Loss 2.1181 Accuracy 0.9974\n",
      "Epoch 160 Batch 500 Loss 2.1069 Accuracy 0.9974\n",
      "Epoch 160 Batch 550 Loss 2.1162 Accuracy 0.9974\n",
      "Epoch 160 Batch 600 Loss 2.1286 Accuracy 0.9974\n",
      "Epoch 160 Batch 650 Loss 2.1228 Accuracy 0.9974\n",
      "Epoch 160 Batch 700 Loss 2.1198 Accuracy 0.9974\n",
      "Epoch 160 Batch 750 Loss 2.1242 Accuracy 0.9974\n",
      "Epoch 160 Batch 800 Loss 2.1150 Accuracy 0.9974\n",
      "Epoch 160 Batch 850 Loss 2.1180 Accuracy 0.9974\n",
      "Epoch 160 Batch 900 Loss 2.1207 Accuracy 0.9974\n",
      "Epoch 160 Batch 950 Loss 2.1266 Accuracy 0.9974\n",
      "Epoch 160 Batch 1000 Loss 2.1249 Accuracy 0.9974\n",
      "Epoch 160 Batch 1050 Loss 2.1170 Accuracy 0.9974\n",
      "Epoch 160 Batch 1100 Loss 2.1147 Accuracy 0.9974\n",
      "Epoch 160 Batch 1150 Loss 2.1071 Accuracy 0.9974\n",
      "Epoch 160 Batch 1200 Loss 2.1164 Accuracy 0.9974\n",
      "Epoch 160 Batch 1250 Loss 2.1109 Accuracy 0.9974\n",
      "Epoch 160 Batch 1300 Loss 2.1135 Accuracy 0.9974\n",
      "Epoch 160 Batch 1350 Loss 2.1080 Accuracy 0.9975\n",
      "Epoch 160 Batch 1400 Loss 2.1088 Accuracy 0.9975\n",
      "Epoch 160 Batch 1450 Loss 2.1041 Accuracy 0.9975\n",
      "Epoch 160 Batch 1500 Loss 2.1017 Accuracy 0.9975\n",
      "Epoch 160 Batch 1550 Loss 2.1035 Accuracy 0.9975\n",
      "Epoch 160 Batch 1600 Loss 2.1039 Accuracy 0.9975\n",
      "Epoch 160 Batch 1650 Loss 2.1032 Accuracy 0.9975\n",
      "Epoch 160 Batch 1700 Loss 2.1049 Accuracy 0.9975\n",
      "Epoch 160 Batch 1750 Loss 2.1016 Accuracy 0.9975\n",
      "Epoch 160 Batch 1800 Loss 2.1024 Accuracy 0.9975\n",
      "Epoch 160 Batch 1850 Loss 2.0965 Accuracy 0.9975\n",
      "Epoch 160 Batch 1900 Loss 2.0935 Accuracy 0.9975\n",
      "Epoch 160 Batch 1950 Loss 2.0867 Accuracy 0.9975\n",
      "Epoch 160 Batch 2000 Loss 2.0912 Accuracy 0.9975\n",
      "Epoch 160 Batch 2050 Loss 2.0964 Accuracy 0.9975\n",
      "Epoch 160 Batch 2100 Loss 2.0959 Accuracy 0.9975\n",
      "Epoch 160 Batch 2150 Loss 2.0972 Accuracy 0.9975\n",
      "Epoch 160 Batch 2200 Loss 2.1000 Accuracy 0.9975\n",
      "Epoch 160 Batch 2250 Loss 2.1021 Accuracy 0.9975\n",
      "Epoch 160 Batch 2300 Loss 2.1005 Accuracy 0.9975\n",
      "Epoch 160 Batch 2350 Loss 2.1009 Accuracy 0.9975\n",
      "Epoch 160 Batch 2400 Loss 2.1025 Accuracy 0.9975\n",
      "Epoch 160 Batch 2450 Loss 2.1040 Accuracy 0.9975\n",
      "Epoch 160 Batch 2500 Loss 2.1060 Accuracy 0.9975\n",
      "Epoch 160 Batch 2550 Loss 2.1051 Accuracy 0.9975\n",
      "Epoch 160 Batch 2600 Loss 2.1029 Accuracy 0.9975\n",
      "Epoch 160 Batch 2650 Loss 2.1019 Accuracy 0.9975\n",
      "Saving checkpoint for epoch 160 at ./checkpoints/train\\ckpt-33\n",
      "Epoch 160 Loss 2.1028 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 196.6833896636963 secs\n",
      "\n",
      "Epoch 161 Batch 0 Loss 1.5974 Accuracy 0.9981\n",
      "Epoch 161 Batch 50 Loss 2.1357 Accuracy 0.9974\n",
      "Epoch 161 Batch 100 Loss 2.1224 Accuracy 0.9974\n",
      "Epoch 161 Batch 150 Loss 2.1414 Accuracy 0.9974\n",
      "Epoch 161 Batch 200 Loss 2.0919 Accuracy 0.9975\n",
      "Epoch 161 Batch 250 Loss 2.0831 Accuracy 0.9975\n",
      "Epoch 161 Batch 300 Loss 2.0781 Accuracy 0.9975\n",
      "Epoch 161 Batch 350 Loss 2.0771 Accuracy 0.9975\n",
      "Epoch 161 Batch 400 Loss 2.0706 Accuracy 0.9975\n",
      "Epoch 161 Batch 450 Loss 2.0930 Accuracy 0.9975\n",
      "Epoch 161 Batch 500 Loss 2.0827 Accuracy 0.9975\n",
      "Epoch 161 Batch 550 Loss 2.0930 Accuracy 0.9975\n",
      "Epoch 161 Batch 600 Loss 2.1021 Accuracy 0.9974\n",
      "Epoch 161 Batch 650 Loss 2.1034 Accuracy 0.9974\n",
      "Epoch 161 Batch 700 Loss 2.1040 Accuracy 0.9974\n",
      "Epoch 161 Batch 750 Loss 2.1044 Accuracy 0.9974\n",
      "Epoch 161 Batch 800 Loss 2.0935 Accuracy 0.9975\n",
      "Epoch 161 Batch 850 Loss 2.0981 Accuracy 0.9975\n",
      "Epoch 161 Batch 900 Loss 2.0986 Accuracy 0.9975\n",
      "Epoch 161 Batch 950 Loss 2.1012 Accuracy 0.9975\n",
      "Epoch 161 Batch 1000 Loss 2.1012 Accuracy 0.9975\n",
      "Epoch 161 Batch 1050 Loss 2.0917 Accuracy 0.9975\n",
      "Epoch 161 Batch 1100 Loss 2.0902 Accuracy 0.9975\n",
      "Epoch 161 Batch 1150 Loss 2.0830 Accuracy 0.9975\n",
      "Epoch 161 Batch 1200 Loss 2.0928 Accuracy 0.9975\n",
      "Epoch 161 Batch 1250 Loss 2.0867 Accuracy 0.9975\n",
      "Epoch 161 Batch 1300 Loss 2.0887 Accuracy 0.9975\n",
      "Epoch 161 Batch 1350 Loss 2.0847 Accuracy 0.9975\n",
      "Epoch 161 Batch 1400 Loss 2.0883 Accuracy 0.9975\n",
      "Epoch 161 Batch 1450 Loss 2.0842 Accuracy 0.9975\n",
      "Epoch 161 Batch 1500 Loss 2.0847 Accuracy 0.9975\n",
      "Epoch 161 Batch 1550 Loss 2.0863 Accuracy 0.9975\n",
      "Epoch 161 Batch 1600 Loss 2.0875 Accuracy 0.9975\n",
      "Epoch 161 Batch 1650 Loss 2.0886 Accuracy 0.9975\n",
      "Epoch 161 Batch 1700 Loss 2.0905 Accuracy 0.9975\n",
      "Epoch 161 Batch 1750 Loss 2.0874 Accuracy 0.9975\n",
      "Epoch 161 Batch 1800 Loss 2.0892 Accuracy 0.9975\n",
      "Epoch 161 Batch 1850 Loss 2.0853 Accuracy 0.9975\n",
      "Epoch 161 Batch 1900 Loss 2.0815 Accuracy 0.9975\n",
      "Epoch 161 Batch 1950 Loss 2.0745 Accuracy 0.9975\n",
      "Epoch 161 Batch 2000 Loss 2.0786 Accuracy 0.9975\n",
      "Epoch 161 Batch 2050 Loss 2.0833 Accuracy 0.9975\n",
      "Epoch 161 Batch 2100 Loss 2.0818 Accuracy 0.9975\n",
      "Epoch 161 Batch 2150 Loss 2.0852 Accuracy 0.9975\n",
      "Epoch 161 Batch 2200 Loss 2.0894 Accuracy 0.9975\n",
      "Epoch 161 Batch 2250 Loss 2.0919 Accuracy 0.9975\n",
      "Epoch 161 Batch 2300 Loss 2.0902 Accuracy 0.9975\n",
      "Epoch 161 Batch 2350 Loss 2.0900 Accuracy 0.9975\n",
      "Epoch 161 Batch 2400 Loss 2.0916 Accuracy 0.9975\n",
      "Epoch 161 Batch 2450 Loss 2.0945 Accuracy 0.9975\n",
      "Epoch 161 Batch 2500 Loss 2.0965 Accuracy 0.9975\n",
      "Epoch 161 Batch 2550 Loss 2.0958 Accuracy 0.9975\n",
      "Epoch 161 Batch 2600 Loss 2.0942 Accuracy 0.9975\n",
      "Epoch 161 Batch 2650 Loss 2.0925 Accuracy 0.9975\n",
      "Epoch 161 Loss 2.0931 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 197.99335861206055 secs\n",
      "\n",
      "Epoch 162 Batch 0 Loss 1.5439 Accuracy 0.9980\n",
      "Epoch 162 Batch 50 Loss 2.1216 Accuracy 0.9974\n",
      "Epoch 162 Batch 100 Loss 2.1209 Accuracy 0.9974\n",
      "Epoch 162 Batch 150 Loss 2.1545 Accuracy 0.9974\n",
      "Epoch 162 Batch 200 Loss 2.0986 Accuracy 0.9974\n",
      "Epoch 162 Batch 250 Loss 2.0921 Accuracy 0.9975\n",
      "Epoch 162 Batch 300 Loss 2.0819 Accuracy 0.9975\n",
      "Epoch 162 Batch 350 Loss 2.0828 Accuracy 0.9975\n",
      "Epoch 162 Batch 400 Loss 2.0799 Accuracy 0.9975\n",
      "Epoch 162 Batch 450 Loss 2.1067 Accuracy 0.9974\n",
      "Epoch 162 Batch 500 Loss 2.1001 Accuracy 0.9974\n",
      "Epoch 162 Batch 550 Loss 2.1090 Accuracy 0.9974\n",
      "Epoch 162 Batch 600 Loss 2.1216 Accuracy 0.9974\n",
      "Epoch 162 Batch 650 Loss 2.1174 Accuracy 0.9974\n",
      "Epoch 162 Batch 700 Loss 2.1108 Accuracy 0.9974\n",
      "Epoch 162 Batch 750 Loss 2.1138 Accuracy 0.9974\n",
      "Epoch 162 Batch 800 Loss 2.1019 Accuracy 0.9974\n",
      "Epoch 162 Batch 850 Loss 2.1038 Accuracy 0.9974\n",
      "Epoch 162 Batch 900 Loss 2.1018 Accuracy 0.9974\n",
      "Epoch 162 Batch 950 Loss 2.1029 Accuracy 0.9974\n",
      "Epoch 162 Batch 1000 Loss 2.1020 Accuracy 0.9974\n",
      "Epoch 162 Batch 1050 Loss 2.0929 Accuracy 0.9975\n",
      "Epoch 162 Batch 1100 Loss 2.0916 Accuracy 0.9975\n",
      "Epoch 162 Batch 1150 Loss 2.0833 Accuracy 0.9975\n",
      "Epoch 162 Batch 1200 Loss 2.0933 Accuracy 0.9975\n",
      "Epoch 162 Batch 1250 Loss 2.0875 Accuracy 0.9975\n",
      "Epoch 162 Batch 1300 Loss 2.0899 Accuracy 0.9975\n",
      "Epoch 162 Batch 1350 Loss 2.0868 Accuracy 0.9975\n",
      "Epoch 162 Batch 1400 Loss 2.0904 Accuracy 0.9975\n",
      "Epoch 162 Batch 1450 Loss 2.0862 Accuracy 0.9975\n",
      "Epoch 162 Batch 1500 Loss 2.0841 Accuracy 0.9975\n",
      "Epoch 162 Batch 1550 Loss 2.0872 Accuracy 0.9975\n",
      "Epoch 162 Batch 1600 Loss 2.0889 Accuracy 0.9975\n",
      "Epoch 162 Batch 1650 Loss 2.0914 Accuracy 0.9975\n",
      "Epoch 162 Batch 1700 Loss 2.0931 Accuracy 0.9975\n",
      "Epoch 162 Batch 1750 Loss 2.0888 Accuracy 0.9975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162 Batch 1800 Loss 2.0920 Accuracy 0.9975\n",
      "Epoch 162 Batch 1850 Loss 2.0888 Accuracy 0.9975\n",
      "Epoch 162 Batch 1900 Loss 2.0870 Accuracy 0.9975\n",
      "Epoch 162 Batch 1950 Loss 2.0795 Accuracy 0.9975\n",
      "Epoch 162 Batch 2000 Loss 2.0829 Accuracy 0.9975\n",
      "Epoch 162 Batch 2050 Loss 2.0872 Accuracy 0.9975\n",
      "Epoch 162 Batch 2100 Loss 2.0870 Accuracy 0.9975\n",
      "Epoch 162 Batch 2150 Loss 2.0877 Accuracy 0.9975\n",
      "Epoch 162 Batch 2200 Loss 2.0917 Accuracy 0.9975\n",
      "Epoch 162 Batch 2250 Loss 2.0934 Accuracy 0.9975\n",
      "Epoch 162 Batch 2300 Loss 2.0923 Accuracy 0.9975\n",
      "Epoch 162 Batch 2350 Loss 2.0926 Accuracy 0.9975\n",
      "Epoch 162 Batch 2400 Loss 2.0941 Accuracy 0.9975\n",
      "Epoch 162 Batch 2450 Loss 2.0947 Accuracy 0.9975\n",
      "Epoch 162 Batch 2500 Loss 2.0958 Accuracy 0.9975\n",
      "Epoch 162 Batch 2550 Loss 2.0943 Accuracy 0.9975\n",
      "Epoch 162 Batch 2600 Loss 2.0917 Accuracy 0.9975\n",
      "Epoch 162 Batch 2650 Loss 2.0899 Accuracy 0.9975\n",
      "Epoch 162 Loss 2.0899 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 196.53298258781433 secs\n",
      "\n",
      "Epoch 163 Batch 0 Loss 1.5907 Accuracy 0.9981\n",
      "Epoch 163 Batch 50 Loss 2.1136 Accuracy 0.9974\n",
      "Epoch 163 Batch 100 Loss 2.1359 Accuracy 0.9974\n",
      "Epoch 163 Batch 150 Loss 2.1353 Accuracy 0.9974\n",
      "Epoch 163 Batch 200 Loss 2.0683 Accuracy 0.9975\n",
      "Epoch 163 Batch 250 Loss 2.0548 Accuracy 0.9975\n",
      "Epoch 163 Batch 300 Loss 2.0559 Accuracy 0.9975\n",
      "Epoch 163 Batch 350 Loss 2.0484 Accuracy 0.9975\n",
      "Epoch 163 Batch 400 Loss 2.0449 Accuracy 0.9975\n",
      "Epoch 163 Batch 450 Loss 2.0780 Accuracy 0.9975\n",
      "Epoch 163 Batch 500 Loss 2.0654 Accuracy 0.9975\n",
      "Epoch 163 Batch 550 Loss 2.0818 Accuracy 0.9975\n",
      "Epoch 163 Batch 600 Loss 2.0959 Accuracy 0.9975\n",
      "Epoch 163 Batch 650 Loss 2.0964 Accuracy 0.9975\n",
      "Epoch 163 Batch 700 Loss 2.0952 Accuracy 0.9975\n",
      "Epoch 163 Batch 750 Loss 2.0941 Accuracy 0.9975\n",
      "Epoch 163 Batch 800 Loss 2.0841 Accuracy 0.9975\n",
      "Epoch 163 Batch 850 Loss 2.0926 Accuracy 0.9975\n",
      "Epoch 163 Batch 900 Loss 2.0936 Accuracy 0.9975\n",
      "Epoch 163 Batch 950 Loss 2.0972 Accuracy 0.9975\n",
      "Epoch 163 Batch 1000 Loss 2.0941 Accuracy 0.9975\n",
      "Epoch 163 Batch 1050 Loss 2.0851 Accuracy 0.9975\n",
      "Epoch 163 Batch 1100 Loss 2.0829 Accuracy 0.9975\n",
      "Epoch 163 Batch 1150 Loss 2.0782 Accuracy 0.9975\n",
      "Epoch 163 Batch 1200 Loss 2.0875 Accuracy 0.9975\n",
      "Epoch 163 Batch 1250 Loss 2.0821 Accuracy 0.9975\n",
      "Epoch 163 Batch 1300 Loss 2.0837 Accuracy 0.9975\n",
      "Epoch 163 Batch 1350 Loss 2.0817 Accuracy 0.9975\n",
      "Epoch 163 Batch 1400 Loss 2.0827 Accuracy 0.9975\n",
      "Epoch 163 Batch 1450 Loss 2.0794 Accuracy 0.9975\n",
      "Epoch 163 Batch 1500 Loss 2.0792 Accuracy 0.9975\n",
      "Epoch 163 Batch 1550 Loss 2.0786 Accuracy 0.9975\n",
      "Epoch 163 Batch 1600 Loss 2.0804 Accuracy 0.9975\n",
      "Epoch 163 Batch 1650 Loss 2.0812 Accuracy 0.9975\n",
      "Epoch 163 Batch 1700 Loss 2.0840 Accuracy 0.9975\n",
      "Epoch 163 Batch 1750 Loss 2.0797 Accuracy 0.9975\n",
      "Epoch 163 Batch 1800 Loss 2.0829 Accuracy 0.9975\n",
      "Epoch 163 Batch 1850 Loss 2.0790 Accuracy 0.9975\n",
      "Epoch 163 Batch 1900 Loss 2.0758 Accuracy 0.9975\n",
      "Epoch 163 Batch 1950 Loss 2.0694 Accuracy 0.9975\n",
      "Epoch 163 Batch 2000 Loss 2.0736 Accuracy 0.9975\n",
      "Epoch 163 Batch 2050 Loss 2.0773 Accuracy 0.9975\n",
      "Epoch 163 Batch 2100 Loss 2.0769 Accuracy 0.9975\n",
      "Epoch 163 Batch 2150 Loss 2.0786 Accuracy 0.9975\n",
      "Epoch 163 Batch 2200 Loss 2.0816 Accuracy 0.9975\n",
      "Epoch 163 Batch 2250 Loss 2.0831 Accuracy 0.9975\n",
      "Epoch 163 Batch 2300 Loss 2.0808 Accuracy 0.9975\n",
      "Epoch 163 Batch 2350 Loss 2.0814 Accuracy 0.9975\n",
      "Epoch 163 Batch 2400 Loss 2.0841 Accuracy 0.9975\n",
      "Epoch 163 Batch 2450 Loss 2.0855 Accuracy 0.9975\n",
      "Epoch 163 Batch 2500 Loss 2.0862 Accuracy 0.9975\n",
      "Epoch 163 Batch 2550 Loss 2.0854 Accuracy 0.9975\n",
      "Epoch 163 Batch 2600 Loss 2.0837 Accuracy 0.9975\n",
      "Epoch 163 Batch 2650 Loss 2.0828 Accuracy 0.9975\n",
      "Epoch 163 Loss 2.0827 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 196.58677315711975 secs\n",
      "\n",
      "Epoch 164 Batch 0 Loss 1.5629 Accuracy 0.9982\n",
      "Epoch 164 Batch 50 Loss 2.1018 Accuracy 0.9975\n",
      "Epoch 164 Batch 100 Loss 2.1043 Accuracy 0.9974\n",
      "Epoch 164 Batch 150 Loss 2.1410 Accuracy 0.9974\n",
      "Epoch 164 Batch 200 Loss 2.0658 Accuracy 0.9975\n",
      "Epoch 164 Batch 250 Loss 2.0621 Accuracy 0.9975\n",
      "Epoch 164 Batch 300 Loss 2.0668 Accuracy 0.9975\n",
      "Epoch 164 Batch 350 Loss 2.0627 Accuracy 0.9975\n",
      "Epoch 164 Batch 400 Loss 2.0529 Accuracy 0.9975\n",
      "Epoch 164 Batch 450 Loss 2.0873 Accuracy 0.9975\n",
      "Epoch 164 Batch 500 Loss 2.0793 Accuracy 0.9975\n",
      "Epoch 164 Batch 550 Loss 2.0900 Accuracy 0.9975\n",
      "Epoch 164 Batch 600 Loss 2.1018 Accuracy 0.9975\n",
      "Epoch 164 Batch 650 Loss 2.1001 Accuracy 0.9975\n",
      "Epoch 164 Batch 700 Loss 2.0949 Accuracy 0.9975\n",
      "Epoch 164 Batch 750 Loss 2.0968 Accuracy 0.9975\n",
      "Epoch 164 Batch 800 Loss 2.0878 Accuracy 0.9975\n",
      "Epoch 164 Batch 850 Loss 2.0903 Accuracy 0.9975\n",
      "Epoch 164 Batch 900 Loss 2.0926 Accuracy 0.9975\n",
      "Epoch 164 Batch 950 Loss 2.0949 Accuracy 0.9975\n",
      "Epoch 164 Batch 1000 Loss 2.0905 Accuracy 0.9975\n",
      "Epoch 164 Batch 1050 Loss 2.0830 Accuracy 0.9975\n",
      "Epoch 164 Batch 1100 Loss 2.0804 Accuracy 0.9975\n",
      "Epoch 164 Batch 1150 Loss 2.0727 Accuracy 0.9975\n",
      "Epoch 164 Batch 1200 Loss 2.0811 Accuracy 0.9975\n",
      "Epoch 164 Batch 1250 Loss 2.0779 Accuracy 0.9975\n",
      "Epoch 164 Batch 1300 Loss 2.0786 Accuracy 0.9975\n",
      "Epoch 164 Batch 1350 Loss 2.0742 Accuracy 0.9975\n",
      "Epoch 164 Batch 1400 Loss 2.0769 Accuracy 0.9975\n",
      "Epoch 164 Batch 1450 Loss 2.0735 Accuracy 0.9975\n",
      "Epoch 164 Batch 1500 Loss 2.0721 Accuracy 0.9975\n",
      "Epoch 164 Batch 1550 Loss 2.0749 Accuracy 0.9975\n",
      "Epoch 164 Batch 1600 Loss 2.0760 Accuracy 0.9975\n",
      "Epoch 164 Batch 1650 Loss 2.0764 Accuracy 0.9975\n",
      "Epoch 164 Batch 1700 Loss 2.0778 Accuracy 0.9975\n",
      "Epoch 164 Batch 1750 Loss 2.0745 Accuracy 0.9975\n",
      "Epoch 164 Batch 1800 Loss 2.0775 Accuracy 0.9975\n",
      "Epoch 164 Batch 1850 Loss 2.0728 Accuracy 0.9975\n",
      "Epoch 164 Batch 1900 Loss 2.0698 Accuracy 0.9975\n",
      "Epoch 164 Batch 1950 Loss 2.0644 Accuracy 0.9975\n",
      "Epoch 164 Batch 2000 Loss 2.0686 Accuracy 0.9975\n",
      "Epoch 164 Batch 2050 Loss 2.0731 Accuracy 0.9975\n",
      "Epoch 164 Batch 2100 Loss 2.0718 Accuracy 0.9975\n",
      "Epoch 164 Batch 2150 Loss 2.0739 Accuracy 0.9975\n",
      "Epoch 164 Batch 2200 Loss 2.0772 Accuracy 0.9975\n",
      "Epoch 164 Batch 2250 Loss 2.0784 Accuracy 0.9975\n",
      "Epoch 164 Batch 2300 Loss 2.0753 Accuracy 0.9975\n",
      "Epoch 164 Batch 2350 Loss 2.0748 Accuracy 0.9975\n",
      "Epoch 164 Batch 2400 Loss 2.0771 Accuracy 0.9975\n",
      "Epoch 164 Batch 2450 Loss 2.0798 Accuracy 0.9975\n",
      "Epoch 164 Batch 2500 Loss 2.0812 Accuracy 0.9975\n",
      "Epoch 164 Batch 2550 Loss 2.0798 Accuracy 0.9975\n",
      "Epoch 164 Batch 2600 Loss 2.0778 Accuracy 0.9975\n",
      "Epoch 164 Batch 2650 Loss 2.0753 Accuracy 0.9975\n",
      "Epoch 164 Loss 2.0751 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 197.40363121032715 secs\n",
      "\n",
      "Epoch 165 Batch 0 Loss 1.5742 Accuracy 0.9979\n",
      "Epoch 165 Batch 50 Loss 2.0975 Accuracy 0.9974\n",
      "Epoch 165 Batch 100 Loss 2.0927 Accuracy 0.9975\n",
      "Epoch 165 Batch 150 Loss 2.1125 Accuracy 0.9974\n",
      "Epoch 165 Batch 200 Loss 2.0557 Accuracy 0.9975\n",
      "Epoch 165 Batch 250 Loss 2.0505 Accuracy 0.9975\n",
      "Epoch 165 Batch 300 Loss 2.0534 Accuracy 0.9975\n",
      "Epoch 165 Batch 350 Loss 2.0487 Accuracy 0.9975\n",
      "Epoch 165 Batch 400 Loss 2.0438 Accuracy 0.9975\n",
      "Epoch 165 Batch 450 Loss 2.0759 Accuracy 0.9975\n",
      "Epoch 165 Batch 500 Loss 2.0686 Accuracy 0.9975\n",
      "Epoch 165 Batch 550 Loss 2.0818 Accuracy 0.9975\n",
      "Epoch 165 Batch 600 Loss 2.0936 Accuracy 0.9975\n",
      "Epoch 165 Batch 650 Loss 2.0902 Accuracy 0.9975\n",
      "Epoch 165 Batch 700 Loss 2.0867 Accuracy 0.9975\n",
      "Epoch 165 Batch 750 Loss 2.0886 Accuracy 0.9975\n",
      "Epoch 165 Batch 800 Loss 2.0803 Accuracy 0.9975\n",
      "Epoch 165 Batch 850 Loss 2.0831 Accuracy 0.9975\n",
      "Epoch 165 Batch 900 Loss 2.0862 Accuracy 0.9975\n",
      "Epoch 165 Batch 950 Loss 2.0904 Accuracy 0.9975\n",
      "Epoch 165 Batch 1000 Loss 2.0891 Accuracy 0.9975\n",
      "Epoch 165 Batch 1050 Loss 2.0828 Accuracy 0.9975\n",
      "Epoch 165 Batch 1100 Loss 2.0804 Accuracy 0.9975\n",
      "Epoch 165 Batch 1150 Loss 2.0727 Accuracy 0.9975\n",
      "Epoch 165 Batch 1200 Loss 2.0807 Accuracy 0.9975\n",
      "Epoch 165 Batch 1250 Loss 2.0766 Accuracy 0.9975\n",
      "Epoch 165 Batch 1300 Loss 2.0772 Accuracy 0.9975\n",
      "Epoch 165 Batch 1350 Loss 2.0732 Accuracy 0.9975\n",
      "Epoch 165 Batch 1400 Loss 2.0740 Accuracy 0.9975\n",
      "Epoch 165 Batch 1450 Loss 2.0711 Accuracy 0.9975\n",
      "Epoch 165 Batch 1500 Loss 2.0702 Accuracy 0.9975\n",
      "Epoch 165 Batch 1550 Loss 2.0728 Accuracy 0.9975\n",
      "Epoch 165 Batch 1600 Loss 2.0742 Accuracy 0.9975\n",
      "Epoch 165 Batch 1650 Loss 2.0758 Accuracy 0.9975\n",
      "Epoch 165 Batch 1700 Loss 2.0772 Accuracy 0.9975\n",
      "Epoch 165 Batch 1750 Loss 2.0713 Accuracy 0.9975\n",
      "Epoch 165 Batch 1800 Loss 2.0732 Accuracy 0.9975\n",
      "Epoch 165 Batch 1850 Loss 2.0679 Accuracy 0.9975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165 Batch 1900 Loss 2.0648 Accuracy 0.9975\n",
      "Epoch 165 Batch 1950 Loss 2.0590 Accuracy 0.9975\n",
      "Epoch 165 Batch 2000 Loss 2.0633 Accuracy 0.9975\n",
      "Epoch 165 Batch 2050 Loss 2.0672 Accuracy 0.9975\n",
      "Epoch 165 Batch 2100 Loss 2.0658 Accuracy 0.9975\n",
      "Epoch 165 Batch 2150 Loss 2.0676 Accuracy 0.9975\n",
      "Epoch 165 Batch 2200 Loss 2.0719 Accuracy 0.9975\n",
      "Epoch 165 Batch 2250 Loss 2.0744 Accuracy 0.9975\n",
      "Epoch 165 Batch 2300 Loss 2.0724 Accuracy 0.9975\n",
      "Epoch 165 Batch 2350 Loss 2.0720 Accuracy 0.9975\n",
      "Epoch 165 Batch 2400 Loss 2.0733 Accuracy 0.9975\n",
      "Epoch 165 Batch 2450 Loss 2.0746 Accuracy 0.9975\n",
      "Epoch 165 Batch 2500 Loss 2.0764 Accuracy 0.9975\n",
      "Epoch 165 Batch 2550 Loss 2.0762 Accuracy 0.9975\n",
      "Epoch 165 Batch 2600 Loss 2.0737 Accuracy 0.9975\n",
      "Epoch 165 Batch 2650 Loss 2.0718 Accuracy 0.9975\n",
      "Saving checkpoint for epoch 165 at ./checkpoints/train\\ckpt-34\n",
      "Epoch 165 Loss 2.0728 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 196.7529740333557 secs\n",
      "\n",
      "Epoch 166 Batch 0 Loss 1.3729 Accuracy 0.9981\n",
      "Epoch 166 Batch 50 Loss 2.0662 Accuracy 0.9975\n",
      "Epoch 166 Batch 100 Loss 2.0666 Accuracy 0.9975\n",
      "Epoch 166 Batch 150 Loss 2.1150 Accuracy 0.9974\n",
      "Epoch 166 Batch 200 Loss 2.0677 Accuracy 0.9975\n",
      "Epoch 166 Batch 250 Loss 2.0614 Accuracy 0.9975\n",
      "Epoch 166 Batch 300 Loss 2.0601 Accuracy 0.9975\n",
      "Epoch 166 Batch 350 Loss 2.0549 Accuracy 0.9975\n",
      "Epoch 166 Batch 400 Loss 2.0536 Accuracy 0.9975\n",
      "Epoch 166 Batch 450 Loss 2.0776 Accuracy 0.9975\n",
      "Epoch 166 Batch 500 Loss 2.0668 Accuracy 0.9975\n",
      "Epoch 166 Batch 550 Loss 2.0767 Accuracy 0.9975\n",
      "Epoch 166 Batch 600 Loss 2.0916 Accuracy 0.9975\n",
      "Epoch 166 Batch 650 Loss 2.0903 Accuracy 0.9975\n",
      "Epoch 166 Batch 700 Loss 2.0892 Accuracy 0.9975\n",
      "Epoch 166 Batch 750 Loss 2.0882 Accuracy 0.9975\n",
      "Epoch 166 Batch 800 Loss 2.0789 Accuracy 0.9975\n",
      "Epoch 166 Batch 850 Loss 2.0830 Accuracy 0.9975\n",
      "Epoch 166 Batch 900 Loss 2.0848 Accuracy 0.9975\n",
      "Epoch 166 Batch 950 Loss 2.0875 Accuracy 0.9975\n",
      "Epoch 166 Batch 1000 Loss 2.0867 Accuracy 0.9975\n",
      "Epoch 166 Batch 1050 Loss 2.0794 Accuracy 0.9975\n",
      "Epoch 166 Batch 1100 Loss 2.0760 Accuracy 0.9975\n",
      "Epoch 166 Batch 1150 Loss 2.0686 Accuracy 0.9975\n",
      "Epoch 166 Batch 1200 Loss 2.0771 Accuracy 0.9975\n",
      "Epoch 166 Batch 1250 Loss 2.0748 Accuracy 0.9975\n",
      "Epoch 166 Batch 1300 Loss 2.0777 Accuracy 0.9975\n",
      "Epoch 166 Batch 1350 Loss 2.0742 Accuracy 0.9975\n",
      "Epoch 166 Batch 1400 Loss 2.0753 Accuracy 0.9975\n",
      "Epoch 166 Batch 1450 Loss 2.0713 Accuracy 0.9975\n",
      "Epoch 166 Batch 1500 Loss 2.0689 Accuracy 0.9975\n",
      "Epoch 166 Batch 1550 Loss 2.0709 Accuracy 0.9975\n",
      "Epoch 166 Batch 1600 Loss 2.0713 Accuracy 0.9975\n",
      "Epoch 166 Batch 1650 Loss 2.0720 Accuracy 0.9975\n",
      "Epoch 166 Batch 1700 Loss 2.0739 Accuracy 0.9975\n",
      "Epoch 166 Batch 1750 Loss 2.0703 Accuracy 0.9975\n",
      "Epoch 166 Batch 1800 Loss 2.0701 Accuracy 0.9975\n",
      "Epoch 166 Batch 1850 Loss 2.0654 Accuracy 0.9975\n",
      "Epoch 166 Batch 1900 Loss 2.0630 Accuracy 0.9975\n",
      "Epoch 166 Batch 1950 Loss 2.0569 Accuracy 0.9975\n",
      "Epoch 166 Batch 2000 Loss 2.0620 Accuracy 0.9975\n",
      "Epoch 166 Batch 2050 Loss 2.0667 Accuracy 0.9975\n",
      "Epoch 166 Batch 2100 Loss 2.0652 Accuracy 0.9975\n",
      "Epoch 166 Batch 2150 Loss 2.0663 Accuracy 0.9975\n",
      "Epoch 166 Batch 2200 Loss 2.0691 Accuracy 0.9975\n",
      "Epoch 166 Batch 2250 Loss 2.0722 Accuracy 0.9975\n",
      "Epoch 166 Batch 2300 Loss 2.0709 Accuracy 0.9975\n",
      "Epoch 166 Batch 2350 Loss 2.0710 Accuracy 0.9975\n",
      "Epoch 166 Batch 2400 Loss 2.0725 Accuracy 0.9975\n",
      "Epoch 166 Batch 2450 Loss 2.0739 Accuracy 0.9975\n",
      "Epoch 166 Batch 2500 Loss 2.0753 Accuracy 0.9975\n",
      "Epoch 166 Batch 2550 Loss 2.0753 Accuracy 0.9975\n",
      "Epoch 166 Batch 2600 Loss 2.0740 Accuracy 0.9975\n",
      "Epoch 166 Batch 2650 Loss 2.0716 Accuracy 0.9975\n",
      "Epoch 166 Loss 2.0725 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 196.50368762016296 secs\n",
      "\n",
      "Epoch 167 Batch 0 Loss 1.4056 Accuracy 0.9983\n",
      "Epoch 167 Batch 50 Loss 2.0525 Accuracy 0.9975\n",
      "Epoch 167 Batch 100 Loss 2.0878 Accuracy 0.9975\n",
      "Epoch 167 Batch 150 Loss 2.1264 Accuracy 0.9974\n",
      "Epoch 167 Batch 200 Loss 2.0618 Accuracy 0.9975\n",
      "Epoch 167 Batch 250 Loss 2.0507 Accuracy 0.9975\n",
      "Epoch 167 Batch 300 Loss 2.0520 Accuracy 0.9975\n",
      "Epoch 167 Batch 350 Loss 2.0510 Accuracy 0.9975\n",
      "Epoch 167 Batch 400 Loss 2.0471 Accuracy 0.9975\n",
      "Epoch 167 Batch 450 Loss 2.0722 Accuracy 0.9975\n",
      "Epoch 167 Batch 500 Loss 2.0729 Accuracy 0.9975\n",
      "Epoch 167 Batch 550 Loss 2.0826 Accuracy 0.9975\n",
      "Epoch 167 Batch 600 Loss 2.0949 Accuracy 0.9975\n",
      "Epoch 167 Batch 650 Loss 2.0940 Accuracy 0.9975\n",
      "Epoch 167 Batch 700 Loss 2.0895 Accuracy 0.9975\n",
      "Epoch 167 Batch 750 Loss 2.0877 Accuracy 0.9975\n",
      "Epoch 167 Batch 800 Loss 2.0765 Accuracy 0.9975\n",
      "Epoch 167 Batch 850 Loss 2.0802 Accuracy 0.9975\n",
      "Epoch 167 Batch 900 Loss 2.0801 Accuracy 0.9975\n",
      "Epoch 167 Batch 950 Loss 2.0855 Accuracy 0.9975\n",
      "Epoch 167 Batch 1000 Loss 2.0801 Accuracy 0.9975\n",
      "Epoch 167 Batch 1050 Loss 2.0726 Accuracy 0.9975\n",
      "Epoch 167 Batch 1100 Loss 2.0704 Accuracy 0.9975\n",
      "Epoch 167 Batch 1150 Loss 2.0633 Accuracy 0.9975\n",
      "Epoch 167 Batch 1200 Loss 2.0720 Accuracy 0.9975\n",
      "Epoch 167 Batch 1250 Loss 2.0683 Accuracy 0.9975\n",
      "Epoch 167 Batch 1300 Loss 2.0703 Accuracy 0.9975\n",
      "Epoch 167 Batch 1350 Loss 2.0686 Accuracy 0.9975\n",
      "Epoch 167 Batch 1400 Loss 2.0721 Accuracy 0.9975\n",
      "Epoch 167 Batch 1450 Loss 2.0683 Accuracy 0.9975\n",
      "Epoch 167 Batch 1500 Loss 2.0679 Accuracy 0.9975\n",
      "Epoch 167 Batch 1550 Loss 2.0691 Accuracy 0.9975\n",
      "Epoch 167 Batch 1600 Loss 2.0699 Accuracy 0.9975\n",
      "Epoch 167 Batch 1650 Loss 2.0700 Accuracy 0.9975\n",
      "Epoch 167 Batch 1700 Loss 2.0724 Accuracy 0.9975\n",
      "Epoch 167 Batch 1750 Loss 2.0694 Accuracy 0.9975\n",
      "Epoch 167 Batch 1800 Loss 2.0708 Accuracy 0.9975\n",
      "Epoch 167 Batch 1850 Loss 2.0666 Accuracy 0.9975\n",
      "Epoch 167 Batch 1900 Loss 2.0630 Accuracy 0.9975\n",
      "Epoch 167 Batch 1950 Loss 2.0561 Accuracy 0.9975\n",
      "Epoch 167 Batch 2000 Loss 2.0598 Accuracy 0.9975\n",
      "Epoch 167 Batch 2050 Loss 2.0646 Accuracy 0.9975\n",
      "Epoch 167 Batch 2100 Loss 2.0632 Accuracy 0.9975\n",
      "Epoch 167 Batch 2150 Loss 2.0649 Accuracy 0.9975\n",
      "Epoch 167 Batch 2200 Loss 2.0691 Accuracy 0.9975\n",
      "Epoch 167 Batch 2250 Loss 2.0713 Accuracy 0.9975\n",
      "Epoch 167 Batch 2300 Loss 2.0702 Accuracy 0.9975\n",
      "Epoch 167 Batch 2350 Loss 2.0696 Accuracy 0.9975\n",
      "Epoch 167 Batch 2400 Loss 2.0705 Accuracy 0.9975\n",
      "Epoch 167 Batch 2450 Loss 2.0730 Accuracy 0.9975\n",
      "Epoch 167 Batch 2500 Loss 2.0738 Accuracy 0.9975\n",
      "Epoch 167 Batch 2550 Loss 2.0722 Accuracy 0.9975\n",
      "Epoch 167 Batch 2600 Loss 2.0697 Accuracy 0.9975\n",
      "Epoch 167 Batch 2650 Loss 2.0685 Accuracy 0.9975\n",
      "Epoch 167 Loss 2.0690 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 196.28291058540344 secs\n",
      "\n",
      "Epoch 168 Batch 0 Loss 1.6767 Accuracy 0.9976\n",
      "Epoch 168 Batch 50 Loss 2.0900 Accuracy 0.9975\n",
      "Epoch 168 Batch 100 Loss 2.0925 Accuracy 0.9975\n",
      "Epoch 168 Batch 150 Loss 2.1263 Accuracy 0.9974\n",
      "Epoch 168 Batch 200 Loss 2.0700 Accuracy 0.9975\n",
      "Epoch 168 Batch 250 Loss 2.0492 Accuracy 0.9975\n",
      "Epoch 168 Batch 300 Loss 2.0531 Accuracy 0.9975\n",
      "Epoch 168 Batch 350 Loss 2.0565 Accuracy 0.9975\n",
      "Epoch 168 Batch 400 Loss 2.0481 Accuracy 0.9975\n",
      "Epoch 168 Batch 450 Loss 2.0704 Accuracy 0.9975\n",
      "Epoch 168 Batch 500 Loss 2.0607 Accuracy 0.9975\n",
      "Epoch 168 Batch 550 Loss 2.0731 Accuracy 0.9975\n",
      "Epoch 168 Batch 600 Loss 2.0857 Accuracy 0.9975\n",
      "Epoch 168 Batch 650 Loss 2.0804 Accuracy 0.9975\n",
      "Epoch 168 Batch 700 Loss 2.0793 Accuracy 0.9975\n",
      "Epoch 168 Batch 750 Loss 2.0803 Accuracy 0.9975\n",
      "Epoch 168 Batch 800 Loss 2.0718 Accuracy 0.9975\n",
      "Epoch 168 Batch 850 Loss 2.0771 Accuracy 0.9975\n",
      "Epoch 168 Batch 900 Loss 2.0732 Accuracy 0.9975\n",
      "Epoch 168 Batch 950 Loss 2.0801 Accuracy 0.9975\n",
      "Epoch 168 Batch 1000 Loss 2.0790 Accuracy 0.9975\n",
      "Epoch 168 Batch 1050 Loss 2.0723 Accuracy 0.9975\n",
      "Epoch 168 Batch 1100 Loss 2.0734 Accuracy 0.9975\n",
      "Epoch 168 Batch 1150 Loss 2.0663 Accuracy 0.9975\n",
      "Epoch 168 Batch 1200 Loss 2.0748 Accuracy 0.9975\n",
      "Epoch 168 Batch 1250 Loss 2.0695 Accuracy 0.9975\n",
      "Epoch 168 Batch 1300 Loss 2.0712 Accuracy 0.9975\n",
      "Epoch 168 Batch 1350 Loss 2.0698 Accuracy 0.9975\n",
      "Epoch 168 Batch 1400 Loss 2.0712 Accuracy 0.9975\n",
      "Epoch 168 Batch 1450 Loss 2.0678 Accuracy 0.9975\n",
      "Epoch 168 Batch 1500 Loss 2.0660 Accuracy 0.9975\n",
      "Epoch 168 Batch 1550 Loss 2.0675 Accuracy 0.9975\n",
      "Epoch 168 Batch 1600 Loss 2.0682 Accuracy 0.9975\n",
      "Epoch 168 Batch 1650 Loss 2.0681 Accuracy 0.9975\n",
      "Epoch 168 Batch 1700 Loss 2.0706 Accuracy 0.9975\n",
      "Epoch 168 Batch 1750 Loss 2.0648 Accuracy 0.9975\n",
      "Epoch 168 Batch 1800 Loss 2.0650 Accuracy 0.9975\n",
      "Epoch 168 Batch 1850 Loss 2.0594 Accuracy 0.9975\n",
      "Epoch 168 Batch 1900 Loss 2.0547 Accuracy 0.9975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168 Batch 1950 Loss 2.0500 Accuracy 0.9975\n",
      "Epoch 168 Batch 2000 Loss 2.0539 Accuracy 0.9975\n",
      "Epoch 168 Batch 2050 Loss 2.0578 Accuracy 0.9975\n",
      "Epoch 168 Batch 2100 Loss 2.0551 Accuracy 0.9975\n",
      "Epoch 168 Batch 2150 Loss 2.0565 Accuracy 0.9975\n",
      "Epoch 168 Batch 2200 Loss 2.0602 Accuracy 0.9975\n",
      "Epoch 168 Batch 2250 Loss 2.0606 Accuracy 0.9975\n",
      "Epoch 168 Batch 2300 Loss 2.0587 Accuracy 0.9975\n",
      "Epoch 168 Batch 2350 Loss 2.0582 Accuracy 0.9975\n",
      "Epoch 168 Batch 2400 Loss 2.0597 Accuracy 0.9975\n",
      "Epoch 168 Batch 2450 Loss 2.0622 Accuracy 0.9975\n",
      "Epoch 168 Batch 2500 Loss 2.0650 Accuracy 0.9975\n",
      "Epoch 168 Batch 2550 Loss 2.0644 Accuracy 0.9975\n",
      "Epoch 168 Batch 2600 Loss 2.0625 Accuracy 0.9975\n",
      "Epoch 168 Batch 2650 Loss 2.0600 Accuracy 0.9975\n",
      "Epoch 168 Loss 2.0616 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 196.75036454200745 secs\n",
      "\n",
      "Epoch 169 Batch 0 Loss 1.4375 Accuracy 0.9981\n",
      "Epoch 169 Batch 50 Loss 2.0720 Accuracy 0.9975\n",
      "Epoch 169 Batch 100 Loss 2.0762 Accuracy 0.9975\n",
      "Epoch 169 Batch 150 Loss 2.1002 Accuracy 0.9974\n",
      "Epoch 169 Batch 200 Loss 2.0477 Accuracy 0.9975\n",
      "Epoch 169 Batch 250 Loss 2.0464 Accuracy 0.9975\n",
      "Epoch 169 Batch 300 Loss 2.0442 Accuracy 0.9975\n",
      "Epoch 169 Batch 350 Loss 2.0411 Accuracy 0.9975\n",
      "Epoch 169 Batch 400 Loss 2.0395 Accuracy 0.9975\n",
      "Epoch 169 Batch 450 Loss 2.0650 Accuracy 0.9975\n",
      "Epoch 169 Batch 500 Loss 2.0566 Accuracy 0.9975\n",
      "Epoch 169 Batch 550 Loss 2.0703 Accuracy 0.9975\n",
      "Epoch 169 Batch 600 Loss 2.0840 Accuracy 0.9975\n",
      "Epoch 169 Batch 650 Loss 2.0813 Accuracy 0.9975\n",
      "Epoch 169 Batch 700 Loss 2.0781 Accuracy 0.9975\n",
      "Epoch 169 Batch 750 Loss 2.0753 Accuracy 0.9975\n",
      "Epoch 169 Batch 800 Loss 2.0666 Accuracy 0.9975\n",
      "Epoch 169 Batch 850 Loss 2.0693 Accuracy 0.9975\n",
      "Epoch 169 Batch 900 Loss 2.0713 Accuracy 0.9975\n",
      "Epoch 169 Batch 950 Loss 2.0744 Accuracy 0.9975\n",
      "Epoch 169 Batch 1000 Loss 2.0732 Accuracy 0.9975\n",
      "Epoch 169 Batch 1050 Loss 2.0651 Accuracy 0.9975\n",
      "Epoch 169 Batch 1100 Loss 2.0633 Accuracy 0.9975\n",
      "Epoch 169 Batch 1150 Loss 2.0567 Accuracy 0.9975\n",
      "Epoch 169 Batch 1200 Loss 2.0694 Accuracy 0.9975\n",
      "Epoch 169 Batch 1250 Loss 2.0659 Accuracy 0.9975\n",
      "Epoch 169 Batch 1300 Loss 2.0677 Accuracy 0.9975\n",
      "Epoch 169 Batch 1350 Loss 2.0620 Accuracy 0.9975\n",
      "Epoch 169 Batch 1400 Loss 2.0641 Accuracy 0.9975\n",
      "Epoch 169 Batch 1450 Loss 2.0611 Accuracy 0.9975\n",
      "Epoch 169 Batch 1500 Loss 2.0598 Accuracy 0.9975\n",
      "Epoch 169 Batch 1550 Loss 2.0625 Accuracy 0.9975\n",
      "Epoch 169 Batch 1600 Loss 2.0626 Accuracy 0.9975\n",
      "Epoch 169 Batch 1650 Loss 2.0657 Accuracy 0.9975\n",
      "Epoch 169 Batch 1700 Loss 2.0675 Accuracy 0.9975\n",
      "Epoch 169 Batch 1750 Loss 2.0649 Accuracy 0.9975\n",
      "Epoch 169 Batch 1800 Loss 2.0662 Accuracy 0.9975\n",
      "Epoch 169 Batch 1850 Loss 2.0622 Accuracy 0.9975\n",
      "Epoch 169 Batch 1900 Loss 2.0595 Accuracy 0.9975\n",
      "Epoch 169 Batch 1950 Loss 2.0523 Accuracy 0.9975\n",
      "Epoch 169 Batch 2000 Loss 2.0564 Accuracy 0.9975\n",
      "Epoch 169 Batch 2050 Loss 2.0613 Accuracy 0.9975\n",
      "Epoch 169 Batch 2100 Loss 2.0593 Accuracy 0.9975\n",
      "Epoch 169 Batch 2150 Loss 2.0617 Accuracy 0.9975\n",
      "Epoch 169 Batch 2200 Loss 2.0644 Accuracy 0.9975\n",
      "Epoch 169 Batch 2250 Loss 2.0653 Accuracy 0.9975\n",
      "Epoch 169 Batch 2300 Loss 2.0630 Accuracy 0.9975\n",
      "Epoch 169 Batch 2350 Loss 2.0629 Accuracy 0.9975\n",
      "Epoch 169 Batch 2400 Loss 2.0638 Accuracy 0.9975\n",
      "Epoch 169 Batch 2450 Loss 2.0651 Accuracy 0.9975\n",
      "Epoch 169 Batch 2500 Loss 2.0673 Accuracy 0.9975\n",
      "Epoch 169 Batch 2550 Loss 2.0663 Accuracy 0.9975\n",
      "Epoch 169 Batch 2600 Loss 2.0648 Accuracy 0.9975\n",
      "Epoch 169 Batch 2650 Loss 2.0626 Accuracy 0.9975\n",
      "Epoch 169 Loss 2.0641 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 197.63325119018555 secs\n",
      "\n",
      "Epoch 170 Batch 0 Loss 1.6134 Accuracy 0.9980\n",
      "Epoch 170 Batch 50 Loss 2.0734 Accuracy 0.9975\n",
      "Epoch 170 Batch 100 Loss 2.0900 Accuracy 0.9975\n",
      "Epoch 170 Batch 150 Loss 2.0993 Accuracy 0.9975\n",
      "Epoch 170 Batch 200 Loss 2.0402 Accuracy 0.9975\n",
      "Epoch 170 Batch 250 Loss 2.0278 Accuracy 0.9976\n",
      "Epoch 170 Batch 300 Loss 2.0374 Accuracy 0.9975\n",
      "Epoch 170 Batch 350 Loss 2.0424 Accuracy 0.9975\n",
      "Epoch 170 Batch 400 Loss 2.0364 Accuracy 0.9975\n",
      "Epoch 170 Batch 450 Loss 2.0621 Accuracy 0.9975\n",
      "Epoch 170 Batch 500 Loss 2.0523 Accuracy 0.9975\n",
      "Epoch 170 Batch 550 Loss 2.0595 Accuracy 0.9975\n",
      "Epoch 170 Batch 600 Loss 2.0720 Accuracy 0.9975\n",
      "Epoch 170 Batch 650 Loss 2.0683 Accuracy 0.9975\n",
      "Epoch 170 Batch 700 Loss 2.0657 Accuracy 0.9975\n",
      "Epoch 170 Batch 750 Loss 2.0680 Accuracy 0.9975\n",
      "Epoch 170 Batch 800 Loss 2.0580 Accuracy 0.9975\n",
      "Epoch 170 Batch 850 Loss 2.0653 Accuracy 0.9975\n",
      "Epoch 170 Batch 900 Loss 2.0658 Accuracy 0.9975\n",
      "Epoch 170 Batch 950 Loss 2.0733 Accuracy 0.9975\n",
      "Epoch 170 Batch 1000 Loss 2.0706 Accuracy 0.9975\n",
      "Epoch 170 Batch 1050 Loss 2.0609 Accuracy 0.9975\n",
      "Epoch 170 Batch 1100 Loss 2.0616 Accuracy 0.9975\n",
      "Epoch 170 Batch 1150 Loss 2.0541 Accuracy 0.9975\n",
      "Epoch 170 Batch 1200 Loss 2.0641 Accuracy 0.9975\n",
      "Epoch 170 Batch 1250 Loss 2.0602 Accuracy 0.9975\n",
      "Epoch 170 Batch 1300 Loss 2.0621 Accuracy 0.9975\n",
      "Epoch 170 Batch 1350 Loss 2.0600 Accuracy 0.9975\n",
      "Epoch 170 Batch 1400 Loss 2.0624 Accuracy 0.9975\n",
      "Epoch 170 Batch 1450 Loss 2.0593 Accuracy 0.9975\n",
      "Epoch 170 Batch 1500 Loss 2.0592 Accuracy 0.9975\n",
      "Epoch 170 Batch 1550 Loss 2.0629 Accuracy 0.9975\n",
      "Epoch 170 Batch 1600 Loss 2.0622 Accuracy 0.9975\n",
      "Epoch 170 Batch 1650 Loss 2.0630 Accuracy 0.9975\n",
      "Epoch 170 Batch 1700 Loss 2.0650 Accuracy 0.9975\n",
      "Epoch 170 Batch 1750 Loss 2.0612 Accuracy 0.9975\n",
      "Epoch 170 Batch 1800 Loss 2.0635 Accuracy 0.9975\n",
      "Epoch 170 Batch 1850 Loss 2.0578 Accuracy 0.9975\n",
      "Epoch 170 Batch 1900 Loss 2.0548 Accuracy 0.9975\n",
      "Epoch 170 Batch 1950 Loss 2.0486 Accuracy 0.9975\n",
      "Epoch 170 Batch 2000 Loss 2.0529 Accuracy 0.9975\n",
      "Epoch 170 Batch 2050 Loss 2.0574 Accuracy 0.9975\n",
      "Epoch 170 Batch 2100 Loss 2.0556 Accuracy 0.9975\n",
      "Epoch 170 Batch 2150 Loss 2.0582 Accuracy 0.9975\n",
      "Epoch 170 Batch 2200 Loss 2.0619 Accuracy 0.9975\n",
      "Epoch 170 Batch 2250 Loss 2.0630 Accuracy 0.9975\n",
      "Epoch 170 Batch 2300 Loss 2.0602 Accuracy 0.9975\n",
      "Epoch 170 Batch 2350 Loss 2.0603 Accuracy 0.9975\n",
      "Epoch 170 Batch 2400 Loss 2.0630 Accuracy 0.9975\n",
      "Epoch 170 Batch 2450 Loss 2.0647 Accuracy 0.9975\n",
      "Epoch 170 Batch 2500 Loss 2.0668 Accuracy 0.9975\n",
      "Epoch 170 Batch 2550 Loss 2.0663 Accuracy 0.9975\n",
      "Epoch 170 Batch 2600 Loss 2.0642 Accuracy 0.9975\n",
      "Epoch 170 Batch 2650 Loss 2.0624 Accuracy 0.9975\n",
      "Saving checkpoint for epoch 170 at ./checkpoints/train\\ckpt-35\n",
      "Epoch 170 Loss 2.0636 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 196.53304028511047 secs\n",
      "\n",
      "Epoch 171 Batch 0 Loss 1.6498 Accuracy 0.9981\n",
      "Epoch 171 Batch 50 Loss 2.0978 Accuracy 0.9975\n",
      "Epoch 171 Batch 100 Loss 2.0729 Accuracy 0.9975\n",
      "Epoch 171 Batch 150 Loss 2.0967 Accuracy 0.9974\n",
      "Epoch 171 Batch 200 Loss 2.0358 Accuracy 0.9975\n",
      "Epoch 171 Batch 250 Loss 2.0187 Accuracy 0.9975\n",
      "Epoch 171 Batch 300 Loss 2.0224 Accuracy 0.9975\n",
      "Epoch 171 Batch 350 Loss 2.0197 Accuracy 0.9975\n",
      "Epoch 171 Batch 400 Loss 2.0180 Accuracy 0.9975\n",
      "Epoch 171 Batch 450 Loss 2.0451 Accuracy 0.9975\n",
      "Epoch 171 Batch 500 Loss 2.0376 Accuracy 0.9975\n",
      "Epoch 171 Batch 550 Loss 2.0496 Accuracy 0.9975\n",
      "Epoch 171 Batch 600 Loss 2.0616 Accuracy 0.9975\n",
      "Epoch 171 Batch 650 Loss 2.0559 Accuracy 0.9975\n",
      "Epoch 171 Batch 700 Loss 2.0568 Accuracy 0.9975\n",
      "Epoch 171 Batch 750 Loss 2.0583 Accuracy 0.9975\n",
      "Epoch 171 Batch 800 Loss 2.0506 Accuracy 0.9975\n",
      "Epoch 171 Batch 850 Loss 2.0554 Accuracy 0.9975\n",
      "Epoch 171 Batch 900 Loss 2.0540 Accuracy 0.9975\n",
      "Epoch 171 Batch 950 Loss 2.0562 Accuracy 0.9975\n",
      "Epoch 171 Batch 1000 Loss 2.0544 Accuracy 0.9975\n",
      "Epoch 171 Batch 1050 Loss 2.0470 Accuracy 0.9975\n",
      "Epoch 171 Batch 1100 Loss 2.0456 Accuracy 0.9975\n",
      "Epoch 171 Batch 1150 Loss 2.0424 Accuracy 0.9975\n",
      "Epoch 171 Batch 1200 Loss 2.0514 Accuracy 0.9975\n",
      "Epoch 171 Batch 1250 Loss 2.0488 Accuracy 0.9975\n",
      "Epoch 171 Batch 1300 Loss 2.0510 Accuracy 0.9975\n",
      "Epoch 171 Batch 1350 Loss 2.0485 Accuracy 0.9975\n",
      "Epoch 171 Batch 1400 Loss 2.0501 Accuracy 0.9975\n",
      "Epoch 171 Batch 1450 Loss 2.0460 Accuracy 0.9975\n",
      "Epoch 171 Batch 1500 Loss 2.0442 Accuracy 0.9975\n",
      "Epoch 171 Batch 1550 Loss 2.0480 Accuracy 0.9975\n",
      "Epoch 171 Batch 1600 Loss 2.0494 Accuracy 0.9975\n",
      "Epoch 171 Batch 1650 Loss 2.0508 Accuracy 0.9975\n",
      "Epoch 171 Batch 1700 Loss 2.0528 Accuracy 0.9975\n",
      "Epoch 171 Batch 1750 Loss 2.0487 Accuracy 0.9975\n",
      "Epoch 171 Batch 1800 Loss 2.0488 Accuracy 0.9975\n",
      "Epoch 171 Batch 1850 Loss 2.0453 Accuracy 0.9975\n",
      "Epoch 171 Batch 1900 Loss 2.0417 Accuracy 0.9975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171 Batch 1950 Loss 2.0373 Accuracy 0.9975\n",
      "Epoch 171 Batch 2000 Loss 2.0436 Accuracy 0.9975\n",
      "Epoch 171 Batch 2050 Loss 2.0478 Accuracy 0.9975\n",
      "Epoch 171 Batch 2100 Loss 2.0461 Accuracy 0.9975\n",
      "Epoch 171 Batch 2150 Loss 2.0482 Accuracy 0.9975\n",
      "Epoch 171 Batch 2200 Loss 2.0510 Accuracy 0.9975\n",
      "Epoch 171 Batch 2250 Loss 2.0529 Accuracy 0.9975\n",
      "Epoch 171 Batch 2300 Loss 2.0500 Accuracy 0.9975\n",
      "Epoch 171 Batch 2350 Loss 2.0507 Accuracy 0.9975\n",
      "Epoch 171 Batch 2400 Loss 2.0512 Accuracy 0.9975\n",
      "Epoch 171 Batch 2450 Loss 2.0533 Accuracy 0.9975\n",
      "Epoch 171 Batch 2500 Loss 2.0555 Accuracy 0.9975\n",
      "Epoch 171 Batch 2550 Loss 2.0552 Accuracy 0.9975\n",
      "Epoch 171 Batch 2600 Loss 2.0532 Accuracy 0.9975\n",
      "Epoch 171 Batch 2650 Loss 2.0515 Accuracy 0.9975\n",
      "Epoch 171 Loss 2.0534 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 197.79670357704163 secs\n",
      "\n",
      "Epoch 172 Batch 0 Loss 1.3221 Accuracy 0.9984\n",
      "Epoch 172 Batch 50 Loss 2.1448 Accuracy 0.9974\n",
      "Epoch 172 Batch 100 Loss 2.1120 Accuracy 0.9974\n",
      "Epoch 172 Batch 150 Loss 2.1150 Accuracy 0.9975\n",
      "Epoch 172 Batch 200 Loss 2.0504 Accuracy 0.9975\n",
      "Epoch 172 Batch 250 Loss 2.0271 Accuracy 0.9976\n",
      "Epoch 172 Batch 300 Loss 2.0238 Accuracy 0.9976\n",
      "Epoch 172 Batch 350 Loss 2.0287 Accuracy 0.9976\n",
      "Epoch 172 Batch 400 Loss 2.0208 Accuracy 0.9976\n",
      "Epoch 172 Batch 450 Loss 2.0500 Accuracy 0.9975\n",
      "Epoch 172 Batch 500 Loss 2.0425 Accuracy 0.9975\n",
      "Epoch 172 Batch 550 Loss 2.0539 Accuracy 0.9975\n",
      "Epoch 172 Batch 600 Loss 2.0655 Accuracy 0.9975\n",
      "Epoch 172 Batch 650 Loss 2.0642 Accuracy 0.9975\n",
      "Epoch 172 Batch 700 Loss 2.0652 Accuracy 0.9975\n",
      "Epoch 172 Batch 750 Loss 2.0658 Accuracy 0.9975\n",
      "Epoch 172 Batch 800 Loss 2.0556 Accuracy 0.9975\n",
      "Epoch 172 Batch 850 Loss 2.0563 Accuracy 0.9975\n",
      "Epoch 172 Batch 900 Loss 2.0542 Accuracy 0.9975\n",
      "Epoch 172 Batch 950 Loss 2.0578 Accuracy 0.9975\n",
      "Epoch 172 Batch 1000 Loss 2.0571 Accuracy 0.9975\n",
      "Epoch 172 Batch 1050 Loss 2.0487 Accuracy 0.9975\n",
      "Epoch 172 Batch 1100 Loss 2.0464 Accuracy 0.9975\n",
      "Epoch 172 Batch 1150 Loss 2.0403 Accuracy 0.9975\n",
      "Epoch 172 Batch 1200 Loss 2.0503 Accuracy 0.9975\n",
      "Epoch 172 Batch 1250 Loss 2.0454 Accuracy 0.9975\n",
      "Epoch 172 Batch 1300 Loss 2.0471 Accuracy 0.9975\n",
      "Epoch 172 Batch 1350 Loss 2.0435 Accuracy 0.9975\n",
      "Epoch 172 Batch 1400 Loss 2.0453 Accuracy 0.9975\n",
      "Epoch 172 Batch 1450 Loss 2.0400 Accuracy 0.9975\n",
      "Epoch 172 Batch 1500 Loss 2.0415 Accuracy 0.9975\n",
      "Epoch 172 Batch 1550 Loss 2.0434 Accuracy 0.9975\n",
      "Epoch 172 Batch 1600 Loss 2.0446 Accuracy 0.9975\n",
      "Epoch 172 Batch 1650 Loss 2.0463 Accuracy 0.9975\n",
      "Epoch 172 Batch 1700 Loss 2.0496 Accuracy 0.9975\n",
      "Epoch 172 Batch 1750 Loss 2.0475 Accuracy 0.9975\n",
      "Epoch 172 Batch 1800 Loss 2.0486 Accuracy 0.9975\n",
      "Epoch 172 Batch 1850 Loss 2.0451 Accuracy 0.9975\n",
      "Epoch 172 Batch 1900 Loss 2.0420 Accuracy 0.9975\n",
      "Epoch 172 Batch 1950 Loss 2.0358 Accuracy 0.9975\n",
      "Epoch 172 Batch 2000 Loss 2.0400 Accuracy 0.9975\n",
      "Epoch 172 Batch 2050 Loss 2.0442 Accuracy 0.9975\n",
      "Epoch 172 Batch 2100 Loss 2.0425 Accuracy 0.9975\n",
      "Epoch 172 Batch 2150 Loss 2.0436 Accuracy 0.9975\n",
      "Epoch 172 Batch 2200 Loss 2.0468 Accuracy 0.9975\n",
      "Epoch 172 Batch 2250 Loss 2.0488 Accuracy 0.9975\n",
      "Epoch 172 Batch 2300 Loss 2.0475 Accuracy 0.9975\n",
      "Epoch 172 Batch 2350 Loss 2.0477 Accuracy 0.9975\n",
      "Epoch 172 Batch 2400 Loss 2.0496 Accuracy 0.9975\n",
      "Epoch 172 Batch 2450 Loss 2.0506 Accuracy 0.9975\n",
      "Epoch 172 Batch 2500 Loss 2.0523 Accuracy 0.9975\n",
      "Epoch 172 Batch 2550 Loss 2.0516 Accuracy 0.9975\n",
      "Epoch 172 Batch 2600 Loss 2.0503 Accuracy 0.9975\n",
      "Epoch 172 Batch 2650 Loss 2.0491 Accuracy 0.9975\n",
      "Epoch 172 Loss 2.0502 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 195.9933180809021 secs\n",
      "\n",
      "Epoch 173 Batch 0 Loss 1.5196 Accuracy 0.9982\n",
      "Epoch 173 Batch 50 Loss 2.1220 Accuracy 0.9974\n",
      "Epoch 173 Batch 100 Loss 2.0891 Accuracy 0.9975\n",
      "Epoch 173 Batch 150 Loss 2.0981 Accuracy 0.9975\n",
      "Epoch 173 Batch 200 Loss 2.0532 Accuracy 0.9975\n",
      "Epoch 173 Batch 250 Loss 2.0493 Accuracy 0.9975\n",
      "Epoch 173 Batch 300 Loss 2.0449 Accuracy 0.9975\n",
      "Epoch 173 Batch 350 Loss 2.0477 Accuracy 0.9975\n",
      "Epoch 173 Batch 400 Loss 2.0489 Accuracy 0.9975\n",
      "Epoch 173 Batch 450 Loss 2.0656 Accuracy 0.9975\n",
      "Epoch 173 Batch 500 Loss 2.0560 Accuracy 0.9975\n",
      "Epoch 173 Batch 550 Loss 2.0655 Accuracy 0.9975\n",
      "Epoch 173 Batch 600 Loss 2.0783 Accuracy 0.9975\n",
      "Epoch 173 Batch 650 Loss 2.0731 Accuracy 0.9975\n",
      "Epoch 173 Batch 700 Loss 2.0673 Accuracy 0.9975\n",
      "Epoch 173 Batch 750 Loss 2.0665 Accuracy 0.9975\n",
      "Epoch 173 Batch 800 Loss 2.0548 Accuracy 0.9975\n",
      "Epoch 173 Batch 850 Loss 2.0604 Accuracy 0.9975\n",
      "Epoch 173 Batch 900 Loss 2.0601 Accuracy 0.9975\n",
      "Epoch 173 Batch 950 Loss 2.0644 Accuracy 0.9975\n",
      "Epoch 173 Batch 1000 Loss 2.0622 Accuracy 0.9975\n",
      "Epoch 173 Batch 1050 Loss 2.0568 Accuracy 0.9975\n",
      "Epoch 173 Batch 1100 Loss 2.0547 Accuracy 0.9975\n",
      "Epoch 173 Batch 1150 Loss 2.0473 Accuracy 0.9975\n",
      "Epoch 173 Batch 1200 Loss 2.0578 Accuracy 0.9975\n",
      "Epoch 173 Batch 1250 Loss 2.0505 Accuracy 0.9975\n",
      "Epoch 173 Batch 1300 Loss 2.0514 Accuracy 0.9975\n",
      "Epoch 173 Batch 1350 Loss 2.0480 Accuracy 0.9975\n",
      "Epoch 173 Batch 1400 Loss 2.0505 Accuracy 0.9975\n",
      "Epoch 173 Batch 1450 Loss 2.0452 Accuracy 0.9975\n",
      "Epoch 173 Batch 1500 Loss 2.0430 Accuracy 0.9975\n",
      "Epoch 173 Batch 1550 Loss 2.0433 Accuracy 0.9975\n",
      "Epoch 173 Batch 1600 Loss 2.0429 Accuracy 0.9975\n",
      "Epoch 173 Batch 1650 Loss 2.0437 Accuracy 0.9975\n",
      "Epoch 173 Batch 1700 Loss 2.0453 Accuracy 0.9975\n",
      "Epoch 173 Batch 1750 Loss 2.0410 Accuracy 0.9975\n",
      "Epoch 173 Batch 1800 Loss 2.0417 Accuracy 0.9975\n",
      "Epoch 173 Batch 1850 Loss 2.0364 Accuracy 0.9975\n",
      "Epoch 173 Batch 1900 Loss 2.0329 Accuracy 0.9975\n",
      "Epoch 173 Batch 1950 Loss 2.0272 Accuracy 0.9975\n",
      "Epoch 173 Batch 2000 Loss 2.0302 Accuracy 0.9975\n",
      "Epoch 173 Batch 2050 Loss 2.0332 Accuracy 0.9975\n",
      "Epoch 173 Batch 2100 Loss 2.0334 Accuracy 0.9975\n",
      "Epoch 173 Batch 2150 Loss 2.0345 Accuracy 0.9975\n",
      "Epoch 173 Batch 2200 Loss 2.0373 Accuracy 0.9975\n",
      "Epoch 173 Batch 2250 Loss 2.0397 Accuracy 0.9975\n",
      "Epoch 173 Batch 2300 Loss 2.0384 Accuracy 0.9975\n",
      "Epoch 173 Batch 2350 Loss 2.0391 Accuracy 0.9975\n",
      "Epoch 173 Batch 2400 Loss 2.0407 Accuracy 0.9975\n",
      "Epoch 173 Batch 2450 Loss 2.0420 Accuracy 0.9975\n",
      "Epoch 173 Batch 2500 Loss 2.0432 Accuracy 0.9975\n",
      "Epoch 173 Batch 2550 Loss 2.0415 Accuracy 0.9975\n",
      "Epoch 173 Batch 2600 Loss 2.0393 Accuracy 0.9975\n",
      "Epoch 173 Batch 2650 Loss 2.0376 Accuracy 0.9975\n",
      "Epoch 173 Loss 2.0401 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 195.98348999023438 secs\n",
      "\n",
      "Epoch 174 Batch 0 Loss 1.4219 Accuracy 0.9983\n",
      "Epoch 174 Batch 50 Loss 2.0827 Accuracy 0.9975\n",
      "Epoch 174 Batch 100 Loss 2.0889 Accuracy 0.9975\n",
      "Epoch 174 Batch 150 Loss 2.1036 Accuracy 0.9975\n",
      "Epoch 174 Batch 200 Loss 2.0377 Accuracy 0.9975\n",
      "Epoch 174 Batch 250 Loss 2.0269 Accuracy 0.9975\n",
      "Epoch 174 Batch 300 Loss 2.0197 Accuracy 0.9976\n",
      "Epoch 174 Batch 350 Loss 2.0203 Accuracy 0.9975\n",
      "Epoch 174 Batch 400 Loss 2.0161 Accuracy 0.9976\n",
      "Epoch 174 Batch 450 Loss 2.0404 Accuracy 0.9975\n",
      "Epoch 174 Batch 500 Loss 2.0372 Accuracy 0.9975\n",
      "Epoch 174 Batch 550 Loss 2.0452 Accuracy 0.9975\n",
      "Epoch 174 Batch 600 Loss 2.0552 Accuracy 0.9975\n",
      "Epoch 174 Batch 650 Loss 2.0563 Accuracy 0.9975\n",
      "Epoch 174 Batch 700 Loss 2.0528 Accuracy 0.9975\n",
      "Epoch 174 Batch 750 Loss 2.0559 Accuracy 0.9975\n",
      "Epoch 174 Batch 800 Loss 2.0451 Accuracy 0.9975\n",
      "Epoch 174 Batch 850 Loss 2.0504 Accuracy 0.9975\n",
      "Epoch 174 Batch 900 Loss 2.0503 Accuracy 0.9975\n",
      "Epoch 174 Batch 950 Loss 2.0516 Accuracy 0.9975\n",
      "Epoch 174 Batch 1000 Loss 2.0519 Accuracy 0.9975\n",
      "Epoch 174 Batch 1050 Loss 2.0436 Accuracy 0.9975\n",
      "Epoch 174 Batch 1100 Loss 2.0427 Accuracy 0.9975\n",
      "Epoch 174 Batch 1150 Loss 2.0357 Accuracy 0.9975\n",
      "Epoch 174 Batch 1200 Loss 2.0451 Accuracy 0.9975\n",
      "Epoch 174 Batch 1250 Loss 2.0399 Accuracy 0.9975\n",
      "Epoch 174 Batch 1300 Loss 2.0413 Accuracy 0.9975\n",
      "Epoch 174 Batch 1350 Loss 2.0390 Accuracy 0.9975\n",
      "Epoch 174 Batch 1400 Loss 2.0412 Accuracy 0.9975\n",
      "Epoch 174 Batch 1450 Loss 2.0387 Accuracy 0.9975\n",
      "Epoch 174 Batch 1500 Loss 2.0375 Accuracy 0.9975\n",
      "Epoch 174 Batch 1550 Loss 2.0401 Accuracy 0.9975\n",
      "Epoch 174 Batch 1600 Loss 2.0403 Accuracy 0.9975\n",
      "Epoch 174 Batch 1650 Loss 2.0425 Accuracy 0.9975\n",
      "Epoch 174 Batch 1700 Loss 2.0440 Accuracy 0.9975\n",
      "Epoch 174 Batch 1750 Loss 2.0406 Accuracy 0.9975\n",
      "Epoch 174 Batch 1800 Loss 2.0419 Accuracy 0.9975\n",
      "Epoch 174 Batch 1850 Loss 2.0372 Accuracy 0.9975\n",
      "Epoch 174 Batch 1900 Loss 2.0347 Accuracy 0.9975\n",
      "Epoch 174 Batch 1950 Loss 2.0283 Accuracy 0.9975\n",
      "Epoch 174 Batch 2000 Loss 2.0342 Accuracy 0.9975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174 Batch 2050 Loss 2.0388 Accuracy 0.9975\n",
      "Epoch 174 Batch 2100 Loss 2.0376 Accuracy 0.9975\n",
      "Epoch 174 Batch 2150 Loss 2.0399 Accuracy 0.9975\n",
      "Epoch 174 Batch 2200 Loss 2.0421 Accuracy 0.9975\n",
      "Epoch 174 Batch 2250 Loss 2.0430 Accuracy 0.9975\n",
      "Epoch 174 Batch 2300 Loss 2.0402 Accuracy 0.9975\n",
      "Epoch 174 Batch 2350 Loss 2.0398 Accuracy 0.9975\n",
      "Epoch 174 Batch 2400 Loss 2.0415 Accuracy 0.9975\n",
      "Epoch 174 Batch 2450 Loss 2.0431 Accuracy 0.9975\n",
      "Epoch 174 Batch 2500 Loss 2.0445 Accuracy 0.9975\n",
      "Epoch 174 Batch 2550 Loss 2.0439 Accuracy 0.9975\n",
      "Epoch 174 Batch 2600 Loss 2.0424 Accuracy 0.9975\n",
      "Epoch 174 Batch 2650 Loss 2.0409 Accuracy 0.9975\n",
      "Epoch 174 Loss 2.0417 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 196.31339597702026 secs\n",
      "\n",
      "Epoch 175 Batch 0 Loss 1.4113 Accuracy 0.9983\n",
      "Epoch 175 Batch 50 Loss 2.0526 Accuracy 0.9975\n",
      "Epoch 175 Batch 100 Loss 2.0310 Accuracy 0.9975\n",
      "Epoch 175 Batch 150 Loss 2.0549 Accuracy 0.9975\n",
      "Epoch 175 Batch 200 Loss 2.0119 Accuracy 0.9976\n",
      "Epoch 175 Batch 250 Loss 2.0144 Accuracy 0.9976\n",
      "Epoch 175 Batch 300 Loss 2.0122 Accuracy 0.9976\n",
      "Epoch 175 Batch 350 Loss 2.0235 Accuracy 0.9975\n",
      "Epoch 175 Batch 400 Loss 2.0220 Accuracy 0.9975\n",
      "Epoch 175 Batch 450 Loss 2.0527 Accuracy 0.9975\n",
      "Epoch 175 Batch 500 Loss 2.0486 Accuracy 0.9975\n",
      "Epoch 175 Batch 550 Loss 2.0544 Accuracy 0.9975\n",
      "Epoch 175 Batch 600 Loss 2.0673 Accuracy 0.9975\n",
      "Epoch 175 Batch 650 Loss 2.0669 Accuracy 0.9975\n",
      "Epoch 175 Batch 700 Loss 2.0648 Accuracy 0.9975\n",
      "Epoch 175 Batch 750 Loss 2.0641 Accuracy 0.9975\n",
      "Epoch 175 Batch 800 Loss 2.0556 Accuracy 0.9975\n",
      "Epoch 175 Batch 850 Loss 2.0593 Accuracy 0.9975\n",
      "Epoch 175 Batch 900 Loss 2.0553 Accuracy 0.9975\n",
      "Epoch 175 Batch 950 Loss 2.0555 Accuracy 0.9975\n",
      "Epoch 175 Batch 1000 Loss 2.0540 Accuracy 0.9975\n",
      "Epoch 175 Batch 1050 Loss 2.0478 Accuracy 0.9975\n",
      "Epoch 175 Batch 1100 Loss 2.0478 Accuracy 0.9975\n",
      "Epoch 175 Batch 1150 Loss 2.0424 Accuracy 0.9975\n",
      "Epoch 175 Batch 1200 Loss 2.0515 Accuracy 0.9975\n",
      "Epoch 175 Batch 1250 Loss 2.0478 Accuracy 0.9975\n",
      "Epoch 175 Batch 1300 Loss 2.0492 Accuracy 0.9975\n",
      "Epoch 175 Batch 1350 Loss 2.0462 Accuracy 0.9975\n",
      "Epoch 175 Batch 1400 Loss 2.0478 Accuracy 0.9975\n",
      "Epoch 175 Batch 1450 Loss 2.0444 Accuracy 0.9975\n",
      "Epoch 175 Batch 1500 Loss 2.0433 Accuracy 0.9975\n",
      "Epoch 175 Batch 1550 Loss 2.0449 Accuracy 0.9975\n",
      "Epoch 175 Batch 1600 Loss 2.0457 Accuracy 0.9975\n",
      "Epoch 175 Batch 1650 Loss 2.0460 Accuracy 0.9975\n",
      "Epoch 175 Batch 1700 Loss 2.0468 Accuracy 0.9975\n",
      "Epoch 175 Batch 1750 Loss 2.0426 Accuracy 0.9975\n",
      "Epoch 175 Batch 1800 Loss 2.0442 Accuracy 0.9975\n",
      "Epoch 175 Batch 1850 Loss 2.0392 Accuracy 0.9975\n",
      "Epoch 175 Batch 1900 Loss 2.0363 Accuracy 0.9975\n",
      "Epoch 175 Batch 1950 Loss 2.0304 Accuracy 0.9975\n",
      "Epoch 175 Batch 2000 Loss 2.0349 Accuracy 0.9975\n",
      "Epoch 175 Batch 2050 Loss 2.0402 Accuracy 0.9975\n",
      "Epoch 175 Batch 2100 Loss 2.0382 Accuracy 0.9975\n",
      "Epoch 175 Batch 2150 Loss 2.0397 Accuracy 0.9975\n",
      "Epoch 175 Batch 2200 Loss 2.0421 Accuracy 0.9975\n",
      "Epoch 175 Batch 2250 Loss 2.0437 Accuracy 0.9975\n",
      "Epoch 175 Batch 2300 Loss 2.0415 Accuracy 0.9975\n",
      "Epoch 175 Batch 2350 Loss 2.0416 Accuracy 0.9975\n",
      "Epoch 175 Batch 2400 Loss 2.0430 Accuracy 0.9975\n",
      "Epoch 175 Batch 2450 Loss 2.0444 Accuracy 0.9975\n",
      "Epoch 175 Batch 2500 Loss 2.0448 Accuracy 0.9975\n",
      "Epoch 175 Batch 2550 Loss 2.0440 Accuracy 0.9975\n",
      "Epoch 175 Batch 2600 Loss 2.0423 Accuracy 0.9975\n",
      "Epoch 175 Batch 2650 Loss 2.0405 Accuracy 0.9975\n",
      "Saving checkpoint for epoch 175 at ./checkpoints/train\\ckpt-36\n",
      "Epoch 175 Loss 2.0419 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 196.2101936340332 secs\n",
      "\n",
      "Epoch 176 Batch 0 Loss 1.4878 Accuracy 0.9981\n",
      "Epoch 176 Batch 50 Loss 2.1008 Accuracy 0.9974\n",
      "Epoch 176 Batch 100 Loss 2.0493 Accuracy 0.9975\n",
      "Epoch 176 Batch 150 Loss 2.0787 Accuracy 0.9975\n",
      "Epoch 176 Batch 200 Loss 2.0335 Accuracy 0.9975\n",
      "Epoch 176 Batch 250 Loss 2.0260 Accuracy 0.9975\n",
      "Epoch 176 Batch 300 Loss 2.0221 Accuracy 0.9975\n",
      "Epoch 176 Batch 350 Loss 2.0218 Accuracy 0.9975\n",
      "Epoch 176 Batch 400 Loss 2.0171 Accuracy 0.9976\n",
      "Epoch 176 Batch 450 Loss 2.0404 Accuracy 0.9975\n",
      "Epoch 176 Batch 500 Loss 2.0324 Accuracy 0.9975\n",
      "Epoch 176 Batch 550 Loss 2.0406 Accuracy 0.9975\n",
      "Epoch 176 Batch 600 Loss 2.0539 Accuracy 0.9975\n",
      "Epoch 176 Batch 650 Loss 2.0496 Accuracy 0.9975\n",
      "Epoch 176 Batch 700 Loss 2.0471 Accuracy 0.9975\n",
      "Epoch 176 Batch 750 Loss 2.0489 Accuracy 0.9975\n",
      "Epoch 176 Batch 800 Loss 2.0414 Accuracy 0.9975\n",
      "Epoch 176 Batch 850 Loss 2.0460 Accuracy 0.9975\n",
      "Epoch 176 Batch 900 Loss 2.0457 Accuracy 0.9975\n",
      "Epoch 176 Batch 950 Loss 2.0478 Accuracy 0.9975\n",
      "Epoch 176 Batch 1000 Loss 2.0455 Accuracy 0.9975\n",
      "Epoch 176 Batch 1050 Loss 2.0376 Accuracy 0.9975\n",
      "Epoch 176 Batch 1100 Loss 2.0359 Accuracy 0.9975\n",
      "Epoch 176 Batch 1150 Loss 2.0309 Accuracy 0.9975\n",
      "Epoch 176 Batch 1200 Loss 2.0382 Accuracy 0.9975\n",
      "Epoch 176 Batch 1250 Loss 2.0340 Accuracy 0.9975\n",
      "Epoch 176 Batch 1300 Loss 2.0354 Accuracy 0.9975\n",
      "Epoch 176 Batch 1350 Loss 2.0335 Accuracy 0.9975\n",
      "Epoch 176 Batch 1400 Loss 2.0352 Accuracy 0.9975\n",
      "Epoch 176 Batch 1450 Loss 2.0307 Accuracy 0.9975\n",
      "Epoch 176 Batch 1500 Loss 2.0293 Accuracy 0.9975\n",
      "Epoch 176 Batch 1550 Loss 2.0310 Accuracy 0.9975\n",
      "Epoch 176 Batch 1600 Loss 2.0325 Accuracy 0.9975\n",
      "Epoch 176 Batch 1650 Loss 2.0328 Accuracy 0.9975\n",
      "Epoch 176 Batch 1700 Loss 2.0352 Accuracy 0.9975\n",
      "Epoch 176 Batch 1750 Loss 2.0310 Accuracy 0.9975\n",
      "Epoch 176 Batch 1800 Loss 2.0336 Accuracy 0.9975\n",
      "Epoch 176 Batch 1850 Loss 2.0283 Accuracy 0.9975\n",
      "Epoch 176 Batch 1900 Loss 2.0257 Accuracy 0.9976\n",
      "Epoch 176 Batch 1950 Loss 2.0199 Accuracy 0.9976\n",
      "Epoch 176 Batch 2000 Loss 2.0249 Accuracy 0.9976\n",
      "Epoch 176 Batch 2050 Loss 2.0284 Accuracy 0.9975\n",
      "Epoch 176 Batch 2100 Loss 2.0276 Accuracy 0.9975\n",
      "Epoch 176 Batch 2150 Loss 2.0287 Accuracy 0.9975\n",
      "Epoch 176 Batch 2200 Loss 2.0337 Accuracy 0.9975\n",
      "Epoch 176 Batch 2250 Loss 2.0344 Accuracy 0.9975\n",
      "Epoch 176 Batch 2300 Loss 2.0322 Accuracy 0.9975\n",
      "Epoch 176 Batch 2350 Loss 2.0329 Accuracy 0.9975\n",
      "Epoch 176 Batch 2400 Loss 2.0341 Accuracy 0.9975\n",
      "Epoch 176 Batch 2450 Loss 2.0359 Accuracy 0.9975\n",
      "Epoch 176 Batch 2500 Loss 2.0367 Accuracy 0.9975\n",
      "Epoch 176 Batch 2550 Loss 2.0351 Accuracy 0.9975\n",
      "Epoch 176 Batch 2600 Loss 2.0332 Accuracy 0.9975\n",
      "Epoch 176 Batch 2650 Loss 2.0307 Accuracy 0.9975\n",
      "Epoch 176 Loss 2.0314 Accuracy 0.9975\n",
      "Time taken for 1 epoch: 197.3762547969818 secs\n",
      "\n",
      "Epoch 177 Batch 0 Loss 1.5287 Accuracy 0.9982\n",
      "Epoch 177 Batch 50 Loss 2.0459 Accuracy 0.9975\n",
      "Epoch 177 Batch 100 Loss 2.0495 Accuracy 0.9975\n",
      "Epoch 177 Batch 150 Loss 2.0633 Accuracy 0.9975\n",
      "Epoch 177 Batch 200 Loss 2.0151 Accuracy 0.9975\n",
      "Epoch 177 Batch 250 Loss 2.0115 Accuracy 0.9976\n",
      "Epoch 177 Batch 300 Loss 2.0142 Accuracy 0.9975\n",
      "Epoch 177 Batch 350 Loss 2.0083 Accuracy 0.9976\n",
      "Epoch 177 Batch 400 Loss 1.9999 Accuracy 0.9976\n",
      "Epoch 177 Batch 450 Loss 2.0215 Accuracy 0.9975\n",
      "Epoch 177 Batch 500 Loss 2.0064 Accuracy 0.9976\n",
      "Epoch 177 Batch 550 Loss 2.0175 Accuracy 0.9975\n",
      "Epoch 177 Batch 600 Loss 2.0301 Accuracy 0.9975\n",
      "Epoch 177 Batch 650 Loss 2.0265 Accuracy 0.9975\n",
      "Epoch 177 Batch 700 Loss 2.0252 Accuracy 0.9975\n",
      "Epoch 177 Batch 750 Loss 2.0224 Accuracy 0.9975\n",
      "Epoch 177 Batch 800 Loss 2.0119 Accuracy 0.9976\n",
      "Epoch 177 Batch 850 Loss 2.0115 Accuracy 0.9976\n",
      "Epoch 177 Batch 900 Loss 2.0141 Accuracy 0.9976\n",
      "Epoch 177 Batch 950 Loss 2.0180 Accuracy 0.9975\n",
      "Epoch 177 Batch 1000 Loss 2.0184 Accuracy 0.9976\n",
      "Epoch 177 Batch 1050 Loss 2.0122 Accuracy 0.9976\n",
      "Epoch 177 Batch 1100 Loss 2.0103 Accuracy 0.9976\n",
      "Epoch 177 Batch 1150 Loss 2.0040 Accuracy 0.9976\n",
      "Epoch 177 Batch 1200 Loss 2.0144 Accuracy 0.9976\n",
      "Epoch 177 Batch 1250 Loss 2.0132 Accuracy 0.9976\n",
      "Epoch 177 Batch 1300 Loss 2.0132 Accuracy 0.9976\n",
      "Epoch 177 Batch 1350 Loss 2.0105 Accuracy 0.9976\n",
      "Epoch 177 Batch 1400 Loss 2.0136 Accuracy 0.9976\n",
      "Epoch 177 Batch 1450 Loss 2.0105 Accuracy 0.9976\n",
      "Epoch 177 Batch 1500 Loss 2.0094 Accuracy 0.9976\n",
      "Epoch 177 Batch 1550 Loss 2.0113 Accuracy 0.9976\n",
      "Epoch 177 Batch 1600 Loss 2.0130 Accuracy 0.9976\n",
      "Epoch 177 Batch 1650 Loss 2.0156 Accuracy 0.9976\n",
      "Epoch 177 Batch 1700 Loss 2.0195 Accuracy 0.9976\n",
      "Epoch 177 Batch 1750 Loss 2.0156 Accuracy 0.9976\n",
      "Epoch 177 Batch 1800 Loss 2.0174 Accuracy 0.9976\n",
      "Epoch 177 Batch 1850 Loss 2.0134 Accuracy 0.9976\n",
      "Epoch 177 Batch 1900 Loss 2.0117 Accuracy 0.9976\n",
      "Epoch 177 Batch 1950 Loss 2.0056 Accuracy 0.9976\n",
      "Epoch 177 Batch 2000 Loss 2.0106 Accuracy 0.9976\n",
      "Epoch 177 Batch 2050 Loss 2.0145 Accuracy 0.9976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177 Batch 2100 Loss 2.0131 Accuracy 0.9976\n",
      "Epoch 177 Batch 2150 Loss 2.0144 Accuracy 0.9976\n",
      "Epoch 177 Batch 2200 Loss 2.0179 Accuracy 0.9976\n",
      "Epoch 177 Batch 2250 Loss 2.0186 Accuracy 0.9976\n",
      "Epoch 177 Batch 2300 Loss 2.0174 Accuracy 0.9976\n",
      "Epoch 177 Batch 2350 Loss 2.0166 Accuracy 0.9976\n",
      "Epoch 177 Batch 2400 Loss 2.0178 Accuracy 0.9976\n",
      "Epoch 177 Batch 2450 Loss 2.0206 Accuracy 0.9976\n",
      "Epoch 177 Batch 2500 Loss 2.0215 Accuracy 0.9976\n",
      "Epoch 177 Batch 2550 Loss 2.0216 Accuracy 0.9976\n",
      "Epoch 177 Batch 2600 Loss 2.0196 Accuracy 0.9976\n",
      "Epoch 177 Batch 2650 Loss 2.0185 Accuracy 0.9976\n",
      "Epoch 177 Loss 2.0193 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 196.97170686721802 secs\n",
      "\n",
      "Epoch 178 Batch 0 Loss 1.4004 Accuracy 0.9982\n",
      "Epoch 178 Batch 50 Loss 2.0850 Accuracy 0.9975\n",
      "Epoch 178 Batch 100 Loss 2.0649 Accuracy 0.9975\n",
      "Epoch 178 Batch 150 Loss 2.0707 Accuracy 0.9975\n",
      "Epoch 178 Batch 200 Loss 2.0111 Accuracy 0.9976\n",
      "Epoch 178 Batch 250 Loss 2.0007 Accuracy 0.9976\n",
      "Epoch 178 Batch 300 Loss 2.0040 Accuracy 0.9976\n",
      "Epoch 178 Batch 350 Loss 2.0008 Accuracy 0.9976\n",
      "Epoch 178 Batch 400 Loss 2.0002 Accuracy 0.9976\n",
      "Epoch 178 Batch 450 Loss 2.0299 Accuracy 0.9975\n",
      "Epoch 178 Batch 500 Loss 2.0209 Accuracy 0.9976\n",
      "Epoch 178 Batch 550 Loss 2.0276 Accuracy 0.9975\n",
      "Epoch 178 Batch 600 Loss 2.0399 Accuracy 0.9975\n",
      "Epoch 178 Batch 650 Loss 2.0391 Accuracy 0.9975\n",
      "Epoch 178 Batch 700 Loss 2.0359 Accuracy 0.9975\n",
      "Epoch 178 Batch 750 Loss 2.0360 Accuracy 0.9975\n",
      "Epoch 178 Batch 800 Loss 2.0268 Accuracy 0.9975\n",
      "Epoch 178 Batch 850 Loss 2.0322 Accuracy 0.9975\n",
      "Epoch 178 Batch 900 Loss 2.0359 Accuracy 0.9975\n",
      "Epoch 178 Batch 950 Loss 2.0394 Accuracy 0.9975\n",
      "Epoch 178 Batch 1000 Loss 2.0374 Accuracy 0.9975\n",
      "Epoch 178 Batch 1050 Loss 2.0291 Accuracy 0.9975\n",
      "Epoch 178 Batch 1100 Loss 2.0277 Accuracy 0.9975\n",
      "Epoch 178 Batch 1150 Loss 2.0233 Accuracy 0.9976\n",
      "Epoch 178 Batch 1200 Loss 2.0315 Accuracy 0.9975\n",
      "Epoch 178 Batch 1250 Loss 2.0277 Accuracy 0.9975\n",
      "Epoch 178 Batch 1300 Loss 2.0306 Accuracy 0.9975\n",
      "Epoch 178 Batch 1350 Loss 2.0271 Accuracy 0.9975\n",
      "Epoch 178 Batch 1400 Loss 2.0288 Accuracy 0.9975\n",
      "Epoch 178 Batch 1450 Loss 2.0260 Accuracy 0.9976\n",
      "Epoch 178 Batch 1500 Loss 2.0254 Accuracy 0.9976\n",
      "Epoch 178 Batch 1550 Loss 2.0268 Accuracy 0.9976\n",
      "Epoch 178 Batch 1600 Loss 2.0285 Accuracy 0.9975\n",
      "Epoch 178 Batch 1650 Loss 2.0307 Accuracy 0.9975\n",
      "Epoch 178 Batch 1700 Loss 2.0308 Accuracy 0.9975\n",
      "Epoch 178 Batch 1750 Loss 2.0272 Accuracy 0.9976\n",
      "Epoch 178 Batch 1800 Loss 2.0283 Accuracy 0.9976\n",
      "Epoch 178 Batch 1850 Loss 2.0249 Accuracy 0.9976\n",
      "Epoch 178 Batch 1900 Loss 2.0212 Accuracy 0.9976\n",
      "Epoch 178 Batch 1950 Loss 2.0144 Accuracy 0.9976\n",
      "Epoch 178 Batch 2000 Loss 2.0192 Accuracy 0.9976\n",
      "Epoch 178 Batch 2050 Loss 2.0249 Accuracy 0.9976\n",
      "Epoch 178 Batch 2100 Loss 2.0249 Accuracy 0.9976\n",
      "Epoch 178 Batch 2150 Loss 2.0255 Accuracy 0.9976\n",
      "Epoch 178 Batch 2200 Loss 2.0275 Accuracy 0.9976\n",
      "Epoch 178 Batch 2250 Loss 2.0301 Accuracy 0.9975\n",
      "Epoch 178 Batch 2300 Loss 2.0276 Accuracy 0.9976\n",
      "Epoch 178 Batch 2350 Loss 2.0259 Accuracy 0.9976\n",
      "Epoch 178 Batch 2400 Loss 2.0276 Accuracy 0.9976\n",
      "Epoch 178 Batch 2450 Loss 2.0285 Accuracy 0.9975\n",
      "Epoch 178 Batch 2500 Loss 2.0286 Accuracy 0.9975\n",
      "Epoch 178 Batch 2550 Loss 2.0275 Accuracy 0.9975\n",
      "Epoch 178 Batch 2600 Loss 2.0258 Accuracy 0.9976\n",
      "Epoch 178 Batch 2650 Loss 2.0244 Accuracy 0.9976\n",
      "Epoch 178 Loss 2.0257 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 198.01168775558472 secs\n",
      "\n",
      "Epoch 179 Batch 0 Loss 1.6112 Accuracy 0.9981\n",
      "Epoch 179 Batch 50 Loss 2.0452 Accuracy 0.9975\n",
      "Epoch 179 Batch 100 Loss 2.0509 Accuracy 0.9975\n",
      "Epoch 179 Batch 150 Loss 2.0663 Accuracy 0.9975\n",
      "Epoch 179 Batch 200 Loss 2.0141 Accuracy 0.9976\n",
      "Epoch 179 Batch 250 Loss 2.0023 Accuracy 0.9976\n",
      "Epoch 179 Batch 300 Loss 2.0005 Accuracy 0.9976\n",
      "Epoch 179 Batch 350 Loss 2.0109 Accuracy 0.9976\n",
      "Epoch 179 Batch 400 Loss 2.0098 Accuracy 0.9976\n",
      "Epoch 179 Batch 450 Loss 2.0330 Accuracy 0.9975\n",
      "Epoch 179 Batch 500 Loss 2.0300 Accuracy 0.9975\n",
      "Epoch 179 Batch 550 Loss 2.0384 Accuracy 0.9975\n",
      "Epoch 179 Batch 600 Loss 2.0500 Accuracy 0.9975\n",
      "Epoch 179 Batch 650 Loss 2.0486 Accuracy 0.9975\n",
      "Epoch 179 Batch 700 Loss 2.0428 Accuracy 0.9975\n",
      "Epoch 179 Batch 750 Loss 2.0445 Accuracy 0.9975\n",
      "Epoch 179 Batch 800 Loss 2.0332 Accuracy 0.9975\n",
      "Epoch 179 Batch 850 Loss 2.0356 Accuracy 0.9975\n",
      "Epoch 179 Batch 900 Loss 2.0366 Accuracy 0.9975\n",
      "Epoch 179 Batch 950 Loss 2.0401 Accuracy 0.9975\n",
      "Epoch 179 Batch 1000 Loss 2.0382 Accuracy 0.9975\n",
      "Epoch 179 Batch 1050 Loss 2.0284 Accuracy 0.9975\n",
      "Epoch 179 Batch 1100 Loss 2.0250 Accuracy 0.9975\n",
      "Epoch 179 Batch 1150 Loss 2.0184 Accuracy 0.9976\n",
      "Epoch 179 Batch 1200 Loss 2.0263 Accuracy 0.9975\n",
      "Epoch 179 Batch 1250 Loss 2.0243 Accuracy 0.9975\n",
      "Epoch 179 Batch 1300 Loss 2.0258 Accuracy 0.9975\n",
      "Epoch 179 Batch 1350 Loss 2.0236 Accuracy 0.9975\n",
      "Epoch 179 Batch 1400 Loss 2.0260 Accuracy 0.9975\n",
      "Epoch 179 Batch 1450 Loss 2.0215 Accuracy 0.9976\n",
      "Epoch 179 Batch 1500 Loss 2.0193 Accuracy 0.9976\n",
      "Epoch 179 Batch 1550 Loss 2.0211 Accuracy 0.9976\n",
      "Epoch 179 Batch 1600 Loss 2.0209 Accuracy 0.9976\n",
      "Epoch 179 Batch 1650 Loss 2.0204 Accuracy 0.9976\n",
      "Epoch 179 Batch 1700 Loss 2.0210 Accuracy 0.9976\n",
      "Epoch 179 Batch 1750 Loss 2.0165 Accuracy 0.9976\n",
      "Epoch 179 Batch 1800 Loss 2.0175 Accuracy 0.9976\n",
      "Epoch 179 Batch 1850 Loss 2.0135 Accuracy 0.9976\n",
      "Epoch 179 Batch 1900 Loss 2.0106 Accuracy 0.9976\n",
      "Epoch 179 Batch 1950 Loss 2.0046 Accuracy 0.9976\n",
      "Epoch 179 Batch 2000 Loss 2.0085 Accuracy 0.9976\n",
      "Epoch 179 Batch 2050 Loss 2.0137 Accuracy 0.9976\n",
      "Epoch 179 Batch 2100 Loss 2.0142 Accuracy 0.9976\n",
      "Epoch 179 Batch 2150 Loss 2.0156 Accuracy 0.9976\n",
      "Epoch 179 Batch 2200 Loss 2.0193 Accuracy 0.9976\n",
      "Epoch 179 Batch 2250 Loss 2.0214 Accuracy 0.9976\n",
      "Epoch 179 Batch 2300 Loss 2.0196 Accuracy 0.9976\n",
      "Epoch 179 Batch 2350 Loss 2.0194 Accuracy 0.9976\n",
      "Epoch 179 Batch 2400 Loss 2.0201 Accuracy 0.9976\n",
      "Epoch 179 Batch 2450 Loss 2.0206 Accuracy 0.9976\n",
      "Epoch 179 Batch 2500 Loss 2.0218 Accuracy 0.9975\n",
      "Epoch 179 Batch 2550 Loss 2.0212 Accuracy 0.9976\n",
      "Epoch 179 Batch 2600 Loss 2.0187 Accuracy 0.9976\n",
      "Epoch 179 Batch 2650 Loss 2.0165 Accuracy 0.9976\n",
      "Epoch 179 Loss 2.0171 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 197.01031947135925 secs\n",
      "\n",
      "Epoch 180 Batch 0 Loss 1.6221 Accuracy 0.9981\n",
      "Epoch 180 Batch 50 Loss 2.0517 Accuracy 0.9975\n",
      "Epoch 180 Batch 100 Loss 2.0305 Accuracy 0.9975\n",
      "Epoch 180 Batch 150 Loss 2.0457 Accuracy 0.9975\n",
      "Epoch 180 Batch 200 Loss 1.9924 Accuracy 0.9976\n",
      "Epoch 180 Batch 250 Loss 1.9901 Accuracy 0.9976\n",
      "Epoch 180 Batch 300 Loss 1.9890 Accuracy 0.9976\n",
      "Epoch 180 Batch 350 Loss 1.9887 Accuracy 0.9976\n",
      "Epoch 180 Batch 400 Loss 1.9927 Accuracy 0.9976\n",
      "Epoch 180 Batch 450 Loss 2.0194 Accuracy 0.9976\n",
      "Epoch 180 Batch 500 Loss 2.0111 Accuracy 0.9976\n",
      "Epoch 180 Batch 550 Loss 2.0228 Accuracy 0.9976\n",
      "Epoch 180 Batch 600 Loss 2.0337 Accuracy 0.9975\n",
      "Epoch 180 Batch 650 Loss 2.0329 Accuracy 0.9975\n",
      "Epoch 180 Batch 700 Loss 2.0339 Accuracy 0.9975\n",
      "Epoch 180 Batch 750 Loss 2.0345 Accuracy 0.9975\n",
      "Epoch 180 Batch 800 Loss 2.0204 Accuracy 0.9976\n",
      "Epoch 180 Batch 850 Loss 2.0251 Accuracy 0.9976\n",
      "Epoch 180 Batch 900 Loss 2.0269 Accuracy 0.9975\n",
      "Epoch 180 Batch 950 Loss 2.0343 Accuracy 0.9975\n",
      "Epoch 180 Batch 1000 Loss 2.0322 Accuracy 0.9975\n",
      "Epoch 180 Batch 1050 Loss 2.0228 Accuracy 0.9976\n",
      "Epoch 180 Batch 1100 Loss 2.0213 Accuracy 0.9976\n",
      "Epoch 180 Batch 1150 Loss 2.0147 Accuracy 0.9976\n",
      "Epoch 180 Batch 1200 Loss 2.0213 Accuracy 0.9976\n",
      "Epoch 180 Batch 1250 Loss 2.0164 Accuracy 0.9976\n",
      "Epoch 180 Batch 1300 Loss 2.0170 Accuracy 0.9976\n",
      "Epoch 180 Batch 1350 Loss 2.0146 Accuracy 0.9976\n",
      "Epoch 180 Batch 1400 Loss 2.0164 Accuracy 0.9976\n",
      "Epoch 180 Batch 1450 Loss 2.0142 Accuracy 0.9976\n",
      "Epoch 180 Batch 1500 Loss 2.0142 Accuracy 0.9976\n",
      "Epoch 180 Batch 1550 Loss 2.0166 Accuracy 0.9976\n",
      "Epoch 180 Batch 1600 Loss 2.0169 Accuracy 0.9976\n",
      "Epoch 180 Batch 1650 Loss 2.0176 Accuracy 0.9976\n",
      "Epoch 180 Batch 1700 Loss 2.0192 Accuracy 0.9976\n",
      "Epoch 180 Batch 1750 Loss 2.0142 Accuracy 0.9976\n",
      "Epoch 180 Batch 1800 Loss 2.0150 Accuracy 0.9976\n",
      "Epoch 180 Batch 1850 Loss 2.0113 Accuracy 0.9976\n",
      "Epoch 180 Batch 1900 Loss 2.0083 Accuracy 0.9976\n",
      "Epoch 180 Batch 1950 Loss 2.0021 Accuracy 0.9976\n",
      "Epoch 180 Batch 2000 Loss 2.0078 Accuracy 0.9976\n",
      "Epoch 180 Batch 2050 Loss 2.0126 Accuracy 0.9976\n",
      "Epoch 180 Batch 2100 Loss 2.0119 Accuracy 0.9976\n",
      "Epoch 180 Batch 2150 Loss 2.0133 Accuracy 0.9976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180 Batch 2200 Loss 2.0175 Accuracy 0.9976\n",
      "Epoch 180 Batch 2250 Loss 2.0186 Accuracy 0.9976\n",
      "Epoch 180 Batch 2300 Loss 2.0163 Accuracy 0.9976\n",
      "Epoch 180 Batch 2350 Loss 2.0171 Accuracy 0.9976\n",
      "Epoch 180 Batch 2400 Loss 2.0188 Accuracy 0.9976\n",
      "Epoch 180 Batch 2450 Loss 2.0208 Accuracy 0.9976\n",
      "Epoch 180 Batch 2500 Loss 2.0222 Accuracy 0.9976\n",
      "Epoch 180 Batch 2550 Loss 2.0206 Accuracy 0.9976\n",
      "Epoch 180 Batch 2600 Loss 2.0188 Accuracy 0.9976\n",
      "Epoch 180 Batch 2650 Loss 2.0171 Accuracy 0.9976\n",
      "Saving checkpoint for epoch 180 at ./checkpoints/train\\ckpt-37\n",
      "Epoch 180 Loss 2.0175 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 198.9031355381012 secs\n",
      "\n",
      "Epoch 181 Batch 0 Loss 1.3594 Accuracy 0.9984\n",
      "Epoch 181 Batch 50 Loss 2.0213 Accuracy 0.9976\n",
      "Epoch 181 Batch 100 Loss 2.0400 Accuracy 0.9975\n",
      "Epoch 181 Batch 150 Loss 2.0458 Accuracy 0.9975\n",
      "Epoch 181 Batch 200 Loss 2.0048 Accuracy 0.9976\n",
      "Epoch 181 Batch 250 Loss 1.9875 Accuracy 0.9976\n",
      "Epoch 181 Batch 300 Loss 2.0037 Accuracy 0.9976\n",
      "Epoch 181 Batch 350 Loss 1.9972 Accuracy 0.9976\n",
      "Epoch 181 Batch 400 Loss 2.0036 Accuracy 0.9976\n",
      "Epoch 181 Batch 450 Loss 2.0280 Accuracy 0.9976\n",
      "Epoch 181 Batch 500 Loss 2.0128 Accuracy 0.9976\n",
      "Epoch 181 Batch 550 Loss 2.0207 Accuracy 0.9976\n",
      "Epoch 181 Batch 600 Loss 2.0313 Accuracy 0.9976\n",
      "Epoch 181 Batch 650 Loss 2.0333 Accuracy 0.9976\n",
      "Epoch 181 Batch 700 Loss 2.0337 Accuracy 0.9976\n",
      "Epoch 181 Batch 750 Loss 2.0336 Accuracy 0.9976\n",
      "Epoch 181 Batch 800 Loss 2.0270 Accuracy 0.9976\n",
      "Epoch 181 Batch 850 Loss 2.0330 Accuracy 0.9976\n",
      "Epoch 181 Batch 900 Loss 2.0323 Accuracy 0.9976\n",
      "Epoch 181 Batch 950 Loss 2.0342 Accuracy 0.9976\n",
      "Epoch 181 Batch 1000 Loss 2.0314 Accuracy 0.9976\n",
      "Epoch 181 Batch 1050 Loss 2.0246 Accuracy 0.9976\n",
      "Epoch 181 Batch 1100 Loss 2.0252 Accuracy 0.9976\n",
      "Epoch 181 Batch 1150 Loss 2.0195 Accuracy 0.9976\n",
      "Epoch 181 Batch 1200 Loss 2.0259 Accuracy 0.9976\n",
      "Epoch 181 Batch 1250 Loss 2.0215 Accuracy 0.9976\n",
      "Epoch 181 Batch 1300 Loss 2.0231 Accuracy 0.9976\n",
      "Epoch 181 Batch 1350 Loss 2.0174 Accuracy 0.9976\n",
      "Epoch 181 Batch 1400 Loss 2.0220 Accuracy 0.9976\n",
      "Epoch 181 Batch 1450 Loss 2.0182 Accuracy 0.9976\n",
      "Epoch 181 Batch 1500 Loss 2.0169 Accuracy 0.9976\n",
      "Epoch 181 Batch 1550 Loss 2.0186 Accuracy 0.9976\n",
      "Epoch 181 Batch 1600 Loss 2.0185 Accuracy 0.9976\n",
      "Epoch 181 Batch 1650 Loss 2.0199 Accuracy 0.9976\n",
      "Epoch 181 Batch 1700 Loss 2.0212 Accuracy 0.9976\n",
      "Epoch 181 Batch 1750 Loss 2.0169 Accuracy 0.9976\n",
      "Epoch 181 Batch 1800 Loss 2.0187 Accuracy 0.9976\n",
      "Epoch 181 Batch 1850 Loss 2.0138 Accuracy 0.9976\n",
      "Epoch 181 Batch 1900 Loss 2.0107 Accuracy 0.9976\n",
      "Epoch 181 Batch 1950 Loss 2.0036 Accuracy 0.9976\n",
      "Epoch 181 Batch 2000 Loss 2.0078 Accuracy 0.9976\n",
      "Epoch 181 Batch 2050 Loss 2.0130 Accuracy 0.9976\n",
      "Epoch 181 Batch 2100 Loss 2.0123 Accuracy 0.9976\n",
      "Epoch 181 Batch 2150 Loss 2.0140 Accuracy 0.9976\n",
      "Epoch 181 Batch 2200 Loss 2.0172 Accuracy 0.9976\n",
      "Epoch 181 Batch 2250 Loss 2.0184 Accuracy 0.9976\n",
      "Epoch 181 Batch 2300 Loss 2.0165 Accuracy 0.9976\n",
      "Epoch 181 Batch 2350 Loss 2.0154 Accuracy 0.9976\n",
      "Epoch 181 Batch 2400 Loss 2.0166 Accuracy 0.9976\n",
      "Epoch 181 Batch 2450 Loss 2.0183 Accuracy 0.9976\n",
      "Epoch 181 Batch 2500 Loss 2.0198 Accuracy 0.9976\n",
      "Epoch 181 Batch 2550 Loss 2.0194 Accuracy 0.9976\n",
      "Epoch 181 Batch 2600 Loss 2.0182 Accuracy 0.9976\n",
      "Epoch 181 Batch 2650 Loss 2.0161 Accuracy 0.9976\n",
      "Epoch 181 Loss 2.0177 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 196.4668538570404 secs\n",
      "\n",
      "Epoch 182 Batch 0 Loss 1.5175 Accuracy 0.9982\n",
      "Epoch 182 Batch 50 Loss 2.0444 Accuracy 0.9975\n",
      "Epoch 182 Batch 100 Loss 2.0327 Accuracy 0.9975\n",
      "Epoch 182 Batch 150 Loss 2.0659 Accuracy 0.9975\n",
      "Epoch 182 Batch 200 Loss 1.9991 Accuracy 0.9976\n",
      "Epoch 182 Batch 250 Loss 1.9924 Accuracy 0.9976\n",
      "Epoch 182 Batch 300 Loss 1.9908 Accuracy 0.9976\n",
      "Epoch 182 Batch 350 Loss 1.9866 Accuracy 0.9976\n",
      "Epoch 182 Batch 400 Loss 1.9822 Accuracy 0.9976\n",
      "Epoch 182 Batch 450 Loss 2.0050 Accuracy 0.9976\n",
      "Epoch 182 Batch 500 Loss 1.9998 Accuracy 0.9976\n",
      "Epoch 182 Batch 550 Loss 2.0116 Accuracy 0.9976\n",
      "Epoch 182 Batch 600 Loss 2.0225 Accuracy 0.9976\n",
      "Epoch 182 Batch 650 Loss 2.0140 Accuracy 0.9976\n",
      "Epoch 182 Batch 700 Loss 2.0176 Accuracy 0.9976\n",
      "Epoch 182 Batch 750 Loss 2.0179 Accuracy 0.9976\n",
      "Epoch 182 Batch 800 Loss 2.0077 Accuracy 0.9976\n",
      "Epoch 182 Batch 850 Loss 2.0105 Accuracy 0.9976\n",
      "Epoch 182 Batch 900 Loss 2.0116 Accuracy 0.9976\n",
      "Epoch 182 Batch 950 Loss 2.0145 Accuracy 0.9976\n",
      "Epoch 182 Batch 1000 Loss 2.0109 Accuracy 0.9976\n",
      "Epoch 182 Batch 1050 Loss 2.0022 Accuracy 0.9976\n",
      "Epoch 182 Batch 1100 Loss 2.0039 Accuracy 0.9976\n",
      "Epoch 182 Batch 1150 Loss 1.9984 Accuracy 0.9976\n",
      "Epoch 182 Batch 1200 Loss 2.0105 Accuracy 0.9976\n",
      "Epoch 182 Batch 1250 Loss 2.0078 Accuracy 0.9976\n",
      "Epoch 182 Batch 1300 Loss 2.0079 Accuracy 0.9976\n",
      "Epoch 182 Batch 1350 Loss 2.0074 Accuracy 0.9976\n",
      "Epoch 182 Batch 1400 Loss 2.0094 Accuracy 0.9976\n",
      "Epoch 182 Batch 1450 Loss 2.0042 Accuracy 0.9976\n",
      "Epoch 182 Batch 1500 Loss 2.0022 Accuracy 0.9976\n",
      "Epoch 182 Batch 1550 Loss 2.0030 Accuracy 0.9976\n",
      "Epoch 182 Batch 1600 Loss 2.0035 Accuracy 0.9976\n",
      "Epoch 182 Batch 1650 Loss 2.0050 Accuracy 0.9976\n",
      "Epoch 182 Batch 1700 Loss 2.0087 Accuracy 0.9976\n",
      "Epoch 182 Batch 1750 Loss 2.0065 Accuracy 0.9976\n",
      "Epoch 182 Batch 1800 Loss 2.0081 Accuracy 0.9976\n",
      "Epoch 182 Batch 1850 Loss 2.0037 Accuracy 0.9976\n",
      "Epoch 182 Batch 1900 Loss 2.0028 Accuracy 0.9976\n",
      "Epoch 182 Batch 1950 Loss 1.9972 Accuracy 0.9976\n",
      "Epoch 182 Batch 2000 Loss 2.0014 Accuracy 0.9976\n",
      "Epoch 182 Batch 2050 Loss 2.0059 Accuracy 0.9976\n",
      "Epoch 182 Batch 2100 Loss 2.0057 Accuracy 0.9976\n",
      "Epoch 182 Batch 2150 Loss 2.0061 Accuracy 0.9976\n",
      "Epoch 182 Batch 2200 Loss 2.0092 Accuracy 0.9976\n",
      "Epoch 182 Batch 2250 Loss 2.0107 Accuracy 0.9976\n",
      "Epoch 182 Batch 2300 Loss 2.0077 Accuracy 0.9976\n",
      "Epoch 182 Batch 2350 Loss 2.0082 Accuracy 0.9976\n",
      "Epoch 182 Batch 2400 Loss 2.0084 Accuracy 0.9976\n",
      "Epoch 182 Batch 2450 Loss 2.0091 Accuracy 0.9976\n",
      "Epoch 182 Batch 2500 Loss 2.0113 Accuracy 0.9976\n",
      "Epoch 182 Batch 2550 Loss 2.0118 Accuracy 0.9976\n",
      "Epoch 182 Batch 2600 Loss 2.0098 Accuracy 0.9976\n",
      "Epoch 182 Batch 2650 Loss 2.0078 Accuracy 0.9976\n",
      "Epoch 182 Loss 2.0095 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 196.4600419998169 secs\n",
      "\n",
      "Epoch 183 Batch 0 Loss 1.5444 Accuracy 0.9980\n",
      "Epoch 183 Batch 50 Loss 2.0204 Accuracy 0.9975\n",
      "Epoch 183 Batch 100 Loss 2.0311 Accuracy 0.9975\n",
      "Epoch 183 Batch 150 Loss 2.0460 Accuracy 0.9975\n",
      "Epoch 183 Batch 200 Loss 1.9880 Accuracy 0.9976\n",
      "Epoch 183 Batch 250 Loss 1.9774 Accuracy 0.9976\n",
      "Epoch 183 Batch 300 Loss 1.9824 Accuracy 0.9976\n",
      "Epoch 183 Batch 350 Loss 1.9857 Accuracy 0.9976\n",
      "Epoch 183 Batch 400 Loss 1.9862 Accuracy 0.9976\n",
      "Epoch 183 Batch 450 Loss 2.0088 Accuracy 0.9976\n",
      "Epoch 183 Batch 500 Loss 2.0019 Accuracy 0.9976\n",
      "Epoch 183 Batch 550 Loss 2.0134 Accuracy 0.9976\n",
      "Epoch 183 Batch 600 Loss 2.0273 Accuracy 0.9975\n",
      "Epoch 183 Batch 650 Loss 2.0242 Accuracy 0.9975\n",
      "Epoch 183 Batch 700 Loss 2.0203 Accuracy 0.9975\n",
      "Epoch 183 Batch 750 Loss 2.0209 Accuracy 0.9975\n",
      "Epoch 183 Batch 800 Loss 2.0117 Accuracy 0.9976\n",
      "Epoch 183 Batch 850 Loss 2.0150 Accuracy 0.9976\n",
      "Epoch 183 Batch 900 Loss 2.0158 Accuracy 0.9976\n",
      "Epoch 183 Batch 950 Loss 2.0170 Accuracy 0.9976\n",
      "Epoch 183 Batch 1000 Loss 2.0131 Accuracy 0.9976\n",
      "Epoch 183 Batch 1050 Loss 2.0069 Accuracy 0.9976\n",
      "Epoch 183 Batch 1100 Loss 2.0074 Accuracy 0.9976\n",
      "Epoch 183 Batch 1150 Loss 2.0013 Accuracy 0.9976\n",
      "Epoch 183 Batch 1200 Loss 2.0110 Accuracy 0.9976\n",
      "Epoch 183 Batch 1250 Loss 2.0067 Accuracy 0.9976\n",
      "Epoch 183 Batch 1300 Loss 2.0080 Accuracy 0.9976\n",
      "Epoch 183 Batch 1350 Loss 2.0055 Accuracy 0.9976\n",
      "Epoch 183 Batch 1400 Loss 2.0071 Accuracy 0.9976\n",
      "Epoch 183 Batch 1450 Loss 2.0023 Accuracy 0.9976\n",
      "Epoch 183 Batch 1500 Loss 2.0007 Accuracy 0.9976\n",
      "Epoch 183 Batch 1550 Loss 2.0019 Accuracy 0.9976\n",
      "Epoch 183 Batch 1600 Loss 2.0035 Accuracy 0.9976\n",
      "Epoch 183 Batch 1650 Loss 2.0048 Accuracy 0.9976\n",
      "Epoch 183 Batch 1700 Loss 2.0081 Accuracy 0.9976\n",
      "Epoch 183 Batch 1750 Loss 2.0046 Accuracy 0.9976\n",
      "Epoch 183 Batch 1800 Loss 2.0064 Accuracy 0.9976\n",
      "Epoch 183 Batch 1850 Loss 2.0024 Accuracy 0.9976\n",
      "Epoch 183 Batch 1900 Loss 2.0001 Accuracy 0.9976\n",
      "Epoch 183 Batch 1950 Loss 1.9947 Accuracy 0.9976\n",
      "Epoch 183 Batch 2000 Loss 1.9983 Accuracy 0.9976\n",
      "Epoch 183 Batch 2050 Loss 2.0024 Accuracy 0.9976\n",
      "Epoch 183 Batch 2100 Loss 2.0031 Accuracy 0.9976\n",
      "Epoch 183 Batch 2150 Loss 2.0044 Accuracy 0.9976\n",
      "Epoch 183 Batch 2200 Loss 2.0078 Accuracy 0.9976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183 Batch 2250 Loss 2.0091 Accuracy 0.9976\n",
      "Epoch 183 Batch 2300 Loss 2.0075 Accuracy 0.9976\n",
      "Epoch 183 Batch 2350 Loss 2.0068 Accuracy 0.9976\n",
      "Epoch 183 Batch 2400 Loss 2.0091 Accuracy 0.9976\n",
      "Epoch 183 Batch 2450 Loss 2.0113 Accuracy 0.9976\n",
      "Epoch 183 Batch 2500 Loss 2.0133 Accuracy 0.9976\n",
      "Epoch 183 Batch 2550 Loss 2.0135 Accuracy 0.9976\n",
      "Epoch 183 Batch 2600 Loss 2.0110 Accuracy 0.9976\n",
      "Epoch 183 Batch 2650 Loss 2.0097 Accuracy 0.9976\n",
      "Epoch 183 Loss 2.0111 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 196.393230676651 secs\n",
      "\n",
      "Epoch 184 Batch 0 Loss 1.6634 Accuracy 0.9979\n",
      "Epoch 184 Batch 50 Loss 2.0259 Accuracy 0.9975\n",
      "Epoch 184 Batch 100 Loss 2.0304 Accuracy 0.9976\n",
      "Epoch 184 Batch 150 Loss 2.0536 Accuracy 0.9975\n",
      "Epoch 184 Batch 200 Loss 1.9889 Accuracy 0.9976\n",
      "Epoch 184 Batch 250 Loss 1.9853 Accuracy 0.9976\n",
      "Epoch 184 Batch 300 Loss 1.9961 Accuracy 0.9976\n",
      "Epoch 184 Batch 350 Loss 1.9981 Accuracy 0.9976\n",
      "Epoch 184 Batch 400 Loss 1.9946 Accuracy 0.9976\n",
      "Epoch 184 Batch 450 Loss 2.0185 Accuracy 0.9976\n",
      "Epoch 184 Batch 500 Loss 2.0108 Accuracy 0.9976\n",
      "Epoch 184 Batch 550 Loss 2.0219 Accuracy 0.9976\n",
      "Epoch 184 Batch 600 Loss 2.0350 Accuracy 0.9975\n",
      "Epoch 184 Batch 650 Loss 2.0331 Accuracy 0.9976\n",
      "Epoch 184 Batch 700 Loss 2.0326 Accuracy 0.9976\n",
      "Epoch 184 Batch 750 Loss 2.0313 Accuracy 0.9976\n",
      "Epoch 184 Batch 800 Loss 2.0170 Accuracy 0.9976\n",
      "Epoch 184 Batch 850 Loss 2.0174 Accuracy 0.9976\n",
      "Epoch 184 Batch 900 Loss 2.0189 Accuracy 0.9976\n",
      "Epoch 184 Batch 950 Loss 2.0229 Accuracy 0.9976\n",
      "Epoch 184 Batch 1000 Loss 2.0187 Accuracy 0.9976\n",
      "Epoch 184 Batch 1050 Loss 2.0111 Accuracy 0.9976\n",
      "Epoch 184 Batch 1100 Loss 2.0100 Accuracy 0.9976\n",
      "Epoch 184 Batch 1150 Loss 2.0053 Accuracy 0.9976\n",
      "Epoch 184 Batch 1200 Loss 2.0157 Accuracy 0.9976\n",
      "Epoch 184 Batch 1250 Loss 2.0130 Accuracy 0.9976\n",
      "Epoch 184 Batch 1300 Loss 2.0124 Accuracy 0.9976\n",
      "Epoch 184 Batch 1350 Loss 2.0104 Accuracy 0.9976\n",
      "Epoch 184 Batch 1400 Loss 2.0111 Accuracy 0.9976\n",
      "Epoch 184 Batch 1450 Loss 2.0073 Accuracy 0.9976\n",
      "Epoch 184 Batch 1500 Loss 2.0066 Accuracy 0.9976\n",
      "Epoch 184 Batch 1550 Loss 2.0084 Accuracy 0.9976\n",
      "Epoch 184 Batch 1600 Loss 2.0097 Accuracy 0.9976\n",
      "Epoch 184 Batch 1650 Loss 2.0100 Accuracy 0.9976\n",
      "Epoch 184 Batch 1700 Loss 2.0110 Accuracy 0.9976\n",
      "Epoch 184 Batch 1750 Loss 2.0080 Accuracy 0.9976\n",
      "Epoch 184 Batch 1800 Loss 2.0084 Accuracy 0.9976\n",
      "Epoch 184 Batch 1850 Loss 2.0041 Accuracy 0.9976\n",
      "Epoch 184 Batch 1900 Loss 2.0010 Accuracy 0.9976\n",
      "Epoch 184 Batch 1950 Loss 1.9953 Accuracy 0.9976\n",
      "Epoch 184 Batch 2000 Loss 1.9997 Accuracy 0.9976\n",
      "Epoch 184 Batch 2050 Loss 2.0048 Accuracy 0.9976\n",
      "Epoch 184 Batch 2100 Loss 2.0028 Accuracy 0.9976\n",
      "Epoch 184 Batch 2150 Loss 2.0048 Accuracy 0.9976\n",
      "Epoch 184 Batch 2200 Loss 2.0075 Accuracy 0.9976\n",
      "Epoch 184 Batch 2250 Loss 2.0099 Accuracy 0.9976\n",
      "Epoch 184 Batch 2300 Loss 2.0084 Accuracy 0.9976\n",
      "Epoch 184 Batch 2350 Loss 2.0083 Accuracy 0.9976\n",
      "Epoch 184 Batch 2400 Loss 2.0088 Accuracy 0.9976\n",
      "Epoch 184 Batch 2450 Loss 2.0100 Accuracy 0.9976\n",
      "Epoch 184 Batch 2500 Loss 2.0111 Accuracy 0.9976\n",
      "Epoch 184 Batch 2550 Loss 2.0107 Accuracy 0.9976\n",
      "Epoch 184 Batch 2600 Loss 2.0084 Accuracy 0.9976\n",
      "Epoch 184 Batch 2650 Loss 2.0070 Accuracy 0.9976\n",
      "Epoch 184 Loss 2.0085 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 196.349760055542 secs\n",
      "\n",
      "Epoch 185 Batch 0 Loss 1.7972 Accuracy 0.9978\n",
      "Epoch 185 Batch 50 Loss 2.0583 Accuracy 0.9975\n",
      "Epoch 185 Batch 100 Loss 2.0461 Accuracy 0.9975\n",
      "Epoch 185 Batch 150 Loss 2.0599 Accuracy 0.9975\n",
      "Epoch 185 Batch 200 Loss 2.0131 Accuracy 0.9976\n",
      "Epoch 185 Batch 250 Loss 1.9932 Accuracy 0.9976\n",
      "Epoch 185 Batch 300 Loss 1.9924 Accuracy 0.9976\n",
      "Epoch 185 Batch 350 Loss 1.9882 Accuracy 0.9976\n",
      "Epoch 185 Batch 400 Loss 1.9853 Accuracy 0.9976\n",
      "Epoch 185 Batch 450 Loss 2.0108 Accuracy 0.9976\n",
      "Epoch 185 Batch 500 Loss 2.0052 Accuracy 0.9976\n",
      "Epoch 185 Batch 550 Loss 2.0241 Accuracy 0.9976\n",
      "Epoch 185 Batch 600 Loss 2.0345 Accuracy 0.9975\n",
      "Epoch 185 Batch 650 Loss 2.0301 Accuracy 0.9975\n",
      "Epoch 185 Batch 700 Loss 2.0262 Accuracy 0.9975\n",
      "Epoch 185 Batch 750 Loss 2.0296 Accuracy 0.9975\n",
      "Epoch 185 Batch 800 Loss 2.0195 Accuracy 0.9976\n",
      "Epoch 185 Batch 850 Loss 2.0218 Accuracy 0.9976\n",
      "Epoch 185 Batch 900 Loss 2.0230 Accuracy 0.9976\n",
      "Epoch 185 Batch 950 Loss 2.0269 Accuracy 0.9975\n",
      "Epoch 185 Batch 1000 Loss 2.0229 Accuracy 0.9976\n",
      "Epoch 185 Batch 1050 Loss 2.0157 Accuracy 0.9976\n",
      "Epoch 185 Batch 1100 Loss 2.0159 Accuracy 0.9976\n",
      "Epoch 185 Batch 1150 Loss 2.0097 Accuracy 0.9976\n",
      "Epoch 185 Batch 1200 Loss 2.0170 Accuracy 0.9976\n",
      "Epoch 185 Batch 1250 Loss 2.0103 Accuracy 0.9976\n",
      "Epoch 185 Batch 1300 Loss 2.0113 Accuracy 0.9976\n",
      "Epoch 185 Batch 1350 Loss 2.0104 Accuracy 0.9976\n",
      "Epoch 185 Batch 1400 Loss 2.0126 Accuracy 0.9976\n",
      "Epoch 185 Batch 1450 Loss 2.0104 Accuracy 0.9976\n",
      "Epoch 185 Batch 1500 Loss 2.0089 Accuracy 0.9976\n",
      "Epoch 185 Batch 1550 Loss 2.0098 Accuracy 0.9976\n",
      "Epoch 185 Batch 1600 Loss 2.0090 Accuracy 0.9976\n",
      "Epoch 185 Batch 1650 Loss 2.0106 Accuracy 0.9976\n",
      "Epoch 185 Batch 1700 Loss 2.0120 Accuracy 0.9976\n",
      "Epoch 185 Batch 1750 Loss 2.0075 Accuracy 0.9976\n",
      "Epoch 185 Batch 1800 Loss 2.0088 Accuracy 0.9976\n",
      "Epoch 185 Batch 1850 Loss 2.0046 Accuracy 0.9976\n",
      "Epoch 185 Batch 1900 Loss 2.0005 Accuracy 0.9976\n",
      "Epoch 185 Batch 1950 Loss 1.9930 Accuracy 0.9976\n",
      "Epoch 185 Batch 2000 Loss 1.9962 Accuracy 0.9976\n",
      "Epoch 185 Batch 2050 Loss 2.0010 Accuracy 0.9976\n",
      "Epoch 185 Batch 2100 Loss 2.0017 Accuracy 0.9976\n",
      "Epoch 185 Batch 2150 Loss 2.0039 Accuracy 0.9976\n",
      "Epoch 185 Batch 2200 Loss 2.0073 Accuracy 0.9976\n",
      "Epoch 185 Batch 2250 Loss 2.0089 Accuracy 0.9976\n",
      "Epoch 185 Batch 2300 Loss 2.0056 Accuracy 0.9976\n",
      "Epoch 185 Batch 2350 Loss 2.0062 Accuracy 0.9976\n",
      "Epoch 185 Batch 2400 Loss 2.0082 Accuracy 0.9976\n",
      "Epoch 185 Batch 2450 Loss 2.0096 Accuracy 0.9976\n",
      "Epoch 185 Batch 2500 Loss 2.0109 Accuracy 0.9976\n",
      "Epoch 185 Batch 2550 Loss 2.0098 Accuracy 0.9976\n",
      "Epoch 185 Batch 2600 Loss 2.0079 Accuracy 0.9976\n",
      "Epoch 185 Batch 2650 Loss 2.0061 Accuracy 0.9976\n",
      "Saving checkpoint for epoch 185 at ./checkpoints/train\\ckpt-38\n",
      "Epoch 185 Loss 2.0070 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 197.0033311843872 secs\n",
      "\n",
      "Epoch 186 Batch 0 Loss 1.5417 Accuracy 0.9983\n",
      "Epoch 186 Batch 50 Loss 2.0181 Accuracy 0.9975\n",
      "Epoch 186 Batch 100 Loss 1.9925 Accuracy 0.9976\n",
      "Epoch 186 Batch 150 Loss 2.0315 Accuracy 0.9975\n",
      "Epoch 186 Batch 200 Loss 1.9844 Accuracy 0.9976\n",
      "Epoch 186 Batch 250 Loss 1.9722 Accuracy 0.9976\n",
      "Epoch 186 Batch 300 Loss 1.9739 Accuracy 0.9976\n",
      "Epoch 186 Batch 350 Loss 1.9748 Accuracy 0.9976\n",
      "Epoch 186 Batch 400 Loss 1.9723 Accuracy 0.9976\n",
      "Epoch 186 Batch 450 Loss 1.9984 Accuracy 0.9976\n",
      "Epoch 186 Batch 500 Loss 1.9917 Accuracy 0.9976\n",
      "Epoch 186 Batch 550 Loss 2.0026 Accuracy 0.9976\n",
      "Epoch 186 Batch 600 Loss 2.0172 Accuracy 0.9976\n",
      "Epoch 186 Batch 650 Loss 2.0144 Accuracy 0.9976\n",
      "Epoch 186 Batch 700 Loss 2.0127 Accuracy 0.9976\n",
      "Epoch 186 Batch 750 Loss 2.0151 Accuracy 0.9976\n",
      "Epoch 186 Batch 800 Loss 2.0035 Accuracy 0.9976\n",
      "Epoch 186 Batch 850 Loss 2.0056 Accuracy 0.9976\n",
      "Epoch 186 Batch 900 Loss 2.0047 Accuracy 0.9976\n",
      "Epoch 186 Batch 950 Loss 2.0123 Accuracy 0.9976\n",
      "Epoch 186 Batch 1000 Loss 2.0117 Accuracy 0.9976\n",
      "Epoch 186 Batch 1050 Loss 2.0067 Accuracy 0.9976\n",
      "Epoch 186 Batch 1100 Loss 2.0038 Accuracy 0.9976\n",
      "Epoch 186 Batch 1150 Loss 1.9992 Accuracy 0.9976\n",
      "Epoch 186 Batch 1200 Loss 2.0096 Accuracy 0.9976\n",
      "Epoch 186 Batch 1250 Loss 2.0039 Accuracy 0.9976\n",
      "Epoch 186 Batch 1300 Loss 2.0067 Accuracy 0.9976\n",
      "Epoch 186 Batch 1350 Loss 2.0035 Accuracy 0.9976\n",
      "Epoch 186 Batch 1400 Loss 2.0052 Accuracy 0.9976\n",
      "Epoch 186 Batch 1450 Loss 2.0005 Accuracy 0.9976\n",
      "Epoch 186 Batch 1500 Loss 1.9993 Accuracy 0.9976\n",
      "Epoch 186 Batch 1550 Loss 2.0016 Accuracy 0.9976\n",
      "Epoch 186 Batch 1600 Loss 2.0025 Accuracy 0.9976\n",
      "Epoch 186 Batch 1650 Loss 2.0038 Accuracy 0.9976\n",
      "Epoch 186 Batch 1700 Loss 2.0037 Accuracy 0.9976\n",
      "Epoch 186 Batch 1750 Loss 1.9996 Accuracy 0.9976\n",
      "Epoch 186 Batch 1800 Loss 2.0009 Accuracy 0.9976\n",
      "Epoch 186 Batch 1850 Loss 1.9965 Accuracy 0.9976\n",
      "Epoch 186 Batch 1900 Loss 1.9938 Accuracy 0.9976\n",
      "Epoch 186 Batch 1950 Loss 1.9874 Accuracy 0.9976\n",
      "Epoch 186 Batch 2000 Loss 1.9912 Accuracy 0.9976\n",
      "Epoch 186 Batch 2050 Loss 1.9952 Accuracy 0.9976\n",
      "Epoch 186 Batch 2100 Loss 1.9938 Accuracy 0.9976\n",
      "Epoch 186 Batch 2150 Loss 1.9947 Accuracy 0.9976\n",
      "Epoch 186 Batch 2200 Loss 1.9960 Accuracy 0.9976\n",
      "Epoch 186 Batch 2250 Loss 1.9980 Accuracy 0.9976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186 Batch 2300 Loss 1.9954 Accuracy 0.9976\n",
      "Epoch 186 Batch 2350 Loss 1.9951 Accuracy 0.9976\n",
      "Epoch 186 Batch 2400 Loss 1.9961 Accuracy 0.9976\n",
      "Epoch 186 Batch 2450 Loss 1.9978 Accuracy 0.9976\n",
      "Epoch 186 Batch 2500 Loss 1.9984 Accuracy 0.9976\n",
      "Epoch 186 Batch 2550 Loss 1.9972 Accuracy 0.9976\n",
      "Epoch 186 Batch 2600 Loss 1.9965 Accuracy 0.9976\n",
      "Epoch 186 Batch 2650 Loss 1.9955 Accuracy 0.9976\n",
      "Epoch 186 Loss 1.9972 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 196.69695711135864 secs\n",
      "\n",
      "Epoch 187 Batch 0 Loss 1.5070 Accuracy 0.9982\n",
      "Epoch 187 Batch 50 Loss 2.0116 Accuracy 0.9976\n",
      "Epoch 187 Batch 100 Loss 2.0267 Accuracy 0.9975\n",
      "Epoch 187 Batch 150 Loss 2.0445 Accuracy 0.9975\n",
      "Epoch 187 Batch 200 Loss 1.9841 Accuracy 0.9976\n",
      "Epoch 187 Batch 250 Loss 1.9699 Accuracy 0.9976\n",
      "Epoch 187 Batch 300 Loss 1.9695 Accuracy 0.9976\n",
      "Epoch 187 Batch 350 Loss 1.9715 Accuracy 0.9976\n",
      "Epoch 187 Batch 400 Loss 1.9733 Accuracy 0.9976\n",
      "Epoch 187 Batch 450 Loss 1.9992 Accuracy 0.9976\n",
      "Epoch 187 Batch 500 Loss 1.9866 Accuracy 0.9976\n",
      "Epoch 187 Batch 550 Loss 1.9970 Accuracy 0.9976\n",
      "Epoch 187 Batch 600 Loss 2.0097 Accuracy 0.9976\n",
      "Epoch 187 Batch 650 Loss 2.0108 Accuracy 0.9976\n",
      "Epoch 187 Batch 700 Loss 2.0116 Accuracy 0.9976\n",
      "Epoch 187 Batch 750 Loss 2.0140 Accuracy 0.9976\n",
      "Epoch 187 Batch 800 Loss 2.0061 Accuracy 0.9976\n",
      "Epoch 187 Batch 850 Loss 2.0091 Accuracy 0.9976\n",
      "Epoch 187 Batch 900 Loss 2.0082 Accuracy 0.9976\n",
      "Epoch 187 Batch 950 Loss 2.0111 Accuracy 0.9976\n",
      "Epoch 187 Batch 1000 Loss 2.0112 Accuracy 0.9976\n",
      "Epoch 187 Batch 1050 Loss 2.0054 Accuracy 0.9976\n",
      "Epoch 187 Batch 1100 Loss 2.0048 Accuracy 0.9976\n",
      "Epoch 187 Batch 1150 Loss 1.9971 Accuracy 0.9976\n",
      "Epoch 187 Batch 1200 Loss 2.0040 Accuracy 0.9976\n",
      "Epoch 187 Batch 1250 Loss 2.0004 Accuracy 0.9976\n",
      "Epoch 187 Batch 1300 Loss 2.0006 Accuracy 0.9976\n",
      "Epoch 187 Batch 1350 Loss 1.9976 Accuracy 0.9976\n",
      "Epoch 187 Batch 1400 Loss 1.9996 Accuracy 0.9976\n",
      "Epoch 187 Batch 1450 Loss 1.9939 Accuracy 0.9976\n",
      "Epoch 187 Batch 1500 Loss 1.9922 Accuracy 0.9976\n",
      "Epoch 187 Batch 1550 Loss 1.9934 Accuracy 0.9976\n",
      "Epoch 187 Batch 1600 Loss 1.9943 Accuracy 0.9976\n",
      "Epoch 187 Batch 1650 Loss 1.9960 Accuracy 0.9976\n",
      "Epoch 187 Batch 1700 Loss 1.9980 Accuracy 0.9976\n",
      "Epoch 187 Batch 1750 Loss 1.9943 Accuracy 0.9976\n",
      "Epoch 187 Batch 1800 Loss 1.9949 Accuracy 0.9976\n",
      "Epoch 187 Batch 1850 Loss 1.9907 Accuracy 0.9976\n",
      "Epoch 187 Batch 1900 Loss 1.9880 Accuracy 0.9976\n",
      "Epoch 187 Batch 1950 Loss 1.9814 Accuracy 0.9976\n",
      "Epoch 187 Batch 2000 Loss 1.9858 Accuracy 0.9976\n",
      "Epoch 187 Batch 2050 Loss 1.9901 Accuracy 0.9976\n",
      "Epoch 187 Batch 2100 Loss 1.9874 Accuracy 0.9976\n",
      "Epoch 187 Batch 2150 Loss 1.9902 Accuracy 0.9976\n",
      "Epoch 187 Batch 2200 Loss 1.9943 Accuracy 0.9976\n",
      "Epoch 187 Batch 2250 Loss 1.9971 Accuracy 0.9976\n",
      "Epoch 187 Batch 2300 Loss 1.9955 Accuracy 0.9976\n",
      "Epoch 187 Batch 2350 Loss 1.9967 Accuracy 0.9976\n",
      "Epoch 187 Batch 2400 Loss 1.9977 Accuracy 0.9976\n",
      "Epoch 187 Batch 2450 Loss 1.9991 Accuracy 0.9976\n",
      "Epoch 187 Batch 2500 Loss 2.0003 Accuracy 0.9976\n",
      "Epoch 187 Batch 2550 Loss 1.9987 Accuracy 0.9976\n",
      "Epoch 187 Batch 2600 Loss 1.9977 Accuracy 0.9976\n",
      "Epoch 187 Batch 2650 Loss 1.9955 Accuracy 0.9976\n",
      "Epoch 187 Loss 1.9970 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 197.30299019813538 secs\n",
      "\n",
      "Epoch 188 Batch 0 Loss 1.2363 Accuracy 0.9986\n",
      "Epoch 188 Batch 50 Loss 2.0384 Accuracy 0.9975\n",
      "Epoch 188 Batch 100 Loss 2.0241 Accuracy 0.9975\n",
      "Epoch 188 Batch 150 Loss 2.0546 Accuracy 0.9975\n",
      "Epoch 188 Batch 200 Loss 1.9939 Accuracy 0.9976\n",
      "Epoch 188 Batch 250 Loss 1.9854 Accuracy 0.9976\n",
      "Epoch 188 Batch 300 Loss 1.9821 Accuracy 0.9976\n",
      "Epoch 188 Batch 350 Loss 1.9778 Accuracy 0.9976\n",
      "Epoch 188 Batch 400 Loss 1.9744 Accuracy 0.9976\n",
      "Epoch 188 Batch 450 Loss 2.0024 Accuracy 0.9976\n",
      "Epoch 188 Batch 500 Loss 1.9986 Accuracy 0.9976\n",
      "Epoch 188 Batch 550 Loss 2.0087 Accuracy 0.9976\n",
      "Epoch 188 Batch 600 Loss 2.0188 Accuracy 0.9976\n",
      "Epoch 188 Batch 650 Loss 2.0154 Accuracy 0.9976\n",
      "Epoch 188 Batch 700 Loss 2.0134 Accuracy 0.9976\n",
      "Epoch 188 Batch 750 Loss 2.0119 Accuracy 0.9976\n",
      "Epoch 188 Batch 800 Loss 2.0015 Accuracy 0.9976\n",
      "Epoch 188 Batch 850 Loss 2.0064 Accuracy 0.9976\n",
      "Epoch 188 Batch 900 Loss 2.0071 Accuracy 0.9976\n",
      "Epoch 188 Batch 950 Loss 2.0110 Accuracy 0.9976\n",
      "Epoch 188 Batch 1000 Loss 2.0079 Accuracy 0.9976\n",
      "Epoch 188 Batch 1050 Loss 1.9996 Accuracy 0.9976\n",
      "Epoch 188 Batch 1100 Loss 1.9983 Accuracy 0.9976\n",
      "Epoch 188 Batch 1150 Loss 1.9918 Accuracy 0.9976\n",
      "Epoch 188 Batch 1200 Loss 2.0003 Accuracy 0.9976\n",
      "Epoch 188 Batch 1250 Loss 1.9962 Accuracy 0.9976\n",
      "Epoch 188 Batch 1300 Loss 1.9965 Accuracy 0.9976\n",
      "Epoch 188 Batch 1350 Loss 1.9923 Accuracy 0.9976\n",
      "Epoch 188 Batch 1400 Loss 1.9944 Accuracy 0.9976\n",
      "Epoch 188 Batch 1450 Loss 1.9905 Accuracy 0.9976\n",
      "Epoch 188 Batch 1500 Loss 1.9898 Accuracy 0.9976\n",
      "Epoch 188 Batch 1550 Loss 1.9933 Accuracy 0.9976\n",
      "Epoch 188 Batch 1600 Loss 1.9922 Accuracy 0.9976\n",
      "Epoch 188 Batch 1650 Loss 1.9924 Accuracy 0.9976\n",
      "Epoch 188 Batch 1700 Loss 1.9949 Accuracy 0.9976\n",
      "Epoch 188 Batch 1750 Loss 1.9916 Accuracy 0.9976\n",
      "Epoch 188 Batch 1800 Loss 1.9921 Accuracy 0.9976\n",
      "Epoch 188 Batch 1850 Loss 1.9880 Accuracy 0.9976\n",
      "Epoch 188 Batch 1900 Loss 1.9866 Accuracy 0.9976\n",
      "Epoch 188 Batch 1950 Loss 1.9802 Accuracy 0.9976\n",
      "Epoch 188 Batch 2000 Loss 1.9845 Accuracy 0.9976\n",
      "Epoch 188 Batch 2050 Loss 1.9890 Accuracy 0.9976\n",
      "Epoch 188 Batch 2100 Loss 1.9881 Accuracy 0.9976\n",
      "Epoch 188 Batch 2150 Loss 1.9911 Accuracy 0.9976\n",
      "Epoch 188 Batch 2200 Loss 1.9941 Accuracy 0.9976\n",
      "Epoch 188 Batch 2250 Loss 1.9943 Accuracy 0.9976\n",
      "Epoch 188 Batch 2300 Loss 1.9921 Accuracy 0.9976\n",
      "Epoch 188 Batch 2350 Loss 1.9926 Accuracy 0.9976\n",
      "Epoch 188 Batch 2400 Loss 1.9942 Accuracy 0.9976\n",
      "Epoch 188 Batch 2450 Loss 1.9957 Accuracy 0.9976\n",
      "Epoch 188 Batch 2500 Loss 1.9972 Accuracy 0.9976\n",
      "Epoch 188 Batch 2550 Loss 1.9964 Accuracy 0.9976\n",
      "Epoch 188 Batch 2600 Loss 1.9950 Accuracy 0.9976\n",
      "Epoch 188 Batch 2650 Loss 1.9932 Accuracy 0.9976\n",
      "Epoch 188 Loss 1.9943 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 197.10659265518188 secs\n",
      "\n",
      "Epoch 189 Batch 0 Loss 1.3555 Accuracy 0.9983\n",
      "Epoch 189 Batch 50 Loss 2.0334 Accuracy 0.9975\n",
      "Epoch 189 Batch 100 Loss 2.0211 Accuracy 0.9975\n",
      "Epoch 189 Batch 150 Loss 2.0504 Accuracy 0.9975\n",
      "Epoch 189 Batch 200 Loss 1.9872 Accuracy 0.9976\n",
      "Epoch 189 Batch 250 Loss 1.9766 Accuracy 0.9976\n",
      "Epoch 189 Batch 300 Loss 1.9762 Accuracy 0.9976\n",
      "Epoch 189 Batch 350 Loss 1.9723 Accuracy 0.9976\n",
      "Epoch 189 Batch 400 Loss 1.9745 Accuracy 0.9976\n",
      "Epoch 189 Batch 450 Loss 1.9972 Accuracy 0.9976\n",
      "Epoch 189 Batch 500 Loss 1.9928 Accuracy 0.9976\n",
      "Epoch 189 Batch 550 Loss 2.0034 Accuracy 0.9976\n",
      "Epoch 189 Batch 600 Loss 2.0173 Accuracy 0.9976\n",
      "Epoch 189 Batch 650 Loss 2.0149 Accuracy 0.9976\n",
      "Epoch 189 Batch 700 Loss 2.0129 Accuracy 0.9976\n",
      "Epoch 189 Batch 750 Loss 2.0138 Accuracy 0.9976\n",
      "Epoch 189 Batch 800 Loss 2.0047 Accuracy 0.9976\n",
      "Epoch 189 Batch 850 Loss 2.0081 Accuracy 0.9976\n",
      "Epoch 189 Batch 900 Loss 2.0079 Accuracy 0.9976\n",
      "Epoch 189 Batch 950 Loss 2.0098 Accuracy 0.9976\n",
      "Epoch 189 Batch 1000 Loss 2.0084 Accuracy 0.9976\n",
      "Epoch 189 Batch 1050 Loss 1.9993 Accuracy 0.9976\n",
      "Epoch 189 Batch 1100 Loss 1.9972 Accuracy 0.9976\n",
      "Epoch 189 Batch 1150 Loss 1.9894 Accuracy 0.9976\n",
      "Epoch 189 Batch 1200 Loss 1.9966 Accuracy 0.9976\n",
      "Epoch 189 Batch 1250 Loss 1.9931 Accuracy 0.9976\n",
      "Epoch 189 Batch 1300 Loss 1.9953 Accuracy 0.9976\n",
      "Epoch 189 Batch 1350 Loss 1.9919 Accuracy 0.9976\n",
      "Epoch 189 Batch 1400 Loss 1.9937 Accuracy 0.9976\n",
      "Epoch 189 Batch 1450 Loss 1.9878 Accuracy 0.9976\n",
      "Epoch 189 Batch 1500 Loss 1.9873 Accuracy 0.9976\n",
      "Epoch 189 Batch 1550 Loss 1.9908 Accuracy 0.9976\n",
      "Epoch 189 Batch 1600 Loss 1.9910 Accuracy 0.9976\n",
      "Epoch 189 Batch 1650 Loss 1.9913 Accuracy 0.9976\n",
      "Epoch 189 Batch 1700 Loss 1.9920 Accuracy 0.9976\n",
      "Epoch 189 Batch 1750 Loss 1.9878 Accuracy 0.9976\n",
      "Epoch 189 Batch 1800 Loss 1.9905 Accuracy 0.9976\n",
      "Epoch 189 Batch 1850 Loss 1.9848 Accuracy 0.9976\n",
      "Epoch 189 Batch 1900 Loss 1.9822 Accuracy 0.9976\n",
      "Epoch 189 Batch 1950 Loss 1.9761 Accuracy 0.9976\n",
      "Epoch 189 Batch 2000 Loss 1.9805 Accuracy 0.9976\n",
      "Epoch 189 Batch 2050 Loss 1.9839 Accuracy 0.9976\n",
      "Epoch 189 Batch 2100 Loss 1.9829 Accuracy 0.9976\n",
      "Epoch 189 Batch 2150 Loss 1.9844 Accuracy 0.9976\n",
      "Epoch 189 Batch 2200 Loss 1.9871 Accuracy 0.9976\n",
      "Epoch 189 Batch 2250 Loss 1.9896 Accuracy 0.9976\n",
      "Epoch 189 Batch 2300 Loss 1.9877 Accuracy 0.9976\n",
      "Epoch 189 Batch 2350 Loss 1.9882 Accuracy 0.9976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189 Batch 2400 Loss 1.9894 Accuracy 0.9976\n",
      "Epoch 189 Batch 2450 Loss 1.9917 Accuracy 0.9976\n",
      "Epoch 189 Batch 2500 Loss 1.9941 Accuracy 0.9976\n",
      "Epoch 189 Batch 2550 Loss 1.9930 Accuracy 0.9976\n",
      "Epoch 189 Batch 2600 Loss 1.9914 Accuracy 0.9976\n",
      "Epoch 189 Batch 2650 Loss 1.9901 Accuracy 0.9976\n",
      "Epoch 189 Loss 1.9914 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 198.0801773071289 secs\n",
      "\n",
      "Epoch 190 Batch 0 Loss 1.3720 Accuracy 0.9983\n",
      "Epoch 190 Batch 50 Loss 2.0324 Accuracy 0.9976\n",
      "Epoch 190 Batch 100 Loss 2.0166 Accuracy 0.9976\n",
      "Epoch 190 Batch 150 Loss 2.0240 Accuracy 0.9975\n",
      "Epoch 190 Batch 200 Loss 1.9692 Accuracy 0.9976\n",
      "Epoch 190 Batch 250 Loss 1.9659 Accuracy 0.9976\n",
      "Epoch 190 Batch 300 Loss 1.9605 Accuracy 0.9976\n",
      "Epoch 190 Batch 350 Loss 1.9552 Accuracy 0.9976\n",
      "Epoch 190 Batch 400 Loss 1.9521 Accuracy 0.9976\n",
      "Epoch 190 Batch 450 Loss 1.9862 Accuracy 0.9976\n",
      "Epoch 190 Batch 500 Loss 1.9809 Accuracy 0.9976\n",
      "Epoch 190 Batch 550 Loss 1.9905 Accuracy 0.9976\n",
      "Epoch 190 Batch 600 Loss 2.0032 Accuracy 0.9976\n",
      "Epoch 190 Batch 650 Loss 2.0012 Accuracy 0.9976\n",
      "Epoch 190 Batch 700 Loss 1.9989 Accuracy 0.9976\n",
      "Epoch 190 Batch 750 Loss 1.9984 Accuracy 0.9976\n",
      "Epoch 190 Batch 800 Loss 1.9870 Accuracy 0.9976\n",
      "Epoch 190 Batch 850 Loss 1.9890 Accuracy 0.9976\n",
      "Epoch 190 Batch 900 Loss 1.9871 Accuracy 0.9976\n",
      "Epoch 190 Batch 950 Loss 1.9903 Accuracy 0.9976\n",
      "Epoch 190 Batch 1000 Loss 1.9878 Accuracy 0.9976\n",
      "Epoch 190 Batch 1050 Loss 1.9814 Accuracy 0.9976\n",
      "Epoch 190 Batch 1100 Loss 1.9808 Accuracy 0.9976\n",
      "Epoch 190 Batch 1150 Loss 1.9747 Accuracy 0.9976\n",
      "Epoch 190 Batch 1200 Loss 1.9829 Accuracy 0.9976\n",
      "Epoch 190 Batch 1250 Loss 1.9782 Accuracy 0.9976\n",
      "Epoch 190 Batch 1300 Loss 1.9791 Accuracy 0.9976\n",
      "Epoch 190 Batch 1350 Loss 1.9762 Accuracy 0.9976\n",
      "Epoch 190 Batch 1400 Loss 1.9771 Accuracy 0.9976\n",
      "Epoch 190 Batch 1450 Loss 1.9737 Accuracy 0.9976\n",
      "Epoch 190 Batch 1500 Loss 1.9737 Accuracy 0.9976\n",
      "Epoch 190 Batch 1550 Loss 1.9777 Accuracy 0.9976\n",
      "Epoch 190 Batch 1600 Loss 1.9784 Accuracy 0.9976\n",
      "Epoch 190 Batch 1650 Loss 1.9795 Accuracy 0.9976\n",
      "Epoch 190 Batch 1700 Loss 1.9803 Accuracy 0.9976\n",
      "Epoch 190 Batch 1750 Loss 1.9770 Accuracy 0.9976\n",
      "Epoch 190 Batch 1800 Loss 1.9798 Accuracy 0.9976\n",
      "Epoch 190 Batch 1850 Loss 1.9738 Accuracy 0.9976\n",
      "Epoch 190 Batch 1900 Loss 1.9700 Accuracy 0.9976\n",
      "Epoch 190 Batch 1950 Loss 1.9643 Accuracy 0.9976\n",
      "Epoch 190 Batch 2000 Loss 1.9693 Accuracy 0.9976\n",
      "Epoch 190 Batch 2050 Loss 1.9739 Accuracy 0.9976\n",
      "Epoch 190 Batch 2100 Loss 1.9746 Accuracy 0.9976\n",
      "Epoch 190 Batch 2150 Loss 1.9772 Accuracy 0.9976\n",
      "Epoch 190 Batch 2200 Loss 1.9810 Accuracy 0.9976\n",
      "Epoch 190 Batch 2250 Loss 1.9835 Accuracy 0.9976\n",
      "Epoch 190 Batch 2300 Loss 1.9811 Accuracy 0.9976\n",
      "Epoch 190 Batch 2350 Loss 1.9809 Accuracy 0.9976\n",
      "Epoch 190 Batch 2400 Loss 1.9821 Accuracy 0.9976\n",
      "Epoch 190 Batch 2450 Loss 1.9839 Accuracy 0.9976\n",
      "Epoch 190 Batch 2500 Loss 1.9854 Accuracy 0.9976\n",
      "Epoch 190 Batch 2550 Loss 1.9847 Accuracy 0.9976\n",
      "Epoch 190 Batch 2600 Loss 1.9829 Accuracy 0.9976\n",
      "Epoch 190 Batch 2650 Loss 1.9808 Accuracy 0.9976\n",
      "Saving checkpoint for epoch 190 at ./checkpoints/train\\ckpt-39\n",
      "Epoch 190 Loss 1.9808 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 196.6169409751892 secs\n",
      "\n",
      "Epoch 191 Batch 0 Loss 1.7786 Accuracy 0.9979\n",
      "Epoch 191 Batch 50 Loss 1.9927 Accuracy 0.9976\n",
      "Epoch 191 Batch 100 Loss 2.0145 Accuracy 0.9976\n",
      "Epoch 191 Batch 150 Loss 2.0356 Accuracy 0.9975\n",
      "Epoch 191 Batch 200 Loss 1.9763 Accuracy 0.9976\n",
      "Epoch 191 Batch 250 Loss 1.9700 Accuracy 0.9976\n",
      "Epoch 191 Batch 300 Loss 1.9665 Accuracy 0.9976\n",
      "Epoch 191 Batch 350 Loss 1.9692 Accuracy 0.9976\n",
      "Epoch 191 Batch 400 Loss 1.9748 Accuracy 0.9976\n",
      "Epoch 191 Batch 450 Loss 1.9918 Accuracy 0.9976\n",
      "Epoch 191 Batch 500 Loss 1.9854 Accuracy 0.9976\n",
      "Epoch 191 Batch 550 Loss 1.9946 Accuracy 0.9976\n",
      "Epoch 191 Batch 600 Loss 2.0044 Accuracy 0.9976\n",
      "Epoch 191 Batch 650 Loss 2.0016 Accuracy 0.9976\n",
      "Epoch 191 Batch 700 Loss 2.0006 Accuracy 0.9976\n",
      "Epoch 191 Batch 750 Loss 2.0020 Accuracy 0.9976\n",
      "Epoch 191 Batch 800 Loss 1.9897 Accuracy 0.9976\n",
      "Epoch 191 Batch 850 Loss 1.9926 Accuracy 0.9976\n",
      "Epoch 191 Batch 900 Loss 1.9934 Accuracy 0.9976\n",
      "Epoch 191 Batch 950 Loss 1.9961 Accuracy 0.9976\n",
      "Epoch 191 Batch 1000 Loss 1.9935 Accuracy 0.9976\n",
      "Epoch 191 Batch 1050 Loss 1.9867 Accuracy 0.9976\n",
      "Epoch 191 Batch 1100 Loss 1.9859 Accuracy 0.9976\n",
      "Epoch 191 Batch 1150 Loss 1.9784 Accuracy 0.9976\n",
      "Epoch 191 Batch 1200 Loss 1.9840 Accuracy 0.9976\n",
      "Epoch 191 Batch 1250 Loss 1.9803 Accuracy 0.9976\n",
      "Epoch 191 Batch 1300 Loss 1.9831 Accuracy 0.9976\n",
      "Epoch 191 Batch 1350 Loss 1.9785 Accuracy 0.9976\n",
      "Epoch 191 Batch 1400 Loss 1.9814 Accuracy 0.9976\n",
      "Epoch 191 Batch 1450 Loss 1.9767 Accuracy 0.9976\n",
      "Epoch 191 Batch 1500 Loss 1.9756 Accuracy 0.9976\n",
      "Epoch 191 Batch 1550 Loss 1.9772 Accuracy 0.9976\n",
      "Epoch 191 Batch 1600 Loss 1.9771 Accuracy 0.9976\n",
      "Epoch 191 Batch 1650 Loss 1.9761 Accuracy 0.9976\n",
      "Epoch 191 Batch 1700 Loss 1.9780 Accuracy 0.9976\n",
      "Epoch 191 Batch 1750 Loss 1.9742 Accuracy 0.9976\n",
      "Epoch 191 Batch 1800 Loss 1.9774 Accuracy 0.9976\n",
      "Epoch 191 Batch 1850 Loss 1.9730 Accuracy 0.9976\n",
      "Epoch 191 Batch 1900 Loss 1.9710 Accuracy 0.9976\n",
      "Epoch 191 Batch 1950 Loss 1.9655 Accuracy 0.9976\n",
      "Epoch 191 Batch 2000 Loss 1.9709 Accuracy 0.9976\n",
      "Epoch 191 Batch 2050 Loss 1.9759 Accuracy 0.9976\n",
      "Epoch 191 Batch 2100 Loss 1.9750 Accuracy 0.9976\n",
      "Epoch 191 Batch 2150 Loss 1.9762 Accuracy 0.9976\n",
      "Epoch 191 Batch 2200 Loss 1.9806 Accuracy 0.9976\n",
      "Epoch 191 Batch 2250 Loss 1.9821 Accuracy 0.9976\n",
      "Epoch 191 Batch 2300 Loss 1.9796 Accuracy 0.9976\n",
      "Epoch 191 Batch 2350 Loss 1.9796 Accuracy 0.9976\n",
      "Epoch 191 Batch 2400 Loss 1.9801 Accuracy 0.9976\n",
      "Epoch 191 Batch 2450 Loss 1.9815 Accuracy 0.9976\n",
      "Epoch 191 Batch 2500 Loss 1.9835 Accuracy 0.9976\n",
      "Epoch 191 Batch 2550 Loss 1.9824 Accuracy 0.9976\n",
      "Epoch 191 Batch 2600 Loss 1.9821 Accuracy 0.9976\n",
      "Epoch 191 Batch 2650 Loss 1.9810 Accuracy 0.9976\n",
      "Epoch 191 Loss 1.9820 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 198.25970125198364 secs\n",
      "\n",
      "Epoch 192 Batch 0 Loss 1.2932 Accuracy 0.9983\n",
      "Epoch 192 Batch 50 Loss 1.9619 Accuracy 0.9976\n",
      "Epoch 192 Batch 100 Loss 2.0008 Accuracy 0.9976\n",
      "Epoch 192 Batch 150 Loss 2.0134 Accuracy 0.9976\n",
      "Epoch 192 Batch 200 Loss 1.9697 Accuracy 0.9976\n",
      "Epoch 192 Batch 250 Loss 1.9565 Accuracy 0.9976\n",
      "Epoch 192 Batch 300 Loss 1.9582 Accuracy 0.9976\n",
      "Epoch 192 Batch 350 Loss 1.9571 Accuracy 0.9976\n",
      "Epoch 192 Batch 400 Loss 1.9529 Accuracy 0.9976\n",
      "Epoch 192 Batch 450 Loss 1.9760 Accuracy 0.9976\n",
      "Epoch 192 Batch 500 Loss 1.9666 Accuracy 0.9976\n",
      "Epoch 192 Batch 550 Loss 1.9802 Accuracy 0.9976\n",
      "Epoch 192 Batch 600 Loss 1.9927 Accuracy 0.9976\n",
      "Epoch 192 Batch 650 Loss 1.9926 Accuracy 0.9976\n",
      "Epoch 192 Batch 700 Loss 1.9893 Accuracy 0.9976\n",
      "Epoch 192 Batch 750 Loss 1.9910 Accuracy 0.9976\n",
      "Epoch 192 Batch 800 Loss 1.9843 Accuracy 0.9976\n",
      "Epoch 192 Batch 850 Loss 1.9899 Accuracy 0.9976\n",
      "Epoch 192 Batch 900 Loss 1.9904 Accuracy 0.9976\n",
      "Epoch 192 Batch 950 Loss 1.9946 Accuracy 0.9976\n",
      "Epoch 192 Batch 1000 Loss 1.9915 Accuracy 0.9976\n",
      "Epoch 192 Batch 1050 Loss 1.9835 Accuracy 0.9976\n",
      "Epoch 192 Batch 1100 Loss 1.9824 Accuracy 0.9976\n",
      "Epoch 192 Batch 1150 Loss 1.9774 Accuracy 0.9976\n",
      "Epoch 192 Batch 1200 Loss 1.9875 Accuracy 0.9976\n",
      "Epoch 192 Batch 1250 Loss 1.9844 Accuracy 0.9976\n",
      "Epoch 192 Batch 1300 Loss 1.9866 Accuracy 0.9976\n",
      "Epoch 192 Batch 1350 Loss 1.9844 Accuracy 0.9976\n",
      "Epoch 192 Batch 1400 Loss 1.9854 Accuracy 0.9976\n",
      "Epoch 192 Batch 1450 Loss 1.9817 Accuracy 0.9976\n",
      "Epoch 192 Batch 1500 Loss 1.9802 Accuracy 0.9976\n",
      "Epoch 192 Batch 1550 Loss 1.9820 Accuracy 0.9976\n",
      "Epoch 192 Batch 1600 Loss 1.9844 Accuracy 0.9976\n",
      "Epoch 192 Batch 1650 Loss 1.9858 Accuracy 0.9976\n",
      "Epoch 192 Batch 1700 Loss 1.9874 Accuracy 0.9976\n",
      "Epoch 192 Batch 1750 Loss 1.9853 Accuracy 0.9976\n",
      "Epoch 192 Batch 1800 Loss 1.9860 Accuracy 0.9976\n",
      "Epoch 192 Batch 1850 Loss 1.9801 Accuracy 0.9976\n",
      "Epoch 192 Batch 1900 Loss 1.9771 Accuracy 0.9976\n",
      "Epoch 192 Batch 1950 Loss 1.9723 Accuracy 0.9976\n",
      "Epoch 192 Batch 2000 Loss 1.9759 Accuracy 0.9976\n",
      "Epoch 192 Batch 2050 Loss 1.9812 Accuracy 0.9976\n",
      "Epoch 192 Batch 2100 Loss 1.9803 Accuracy 0.9976\n",
      "Epoch 192 Batch 2150 Loss 1.9820 Accuracy 0.9976\n",
      "Epoch 192 Batch 2200 Loss 1.9838 Accuracy 0.9976\n",
      "Epoch 192 Batch 2250 Loss 1.9847 Accuracy 0.9976\n",
      "Epoch 192 Batch 2300 Loss 1.9811 Accuracy 0.9976\n",
      "Epoch 192 Batch 2350 Loss 1.9805 Accuracy 0.9976\n",
      "Epoch 192 Batch 2400 Loss 1.9815 Accuracy 0.9976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192 Batch 2450 Loss 1.9826 Accuracy 0.9976\n",
      "Epoch 192 Batch 2500 Loss 1.9837 Accuracy 0.9976\n",
      "Epoch 192 Batch 2550 Loss 1.9819 Accuracy 0.9976\n",
      "Epoch 192 Batch 2600 Loss 1.9796 Accuracy 0.9976\n",
      "Epoch 192 Batch 2650 Loss 1.9773 Accuracy 0.9976\n",
      "Epoch 192 Loss 1.9791 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 217.37322354316711 secs\n",
      "\n",
      "Epoch 193 Batch 0 Loss 1.3369 Accuracy 0.9985\n",
      "Epoch 193 Batch 50 Loss 1.9633 Accuracy 0.9976\n",
      "Epoch 193 Batch 100 Loss 1.9832 Accuracy 0.9976\n",
      "Epoch 193 Batch 150 Loss 1.9914 Accuracy 0.9976\n",
      "Epoch 193 Batch 200 Loss 1.9340 Accuracy 0.9977\n",
      "Epoch 193 Batch 250 Loss 1.9346 Accuracy 0.9977\n",
      "Epoch 193 Batch 300 Loss 1.9358 Accuracy 0.9977\n",
      "Epoch 193 Batch 350 Loss 1.9278 Accuracy 0.9977\n",
      "Epoch 193 Batch 400 Loss 1.9318 Accuracy 0.9977\n",
      "Epoch 193 Batch 450 Loss 1.9555 Accuracy 0.9976\n",
      "Epoch 193 Batch 500 Loss 1.9491 Accuracy 0.9977\n",
      "Epoch 193 Batch 550 Loss 1.9619 Accuracy 0.9976\n",
      "Epoch 193 Batch 600 Loss 1.9756 Accuracy 0.9976\n",
      "Epoch 193 Batch 650 Loss 1.9739 Accuracy 0.9976\n",
      "Epoch 193 Batch 700 Loss 1.9734 Accuracy 0.9976\n",
      "Epoch 193 Batch 750 Loss 1.9747 Accuracy 0.9976\n",
      "Epoch 193 Batch 800 Loss 1.9633 Accuracy 0.9976\n",
      "Epoch 193 Batch 850 Loss 1.9697 Accuracy 0.9976\n",
      "Epoch 193 Batch 900 Loss 1.9682 Accuracy 0.9976\n",
      "Epoch 193 Batch 950 Loss 1.9713 Accuracy 0.9976\n",
      "Epoch 193 Batch 1000 Loss 1.9711 Accuracy 0.9976\n",
      "Epoch 193 Batch 1050 Loss 1.9635 Accuracy 0.9976\n",
      "Epoch 193 Batch 1100 Loss 1.9639 Accuracy 0.9976\n",
      "Epoch 193 Batch 1150 Loss 1.9587 Accuracy 0.9976\n",
      "Epoch 193 Batch 1200 Loss 1.9694 Accuracy 0.9976\n",
      "Epoch 193 Batch 1250 Loss 1.9647 Accuracy 0.9976\n",
      "Epoch 193 Batch 1300 Loss 1.9672 Accuracy 0.9976\n",
      "Epoch 193 Batch 1350 Loss 1.9629 Accuracy 0.9976\n",
      "Epoch 193 Batch 1400 Loss 1.9655 Accuracy 0.9976\n",
      "Epoch 193 Batch 1450 Loss 1.9610 Accuracy 0.9976\n",
      "Epoch 193 Batch 1500 Loss 1.9604 Accuracy 0.9976\n",
      "Epoch 193 Batch 1550 Loss 1.9617 Accuracy 0.9976\n",
      "Epoch 193 Batch 1600 Loss 1.9633 Accuracy 0.9976\n",
      "Epoch 193 Batch 1650 Loss 1.9661 Accuracy 0.9976\n",
      "Epoch 193 Batch 1700 Loss 1.9701 Accuracy 0.9976\n",
      "Epoch 193 Batch 1750 Loss 1.9667 Accuracy 0.9976\n",
      "Epoch 193 Batch 1800 Loss 1.9680 Accuracy 0.9976\n",
      "Epoch 193 Batch 1850 Loss 1.9631 Accuracy 0.9976\n",
      "Epoch 193 Batch 1900 Loss 1.9602 Accuracy 0.9976\n",
      "Epoch 193 Batch 1950 Loss 1.9534 Accuracy 0.9976\n",
      "Epoch 193 Batch 2000 Loss 1.9589 Accuracy 0.9976\n",
      "Epoch 193 Batch 2050 Loss 1.9634 Accuracy 0.9976\n",
      "Epoch 193 Batch 2100 Loss 1.9625 Accuracy 0.9976\n",
      "Epoch 193 Batch 2150 Loss 1.9645 Accuracy 0.9976\n",
      "Epoch 193 Batch 2200 Loss 1.9670 Accuracy 0.9976\n",
      "Epoch 193 Batch 2250 Loss 1.9699 Accuracy 0.9976\n",
      "Epoch 193 Batch 2300 Loss 1.9677 Accuracy 0.9976\n",
      "Epoch 193 Batch 2350 Loss 1.9676 Accuracy 0.9976\n",
      "Epoch 193 Batch 2400 Loss 1.9700 Accuracy 0.9976\n",
      "Epoch 193 Batch 2450 Loss 1.9713 Accuracy 0.9976\n",
      "Epoch 193 Batch 2500 Loss 1.9726 Accuracy 0.9976\n",
      "Epoch 193 Batch 2550 Loss 1.9731 Accuracy 0.9976\n",
      "Epoch 193 Batch 2600 Loss 1.9720 Accuracy 0.9976\n",
      "Epoch 193 Batch 2650 Loss 1.9711 Accuracy 0.9976\n",
      "Epoch 193 Loss 1.9724 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 214.88651752471924 secs\n",
      "\n",
      "Epoch 194 Batch 0 Loss 1.4170 Accuracy 0.9983\n",
      "Epoch 194 Batch 50 Loss 2.0154 Accuracy 0.9976\n",
      "Epoch 194 Batch 100 Loss 1.9973 Accuracy 0.9976\n",
      "Epoch 194 Batch 150 Loss 2.0106 Accuracy 0.9976\n",
      "Epoch 194 Batch 200 Loss 1.9622 Accuracy 0.9976\n",
      "Epoch 194 Batch 250 Loss 1.9544 Accuracy 0.9976\n",
      "Epoch 194 Batch 300 Loss 1.9552 Accuracy 0.9976\n",
      "Epoch 194 Batch 350 Loss 1.9562 Accuracy 0.9976\n",
      "Epoch 194 Batch 400 Loss 1.9550 Accuracy 0.9976\n",
      "Epoch 194 Batch 450 Loss 1.9779 Accuracy 0.9976\n",
      "Epoch 194 Batch 500 Loss 1.9682 Accuracy 0.9976\n",
      "Epoch 194 Batch 550 Loss 1.9755 Accuracy 0.9976\n",
      "Epoch 194 Batch 600 Loss 1.9871 Accuracy 0.9976\n",
      "Epoch 194 Batch 650 Loss 1.9830 Accuracy 0.9976\n",
      "Epoch 194 Batch 700 Loss 1.9834 Accuracy 0.9976\n",
      "Epoch 194 Batch 750 Loss 1.9846 Accuracy 0.9976\n",
      "Epoch 194 Batch 800 Loss 1.9764 Accuracy 0.9976\n",
      "Epoch 194 Batch 850 Loss 1.9789 Accuracy 0.9976\n",
      "Epoch 194 Batch 900 Loss 1.9785 Accuracy 0.9976\n",
      "Epoch 194 Batch 950 Loss 1.9806 Accuracy 0.9976\n",
      "Epoch 194 Batch 1000 Loss 1.9796 Accuracy 0.9976\n",
      "Epoch 194 Batch 1050 Loss 1.9725 Accuracy 0.9976\n",
      "Epoch 194 Batch 1100 Loss 1.9716 Accuracy 0.9976\n",
      "Epoch 194 Batch 1150 Loss 1.9675 Accuracy 0.9976\n",
      "Epoch 194 Batch 1200 Loss 1.9782 Accuracy 0.9976\n",
      "Epoch 194 Batch 1250 Loss 1.9745 Accuracy 0.9976\n",
      "Epoch 194 Batch 1300 Loss 1.9732 Accuracy 0.9976\n",
      "Epoch 194 Batch 1350 Loss 1.9693 Accuracy 0.9976\n",
      "Epoch 194 Batch 1400 Loss 1.9702 Accuracy 0.9976\n",
      "Epoch 194 Batch 1450 Loss 1.9656 Accuracy 0.9976\n",
      "Epoch 194 Batch 1500 Loss 1.9650 Accuracy 0.9976\n",
      "Epoch 194 Batch 1550 Loss 1.9667 Accuracy 0.9976\n",
      "Epoch 194 Batch 1600 Loss 1.9673 Accuracy 0.9976\n",
      "Epoch 194 Batch 1650 Loss 1.9673 Accuracy 0.9976\n",
      "Epoch 194 Batch 1700 Loss 1.9692 Accuracy 0.9976\n",
      "Epoch 194 Batch 1750 Loss 1.9662 Accuracy 0.9976\n",
      "Epoch 194 Batch 1800 Loss 1.9674 Accuracy 0.9976\n",
      "Epoch 194 Batch 1850 Loss 1.9629 Accuracy 0.9976\n",
      "Epoch 194 Batch 1900 Loss 1.9607 Accuracy 0.9976\n",
      "Epoch 194 Batch 1950 Loss 1.9560 Accuracy 0.9976\n",
      "Epoch 194 Batch 2000 Loss 1.9597 Accuracy 0.9976\n",
      "Epoch 194 Batch 2050 Loss 1.9638 Accuracy 0.9976\n",
      "Epoch 194 Batch 2100 Loss 1.9627 Accuracy 0.9976\n",
      "Epoch 194 Batch 2150 Loss 1.9642 Accuracy 0.9976\n",
      "Epoch 194 Batch 2200 Loss 1.9677 Accuracy 0.9976\n",
      "Epoch 194 Batch 2250 Loss 1.9696 Accuracy 0.9976\n",
      "Epoch 194 Batch 2300 Loss 1.9671 Accuracy 0.9976\n",
      "Epoch 194 Batch 2350 Loss 1.9659 Accuracy 0.9976\n",
      "Epoch 194 Batch 2400 Loss 1.9671 Accuracy 0.9976\n",
      "Epoch 194 Batch 2450 Loss 1.9689 Accuracy 0.9976\n",
      "Epoch 194 Batch 2500 Loss 1.9704 Accuracy 0.9976\n",
      "Epoch 194 Batch 2550 Loss 1.9699 Accuracy 0.9976\n",
      "Epoch 194 Batch 2600 Loss 1.9683 Accuracy 0.9976\n",
      "Epoch 194 Batch 2650 Loss 1.9657 Accuracy 0.9976\n",
      "Epoch 194 Loss 1.9671 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 216.73120307922363 secs\n",
      "\n",
      "Epoch 195 Batch 0 Loss 1.4716 Accuracy 0.9982\n",
      "Epoch 195 Batch 50 Loss 2.0261 Accuracy 0.9975\n",
      "Epoch 195 Batch 100 Loss 2.0095 Accuracy 0.9976\n",
      "Epoch 195 Batch 150 Loss 2.0201 Accuracy 0.9975\n",
      "Epoch 195 Batch 200 Loss 1.9647 Accuracy 0.9976\n",
      "Epoch 195 Batch 250 Loss 1.9560 Accuracy 0.9976\n",
      "Epoch 195 Batch 300 Loss 1.9617 Accuracy 0.9976\n",
      "Epoch 195 Batch 350 Loss 1.9615 Accuracy 0.9976\n",
      "Epoch 195 Batch 400 Loss 1.9554 Accuracy 0.9976\n",
      "Epoch 195 Batch 450 Loss 1.9801 Accuracy 0.9976\n",
      "Epoch 195 Batch 500 Loss 1.9708 Accuracy 0.9976\n",
      "Epoch 195 Batch 550 Loss 1.9805 Accuracy 0.9976\n",
      "Epoch 195 Batch 600 Loss 2.0022 Accuracy 0.9976\n",
      "Epoch 195 Batch 650 Loss 2.0004 Accuracy 0.9976\n",
      "Epoch 195 Batch 700 Loss 1.9973 Accuracy 0.9976\n",
      "Epoch 195 Batch 750 Loss 1.9954 Accuracy 0.9976\n",
      "Epoch 195 Batch 800 Loss 1.9843 Accuracy 0.9976\n",
      "Epoch 195 Batch 850 Loss 1.9887 Accuracy 0.9976\n",
      "Epoch 195 Batch 900 Loss 1.9880 Accuracy 0.9976\n",
      "Epoch 195 Batch 950 Loss 1.9878 Accuracy 0.9976\n",
      "Epoch 195 Batch 1000 Loss 1.9840 Accuracy 0.9976\n",
      "Epoch 195 Batch 1050 Loss 1.9746 Accuracy 0.9976\n",
      "Epoch 195 Batch 1100 Loss 1.9725 Accuracy 0.9976\n",
      "Epoch 195 Batch 1150 Loss 1.9652 Accuracy 0.9976\n",
      "Epoch 195 Batch 1200 Loss 1.9711 Accuracy 0.9976\n",
      "Epoch 195 Batch 1250 Loss 1.9669 Accuracy 0.9976\n",
      "Epoch 195 Batch 1300 Loss 1.9679 Accuracy 0.9976\n",
      "Epoch 195 Batch 1350 Loss 1.9651 Accuracy 0.9976\n",
      "Epoch 195 Batch 1400 Loss 1.9669 Accuracy 0.9976\n",
      "Epoch 195 Batch 1450 Loss 1.9626 Accuracy 0.9976\n",
      "Epoch 195 Batch 1500 Loss 1.9612 Accuracy 0.9976\n",
      "Epoch 195 Batch 1550 Loss 1.9631 Accuracy 0.9976\n",
      "Epoch 195 Batch 1600 Loss 1.9625 Accuracy 0.9976\n",
      "Epoch 195 Batch 1650 Loss 1.9627 Accuracy 0.9976\n",
      "Epoch 195 Batch 1700 Loss 1.9648 Accuracy 0.9976\n",
      "Epoch 195 Batch 1750 Loss 1.9624 Accuracy 0.9976\n",
      "Epoch 195 Batch 1800 Loss 1.9637 Accuracy 0.9976\n",
      "Epoch 195 Batch 1850 Loss 1.9586 Accuracy 0.9976\n",
      "Epoch 195 Batch 1900 Loss 1.9570 Accuracy 0.9976\n",
      "Epoch 195 Batch 1950 Loss 1.9505 Accuracy 0.9976\n",
      "Epoch 195 Batch 2000 Loss 1.9556 Accuracy 0.9976\n",
      "Epoch 195 Batch 2050 Loss 1.9608 Accuracy 0.9976\n",
      "Epoch 195 Batch 2100 Loss 1.9605 Accuracy 0.9976\n",
      "Epoch 195 Batch 2150 Loss 1.9626 Accuracy 0.9976\n",
      "Epoch 195 Batch 2200 Loss 1.9658 Accuracy 0.9976\n",
      "Epoch 195 Batch 2250 Loss 1.9672 Accuracy 0.9976\n",
      "Epoch 195 Batch 2300 Loss 1.9650 Accuracy 0.9976\n",
      "Epoch 195 Batch 2350 Loss 1.9636 Accuracy 0.9976\n",
      "Epoch 195 Batch 2400 Loss 1.9654 Accuracy 0.9976\n",
      "Epoch 195 Batch 2450 Loss 1.9675 Accuracy 0.9976\n",
      "Epoch 195 Batch 2500 Loss 1.9695 Accuracy 0.9976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195 Batch 2550 Loss 1.9695 Accuracy 0.9976\n",
      "Epoch 195 Batch 2600 Loss 1.9677 Accuracy 0.9976\n",
      "Epoch 195 Batch 2650 Loss 1.9663 Accuracy 0.9976\n",
      "Saving checkpoint for epoch 195 at ./checkpoints/train\\ckpt-40\n",
      "Epoch 195 Loss 1.9674 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 214.370591878891 secs\n",
      "\n",
      "Epoch 196 Batch 0 Loss 1.3514 Accuracy 0.9983\n",
      "Epoch 196 Batch 50 Loss 2.0185 Accuracy 0.9976\n",
      "Epoch 196 Batch 100 Loss 2.0217 Accuracy 0.9976\n",
      "Epoch 196 Batch 150 Loss 2.0166 Accuracy 0.9976\n",
      "Epoch 196 Batch 200 Loss 1.9554 Accuracy 0.9977\n",
      "Epoch 196 Batch 250 Loss 1.9493 Accuracy 0.9977\n",
      "Epoch 196 Batch 300 Loss 1.9497 Accuracy 0.9977\n",
      "Epoch 196 Batch 350 Loss 1.9484 Accuracy 0.9977\n",
      "Epoch 196 Batch 400 Loss 1.9464 Accuracy 0.9977\n",
      "Epoch 196 Batch 450 Loss 1.9704 Accuracy 0.9976\n",
      "Epoch 196 Batch 500 Loss 1.9620 Accuracy 0.9976\n",
      "Epoch 196 Batch 550 Loss 1.9742 Accuracy 0.9976\n",
      "Epoch 196 Batch 600 Loss 1.9873 Accuracy 0.9976\n",
      "Epoch 196 Batch 650 Loss 1.9885 Accuracy 0.9976\n",
      "Epoch 196 Batch 700 Loss 1.9837 Accuracy 0.9976\n",
      "Epoch 196 Batch 750 Loss 1.9868 Accuracy 0.9976\n",
      "Epoch 196 Batch 800 Loss 1.9738 Accuracy 0.9976\n",
      "Epoch 196 Batch 850 Loss 1.9767 Accuracy 0.9976\n",
      "Epoch 196 Batch 900 Loss 1.9769 Accuracy 0.9976\n",
      "Epoch 196 Batch 950 Loss 1.9810 Accuracy 0.9976\n",
      "Epoch 196 Batch 1000 Loss 1.9779 Accuracy 0.9976\n",
      "Epoch 196 Batch 1050 Loss 1.9697 Accuracy 0.9976\n",
      "Epoch 196 Batch 1100 Loss 1.9665 Accuracy 0.9976\n",
      "Epoch 196 Batch 1150 Loss 1.9600 Accuracy 0.9976\n",
      "Epoch 196 Batch 1200 Loss 1.9684 Accuracy 0.9976\n",
      "Epoch 196 Batch 1250 Loss 1.9652 Accuracy 0.9976\n",
      "Epoch 196 Batch 1300 Loss 1.9678 Accuracy 0.9976\n",
      "Epoch 196 Batch 1350 Loss 1.9647 Accuracy 0.9976\n",
      "Epoch 196 Batch 1400 Loss 1.9666 Accuracy 0.9976\n",
      "Epoch 196 Batch 1450 Loss 1.9632 Accuracy 0.9976\n",
      "Epoch 196 Batch 1500 Loss 1.9624 Accuracy 0.9976\n",
      "Epoch 196 Batch 1550 Loss 1.9627 Accuracy 0.9976\n",
      "Epoch 196 Batch 1600 Loss 1.9634 Accuracy 0.9976\n",
      "Epoch 196 Batch 1650 Loss 1.9633 Accuracy 0.9976\n",
      "Epoch 196 Batch 1700 Loss 1.9659 Accuracy 0.9976\n",
      "Epoch 196 Batch 1750 Loss 1.9617 Accuracy 0.9976\n",
      "Epoch 196 Batch 1800 Loss 1.9633 Accuracy 0.9976\n",
      "Epoch 196 Batch 1850 Loss 1.9597 Accuracy 0.9976\n",
      "Epoch 196 Batch 1900 Loss 1.9576 Accuracy 0.9976\n",
      "Epoch 196 Batch 1950 Loss 1.9519 Accuracy 0.9977\n",
      "Epoch 196 Batch 2000 Loss 1.9550 Accuracy 0.9976\n",
      "Epoch 196 Batch 2050 Loss 1.9590 Accuracy 0.9976\n",
      "Epoch 196 Batch 2100 Loss 1.9566 Accuracy 0.9976\n",
      "Epoch 196 Batch 2150 Loss 1.9576 Accuracy 0.9976\n",
      "Epoch 196 Batch 2200 Loss 1.9616 Accuracy 0.9976\n",
      "Epoch 196 Batch 2250 Loss 1.9636 Accuracy 0.9976\n",
      "Epoch 196 Batch 2300 Loss 1.9619 Accuracy 0.9976\n",
      "Epoch 196 Batch 2350 Loss 1.9624 Accuracy 0.9976\n",
      "Epoch 196 Batch 2400 Loss 1.9644 Accuracy 0.9976\n",
      "Epoch 196 Batch 2450 Loss 1.9666 Accuracy 0.9976\n",
      "Epoch 196 Batch 2500 Loss 1.9679 Accuracy 0.9976\n",
      "Epoch 196 Batch 2550 Loss 1.9679 Accuracy 0.9976\n",
      "Epoch 196 Batch 2600 Loss 1.9670 Accuracy 0.9976\n",
      "Epoch 196 Batch 2650 Loss 1.9656 Accuracy 0.9976\n",
      "Epoch 196 Loss 1.9664 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 215.66409635543823 secs\n",
      "\n",
      "Epoch 197 Batch 0 Loss 1.4139 Accuracy 0.9984\n",
      "Epoch 197 Batch 50 Loss 1.9448 Accuracy 0.9976\n",
      "Epoch 197 Batch 100 Loss 1.9811 Accuracy 0.9976\n",
      "Epoch 197 Batch 150 Loss 2.0097 Accuracy 0.9975\n",
      "Epoch 197 Batch 200 Loss 1.9569 Accuracy 0.9976\n",
      "Epoch 197 Batch 250 Loss 1.9432 Accuracy 0.9976\n",
      "Epoch 197 Batch 300 Loss 1.9467 Accuracy 0.9976\n",
      "Epoch 197 Batch 350 Loss 1.9522 Accuracy 0.9976\n",
      "Epoch 197 Batch 400 Loss 1.9413 Accuracy 0.9976\n",
      "Epoch 197 Batch 450 Loss 1.9672 Accuracy 0.9976\n",
      "Epoch 197 Batch 500 Loss 1.9609 Accuracy 0.9976\n",
      "Epoch 197 Batch 550 Loss 1.9753 Accuracy 0.9976\n",
      "Epoch 197 Batch 600 Loss 1.9858 Accuracy 0.9976\n",
      "Epoch 197 Batch 650 Loss 1.9802 Accuracy 0.9976\n",
      "Epoch 197 Batch 700 Loss 1.9826 Accuracy 0.9976\n",
      "Epoch 197 Batch 750 Loss 1.9826 Accuracy 0.9976\n",
      "Epoch 197 Batch 800 Loss 1.9732 Accuracy 0.9976\n",
      "Epoch 197 Batch 850 Loss 1.9792 Accuracy 0.9976\n",
      "Epoch 197 Batch 900 Loss 1.9798 Accuracy 0.9976\n",
      "Epoch 197 Batch 950 Loss 1.9807 Accuracy 0.9976\n",
      "Epoch 197 Batch 1000 Loss 1.9779 Accuracy 0.9976\n",
      "Epoch 197 Batch 1050 Loss 1.9707 Accuracy 0.9976\n",
      "Epoch 197 Batch 1100 Loss 1.9700 Accuracy 0.9976\n",
      "Epoch 197 Batch 1150 Loss 1.9614 Accuracy 0.9976\n",
      "Epoch 197 Batch 1200 Loss 1.9697 Accuracy 0.9976\n",
      "Epoch 197 Batch 1250 Loss 1.9667 Accuracy 0.9976\n",
      "Epoch 197 Batch 1300 Loss 1.9660 Accuracy 0.9976\n",
      "Epoch 197 Batch 1350 Loss 1.9606 Accuracy 0.9976\n",
      "Epoch 197 Batch 1400 Loss 1.9632 Accuracy 0.9976\n",
      "Epoch 197 Batch 1450 Loss 1.9587 Accuracy 0.9976\n",
      "Epoch 197 Batch 1500 Loss 1.9592 Accuracy 0.9976\n",
      "Epoch 197 Batch 1550 Loss 1.9619 Accuracy 0.9976\n",
      "Epoch 197 Batch 1600 Loss 1.9618 Accuracy 0.9976\n",
      "Epoch 197 Batch 1650 Loss 1.9626 Accuracy 0.9976\n",
      "Epoch 197 Batch 1700 Loss 1.9634 Accuracy 0.9976\n",
      "Epoch 197 Batch 1750 Loss 1.9599 Accuracy 0.9976\n",
      "Epoch 197 Batch 1800 Loss 1.9608 Accuracy 0.9976\n",
      "Epoch 197 Batch 1850 Loss 1.9563 Accuracy 0.9976\n",
      "Epoch 197 Batch 1900 Loss 1.9531 Accuracy 0.9976\n",
      "Epoch 197 Batch 1950 Loss 1.9467 Accuracy 0.9977\n",
      "Epoch 197 Batch 2000 Loss 1.9505 Accuracy 0.9976\n",
      "Epoch 197 Batch 2050 Loss 1.9550 Accuracy 0.9976\n",
      "Epoch 197 Batch 2100 Loss 1.9533 Accuracy 0.9976\n",
      "Epoch 197 Batch 2150 Loss 1.9553 Accuracy 0.9976\n",
      "Epoch 197 Batch 2200 Loss 1.9604 Accuracy 0.9976\n",
      "Epoch 197 Batch 2250 Loss 1.9619 Accuracy 0.9976\n",
      "Epoch 197 Batch 2300 Loss 1.9587 Accuracy 0.9976\n",
      "Epoch 197 Batch 2350 Loss 1.9590 Accuracy 0.9976\n",
      "Epoch 197 Batch 2400 Loss 1.9597 Accuracy 0.9976\n",
      "Epoch 197 Batch 2450 Loss 1.9615 Accuracy 0.9976\n",
      "Epoch 197 Batch 2500 Loss 1.9622 Accuracy 0.9976\n",
      "Epoch 197 Batch 2550 Loss 1.9601 Accuracy 0.9976\n",
      "Epoch 197 Batch 2600 Loss 1.9577 Accuracy 0.9976\n",
      "Epoch 197 Batch 2650 Loss 1.9564 Accuracy 0.9976\n",
      "Epoch 197 Loss 1.9579 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 228.91651320457458 secs\n",
      "\n",
      "Epoch 198 Batch 0 Loss 1.2732 Accuracy 0.9982\n",
      "Epoch 198 Batch 50 Loss 1.9879 Accuracy 0.9976\n",
      "Epoch 198 Batch 100 Loss 1.9622 Accuracy 0.9976\n",
      "Epoch 198 Batch 150 Loss 1.9826 Accuracy 0.9976\n",
      "Epoch 198 Batch 200 Loss 1.9415 Accuracy 0.9976\n",
      "Epoch 198 Batch 250 Loss 1.9288 Accuracy 0.9977\n",
      "Epoch 198 Batch 300 Loss 1.9314 Accuracy 0.9977\n",
      "Epoch 198 Batch 350 Loss 1.9290 Accuracy 0.9977\n",
      "Epoch 198 Batch 400 Loss 1.9346 Accuracy 0.9977\n",
      "Epoch 198 Batch 450 Loss 1.9544 Accuracy 0.9976\n",
      "Epoch 198 Batch 500 Loss 1.9432 Accuracy 0.9976\n",
      "Epoch 198 Batch 550 Loss 1.9529 Accuracy 0.9976\n",
      "Epoch 198 Batch 600 Loss 1.9656 Accuracy 0.9976\n",
      "Epoch 198 Batch 650 Loss 1.9676 Accuracy 0.9976\n",
      "Epoch 198 Batch 700 Loss 1.9673 Accuracy 0.9976\n",
      "Epoch 198 Batch 750 Loss 1.9691 Accuracy 0.9976\n",
      "Epoch 198 Batch 800 Loss 1.9603 Accuracy 0.9976\n",
      "Epoch 198 Batch 850 Loss 1.9672 Accuracy 0.9976\n",
      "Epoch 198 Batch 900 Loss 1.9673 Accuracy 0.9976\n",
      "Epoch 198 Batch 950 Loss 1.9690 Accuracy 0.9976\n",
      "Epoch 198 Batch 1000 Loss 1.9677 Accuracy 0.9976\n",
      "Epoch 198 Batch 1050 Loss 1.9588 Accuracy 0.9976\n",
      "Epoch 198 Batch 1100 Loss 1.9575 Accuracy 0.9976\n",
      "Epoch 198 Batch 1150 Loss 1.9515 Accuracy 0.9976\n",
      "Epoch 198 Batch 1200 Loss 1.9605 Accuracy 0.9976\n",
      "Epoch 198 Batch 1250 Loss 1.9575 Accuracy 0.9976\n",
      "Epoch 198 Batch 1300 Loss 1.9583 Accuracy 0.9976\n",
      "Epoch 198 Batch 1350 Loss 1.9544 Accuracy 0.9976\n",
      "Epoch 198 Batch 1400 Loss 1.9560 Accuracy 0.9976\n",
      "Epoch 198 Batch 1450 Loss 1.9526 Accuracy 0.9976\n",
      "Epoch 198 Batch 1500 Loss 1.9525 Accuracy 0.9976\n",
      "Epoch 198 Batch 1550 Loss 1.9538 Accuracy 0.9976\n",
      "Epoch 198 Batch 1600 Loss 1.9546 Accuracy 0.9976\n",
      "Epoch 198 Batch 1650 Loss 1.9560 Accuracy 0.9976\n",
      "Epoch 198 Batch 1700 Loss 1.9579 Accuracy 0.9976\n",
      "Epoch 198 Batch 1750 Loss 1.9541 Accuracy 0.9976\n",
      "Epoch 198 Batch 1800 Loss 1.9557 Accuracy 0.9976\n",
      "Epoch 198 Batch 1850 Loss 1.9515 Accuracy 0.9976\n",
      "Epoch 198 Batch 1900 Loss 1.9492 Accuracy 0.9977\n",
      "Epoch 198 Batch 1950 Loss 1.9437 Accuracy 0.9977\n",
      "Epoch 198 Batch 2000 Loss 1.9474 Accuracy 0.9977\n",
      "Epoch 198 Batch 2050 Loss 1.9515 Accuracy 0.9976\n",
      "Epoch 198 Batch 2100 Loss 1.9508 Accuracy 0.9976\n",
      "Epoch 198 Batch 2150 Loss 1.9520 Accuracy 0.9976\n",
      "Epoch 198 Batch 2200 Loss 1.9554 Accuracy 0.9976\n",
      "Epoch 198 Batch 2250 Loss 1.9579 Accuracy 0.9976\n",
      "Epoch 198 Batch 2300 Loss 1.9544 Accuracy 0.9976\n",
      "Epoch 198 Batch 2350 Loss 1.9537 Accuracy 0.9976\n",
      "Epoch 198 Batch 2400 Loss 1.9550 Accuracy 0.9976\n",
      "Epoch 198 Batch 2450 Loss 1.9567 Accuracy 0.9976\n",
      "Epoch 198 Batch 2500 Loss 1.9582 Accuracy 0.9976\n",
      "Epoch 198 Batch 2550 Loss 1.9575 Accuracy 0.9976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198 Batch 2600 Loss 1.9564 Accuracy 0.9976\n",
      "Epoch 198 Batch 2650 Loss 1.9545 Accuracy 0.9976\n",
      "Epoch 198 Loss 1.9568 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 212.33452129364014 secs\n",
      "\n",
      "Epoch 199 Batch 0 Loss 1.4707 Accuracy 0.9981\n",
      "Epoch 199 Batch 50 Loss 1.9279 Accuracy 0.9977\n",
      "Epoch 199 Batch 100 Loss 1.9339 Accuracy 0.9977\n",
      "Epoch 199 Batch 150 Loss 1.9592 Accuracy 0.9976\n",
      "Epoch 199 Batch 200 Loss 1.9228 Accuracy 0.9977\n",
      "Epoch 199 Batch 250 Loss 1.9210 Accuracy 0.9977\n",
      "Epoch 199 Batch 300 Loss 1.9277 Accuracy 0.9977\n",
      "Epoch 199 Batch 350 Loss 1.9202 Accuracy 0.9977\n",
      "Epoch 199 Batch 400 Loss 1.9216 Accuracy 0.9977\n",
      "Epoch 199 Batch 450 Loss 1.9427 Accuracy 0.9977\n",
      "Epoch 199 Batch 500 Loss 1.9346 Accuracy 0.9977\n",
      "Epoch 199 Batch 550 Loss 1.9518 Accuracy 0.9977\n",
      "Epoch 199 Batch 600 Loss 1.9597 Accuracy 0.9976\n",
      "Epoch 199 Batch 650 Loss 1.9596 Accuracy 0.9976\n",
      "Epoch 199 Batch 700 Loss 1.9599 Accuracy 0.9976\n",
      "Epoch 199 Batch 750 Loss 1.9606 Accuracy 0.9976\n",
      "Epoch 199 Batch 800 Loss 1.9518 Accuracy 0.9977\n",
      "Epoch 199 Batch 850 Loss 1.9569 Accuracy 0.9976\n",
      "Epoch 199 Batch 900 Loss 1.9569 Accuracy 0.9976\n",
      "Epoch 199 Batch 950 Loss 1.9614 Accuracy 0.9976\n",
      "Epoch 199 Batch 1000 Loss 1.9605 Accuracy 0.9976\n",
      "Epoch 199 Batch 1050 Loss 1.9553 Accuracy 0.9976\n",
      "Epoch 199 Batch 1100 Loss 1.9539 Accuracy 0.9977\n",
      "Epoch 199 Batch 1150 Loss 1.9481 Accuracy 0.9977\n",
      "Epoch 199 Batch 1200 Loss 1.9567 Accuracy 0.9976\n",
      "Epoch 199 Batch 1250 Loss 1.9540 Accuracy 0.9977\n",
      "Epoch 199 Batch 1300 Loss 1.9555 Accuracy 0.9976\n",
      "Epoch 199 Batch 1350 Loss 1.9539 Accuracy 0.9977\n",
      "Epoch 199 Batch 1400 Loss 1.9559 Accuracy 0.9976\n",
      "Epoch 199 Batch 1450 Loss 1.9516 Accuracy 0.9977\n",
      "Epoch 199 Batch 1500 Loss 1.9491 Accuracy 0.9977\n",
      "Epoch 199 Batch 1550 Loss 1.9500 Accuracy 0.9977\n",
      "Epoch 199 Batch 1600 Loss 1.9515 Accuracy 0.9977\n",
      "Epoch 199 Batch 1650 Loss 1.9536 Accuracy 0.9976\n",
      "Epoch 199 Batch 1700 Loss 1.9550 Accuracy 0.9976\n",
      "Epoch 199 Batch 1750 Loss 1.9519 Accuracy 0.9977\n",
      "Epoch 199 Batch 1800 Loss 1.9519 Accuracy 0.9977\n",
      "Epoch 199 Batch 1850 Loss 1.9464 Accuracy 0.9977\n",
      "Epoch 199 Batch 1900 Loss 1.9437 Accuracy 0.9977\n",
      "Epoch 199 Batch 1950 Loss 1.9380 Accuracy 0.9977\n",
      "Epoch 199 Batch 2000 Loss 1.9423 Accuracy 0.9977\n",
      "Epoch 199 Batch 2050 Loss 1.9462 Accuracy 0.9977\n",
      "Epoch 199 Batch 2100 Loss 1.9462 Accuracy 0.9977\n",
      "Epoch 199 Batch 2150 Loss 1.9469 Accuracy 0.9977\n",
      "Epoch 199 Batch 2200 Loss 1.9518 Accuracy 0.9977\n",
      "Epoch 199 Batch 2250 Loss 1.9535 Accuracy 0.9976\n",
      "Epoch 199 Batch 2300 Loss 1.9517 Accuracy 0.9977\n",
      "Epoch 199 Batch 2350 Loss 1.9517 Accuracy 0.9977\n",
      "Epoch 199 Batch 2400 Loss 1.9541 Accuracy 0.9976\n",
      "Epoch 199 Batch 2450 Loss 1.9549 Accuracy 0.9976\n",
      "Epoch 199 Batch 2500 Loss 1.9568 Accuracy 0.9976\n",
      "Epoch 199 Batch 2550 Loss 1.9561 Accuracy 0.9976\n",
      "Epoch 199 Batch 2600 Loss 1.9556 Accuracy 0.9976\n",
      "Epoch 199 Batch 2650 Loss 1.9542 Accuracy 0.9976\n",
      "Epoch 199 Loss 1.9550 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 200.54700136184692 secs\n",
      "\n",
      "Epoch 200 Batch 0 Loss 1.6623 Accuracy 0.9981\n",
      "Epoch 200 Batch 50 Loss 2.0298 Accuracy 0.9975\n",
      "Epoch 200 Batch 100 Loss 2.0149 Accuracy 0.9976\n",
      "Epoch 200 Batch 150 Loss 2.0061 Accuracy 0.9976\n",
      "Epoch 200 Batch 200 Loss 1.9532 Accuracy 0.9976\n",
      "Epoch 200 Batch 250 Loss 1.9445 Accuracy 0.9976\n",
      "Epoch 200 Batch 300 Loss 1.9452 Accuracy 0.9976\n",
      "Epoch 200 Batch 350 Loss 1.9452 Accuracy 0.9977\n",
      "Epoch 200 Batch 400 Loss 1.9419 Accuracy 0.9976\n",
      "Epoch 200 Batch 450 Loss 1.9667 Accuracy 0.9976\n",
      "Epoch 200 Batch 500 Loss 1.9602 Accuracy 0.9976\n",
      "Epoch 200 Batch 550 Loss 1.9694 Accuracy 0.9976\n",
      "Epoch 200 Batch 600 Loss 1.9813 Accuracy 0.9976\n",
      "Epoch 200 Batch 650 Loss 1.9809 Accuracy 0.9976\n",
      "Epoch 200 Batch 700 Loss 1.9774 Accuracy 0.9976\n",
      "Epoch 200 Batch 750 Loss 1.9765 Accuracy 0.9976\n",
      "Epoch 200 Batch 800 Loss 1.9651 Accuracy 0.9976\n",
      "Epoch 200 Batch 850 Loss 1.9692 Accuracy 0.9976\n",
      "Epoch 200 Batch 900 Loss 1.9659 Accuracy 0.9976\n",
      "Epoch 200 Batch 950 Loss 1.9685 Accuracy 0.9976\n",
      "Epoch 200 Batch 1000 Loss 1.9657 Accuracy 0.9976\n",
      "Epoch 200 Batch 1050 Loss 1.9562 Accuracy 0.9976\n",
      "Epoch 200 Batch 1100 Loss 1.9554 Accuracy 0.9976\n",
      "Epoch 200 Batch 1150 Loss 1.9485 Accuracy 0.9976\n",
      "Epoch 200 Batch 1200 Loss 1.9561 Accuracy 0.9976\n",
      "Epoch 200 Batch 1250 Loss 1.9513 Accuracy 0.9976\n",
      "Epoch 200 Batch 1300 Loss 1.9514 Accuracy 0.9976\n",
      "Epoch 200 Batch 1350 Loss 1.9470 Accuracy 0.9976\n",
      "Epoch 200 Batch 1400 Loss 1.9475 Accuracy 0.9976\n",
      "Epoch 200 Batch 1450 Loss 1.9437 Accuracy 0.9977\n",
      "Epoch 200 Batch 1500 Loss 1.9446 Accuracy 0.9977\n",
      "Epoch 200 Batch 1550 Loss 1.9457 Accuracy 0.9977\n",
      "Epoch 200 Batch 1600 Loss 1.9469 Accuracy 0.9976\n",
      "Epoch 200 Batch 1650 Loss 1.9475 Accuracy 0.9976\n",
      "Epoch 200 Batch 1700 Loss 1.9491 Accuracy 0.9976\n",
      "Epoch 200 Batch 1750 Loss 1.9460 Accuracy 0.9976\n",
      "Epoch 200 Batch 1800 Loss 1.9476 Accuracy 0.9976\n",
      "Epoch 200 Batch 1850 Loss 1.9435 Accuracy 0.9977\n",
      "Epoch 200 Batch 1900 Loss 1.9415 Accuracy 0.9977\n",
      "Epoch 200 Batch 1950 Loss 1.9359 Accuracy 0.9977\n",
      "Epoch 200 Batch 2000 Loss 1.9393 Accuracy 0.9977\n",
      "Epoch 200 Batch 2050 Loss 1.9433 Accuracy 0.9977\n",
      "Epoch 200 Batch 2100 Loss 1.9429 Accuracy 0.9977\n",
      "Epoch 200 Batch 2150 Loss 1.9452 Accuracy 0.9977\n",
      "Epoch 200 Batch 2200 Loss 1.9493 Accuracy 0.9976\n",
      "Epoch 200 Batch 2250 Loss 1.9517 Accuracy 0.9976\n",
      "Epoch 200 Batch 2300 Loss 1.9487 Accuracy 0.9976\n",
      "Epoch 200 Batch 2350 Loss 1.9489 Accuracy 0.9976\n",
      "Epoch 200 Batch 2400 Loss 1.9506 Accuracy 0.9976\n",
      "Epoch 200 Batch 2450 Loss 1.9514 Accuracy 0.9976\n",
      "Epoch 200 Batch 2500 Loss 1.9533 Accuracy 0.9976\n",
      "Epoch 200 Batch 2550 Loss 1.9531 Accuracy 0.9976\n",
      "Epoch 200 Batch 2600 Loss 1.9508 Accuracy 0.9976\n",
      "Epoch 200 Batch 2650 Loss 1.9492 Accuracy 0.9976\n",
      "Saving checkpoint for epoch 200 at ./checkpoints/train\\ckpt-41\n",
      "Epoch 200 Loss 1.9500 Accuracy 0.9976\n",
      "Time taken for 1 epoch: 200.47104835510254 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "  \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "  \n",
    "    # inp -> portuguese, tar -> english\n",
    "    #for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    #    train_step(inp, tar)\n",
    "    for i in range(DATASET_SIZE):\n",
    "        train_step(encoderRolls[i], decoderRolls[i])\n",
    "        \n",
    "    \n",
    "        if i % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "                    epoch + 1, i, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next section will generate piano pieces!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeData(prediction):\n",
    "    proto_tensor_output = tf.make_tensor_proto(prediction)\n",
    "    prediction = tf.make_ndarray(proto_tensor_output)\n",
    "    \n",
    "    minElement = prediction.min()\n",
    "    maxElement = prediction.max()\n",
    "\n",
    "    normVector = np.full((len(prediction)), minElement)\n",
    "    \n",
    "    return (prediction - normVector) / ( maxElement - minElement )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertProbabilitiesToActualPianoRoll(decodedPianoRoll):\n",
    "    pianoRoll = np.where(decodedPianoRoll<0.5, decodedPianoRoll, 1)\n",
    "    pianoRoll = np.where(pianoRoll>0.5, pianoRoll, 0)\n",
    "    return pianoRoll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sequence, seed):\n",
    "    start_token = np.full((d_model), 0)\n",
    "    end_token = np.full((1, d_model), 0)\n",
    "  \n",
    "    #inp_sequence = np.insert(inp_sequence, 0, start_token, axis = 0)\n",
    "    #inp_sequence = np.append(inp_sequence, end_token, axis = 0)\n",
    "    encoder_input = tf.expand_dims(inp_sequence, 0)\n",
    "    print(inp_sequence.shape)\n",
    "    #encoder_input = inp_sequence\n",
    "  \n",
    "    #decoder_input = seed\n",
    "    decoder_input = np.full((1, d_model), 0)\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    print(output.shape)\n",
    "    #output = decoder_input\n",
    "    \n",
    "    for i in range(seq_length + 10):\n",
    "        look_ahead_mask = create_masks(output)\n",
    "  \n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     None,\n",
    "                                                     look_ahead_mask,\n",
    "                                                     None)\n",
    "\n",
    "        # select the last time-step from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "        \n",
    "        #Normalizing to squeeze in between 0 and 1\n",
    "        #predictions = normalizeData(predictions)\n",
    "        \n",
    "        #MAYBE REMOVE THIS PART?\n",
    "        #Converting the most probable predictions to values of 1 and most unlikely to 0\n",
    "        #predictions = convertProbabilitiesToActualPianoRoll(predictions)\n",
    "\n",
    "        # concatentate the prediction the output which is given to the decoder as its input.\n",
    "        output = tf.cast(output, tf.float32)\n",
    "        output = tf.concat([output, predictions], axis=1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateSongAtIndex(index):\n",
    "    inp_sequence = VALIDATION[index]\n",
    "    inp_sequence = tf.cast(inp_sequence, tf.float32)\n",
    "    seed = decoderRolls[index,:20,:]\n",
    "    output, _ = evaluate(inp_sequence, seed)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToPianoRoll(output):\n",
    "    proto_tensor = tf.make_tensor_proto(output)\n",
    "    ndarray = tf.make_ndarray(proto_tensor)\n",
    "    \n",
    "    #for i in range(len(ndarray)):\n",
    "    #    print(ndarray[i])\n",
    "    \n",
    "    piano_roll = convertProbabilitiesToActualPianoRoll(ndarray)\n",
    "    \n",
    "    piano_roll = piano_roll * 100\n",
    "    \n",
    "    #for i in range(len(piano_roll)):\n",
    "    #    print(piano_roll[i])\n",
    "    \n",
    "    pianoRoll = reshape(piano_roll)\n",
    "    \n",
    "    return pianoRoll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveToMIDI(pianoRoll, index):\n",
    "    pm = piano_roll_to_pretty_midi(pianoRoll, 10, 0)\n",
    "    pm.write(pathToSave + \"\\\\Transformer\" + \"_output_AP\" + str(index) + \".mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 128)\n",
      "(1, 1, 128)\n"
     ]
    }
   ],
   "source": [
    "output = evaluateSongAtIndex(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "pianoRoll = convertToPianoRoll(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveToMIDI(pianoRoll, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOLLOWING SECTION IS SANDBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 5.27022758e-06 1.31755684e-07 4.94083849e-07\n",
      " 7.08186826e-06 7.18068532e-06 4.05148739e-06 7.12139517e-05\n",
      " 7.29267776e-05 4.19312491e-05 1.75903726e-03 7.52950844e-04\n",
      " 7.11480743e-06 8.72367620e-03 1.54285910e-04 3.65786749e-04\n",
      " 4.59507853e-03 3.15131284e-02 3.90227418e-04 1.00430778e-04\n",
      " 4.80331853e-03 4.53239591e-05 3.80918873e-03 4.34365560e-04\n",
      " 1.13606344e-04 1.83741543e-02 4.78931936e-03 1.31119313e-02\n",
      " 1.07576512e-01 1.00000000e+00 1.62813794e-02 8.89548566e-04\n",
      " 1.20165870e-01 7.19830766e-03 2.12351307e-02 1.65120848e-02\n",
      " 2.69054994e-03 1.09652681e-02 1.86691228e-02 4.91112098e-02\n",
      " 1.87873736e-03 1.04462236e-01 1.45398988e-03 1.37562817e-03\n",
      " 2.31610596e-01 2.04694644e-02 4.41570953e-02 3.92043710e-01\n",
      " 5.17753744e-03 4.70721722e-01 6.16595894e-02 4.62970138e-01\n",
      " 6.10490665e-02 4.31512743e-02 1.94741494e-03 5.01132745e-04\n",
      " 6.79796785e-02 9.33950185e-04 4.20491677e-03 7.54008163e-03\n",
      " 1.91704530e-05 3.94296683e-02 2.34195741e-05 2.67991069e-04\n",
      " 6.58119679e-05 2.12456052e-05 2.23984680e-05 1.33732028e-05\n",
      " 2.88544961e-05 6.02782302e-06 4.06795698e-05 4.23594538e-05\n",
      " 1.28461795e-06 3.07386013e-04 2.30572454e-07 2.04880107e-05\n",
      " 4.31499893e-06 1.28461795e-06 2.63511379e-06 2.10809094e-06\n",
      " 1.48225149e-06 1.11992335e-06 1.31755684e-07 2.96450310e-07\n",
      " 1.97633540e-07 1.31755684e-07 9.88167699e-08 6.58778418e-08\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "arr = [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    " 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    " 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    " 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    " 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    " 0.00000000e+00, 5.27022758e-06, 1.31755684e-07, 4.94083849e-07,\n",
    " 7.08186826e-06, 7.18068532e-06, 4.05148739e-06, 7.12139517e-05,\n",
    " 7.29267776e-05, 4.19312491e-05, 1.75903726e-03, 7.52950844e-04,\n",
    " 7.11480743e-06, 8.72367620e-03, 1.54285910e-04, 3.65786749e-04,\n",
    " 4.59507853e-03, 3.15131284e-02, 3.90227418e-04, 1.00430778e-04,\n",
    " 4.80331853e-03, 4.53239591e-05, 3.80918873e-03, 4.34365560e-04,\n",
    " 1.13606344e-04, 1.83741543e-02, 4.78931936e-03, 1.31119313e-02,\n",
    " 1.07576512e-01, 1.00000000e+00, 1.62813794e-02, 8.89548566e-04,\n",
    " 1.20165870e-01, 7.19830766e-03, 2.12351307e-02, 1.65120848e-02,\n",
    " 2.69054994e-03, 1.09652681e-02, 1.86691228e-02, 4.91112098e-02,\n",
    " 1.87873736e-03, 1.04462236e-01, 1.45398988e-03, 1.37562817e-03,\n",
    " 2.31610596e-01, 2.04694644e-02, 4.41570953e-02, 3.92043710e-01,\n",
    " 5.17753744e-03, 4.70721722e-01, 6.16595894e-02, 4.62970138e-01,\n",
    " 6.10490665e-02, 4.31512743e-02, 1.94741494e-03, 5.01132745e-04,\n",
    " 6.79796785e-02, 9.33950185e-04, 4.20491677e-03, 7.54008163e-03,\n",
    " 1.91704530e-05, 3.94296683e-02, 2.34195741e-05, 2.67991069e-04,\n",
    " 6.58119679e-05, 2.12456052e-05, 2.23984680e-05, 1.33732028e-05,\n",
    " 2.88544961e-05, 6.02782302e-06, 4.06795698e-05, 4.23594538e-05,\n",
    " 1.28461795e-06, 3.07386013e-04, 2.30572454e-07, 2.04880107e-05,\n",
    " 4.31499893e-06, 1.28461795e-06, 2.63511379e-06, 2.10809094e-06,\n",
    " 1.48225149e-06, 1.11992335e-06, 1.31755684e-07, 2.96450310e-07,\n",
    " 1.97633540e-07, 1.31755684e-07, 9.88167699e-08, 6.58778418e-08,\n",
    " 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    " 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    " 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    " 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    " 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]\n",
    "test = normalizeData(arr)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "inp_sequence = encoderRolls[0]\n",
    "inp_sequence = tf.cast(inp_sequence, tf.float32)\n",
    "\n",
    "print(inp_sequence[198])\n",
    "print(inp_sequence.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 128)\n"
     ]
    }
   ],
   "source": [
    "seed = decoderRolls[0,:20,:]\n",
    "print(seed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 128)\n",
      "(1, 20, 128)\n"
     ]
    }
   ],
   "source": [
    "output, _ = evaluate(inp_sequence, seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 128)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)\n",
    "for i in range(output.shape[1]):\n",
    "    print(output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove values from `X` in interval (lo, hi)\n",
    "#mask = tf.math.less(output, 0.5)\n",
    "#test = tf.boolean_mask(output, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_tensor_output = tf.make_tensor_proto(output)\n",
    "ndarray_output = tf.make_ndarray(proto_tensor_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "piano_roll_output = piano_roll_output * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "piano_roll_output = convertProbabilitiesToActualPianoRoll(ndarray_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "piano_roll_output = piano_roll_output * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 128)\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0. 100.   0. 100.   0.   0. 100.   0.   0.   0.   0.   0. 100.   0.\n",
      "   0.   0.   0.   0. 100.   0. 100.   0.   0.   0.   0. 100.   0.   0.\n",
      " 100.   0.   0.   0. 100.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "print(piano_roll_output.shape)\n",
    "print(piano_roll_output[101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 320)\n"
     ]
    }
   ],
   "source": [
    "#Reshaping to become an actual pianoRoll\n",
    "pianoRoll_output = reshape(piano_roll_output)\n",
    "print(pianoRoll_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to midi\n",
    "pm_output = piano_roll_to_pretty_midi(pianoRoll_output, 10, 0)\n",
    "pm_output.write(pathToSave + \"\\\\Transformer\" + \"_output\" + str(1) + \".mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_tensor_input = tf.make_tensor_proto(decoderRolls[1])\n",
    "ndarray_input = tf.make_ndarray(proto_tensor_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "piano_roll_input = convertProbabilitiesToActualPianoRoll(ndarray_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "piano_roll_input = piano_roll_input * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 302)\n"
     ]
    }
   ],
   "source": [
    "#Reshaping to become an actual pianoRoll\n",
    "pianoRoll_input = reshape(piano_roll_input)\n",
    "print(pianoRoll_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to midi\n",
    "pm_input = piano_roll_to_pretty_midi(pianoRoll_input, 10, 0)\n",
    "pm_input.write(pathToSave + \"\\\\Transformer\" + \"_input\" + str(1) + \".mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sequence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "    #sentence = tokenizer_pt.encode(sentence)\n",
    "  \n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "    \n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sequence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                            if i < tokenizer_en.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_ahead_mask = create_look_ahead_mask(302)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 1. 1. ... 1. 1. 1.]\n",
      " [0. 0. 1. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(302, 302), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(look_ahead_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
